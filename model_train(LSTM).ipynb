{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8050e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import requests\n",
    "import urllib\n",
    "import urllib.request\n",
    "import datetime\n",
    "import folium\n",
    "import warnings\n",
    "import lightgbm\n",
    "import xgboost\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76d98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pum = [\n",
    "    '배추', '무', '양파', '건고추','마늘',\n",
    "    '대파', '얼갈이배추', '양배추', '깻잎',\n",
    "    '시금치', '미나리', '당근',\n",
    "    '파프리카', '새송이', '팽이버섯', '토마토',\n",
    "]\n",
    "\n",
    "unique_kind = [\n",
    "    '청상추', '백다다기', '애호박', '캠벨얼리', '샤인마스캇'\n",
    "]\n",
    "\n",
    "a = ['토마토']\n",
    "code_dict={\n",
    "    '전라남도 해남군': '536824B002',\n",
    "    '제주도 제주시': '063057B009',\n",
    "    '전라남도 무안군': '534833E001',\n",
    "    '전남 해남군': '536824B002',\n",
    "    '경상남도 창녕군': '635821A001',\n",
    "    '전라남도 진도군': '539823A001',\n",
    "    '경기도 포천시': '487915A001',\n",
    "    '경상남도 밀양시': '627911A001',\n",
    "    '경기도 시흥시': '429843A001',\n",
    "    '강원도 철원군': '269811A001',\n",
    "    '충청남도 천안시': '330846A001',\n",
    "    '경상북도 청도군': '714902A001',\n",
    "    '부산 강서구': '618803A001',\n",
    "    '전북 남원시': '590823A001',\n",
    "    '경상남도 진주시': '660985B001',\n",
    "    '경상북도 상주시': '742290A001',\n",
    "    '경상북도 김천시': '037268B004'\n",
    "}\n",
    "\n",
    "joosan_dict={\n",
    "    '배추': '전라남도 해남군',\n",
    "    '무': '제주도 제주시',\n",
    "    '양파': '전라남도 무안군',\n",
    "    '건고추': '전남 해남군',\n",
    "    '마늘': '경상남도 창녕군',\n",
    "    '대파': '전라남도 진도군',\n",
    "    '얼갈이배추': '경기도 포천시',\n",
    "    '양배추': '제주도 제주시',\n",
    "    '깻잎': '경상남도 밀양시',\n",
    "    '시금치': '경기도 포천시',\n",
    "    '미나리': '경기도 시흥시',\n",
    "    '당근': '제주도 제주시',\n",
    "    '파프리카': '강원도 철원군',\n",
    "    '새송이': '충청남도 천안시',\n",
    "    '팽이버섯': '경상북도 청도군',\n",
    "    '토마토': '부산 강서구',\n",
    "    '청상추': '전북 남원시',\n",
    "    '백다다기': '충청남도 천안시',\n",
    "    '애호박': '경상남도 진주시',\n",
    "    '캠벨얼리': '경상북도 상주시',\n",
    "    '샤인마스캇': '경상북도 김천시'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f0bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather=pd.read_csv('weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a13c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing1(temp_df,train, pum, len_lag, weather, joosan_dict, code_dict) :\n",
    "    weather_df = train[['date',f'{pum}_거래량(kg)', f'{pum}_가격(원/kg)']]\n",
    "    # 품종과 주산지 날씨 mapping\n",
    "    \n",
    "    joosanji = joosan_dict[pum]\n",
    "    joosan_code = code_dict[joosanji]\n",
    "    joosan_weather = weather[weather['stn_Code']==joosan_code].reset_index(drop=True)\n",
    "    \n",
    "    end_index = np.where(joosan_weather['date']=='2020-09-28')[0][0]\n",
    "    joosan_weather = joosan_weather.iloc[:end_index+1] #2020-09-28 까지만 자르기\n",
    "    weather_df = weather_df.merge(joosan_weather, on='date', how='left')\n",
    "    \n",
    "    # 해당하는 열의 모든 값이 null 값이기 때문에 이열 두개는 삭제 처리  \n",
    "    weather_df.drop(['condens_Time','gr_Temp'],axis=1,inplace=True)\n",
    "    # 결측치가 존재함 -> 날씨의 특성상 앞뒤 날씨의 영향을 받거나 혹은 비슷한 시기의 날씨의 특성과 비슷할 것으로 예상\n",
    "    # 따라서 결측치를 앞날의 데이터를 가져오는 것으로 결정 \n",
    "    weather_df['sun_Time']=weather_df['sun_Time'].fillna(method='ffill')\n",
    "    weather_df['soil_Wt']=weather_df['soil_Wt'].fillna(method='ffill')\n",
    "    wea_col_list=list(weather_df.columns)\n",
    "    del wea_col_list[0:6]\n",
    "    #print(weather_df)\n",
    "    \n",
    "    # p_lag, q_lag 추가, 날씨 열 추가\n",
    "    for lag in range(1,len_lag+1) :\n",
    "      temp_df[f'p_lag_{lag}'] = -1\n",
    "      temp_df[f'q_lag_{lag}'] = -1\n",
    "      for col in range(len(wea_col_list)):\n",
    "        col=wea_col_list[col]\n",
    "         #or col ==\"widdir\" or col == \"wind\"\n",
    "        if(col == \"sun_Time\" or col == \"sun_Qy\" or col ==\"soil_Temp\" or col ==\"soil_Wt\" or col == \"wind\" or col ==\"widdir\"):\n",
    "            continue\n",
    "        if(pum == '건고추' or pum == '당근' or pum =='토마토'):\n",
    "            continue\n",
    "        temp_df[f'{col}_lag_{lag}'] = -1\n",
    "      for index in range(lag, len(temp_df)) :\n",
    "        temp_df.loc[index, f'p_lag_{lag}'] = temp_df[f'{pum}_가격(원/kg)'][index-lag] #1일전, 2일전, ... 가격을 feature로 추가\n",
    "        temp_df.loc[index, f'q_lag_{lag}'] = temp_df[f'{pum}_거래량(kg)'][index-lag] #1일전, 2일전, ... 거래량을 feature로 추가\n",
    "        if(pum == '건고추' or pum == '당근' or pum =='토마토'):\n",
    "            continue\n",
    "        temp_df.loc[index, f'temp_lag_{lag}'] = weather_df['temp'][index-lag]\n",
    "        temp_df.loc[index, f'max_Temp_lag_{lag}'] = weather_df['max_Temp'][index-lag]\n",
    "        temp_df.loc[index, f'min_Temp_lag_{lag}'] = weather_df['min_Temp'][index-lag]\n",
    "        temp_df.loc[index, f'hum_lag_{lag}'] = weather_df['hum'][index-lag]\n",
    "        temp_df.loc[index, f'rain_lag_{lag}'] = weather_df['rain'][index-lag]\n",
    "   \n",
    "    # month 추가\n",
    "    temp_df['date'] = pd.to_datetime(temp_df['date'])\n",
    "    temp_df['week']=temp_df['date'].dt.week\n",
    "    temp_df['day'] = temp_df['date'].dt.weekday\n",
    " \n",
    "    \n",
    "\n",
    "    # 예측 대상(1w,2w,4w) 추가\n",
    "    for week in ['1_week','2_week','4_week'] :\n",
    "      temp_df[week] = 0\n",
    "      n_week = int(week[0])\n",
    "      for index in range(len(temp_df)) :\n",
    "        try : temp_df[week][index] = temp_df[f'{pum}_가격(원/kg)'][index+7*n_week]\n",
    "        except : continue\n",
    "\n",
    "    # 불필요한 column 제거        \n",
    "    temp_df = temp_df.drop(['date',f'{pum}_거래량(kg)',f'{pum}_가격(원/kg)'], axis=1)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7655f517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>배추_거래량(kg)</th>\n",
       "      <th>배추_가격(원/kg)</th>\n",
       "      <th>무_거래량(kg)</th>\n",
       "      <th>무_가격(원/kg)</th>\n",
       "      <th>양파_거래량(kg)</th>\n",
       "      <th>양파_가격(원/kg)</th>\n",
       "      <th>건고추_거래량(kg)</th>\n",
       "      <th>건고추_가격(원/kg)</th>\n",
       "      <th>마늘_거래량(kg)</th>\n",
       "      <th>...</th>\n",
       "      <th>청상추_거래량(kg)</th>\n",
       "      <th>청상추_가격(원/kg)</th>\n",
       "      <th>백다다기_거래량(kg)</th>\n",
       "      <th>백다다기_가격(원/kg)</th>\n",
       "      <th>애호박_거래량(kg)</th>\n",
       "      <th>애호박_가격(원/kg)</th>\n",
       "      <th>캠벨얼리_거래량(kg)</th>\n",
       "      <th>캠벨얼리_가격(원/kg)</th>\n",
       "      <th>샤인마스캇_거래량(kg)</th>\n",
       "      <th>샤인마스캇_가격(원/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>1288392.0</td>\n",
       "      <td>311.647794</td>\n",
       "      <td>855004.0</td>\n",
       "      <td>397.379895</td>\n",
       "      <td>595884.0</td>\n",
       "      <td>1349.292060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23780.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7984.0</td>\n",
       "      <td>6411.0</td>\n",
       "      <td>53780.0</td>\n",
       "      <td>3371.0</td>\n",
       "      <td>72880.0</td>\n",
       "      <td>3677.0</td>\n",
       "      <td>14155.0</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>1005712.0</td>\n",
       "      <td>362.469052</td>\n",
       "      <td>687087.0</td>\n",
       "      <td>377.834757</td>\n",
       "      <td>610021.0</td>\n",
       "      <td>1376.753341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7736.0</td>\n",
       "      <td>6777.0</td>\n",
       "      <td>34635.0</td>\n",
       "      <td>3554.0</td>\n",
       "      <td>61924.0</td>\n",
       "      <td>3890.0</td>\n",
       "      <td>14955.0</td>\n",
       "      <td>2091.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>1448544.0</td>\n",
       "      <td>363.709311</td>\n",
       "      <td>837533.0</td>\n",
       "      <td>371.056543</td>\n",
       "      <td>757880.0</td>\n",
       "      <td>1287.379532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92560.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8040.0</td>\n",
       "      <td>7258.0</td>\n",
       "      <td>64455.0</td>\n",
       "      <td>3574.0</td>\n",
       "      <td>80478.0</td>\n",
       "      <td>3778.0</td>\n",
       "      <td>15969.0</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-04</td>\n",
       "      <td>1065822.0</td>\n",
       "      <td>418.331494</td>\n",
       "      <td>582460.0</td>\n",
       "      <td>347.406088</td>\n",
       "      <td>673494.0</td>\n",
       "      <td>1259.264077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8568.0</td>\n",
       "      <td>8139.0</td>\n",
       "      <td>62537.0</td>\n",
       "      <td>3722.0</td>\n",
       "      <td>85295.0</td>\n",
       "      <td>3824.0</td>\n",
       "      <td>13179.0</td>\n",
       "      <td>2168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-05</td>\n",
       "      <td>1047453.0</td>\n",
       "      <td>346.322484</td>\n",
       "      <td>617740.0</td>\n",
       "      <td>328.650565</td>\n",
       "      <td>540224.0</td>\n",
       "      <td>1175.858348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17974.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9168.0</td>\n",
       "      <td>7946.0</td>\n",
       "      <td>83336.0</td>\n",
       "      <td>3471.0</td>\n",
       "      <td>100114.0</td>\n",
       "      <td>3413.0</td>\n",
       "      <td>12330.0</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>1856965.0</td>\n",
       "      <td>1839.000000</td>\n",
       "      <td>2055640.0</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>2281429.2</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>2818.4</td>\n",
       "      <td>19101.0</td>\n",
       "      <td>134359.9</td>\n",
       "      <td>...</td>\n",
       "      <td>50730.0</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>282212.3</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>313139.7</td>\n",
       "      <td>3426.0</td>\n",
       "      <td>504242.6</td>\n",
       "      <td>3620.0</td>\n",
       "      <td>283196.9</td>\n",
       "      <td>10940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>1880095.5</td>\n",
       "      <td>1789.000000</td>\n",
       "      <td>1879261.0</td>\n",
       "      <td>1011.000000</td>\n",
       "      <td>2074513.0</td>\n",
       "      <td>955.000000</td>\n",
       "      <td>1887.1</td>\n",
       "      <td>23095.0</td>\n",
       "      <td>126926.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54322.0</td>\n",
       "      <td>4178.0</td>\n",
       "      <td>312214.8</td>\n",
       "      <td>2999.0</td>\n",
       "      <td>362741.0</td>\n",
       "      <td>3357.0</td>\n",
       "      <td>479683.1</td>\n",
       "      <td>3618.0</td>\n",
       "      <td>303779.6</td>\n",
       "      <td>10844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>1661090.9</td>\n",
       "      <td>1760.000000</td>\n",
       "      <td>1709385.7</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>2089081.2</td>\n",
       "      <td>961.000000</td>\n",
       "      <td>959.0</td>\n",
       "      <td>22510.0</td>\n",
       "      <td>110357.7</td>\n",
       "      <td>...</td>\n",
       "      <td>61213.0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>327395.8</td>\n",
       "      <td>3065.0</td>\n",
       "      <td>390361.2</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>521493.8</td>\n",
       "      <td>3691.0</td>\n",
       "      <td>313295.7</td>\n",
       "      <td>10636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>25396.0</td>\n",
       "      <td>3066.000000</td>\n",
       "      <td>38222.0</td>\n",
       "      <td>1139.000000</td>\n",
       "      <td>18240.0</td>\n",
       "      <td>1056.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22333.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>...</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4076.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>3707.0</td>\n",
       "      <td>2464.0</td>\n",
       "      <td>3252.0</td>\n",
       "      <td>21717.0</td>\n",
       "      <td>3567.0</td>\n",
       "      <td>9734.0</td>\n",
       "      <td>10699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>2405051.9</td>\n",
       "      <td>1867.000000</td>\n",
       "      <td>2747519.5</td>\n",
       "      <td>1147.000000</td>\n",
       "      <td>2235784.7</td>\n",
       "      <td>964.000000</td>\n",
       "      <td>1630.6</td>\n",
       "      <td>22022.0</td>\n",
       "      <td>175584.1</td>\n",
       "      <td>...</td>\n",
       "      <td>84155.0</td>\n",
       "      <td>4167.0</td>\n",
       "      <td>554862.6</td>\n",
       "      <td>2873.0</td>\n",
       "      <td>667745.0</td>\n",
       "      <td>2782.0</td>\n",
       "      <td>601841.0</td>\n",
       "      <td>3761.0</td>\n",
       "      <td>382263.4</td>\n",
       "      <td>10998.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1760 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  배추_거래량(kg)  배추_가격(원/kg)  무_거래량(kg)   무_가격(원/kg)  양파_거래량(kg)  \\\n",
       "0     2015-12-01   1288392.0   311.647794   855004.0   397.379895    595884.0   \n",
       "1     2015-12-02   1005712.0   362.469052   687087.0   377.834757    610021.0   \n",
       "2     2015-12-03   1448544.0   363.709311   837533.0   371.056543    757880.0   \n",
       "3     2015-12-04   1065822.0   418.331494   582460.0   347.406088    673494.0   \n",
       "4     2015-12-05   1047453.0   346.322484   617740.0   328.650565    540224.0   \n",
       "...          ...         ...          ...        ...          ...         ...   \n",
       "1755  2020-09-24   1856965.0  1839.000000  2055640.0   990.000000   2281429.2   \n",
       "1756  2020-09-25   1880095.5  1789.000000  1879261.0  1011.000000   2074513.0   \n",
       "1757  2020-09-26   1661090.9  1760.000000  1709385.7  1075.000000   2089081.2   \n",
       "1758  2020-09-27     25396.0  3066.000000    38222.0  1139.000000     18240.0   \n",
       "1759  2020-09-28   2405051.9  1867.000000  2747519.5  1147.000000   2235784.7   \n",
       "\n",
       "      양파_가격(원/kg)  건고추_거래량(kg)  건고추_가격(원/kg)  마늘_거래량(kg)  ...  청상추_거래량(kg)  \\\n",
       "0     1349.292060          0.0           0.0     23780.0  ...       7984.0   \n",
       "1     1376.753341          0.0           0.0     16160.0  ...       7736.0   \n",
       "2     1287.379532          0.0           0.0     92560.0  ...       8040.0   \n",
       "3     1259.264077          0.0           0.0     15300.0  ...       8568.0   \n",
       "4     1175.858348          0.0           0.0     17974.0  ...       9168.0   \n",
       "...           ...          ...           ...         ...  ...          ...   \n",
       "1755   990.000000       2818.4       19101.0    134359.9  ...      50730.0   \n",
       "1756   955.000000       1887.1       23095.0    126926.0  ...      54322.0   \n",
       "1757   961.000000        959.0       22510.0    110357.7  ...      61213.0   \n",
       "1758  1056.000000         60.0       22333.0       620.0  ...        144.0   \n",
       "1759   964.000000       1630.6       22022.0    175584.1  ...      84155.0   \n",
       "\n",
       "      청상추_가격(원/kg)  백다다기_거래량(kg)  백다다기_가격(원/kg)  애호박_거래량(kg)  애호박_가격(원/kg)  \\\n",
       "0           6411.0       53780.0         3371.0      72880.0        3677.0   \n",
       "1           6777.0       34635.0         3554.0      61924.0        3890.0   \n",
       "2           7258.0       64455.0         3574.0      80478.0        3778.0   \n",
       "3           8139.0       62537.0         3722.0      85295.0        3824.0   \n",
       "4           7946.0       83336.0         3471.0     100114.0        3413.0   \n",
       "...            ...           ...            ...          ...           ...   \n",
       "1755        4509.0      282212.3         3001.0     313139.7        3426.0   \n",
       "1756        4178.0      312214.8         2999.0     362741.0        3357.0   \n",
       "1757        3770.0      327395.8         3065.0     390361.2        3092.0   \n",
       "1758        4076.0         285.0         3707.0       2464.0        3252.0   \n",
       "1759        4167.0      554862.6         2873.0     667745.0        2782.0   \n",
       "\n",
       "      캠벨얼리_거래량(kg)  캠벨얼리_가격(원/kg)  샤인마스캇_거래량(kg)  샤인마스캇_가격(원/kg)  \n",
       "0          14155.0         2090.0            0.0             0.0  \n",
       "1          14955.0         2091.0            0.0             0.0  \n",
       "2          15969.0         2080.0            0.0             0.0  \n",
       "3          13179.0         2168.0            0.0             0.0  \n",
       "4          12330.0         1928.0            0.0             0.0  \n",
       "...            ...            ...            ...             ...  \n",
       "1755      504242.6         3620.0       283196.9         10940.0  \n",
       "1756      479683.1         3618.0       303779.6         10844.0  \n",
       "1757      521493.8         3691.0       313295.7         10636.0  \n",
       "1758       21717.0         3567.0         9734.0         10699.0  \n",
       "1759      601841.0         3761.0       382263.4         10998.0  \n",
       "\n",
       "[1760 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train_201512~.csv')\n",
    "train = train.drop('Unnamed: 0', axis = 1)\n",
    "train #2015.12 ~ 2020.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c409bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, label, window_size=10):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i+window_size]))\n",
    "    return np.array(feature_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669d300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler3 = MinMaxScaler()\n",
    "scaler4 = MinMaxScaler()\n",
    "scaler5 = MinMaxScaler()\n",
    "scaler6 = MinMaxScaler()\n",
    "scaler7 = MinMaxScaler()\n",
    "scaler8 = MinMaxScaler()\n",
    "scaler9 = MinMaxScaler()\n",
    "scaler10 = MinMaxScaler()\n",
    "scaler11= MinMaxScaler()\n",
    "scaler12 = MinMaxScaler()\n",
    "scaler13 = MinMaxScaler()\n",
    "scaler14 = MinMaxScaler()\n",
    "scaler15 = MinMaxScaler()\n",
    "scaler16 = MinMaxScaler()\n",
    "scaler17 = MinMaxScaler()\n",
    "scaler18 = MinMaxScaler()\n",
    "scaler19 = MinMaxScaler()\n",
    "scaler20 = MinMaxScaler()\n",
    "scaler21 = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b19e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_65 (LSTM)               (None, 16)                1664      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,809\n",
      "Trainable params: 1,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dict[f'{pum}_model_{week_num}'] = Sequential()\n",
    "model_dict[f'{pum}_model_{week_num}'].add(LSTM(16, \n",
    "               input_shape=(train_feature.shape[1], train_feature.shape[2]), \n",
    "               activation='relu', \n",
    "               return_sequences=False)\n",
    "          )\n",
    "model_dict[f'{pum}_model_{week_num}'].add(Dense(8))\n",
    "model_dict[f'{pum}_model_{week_num}'].add(Dense(1))\n",
    "\n",
    "model_path = 'model'\n",
    "model_dict[f'{pum}_model_{week_num}'].compile(loss='mean_absolute_error', optimizer='SGD')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=100)\n",
    "filename = os.path.join(model_path, 'tmp_checkpoint1.h5')\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "model_dict[f'{pum}_model_{week_num}'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5561e192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 503.1296 - val_loss: 775.4613\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 775.46130, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 969us/step - loss: 231.5370 - val_loss: 420.5248\n",
      "\n",
      "Epoch 00002: val_loss improved from 775.46130 to 420.52481, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 243.3653 - val_loss: 736.7921\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 420.52481\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 227.1836 - val_loss: 296.5510\n",
      "\n",
      "Epoch 00004: val_loss improved from 420.52481 to 296.55096, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.7612 - val_loss: 634.7139\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 296.55096\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 229.6004 - val_loss: 677.0670\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 296.55096\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 930us/step - loss: 224.3767 - val_loss: 538.9733\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 296.55096\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 961us/step - loss: 225.1507 - val_loss: 369.6031\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 296.55096\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.1128 - val_loss: 626.4752\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 296.55096\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.1735 - val_loss: 744.9788\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 296.55096\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.0793 - val_loss: 316.0448\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 296.55096\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 957us/step - loss: 234.3528 - val_loss: 452.8217\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 296.55096\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 944us/step - loss: 224.1826 - val_loss: 382.1975\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 296.55096\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.6621 - val_loss: 828.2808\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 296.55096\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.1940 - val_loss: 524.1639\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 296.55096\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 913us/step - loss: 228.2139 - val_loss: 632.4182\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 296.55096\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 209.6842 - val_loss: 343.3279\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 296.55096\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 229.9158 - val_loss: 946.6024\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 296.55096\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.1828 - val_loss: 605.3892\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 296.55096\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 946us/step - loss: 215.8951 - val_loss: 219.1855\n",
      "\n",
      "Epoch 00020: val_loss improved from 296.55096 to 219.18546, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 931us/step - loss: 220.5173 - val_loss: 323.0865\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 219.18546\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 240.3147 - val_loss: 763.8362\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 219.18546\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.9736 - val_loss: 861.7232\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 219.18546\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 205.1534 - val_loss: 308.7097\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 219.18546\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 915us/step - loss: 216.5344 - val_loss: 214.0045\n",
      "\n",
      "Epoch 00025: val_loss improved from 219.18546 to 214.00449, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 938us/step - loss: 218.3449 - val_loss: 795.1347\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 214.00449\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 211.5013 - val_loss: 307.0664\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 214.00449\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 220.7847 - val_loss: 801.3019\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 214.00449\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 220.2488 - val_loss: 455.1649\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 214.00449\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 937us/step - loss: 223.4414 - val_loss: 502.3230\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 214.00449\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 957us/step - loss: 211.2708 - val_loss: 246.4836\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 214.00449\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 205.1062 - val_loss: 379.5016\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 214.00449\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 208.7037 - val_loss: 927.5651\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 214.00449\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 949us/step - loss: 212.8295 - val_loss: 696.2410\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 214.00449\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 951us/step - loss: 214.6253 - val_loss: 298.2545\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 214.00449\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 217.0036 - val_loss: 219.7557\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 214.00449\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 206.1104 - val_loss: 611.7186\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 214.00449\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 995us/step - loss: 218.5560 - val_loss: 837.4358\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 214.00449\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.2658 - val_loss: 221.2614\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 214.00449\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 205.9980 - val_loss: 188.9799\n",
      "\n",
      "Epoch 00040: val_loss improved from 214.00449 to 188.97990, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 920us/step - loss: 220.0691 - val_loss: 399.3937\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 188.97990\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 918us/step - loss: 212.7138 - val_loss: 190.9197\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 188.97990\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 213.4499 - val_loss: 554.8491\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 188.97990\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 216.6092 - val_loss: 947.3760\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 188.97990\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 188.7390 - val_loss: 331.7567\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 188.97990\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 925us/step - loss: 224.2340 - val_loss: 218.5568\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 188.97990\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 982us/step - loss: 216.2314 - val_loss: 233.9028\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 188.97990\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 209.8705 - val_loss: 607.0584\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 188.97990\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.1939 - val_loss: 226.3866\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 188.97990\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 924us/step - loss: 201.4742 - val_loss: 891.5438\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 188.97990\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 199.0608 - val_loss: 995.2211\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 188.97990\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 215.2229 - val_loss: 592.5862\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 188.97990\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 208.9588 - val_loss: 863.1471\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 188.97990\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 917us/step - loss: 211.4091 - val_loss: 364.2962\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 188.97990\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 983us/step - loss: 206.5981 - val_loss: 991.9874\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 188.97990\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 201.3111 - val_loss: 184.5997\n",
      "\n",
      "Epoch 00056: val_loss improved from 188.97990 to 184.59973, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 202.7038 - val_loss: 967.0883\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 184.59973\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 203.7187 - val_loss: 305.3060\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 184.59973\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 212.0034 - val_loss: 387.4834\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 184.59973\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 191.2607 - val_loss: 923.1124\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 184.59973\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 936us/step - loss: 194.5500 - val_loss: 200.9895\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 184.59973\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 974us/step - loss: 206.5702 - val_loss: 528.4255\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 184.59973\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 195.7446 - val_loss: 191.8075\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 184.59973\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 199.2188 - val_loss: 686.6312\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 184.59973\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 987us/step - loss: 177.4058 - val_loss: 208.6503\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 184.59973\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 194.3280 - val_loss: 836.4345\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 184.59973\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 951us/step - loss: 183.1160 - val_loss: 184.4991\n",
      "\n",
      "Epoch 00067: val_loss improved from 184.59973 to 184.49915, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 182.2280 - val_loss: 272.9090\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 184.49915\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 191.3814 - val_loss: 265.1938\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 184.49915\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 184.0179 - val_loss: 384.5447\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 184.49915\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.1257 - val_loss: 252.2464\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 184.49915\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 170.0107 - val_loss: 590.1640\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 184.49915\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 933us/step - loss: 160.8304 - val_loss: 471.1652\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 184.49915\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.8188 - val_loss: 853.4091\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 184.49915\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 168.2083 - val_loss: 469.3387\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 184.49915\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 164.2570 - val_loss: 207.2351\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 184.49915\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 160.4309 - val_loss: 602.2411\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 184.49915\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 160.6903 - val_loss: 507.9177\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 184.49915\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 183.2165 - val_loss: 336.8570\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 184.49915\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 943us/step - loss: 159.8244 - val_loss: 193.5287\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 184.49915\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 162.5055 - val_loss: 532.5525\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 184.49915\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 163.2301 - val_loss: 775.8182\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 184.49915\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.3667 - val_loss: 772.6808\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 184.49915\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 161.1398 - val_loss: 458.4117\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 184.49915\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 158.4781 - val_loss: 306.6673\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 184.49915\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 899us/step - loss: 163.6439 - val_loss: 417.9848\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 184.49915\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 900us/step - loss: 165.2745 - val_loss: 540.4939\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 184.49915\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 171.2986 - val_loss: 407.7161\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 184.49915\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 162.3681 - val_loss: 578.2307\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 184.49915\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.9100 - val_loss: 193.1825\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 184.49915\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 947us/step - loss: 149.9632 - val_loss: 188.1405\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 184.49915\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.0195 - val_loss: 454.1000\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 184.49915\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.2074 - val_loss: 563.4758\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 184.49915\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 993us/step - loss: 147.8081 - val_loss: 191.3999\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 184.49915\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.4160 - val_loss: 407.7870\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 184.49915\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 158.3605 - val_loss: 460.9742\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 184.49915\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 999us/step - loss: 151.5882 - val_loss: 470.9704\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 184.49915\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 923us/step - loss: 152.4824 - val_loss: 387.0045\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 184.49915\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.7456 - val_loss: 530.5055\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 184.49915\n",
      "Epoch 100/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 897us/step - loss: 149.1592 - val_loss: 672.4590\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 184.49915\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.5553 - val_loss: 978.3022\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 184.49915\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.1146 - val_loss: 394.0817\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 184.49915\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.7384 - val_loss: 365.0694\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 184.49915\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.8238 - val_loss: 698.5884\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 184.49915\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.4406 - val_loss: 193.2218\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 184.49915\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 916us/step - loss: 147.2973 - val_loss: 254.7924\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 184.49915\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.7371 - val_loss: 286.7386\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 184.49915\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.4673 - val_loss: 194.8511\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 184.49915\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 138.9214 - val_loss: 805.5689\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 184.49915\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.4103 - val_loss: 288.9672\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 184.49915\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.7327 - val_loss: 431.4469\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 184.49915\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 995us/step - loss: 135.0759 - val_loss: 187.6802\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 184.49915\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 968us/step - loss: 141.2006 - val_loss: 270.7628\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 184.49915\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 918us/step - loss: 147.4524 - val_loss: 420.0287\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 184.49915\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 152.7153 - val_loss: 912.0449\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 184.49915\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.8378 - val_loss: 498.0620\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 184.49915\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.9282 - val_loss: 214.9635\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 184.49915\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.9510 - val_loss: 277.9742\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 184.49915\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.8490 - val_loss: 535.3295\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 184.49915\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.5107 - val_loss: 505.5899\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 184.49915\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 152.9226 - val_loss: 722.1528\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 184.49915\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.9796 - val_loss: 743.5634\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 184.49915\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 953us/step - loss: 150.6204 - val_loss: 480.4191\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 184.49915\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 140.8227 - val_loss: 655.3238\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 184.49915\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.5208 - val_loss: 220.4101\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 184.49915\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.1196 - val_loss: 211.3248\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 184.49915\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 165.1600 - val_loss: 615.9081\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 184.49915\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.8264 - val_loss: 213.7748\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 184.49915\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 931us/step - loss: 140.0677 - val_loss: 394.2295\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 184.49915\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 982us/step - loss: 148.8415 - val_loss: 527.1527\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 184.49915\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.2398 - val_loss: 653.8596\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 184.49915\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.2997 - val_loss: 404.9884\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 184.49915\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 914us/step - loss: 140.2985 - val_loss: 636.0063\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 184.49915\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.6619 - val_loss: 367.0601\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 184.49915\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.5971 - val_loss: 437.3842\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 184.49915\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 897us/step - loss: 140.3214 - val_loss: 365.1750\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 184.49915\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 908us/step - loss: 144.7744 - val_loss: 315.0009\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 184.49915\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.5105 - val_loss: 197.1770\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 184.49915\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.5312 - val_loss: 461.2218\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 184.49915\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.9215 - val_loss: 259.3459\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 184.49915\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 993us/step - loss: 142.7662 - val_loss: 192.0622\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 184.49915\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.4291 - val_loss: 427.1849\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 184.49915\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.6046 - val_loss: 679.1334\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 184.49915\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 131.3390 - val_loss: 487.8549\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 184.49915\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.4799 - val_loss: 719.7238\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 184.49915\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 945us/step - loss: 135.9532 - val_loss: 353.2541\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 184.49915\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.8856 - val_loss: 396.1366\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 184.49915\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.5885 - val_loss: 277.3221\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 184.49915\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.6811 - val_loss: 638.3505\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 184.49915\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 917us/step - loss: 140.2632 - val_loss: 309.4023\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 184.49915\n",
      "Epoch 151/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 151.5482 - val_loss: 261.0551\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 184.49915\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 160.7265 - val_loss: 599.5008\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 184.49915\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 931us/step - loss: 154.5161 - val_loss: 493.3740\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 184.49915\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 945us/step - loss: 157.5494 - val_loss: 362.4919\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 184.49915\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 152.5859 - val_loss: 529.4001\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 184.49915\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.1116 - val_loss: 607.6929\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 184.49915\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 933us/step - loss: 163.9887 - val_loss: 225.7297\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 184.49915\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.0496 - val_loss: 273.1729\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 184.49915\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.1606 - val_loss: 200.9499\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 184.49915\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 895us/step - loss: 152.8205 - val_loss: 356.7251\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 184.49915\n",
      "Epoch 161/10000\n",
      "89/89 [==============================] - 0s 985us/step - loss: 155.1629 - val_loss: 530.9088\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 184.49915\n",
      "Epoch 162/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 151.4952 - val_loss: 632.4832\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 184.49915\n",
      "Epoch 163/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.3091 - val_loss: 265.7062\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 184.49915\n",
      "Epoch 164/10000\n",
      "89/89 [==============================] - 0s 906us/step - loss: 155.9798 - val_loss: 537.0242\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 184.49915\n",
      "Epoch 165/10000\n",
      "89/89 [==============================] - 0s 913us/step - loss: 147.6223 - val_loss: 602.2029\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 184.49915\n",
      "Epoch 166/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.5664 - val_loss: 381.2455\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 184.49915\n",
      "Epoch 167/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.5432 - val_loss: 476.4498\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 184.49915\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 597.2391 - val_loss: 521.4923\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 521.49231, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 902us/step - loss: 247.2584 - val_loss: 488.5221\n",
      "\n",
      "Epoch 00002: val_loss improved from 521.49231 to 488.52209, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 961us/step - loss: 236.0509 - val_loss: 403.4389\n",
      "\n",
      "Epoch 00003: val_loss improved from 488.52209 to 403.43890, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 249.2189 - val_loss: 669.9007\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 403.43890\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.1301 - val_loss: 567.0464\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 403.43890\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 217.7521 - val_loss: 344.0526\n",
      "\n",
      "Epoch 00006: val_loss improved from 403.43890 to 344.05264, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 960us/step - loss: 228.4136 - val_loss: 997.3992\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 344.05264\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 232.5275 - val_loss: 267.4117\n",
      "\n",
      "Epoch 00008: val_loss improved from 344.05264 to 267.41165, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 922us/step - loss: 238.6215 - val_loss: 1144.3813\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 267.41165\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 237.3639 - val_loss: 997.2971\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 267.41165\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 220.9753 - val_loss: 396.3419\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 267.41165\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.6534 - val_loss: 786.9244\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 267.41165\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.5213 - val_loss: 856.1042\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 267.41165\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 221.1935 - val_loss: 535.5815\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 267.41165\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 219.1616 - val_loss: 798.5758\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 267.41165\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 916us/step - loss: 226.8173 - val_loss: 449.0926\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 267.41165\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.6628 - val_loss: 760.2456\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 267.41165\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 961us/step - loss: 224.1859 - val_loss: 1046.7789\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 267.41165\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 917us/step - loss: 228.9833 - val_loss: 563.9717\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 267.41165\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.5949 - val_loss: 733.5792\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 267.41165\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 205.8638 - val_loss: 834.3535\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 267.41165\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 222.9410 - val_loss: 585.0094\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 267.41165\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 227.3760 - val_loss: 303.3358\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 267.41165\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 958us/step - loss: 217.6437 - val_loss: 294.3346\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 267.41165\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 958us/step - loss: 221.5030 - val_loss: 239.3391\n",
      "\n",
      "Epoch 00025: val_loss improved from 267.41165 to 239.33914, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 212.3155 - val_loss: 774.0072\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 239.33914\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 227.4881 - val_loss: 271.0070\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 239.33914\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 211.3764 - val_loss: 724.4744\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 239.33914\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 931us/step - loss: 227.2264 - val_loss: 607.3244\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 239.33914\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 919us/step - loss: 220.2079 - val_loss: 372.4640\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 239.33914\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 221.2547 - val_loss: 281.4592\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 239.33914\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.2268 - val_loss: 205.7534\n",
      "\n",
      "Epoch 00032: val_loss improved from 239.33914 to 205.75336, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 33/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 210.6626 - val_loss: 353.0190\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 205.75336\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 226.5155 - val_loss: 902.4233\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 205.75336\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 897us/step - loss: 222.7641 - val_loss: 758.2857\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 205.75336\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 223.5809 - val_loss: 666.3928\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 205.75336\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.0716 - val_loss: 382.6902\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 205.75336\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 227.5399 - val_loss: 244.6245\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 205.75336\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 212.4167 - val_loss: 311.2520\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 205.75336\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 920us/step - loss: 215.3671 - val_loss: 623.9229\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 205.75336\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.0903 - val_loss: 293.0237\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 205.75336\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 214.3646 - val_loss: 558.2872\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 205.75336\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 917us/step - loss: 215.3508 - val_loss: 258.8625\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 205.75336\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 216.5472 - val_loss: 232.9033\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 205.75336\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 225.2347 - val_loss: 647.4536\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 205.75336\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 918us/step - loss: 203.1420 - val_loss: 254.4399\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 205.75336\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 206.2652 - val_loss: 503.0879\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 205.75336\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 903us/step - loss: 217.2281 - val_loss: 871.2830\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 205.75336\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 207.5876 - val_loss: 673.6923\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 205.75336\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 992us/step - loss: 205.1516 - val_loss: 203.9792\n",
      "\n",
      "Epoch 00050: val_loss improved from 205.75336 to 203.97923, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 219.4734 - val_loss: 559.3069\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 203.97923\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 204.4598 - val_loss: 663.4609\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 203.97923\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 911us/step - loss: 204.0926 - val_loss: 293.9223\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 203.97923\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 935us/step - loss: 224.7845 - val_loss: 1101.3710\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 203.97923\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 935us/step - loss: 225.7700 - val_loss: 462.7547\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 203.97923\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 900us/step - loss: 198.0963 - val_loss: 815.8356\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 203.97923\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 898us/step - loss: 207.8086 - val_loss: 414.2841\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 203.97923\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 897us/step - loss: 200.5044 - val_loss: 907.5689\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 203.97923\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 209.7335 - val_loss: 1091.1803\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 203.97923\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 194.4773 - val_loss: 610.4101\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 203.97923\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 924us/step - loss: 195.5219 - val_loss: 231.8897\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 203.97923\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 203.0644 - val_loss: 618.6558\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 203.97923\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 202.0963 - val_loss: 555.6829\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 203.97923\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 188.0312 - val_loss: 463.0650\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 203.97923\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 198.0131 - val_loss: 258.3591\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 203.97923\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 199.5610 - val_loss: 622.7352\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 203.97923\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 994us/step - loss: 188.6948 - val_loss: 1077.7877\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 203.97923\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 187.3946 - val_loss: 915.8538\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 203.97923\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 920us/step - loss: 199.5351 - val_loss: 836.6250\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 203.97923\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 926us/step - loss: 195.9398 - val_loss: 742.0617\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 203.97923\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 196.0246 - val_loss: 619.3320\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 203.97923\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 194.1348 - val_loss: 422.1795\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 203.97923\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 193.1010 - val_loss: 953.8367\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 203.97923\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 192.2648 - val_loss: 345.9093\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 203.97923\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 913us/step - loss: 189.6964 - val_loss: 406.5774\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 203.97923\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 177.7257 - val_loss: 499.4605\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 203.97923\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 909us/step - loss: 185.0346 - val_loss: 449.5212\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 203.97923\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 181.4281 - val_loss: 905.8450\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 203.97923\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 172.5439 - val_loss: 891.4158\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 203.97923\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 969us/step - loss: 166.0792 - val_loss: 761.9748\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 203.97923\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 917us/step - loss: 161.6038 - val_loss: 496.5723\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 203.97923\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.4202 - val_loss: 590.2410\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 203.97923\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 177.2307 - val_loss: 1031.9794\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 203.97923\n",
      "Epoch 84/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 167.2030 - val_loss: 333.8716\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 203.97923\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 164.7928 - val_loss: 769.3488\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 203.97923\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 176.2048 - val_loss: 863.8796\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 203.97923\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 945us/step - loss: 167.4718 - val_loss: 652.7495\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 203.97923\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 165.1422 - val_loss: 253.6273\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 203.97923\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 172.2977 - val_loss: 311.9930\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 203.97923\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 170.9672 - val_loss: 405.7691\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 203.97923\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 160.4612 - val_loss: 905.1883\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 203.97923\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 988us/step - loss: 165.3571 - val_loss: 533.8696\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 203.97923\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 163.4846 - val_loss: 551.4835\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 203.97923\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.5305 - val_loss: 890.1462\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 203.97923\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 932us/step - loss: 168.5594 - val_loss: 561.6309\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 203.97923\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 163.6044 - val_loss: 693.1724\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 203.97923\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 912us/step - loss: 153.2249 - val_loss: 495.9330\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 203.97923\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.5924 - val_loss: 771.2195\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 203.97923\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.8832 - val_loss: 823.2367\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 203.97923\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 158.6507 - val_loss: 716.4442\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 203.97923\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 151.9125 - val_loss: 804.5555\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 203.97923\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 152.1766 - val_loss: 396.6551\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 203.97923\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 160.4877 - val_loss: 856.0044\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 203.97923\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 903us/step - loss: 146.9995 - val_loss: 351.5565\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 203.97923\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.9315 - val_loss: 308.5391\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 203.97923\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 909us/step - loss: 161.0002 - val_loss: 222.0457\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 203.97923\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.1990 - val_loss: 590.9125\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 203.97923\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.6587 - val_loss: 683.2544\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 203.97923\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 931us/step - loss: 139.5776 - val_loss: 823.3679\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 203.97923\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 940us/step - loss: 147.8987 - val_loss: 668.0647\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 203.97923\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.5215 - val_loss: 697.5781\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 203.97923\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 928us/step - loss: 147.5684 - val_loss: 583.0896\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 203.97923\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.7319 - val_loss: 327.7806\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 203.97923\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.3504 - val_loss: 487.0458\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 203.97923\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.5381 - val_loss: 481.4143\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 203.97923\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.7741 - val_loss: 186.8301\n",
      "\n",
      "Epoch 00116: val_loss improved from 203.97923 to 186.83006, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.0829 - val_loss: 719.1717\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 186.83006\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.5255 - val_loss: 689.5432\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 186.83006\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.2102 - val_loss: 373.2727\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 186.83006\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 959us/step - loss: 152.3978 - val_loss: 534.5751\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 186.83006\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 913us/step - loss: 151.3683 - val_loss: 484.1053\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 186.83006\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.9298 - val_loss: 904.2731\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 186.83006\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 155.4857 - val_loss: 744.1780\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 186.83006\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 152.9880 - val_loss: 567.1887\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 186.83006\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.4321 - val_loss: 705.2886\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 186.83006\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 963us/step - loss: 150.4020 - val_loss: 246.4108\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 186.83006\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.8180 - val_loss: 611.7374\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 186.83006\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.6593 - val_loss: 671.0666\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 186.83006\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 151.1096 - val_loss: 360.7317\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 186.83006\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.7612 - val_loss: 549.1194\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 186.83006\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.5642 - val_loss: 276.5155\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 186.83006\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 915us/step - loss: 142.2022 - val_loss: 267.1701\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 186.83006\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 151.6517 - val_loss: 476.5240\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 186.83006\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.9396 - val_loss: 321.3859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00134: val_loss did not improve from 186.83006\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.1743 - val_loss: 598.5376\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 186.83006\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.3296 - val_loss: 910.0101\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 186.83006\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.4920 - val_loss: 428.6222\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 186.83006\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 928us/step - loss: 146.4779 - val_loss: 405.9179\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 186.83006\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.6902 - val_loss: 447.2997\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 186.83006\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.5144 - val_loss: 586.1627\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 186.83006\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.4955 - val_loss: 686.6855\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 186.83006\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.9231 - val_loss: 513.8621\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 186.83006\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 958us/step - loss: 138.4904 - val_loss: 234.9129\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 186.83006\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.3077 - val_loss: 445.1261\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 186.83006\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.8237 - val_loss: 811.2933\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 186.83006\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.5233 - val_loss: 666.4115\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 186.83006\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.2957 - val_loss: 911.2465\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 186.83006\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 912us/step - loss: 137.4323 - val_loss: 652.8940\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 186.83006\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.2386 - val_loss: 864.1428\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 186.83006\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.6225 - val_loss: 697.3091\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 186.83006\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 946us/step - loss: 141.6584 - val_loss: 263.3173\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 186.83006\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.4988 - val_loss: 812.5362\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 186.83006\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 998us/step - loss: 144.8148 - val_loss: 645.9854\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 186.83006\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.0327 - val_loss: 646.9091\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 186.83006\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.6688 - val_loss: 530.5358\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 186.83006\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.5680 - val_loss: 694.5590\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 186.83006\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 908us/step - loss: 141.9682 - val_loss: 582.5945\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 186.83006\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.7374 - val_loss: 580.5514\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 186.83006\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 923us/step - loss: 137.0978 - val_loss: 694.3582\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 186.83006\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.5253 - val_loss: 446.9215\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 186.83006\n",
      "Epoch 161/10000\n",
      "89/89 [==============================] - 0s 927us/step - loss: 139.5355 - val_loss: 446.1847\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 186.83006\n",
      "Epoch 162/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.2782 - val_loss: 519.3385\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 186.83006\n",
      "Epoch 163/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.4175 - val_loss: 401.9135\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 186.83006\n",
      "Epoch 164/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.8564 - val_loss: 871.7966\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 186.83006\n",
      "Epoch 165/10000\n",
      "89/89 [==============================] - 0s 916us/step - loss: 135.5413 - val_loss: 219.1069\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 186.83006\n",
      "Epoch 166/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.8997 - val_loss: 527.9045\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 186.83006\n",
      "Epoch 167/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.9755 - val_loss: 650.0744\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 186.83006\n",
      "Epoch 168/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.7444 - val_loss: 830.0879\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 186.83006\n",
      "Epoch 169/10000\n",
      "89/89 [==============================] - 0s 934us/step - loss: 138.8234 - val_loss: 697.5857\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 186.83006\n",
      "Epoch 170/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.5320 - val_loss: 638.6697\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 186.83006\n",
      "Epoch 171/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.1038 - val_loss: 814.9744\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 186.83006\n",
      "Epoch 172/10000\n",
      "89/89 [==============================] - 0s 923us/step - loss: 132.8085 - val_loss: 378.9468\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 186.83006\n",
      "Epoch 173/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.3600 - val_loss: 394.6494\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 186.83006\n",
      "Epoch 174/10000\n",
      "89/89 [==============================] - 0s 995us/step - loss: 139.2350 - val_loss: 606.4441\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 186.83006\n",
      "Epoch 175/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.4794 - val_loss: 499.1088\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 186.83006\n",
      "Epoch 176/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.9536 - val_loss: 611.9540\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 186.83006\n",
      "Epoch 177/10000\n",
      "89/89 [==============================] - 0s 914us/step - loss: 136.4907 - val_loss: 227.8579\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 186.83006\n",
      "Epoch 178/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.7775 - val_loss: 399.5038\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 186.83006\n",
      "Epoch 179/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.4864 - val_loss: 644.9165\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 186.83006\n",
      "Epoch 180/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.9159 - val_loss: 414.6895\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 186.83006\n",
      "Epoch 181/10000\n",
      "89/89 [==============================] - 0s 889us/step - loss: 136.0858 - val_loss: 609.7397\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 186.83006\n",
      "Epoch 182/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.8339 - val_loss: 404.1222\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 186.83006\n",
      "Epoch 183/10000\n",
      "89/89 [==============================] - 0s 961us/step - loss: 139.8879 - val_loss: 272.8843\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 186.83006\n",
      "Epoch 184/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.2504 - val_loss: 594.5208\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 186.83006\n",
      "Epoch 185/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.5644 - val_loss: 887.3477\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 186.83006\n",
      "Epoch 186/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.3356 - val_loss: 479.8909\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 186.83006\n",
      "Epoch 187/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.3237 - val_loss: 695.8999\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 186.83006\n",
      "Epoch 188/10000\n",
      "89/89 [==============================] - 0s 928us/step - loss: 148.2256 - val_loss: 332.2304\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 186.83006\n",
      "Epoch 189/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.8940 - val_loss: 372.4822\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 186.83006\n",
      "Epoch 190/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 139.6166 - val_loss: 697.0984\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 186.83006\n",
      "Epoch 191/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.2225 - val_loss: 578.1438\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 186.83006\n",
      "Epoch 192/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.2141 - val_loss: 786.0334\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 186.83006\n",
      "Epoch 193/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.7851 - val_loss: 519.4818\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 186.83006\n",
      "Epoch 194/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.8898 - val_loss: 228.6436\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 186.83006\n",
      "Epoch 195/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.3071 - val_loss: 609.4649\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 186.83006\n",
      "Epoch 196/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 128.6130 - val_loss: 536.1854\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 186.83006\n",
      "Epoch 197/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 130.5854 - val_loss: 513.2018\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 186.83006\n",
      "Epoch 198/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.9668 - val_loss: 670.0244\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 186.83006\n",
      "Epoch 199/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.4840 - val_loss: 361.5798\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 186.83006\n",
      "Epoch 200/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.4516 - val_loss: 696.6877\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 186.83006\n",
      "Epoch 201/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.2890 - val_loss: 575.0452\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 186.83006\n",
      "Epoch 202/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.4279 - val_loss: 344.3947\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 186.83006\n",
      "Epoch 203/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.2499 - val_loss: 653.3215\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 186.83006\n",
      "Epoch 204/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.6952 - val_loss: 500.3123\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 186.83006\n",
      "Epoch 205/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.7650 - val_loss: 643.1704\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 186.83006\n",
      "Epoch 206/10000\n",
      "89/89 [==============================] - 0s 941us/step - loss: 132.8717 - val_loss: 270.6515\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 186.83006\n",
      "Epoch 207/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.3107 - val_loss: 425.1489\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 186.83006\n",
      "Epoch 208/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.0956 - val_loss: 388.6653\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 186.83006\n",
      "Epoch 209/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.2363 - val_loss: 269.8524\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 186.83006\n",
      "Epoch 210/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.2577 - val_loss: 230.0223\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 186.83006\n",
      "Epoch 211/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.2647 - val_loss: 332.2736\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 186.83006\n",
      "Epoch 212/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.4781 - val_loss: 372.1341\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 186.83006\n",
      "Epoch 213/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.1345 - val_loss: 275.1026\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 186.83006\n",
      "Epoch 214/10000\n",
      "89/89 [==============================] - 0s 951us/step - loss: 134.5609 - val_loss: 743.1724\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 186.83006\n",
      "Epoch 215/10000\n",
      "89/89 [==============================] - 0s 969us/step - loss: 137.8108 - val_loss: 547.5583\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 186.83006\n",
      "Epoch 216/10000\n",
      "89/89 [==============================] - 0s 957us/step - loss: 129.3341 - val_loss: 333.5967\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 186.83006\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 426.8469 - val_loss: 569.4294\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 569.42944, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 935us/step - loss: 255.5814 - val_loss: 436.9141\n",
      "\n",
      "Epoch 00002: val_loss improved from 569.42944 to 436.91406, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 244.3650 - val_loss: 422.5925\n",
      "\n",
      "Epoch 00003: val_loss improved from 436.91406 to 422.59250, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 248.2125 - val_loss: 283.5955\n",
      "\n",
      "Epoch 00004: val_loss improved from 422.59250 to 283.59549, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 239.2785 - val_loss: 814.2101\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 283.59549\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 907us/step - loss: 239.4251 - val_loss: 600.2588\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 283.59549\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 246.4024 - val_loss: 796.3936\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 283.59549\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 226.6105 - val_loss: 709.1473\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 283.59549\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 953us/step - loss: 240.1685 - val_loss: 704.1644\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 283.59549\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 227.5650 - val_loss: 1020.8638\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 283.59549\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 252.9207 - val_loss: 432.4164\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 283.59549\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 230.9446 - val_loss: 260.1771\n",
      "\n",
      "Epoch 00012: val_loss improved from 283.59549 to 260.17712, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 241.9480 - val_loss: 520.8513\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 260.17712\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 229.0408 - val_loss: 549.3518\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 260.17712\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 897us/step - loss: 230.0387 - val_loss: 405.9648\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 260.17712\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 231.8069 - val_loss: 756.9587\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 260.17712\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 239.4942 - val_loss: 497.9738\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 260.17712\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 904us/step - loss: 229.9335 - val_loss: 520.9787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_loss did not improve from 260.17712\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 997us/step - loss: 212.1801 - val_loss: 564.8883\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 260.17712\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 940us/step - loss: 225.8444 - val_loss: 525.1378\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 260.17712\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 231.2897 - val_loss: 652.6879\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 260.17712\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 219.6377 - val_loss: 368.6940\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 260.17712\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 994us/step - loss: 215.8235 - val_loss: 234.0807\n",
      "\n",
      "Epoch 00023: val_loss improved from 260.17712 to 234.08070, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 217.3154 - val_loss: 777.1017\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 234.08070\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 998us/step - loss: 225.9588 - val_loss: 771.6488\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 234.08070\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 952us/step - loss: 227.3136 - val_loss: 617.0818\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 234.08070\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 230.3476 - val_loss: 806.0985\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 234.08070\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 217.9573 - val_loss: 568.8227\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 234.08070\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 981us/step - loss: 214.2608 - val_loss: 755.1312\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 234.08070\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 220.5728 - val_loss: 633.0651\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 234.08070\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 927us/step - loss: 225.1970 - val_loss: 994.0599\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 234.08070\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 217.2393 - val_loss: 723.6610\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 234.08070\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 210.2201 - val_loss: 889.3136\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 234.08070\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 215.3158 - val_loss: 902.3292\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 234.08070\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 204.9485 - val_loss: 500.1077\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 234.08070\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 204.5541 - val_loss: 372.7277\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 234.08070\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 213.9898 - val_loss: 422.4710\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 234.08070\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 200.4360 - val_loss: 799.3934\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 234.08070\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 945us/step - loss: 207.8252 - val_loss: 579.1791\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 234.08070\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 215.4345 - val_loss: 782.4754\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 234.08070\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 907us/step - loss: 200.5042 - val_loss: 658.7354\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 234.08070\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 203.8783 - val_loss: 603.9081\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 234.08070\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 196.4118 - val_loss: 589.1980\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 234.08070\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 973us/step - loss: 202.4949 - val_loss: 645.1474\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 234.08070\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 943us/step - loss: 202.2308 - val_loss: 893.8666\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 234.08070\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 190.6573 - val_loss: 648.5298\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 234.08070\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 196.6859 - val_loss: 1097.7390\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 234.08070\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 192.0326 - val_loss: 747.3887\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 234.08070\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 189.6348 - val_loss: 847.6027\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 234.08070\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 195.6549 - val_loss: 935.3092\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 234.08070\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 919us/step - loss: 187.8044 - val_loss: 1007.3894\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 234.08070\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 186.6557 - val_loss: 1078.4434\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 234.08070\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 192.0790 - val_loss: 768.2003\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 234.08070\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 926us/step - loss: 189.1595 - val_loss: 604.3901\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 234.08070\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 184.2461 - val_loss: 416.7115\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 234.08070\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 182.6736 - val_loss: 404.9305\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 234.08070\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 185.6442 - val_loss: 586.8629\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 234.08070\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 910us/step - loss: 173.6037 - val_loss: 393.8104\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 234.08070\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 171.4370 - val_loss: 630.4279\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 234.08070\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 189.1234 - val_loss: 644.5959\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 234.08070\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 183.6350 - val_loss: 811.9125\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 234.08070\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 916us/step - loss: 181.5714 - val_loss: 187.3728\n",
      "\n",
      "Epoch 00062: val_loss improved from 234.08070 to 187.37285, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 924us/step - loss: 185.5354 - val_loss: 343.4217\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 187.37285\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 177.5319 - val_loss: 746.9866\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 187.37285\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 174.1000 - val_loss: 641.0463\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 187.37285\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 999us/step - loss: 183.6422 - val_loss: 838.8594\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 187.37285\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 908us/step - loss: 184.8543 - val_loss: 478.8724\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 187.37285\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 184.3602 - val_loss: 812.3599\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 187.37285\n",
      "Epoch 69/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 178.6398 - val_loss: 349.9689\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 187.37285\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 910us/step - loss: 171.8544 - val_loss: 851.4810\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 187.37285\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 185.4494 - val_loss: 859.2007\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 187.37285\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 181.0313 - val_loss: 522.4576\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 187.37285\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 178.6821 - val_loss: 291.7778\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 187.37285\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 902us/step - loss: 170.3648 - val_loss: 756.2053\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 187.37285\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 181.8911 - val_loss: 745.4467\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 187.37285\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 162.8289 - val_loss: 663.4459\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 187.37285\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 175.1673 - val_loss: 817.3782\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 187.37285\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 984us/step - loss: 182.9408 - val_loss: 313.2279\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 187.37285\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 183.6429 - val_loss: 525.9970\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 187.37285\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 173.9853 - val_loss: 519.5549\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 187.37285\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 170.0250 - val_loss: 692.3254\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 187.37285\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 171.8542 - val_loss: 776.2830\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 187.37285\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 171.5602 - val_loss: 788.5800\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 187.37285\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 171.8811 - val_loss: 597.3705\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 187.37285\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 167.2655 - val_loss: 748.2436\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 187.37285\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 968us/step - loss: 170.9644 - val_loss: 265.3674\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 187.37285\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 947us/step - loss: 163.8742 - val_loss: 492.5864\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 187.37285\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 172.3024 - val_loss: 295.5294\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 187.37285\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 159.9606 - val_loss: 328.2974\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 187.37285\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 161.6184 - val_loss: 694.3223\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 187.37285\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 165.8443 - val_loss: 439.0865\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 187.37285\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 171.8702 - val_loss: 686.9874\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 187.37285\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 166.4999 - val_loss: 635.8618\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 187.37285\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 165.4244 - val_loss: 522.3578\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 187.37285\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 957us/step - loss: 170.1820 - val_loss: 799.3215\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 187.37285\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 163.3365 - val_loss: 568.8105\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 187.37285\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 166.4418 - val_loss: 783.9897\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 187.37285\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 167.0772 - val_loss: 838.7957\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 187.37285\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 153.1906 - val_loss: 507.0471\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 187.37285\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 165.8936 - val_loss: 459.0777\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 187.37285\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 168.6839 - val_loss: 634.8002\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 187.37285\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 172.2782 - val_loss: 772.7894\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 187.37285\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 164.5810 - val_loss: 755.6705\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 187.37285\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 155.0323 - val_loss: 632.7733\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 187.37285\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 155.2949 - val_loss: 801.1498\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 187.37285\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 166.2401 - val_loss: 648.8331\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 187.37285\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.9488 - val_loss: 800.7529\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 187.37285\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.9927 - val_loss: 862.1549\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 187.37285\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.1572 - val_loss: 693.3134\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 187.37285\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 162.7698 - val_loss: 575.2568\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 187.37285\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.9229 - val_loss: 385.9336\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 187.37285\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 987us/step - loss: 164.4681 - val_loss: 338.1755\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 187.37285\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 160.8111 - val_loss: 655.4755\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 187.37285\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 162.6604 - val_loss: 806.9738\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 187.37285\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 158.3451 - val_loss: 781.8809\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 187.37285\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.1452 - val_loss: 604.4122\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 187.37285\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 154.2941 - val_loss: 774.1573\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 187.37285\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 154.8115 - val_loss: 424.3229\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 187.37285\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.9552 - val_loss: 636.4858\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 187.37285\n",
      "Epoch 120/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 156.8509 - val_loss: 706.3215\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 187.37285\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 150.1046 - val_loss: 645.9353\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 187.37285\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.0875 - val_loss: 485.4861\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 187.37285\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.0680 - val_loss: 493.9159\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 187.37285\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 154.1164 - val_loss: 745.1702\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 187.37285\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.9685 - val_loss: 477.7234\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 187.37285\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 150.5889 - val_loss: 479.4952\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 187.37285\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 155.4680 - val_loss: 806.6298\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 187.37285\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.2637 - val_loss: 645.2767\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 187.37285\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.1132 - val_loss: 337.2569\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 187.37285\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 153.1311 - val_loss: 887.5094\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 187.37285\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 152.5210 - val_loss: 195.8225\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 187.37285\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 153.2086 - val_loss: 516.3902\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 187.37285\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 143.0368 - val_loss: 182.8018\n",
      "\n",
      "Epoch 00133: val_loss improved from 187.37285 to 182.80185, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 151.7836 - val_loss: 493.3641\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 182.80185\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 150.3117 - val_loss: 607.3623\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 182.80185\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.3410 - val_loss: 1010.9956\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 182.80185\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.0392 - val_loss: 842.7834\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 182.80185\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.6929 - val_loss: 670.8121\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 182.80185\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 143.3346 - val_loss: 707.0289\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 182.80185\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 146.5440 - val_loss: 713.6458\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 182.80185\n",
      "Epoch 141/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 149.7306 - val_loss: 262.6778\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 182.80185\n",
      "Epoch 142/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 144.3844 - val_loss: 634.3605\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 182.80185\n",
      "Epoch 143/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 152.3913 - val_loss: 723.5651\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 182.80185\n",
      "Epoch 144/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 151.5526 - val_loss: 848.4565\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 182.80185\n",
      "Epoch 145/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.2533 - val_loss: 730.0190\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 182.80185\n",
      "Epoch 146/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.5707 - val_loss: 480.5466\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 182.80185\n",
      "Epoch 147/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 147.1363 - val_loss: 936.8207\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 182.80185\n",
      "Epoch 148/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 149.8462 - val_loss: 223.4452\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 182.80185\n",
      "Epoch 149/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 154.0883 - val_loss: 374.2294\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 182.80185\n",
      "Epoch 150/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 151.1913 - val_loss: 185.2651\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 182.80185\n",
      "Epoch 151/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 145.2627 - val_loss: 741.5474\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 182.80185\n",
      "Epoch 152/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 149.2632 - val_loss: 606.3428\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 182.80185\n",
      "Epoch 153/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.4592 - val_loss: 705.6022\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 182.80185\n",
      "Epoch 154/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 142.7135 - val_loss: 807.1550\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 182.80185\n",
      "Epoch 155/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 143.5841 - val_loss: 542.4974\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 182.80185\n",
      "Epoch 156/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 149.2750 - val_loss: 626.3623\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 182.80185\n",
      "Epoch 157/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 143.0170 - val_loss: 689.6015\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 182.80185\n",
      "Epoch 158/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.7243 - val_loss: 575.8951\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 182.80185\n",
      "Epoch 159/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.5526 - val_loss: 633.4419\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 182.80185\n",
      "Epoch 160/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 142.4328 - val_loss: 713.7605\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 182.80185\n",
      "Epoch 161/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 146.8097 - val_loss: 807.1124\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 182.80185\n",
      "Epoch 162/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.7579 - val_loss: 525.8436\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 182.80185\n",
      "Epoch 163/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.2514 - val_loss: 409.6186\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 182.80185\n",
      "Epoch 164/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 138.7048 - val_loss: 582.7238\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 182.80185\n",
      "Epoch 165/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 143.9243 - val_loss: 372.8131\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 182.80185\n",
      "Epoch 166/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 143.2902 - val_loss: 792.6506\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 182.80185\n",
      "Epoch 167/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 140.0726 - val_loss: 798.3140\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 182.80185\n",
      "Epoch 168/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.6769 - val_loss: 552.6635\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 182.80185\n",
      "Epoch 169/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 134.6558 - val_loss: 181.0715\n",
      "\n",
      "Epoch 00169: val_loss improved from 182.80185 to 181.07150, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 170/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.8871 - val_loss: 931.7759\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 181.07150\n",
      "Epoch 171/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 134.7126 - val_loss: 875.0145\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 181.07150\n",
      "Epoch 172/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 141.6704 - val_loss: 789.1964\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 181.07150\n",
      "Epoch 173/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 135.2372 - val_loss: 611.1174\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 181.07150\n",
      "Epoch 174/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 137.7492 - val_loss: 554.2800\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 181.07150\n",
      "Epoch 175/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 138.1420 - val_loss: 606.8869\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 181.07150\n",
      "Epoch 176/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 131.2772 - val_loss: 681.2111\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 181.07150\n",
      "Epoch 177/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 142.2032 - val_loss: 722.6306\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 181.07150\n",
      "Epoch 178/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 129.6763 - val_loss: 766.4969\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 181.07150\n",
      "Epoch 179/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 127.6235 - val_loss: 659.2581\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 181.07150\n",
      "Epoch 180/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.5755 - val_loss: 747.7610\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 181.07150\n",
      "Epoch 181/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.7750 - val_loss: 476.2372\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 181.07150\n",
      "Epoch 182/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.8186 - val_loss: 915.4385\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 181.07150\n",
      "Epoch 183/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.1597 - val_loss: 865.0291\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 181.07150\n",
      "Epoch 184/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.5383 - val_loss: 845.9835\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 181.07150\n",
      "Epoch 185/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.2111 - val_loss: 564.6616\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 181.07150\n",
      "Epoch 186/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 139.3578 - val_loss: 564.0947\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 181.07150\n",
      "Epoch 187/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 133.9406 - val_loss: 593.2146\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 181.07150\n",
      "Epoch 188/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.0688 - val_loss: 760.6959\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 181.07150\n",
      "Epoch 189/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 131.7121 - val_loss: 392.3557\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 181.07150\n",
      "Epoch 190/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 129.5893 - val_loss: 617.2903\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 181.07150\n",
      "Epoch 191/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 131.0535 - val_loss: 582.0411\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 181.07150\n",
      "Epoch 192/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 133.5571 - val_loss: 610.6536\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 181.07150\n",
      "Epoch 193/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 135.2559 - val_loss: 850.0982\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 181.07150\n",
      "Epoch 194/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 130.1615 - val_loss: 622.3885\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 181.07150\n",
      "Epoch 195/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 126.5903 - val_loss: 656.9512\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 181.07150\n",
      "Epoch 196/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 129.3620 - val_loss: 720.5031\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 181.07150\n",
      "Epoch 197/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 132.6221 - val_loss: 626.9531\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 181.07150\n",
      "Epoch 198/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 132.2418 - val_loss: 618.8076\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 181.07150\n",
      "Epoch 199/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 133.0331 - val_loss: 797.9018\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 181.07150\n",
      "Epoch 200/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 128.3278 - val_loss: 698.5783\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 181.07150\n",
      "Epoch 201/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 132.2451 - val_loss: 570.4010\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 181.07150\n",
      "Epoch 202/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 130.1350 - val_loss: 1134.8676\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 181.07150\n",
      "Epoch 203/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 128.2287 - val_loss: 390.2489\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 181.07150\n",
      "Epoch 204/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 130.4161 - val_loss: 483.0565\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 181.07150\n",
      "Epoch 205/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.4332 - val_loss: 671.7827\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 181.07150\n",
      "Epoch 206/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 129.7778 - val_loss: 536.0323\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 181.07150\n",
      "Epoch 207/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 133.9731 - val_loss: 721.9048\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 181.07150\n",
      "Epoch 208/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 133.8250 - val_loss: 794.6125\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 181.07150\n",
      "Epoch 209/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 130.7163 - val_loss: 783.6644\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 181.07150\n",
      "Epoch 210/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 126.8189 - val_loss: 401.6952\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 181.07150\n",
      "Epoch 211/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 128.8653 - val_loss: 1175.7777\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 181.07150\n",
      "Epoch 212/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.5248 - val_loss: 674.3621\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 181.07150\n",
      "Epoch 213/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 128.1432 - val_loss: 637.8303\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 181.07150\n",
      "Epoch 214/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 127.3506 - val_loss: 238.3281\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 181.07150\n",
      "Epoch 215/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 125.8795 - val_loss: 677.7966\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 181.07150\n",
      "Epoch 216/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.4817 - val_loss: 706.0285\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 181.07150\n",
      "Epoch 217/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 125.0940 - val_loss: 928.8809\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 181.07150\n",
      "Epoch 218/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 127.8505 - val_loss: 534.9293\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 181.07150\n",
      "Epoch 219/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 134.9088 - val_loss: 955.2880\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 181.07150\n",
      "Epoch 220/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 125.8553 - val_loss: 823.6312\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 181.07150\n",
      "Epoch 221/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 2ms/step - loss: 126.8600 - val_loss: 913.9506\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 181.07150\n",
      "Epoch 222/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 127.8869 - val_loss: 418.6292\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 181.07150\n",
      "Epoch 223/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 128.5211 - val_loss: 734.3999\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 181.07150\n",
      "Epoch 224/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 132.4703 - val_loss: 577.4813\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 181.07150\n",
      "Epoch 225/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 123.0684 - val_loss: 829.7249\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 181.07150\n",
      "Epoch 226/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 120.9193 - val_loss: 604.7577\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 181.07150\n",
      "Epoch 227/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 129.8556 - val_loss: 648.3410\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 181.07150\n",
      "Epoch 228/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 129.0897 - val_loss: 562.3269\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 181.07150\n",
      "Epoch 229/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 131.1833 - val_loss: 615.8168\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 181.07150\n",
      "Epoch 230/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.2333 - val_loss: 444.5699\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 181.07150\n",
      "Epoch 231/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 129.9823 - val_loss: 902.4636\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 181.07150\n",
      "Epoch 232/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 127.6755 - val_loss: 627.9052\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 181.07150\n",
      "Epoch 233/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 126.1790 - val_loss: 410.3001\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 181.07150\n",
      "Epoch 234/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 124.7671 - val_loss: 673.6314\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 181.07150\n",
      "Epoch 235/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 118.7451 - val_loss: 861.3129\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 181.07150\n",
      "Epoch 236/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 122.8591 - val_loss: 834.1544\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 181.07150\n",
      "Epoch 237/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 127.5976 - val_loss: 771.7075\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 181.07150\n",
      "Epoch 238/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 123.0578 - val_loss: 627.4683\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 181.07150\n",
      "Epoch 239/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 124.9767 - val_loss: 645.4952\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 181.07150\n",
      "Epoch 240/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 123.7340 - val_loss: 721.1630\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 181.07150\n",
      "Epoch 241/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 124.7791 - val_loss: 589.3176\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 181.07150\n",
      "Epoch 242/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 116.9101 - val_loss: 655.2781\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 181.07150\n",
      "Epoch 243/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 126.0413 - val_loss: 849.5067\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 181.07150\n",
      "Epoch 244/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 126.8898 - val_loss: 674.7314\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 181.07150\n",
      "Epoch 245/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 126.9442 - val_loss: 566.6630\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 181.07150\n",
      "Epoch 246/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 120.2498 - val_loss: 665.3682\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 181.07150\n",
      "Epoch 247/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 128.9148 - val_loss: 861.2740\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 181.07150\n",
      "Epoch 248/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 123.4329 - val_loss: 889.6252\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 181.07150\n",
      "Epoch 249/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 126.7995 - val_loss: 606.3440\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 181.07150\n",
      "Epoch 250/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 127.5251 - val_loss: 705.8156\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 181.07150\n",
      "Epoch 251/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 124.5758 - val_loss: 748.7795\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 181.07150\n",
      "Epoch 252/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 116.9430 - val_loss: 660.4639\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 181.07150\n",
      "Epoch 253/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 123.8218 - val_loss: 535.7765\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 181.07150\n",
      "Epoch 254/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 120.6868 - val_loss: 667.5379\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 181.07150\n",
      "Epoch 255/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 120.0730 - val_loss: 647.1297\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 181.07150\n",
      "Epoch 256/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 123.2854 - val_loss: 798.5706\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 181.07150\n",
      "Epoch 257/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 125.2630 - val_loss: 633.7131\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 181.07150\n",
      "Epoch 258/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 123.1573 - val_loss: 634.0190\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 181.07150\n",
      "Epoch 259/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 125.6726 - val_loss: 468.8225\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 181.07150\n",
      "Epoch 260/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 120.2261 - val_loss: 613.6207\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 181.07150\n",
      "Epoch 261/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 121.0916 - val_loss: 657.9514\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 181.07150\n",
      "Epoch 262/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.9494 - val_loss: 563.9967\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 181.07150\n",
      "Epoch 263/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 117.8655 - val_loss: 841.3973\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 181.07150\n",
      "Epoch 264/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.7322 - val_loss: 612.2794\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 181.07150\n",
      "Epoch 265/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.5642 - val_loss: 892.1867\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 181.07150\n",
      "Epoch 266/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 118.9991 - val_loss: 674.0406\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 181.07150\n",
      "Epoch 267/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.1455 - val_loss: 506.1441\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 181.07150\n",
      "Epoch 268/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 123.8387 - val_loss: 695.1086\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 181.07150\n",
      "Epoch 269/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 119.2049 - val_loss: 605.6699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▉                                                                              | 1/21 [01:57<39:06, 117.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00269: val_loss did not improve from 181.07150\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 297.4775 - val_loss: 143.8437\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 143.84373, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 193.0849 - val_loss: 504.7486\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 143.84373\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 180.8760 - val_loss: 470.3834\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 143.84373\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 177.7489 - val_loss: 131.8515\n",
      "\n",
      "Epoch 00004: val_loss improved from 143.84373 to 131.85146, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 180.2538 - val_loss: 149.5620\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 131.85146\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 180.1195 - val_loss: 184.6594\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 131.85146\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 185.4553 - val_loss: 274.2880\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 131.85146\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 210.2390 - val_loss: 418.0243\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 131.85146\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 993us/step - loss: 191.6039 - val_loss: 399.9571\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 131.85146\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 171.7321 - val_loss: 123.9977\n",
      "\n",
      "Epoch 00010: val_loss improved from 131.85146 to 123.99766, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 198.1906 - val_loss: 369.8123\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 123.99766\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 181.9696 - val_loss: 196.7101\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 123.99766\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 187.2037 - val_loss: 369.9030\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 123.99766\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 178.5512 - val_loss: 124.3790\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 123.99766\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.2931 - val_loss: 320.9789\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 123.99766\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.5595 - val_loss: 342.6462\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 123.99766\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 190.4578 - val_loss: 121.2818\n",
      "\n",
      "Epoch 00017: val_loss improved from 123.99766 to 121.28184, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 990us/step - loss: 163.9666 - val_loss: 120.2155\n",
      "\n",
      "Epoch 00018: val_loss improved from 121.28184 to 120.21548, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 175.2777 - val_loss: 124.1893\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 120.21548\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 179.8619 - val_loss: 130.4964\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 120.21548\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 185.5200 - val_loss: 397.6334\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 120.21548\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 172.4537 - val_loss: 386.3024\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 120.21548\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.7069 - val_loss: 126.8556\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 120.21548\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 975us/step - loss: 166.1853 - val_loss: 127.9858\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 120.21548\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 171.7043 - val_loss: 297.2912\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 120.21548\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.9717 - val_loss: 201.7664\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 120.21548\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 163.6904 - val_loss: 354.2766\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 120.21548\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.3209 - val_loss: 434.1666\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 120.21548\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 172.2361 - val_loss: 117.3590\n",
      "\n",
      "Epoch 00029: val_loss improved from 120.21548 to 117.35899, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 160.6937 - val_loss: 499.2457\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 117.35899\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.9971 - val_loss: 224.9995\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 117.35899\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.1359 - val_loss: 127.4959\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 117.35899\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 152.0162 - val_loss: 328.1223\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 117.35899\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.6937 - val_loss: 403.1718\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 117.35899\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 164.9288 - val_loss: 320.7711\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 117.35899\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.0428 - val_loss: 150.1996\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 117.35899\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 165.4787 - val_loss: 143.2910\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 117.35899\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.8796 - val_loss: 268.7464\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 117.35899\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.4919 - val_loss: 384.4330\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 117.35899\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.7671 - val_loss: 267.9818\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 117.35899\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.4435 - val_loss: 228.5797\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 117.35899\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.6062 - val_loss: 339.9593\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 117.35899\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.1872 - val_loss: 124.6268\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 117.35899\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.5374 - val_loss: 165.3043\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 117.35899\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.1293 - val_loss: 146.4790\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 117.35899\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.7387 - val_loss: 387.8755\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 117.35899\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.8723 - val_loss: 115.8058\n",
      "\n",
      "Epoch 00047: val_loss improved from 117.35899 to 115.80585, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.5983 - val_loss: 277.8005\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 115.80585\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.8105 - val_loss: 270.1413\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 115.80585\n",
      "Epoch 50/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 146.5597 - val_loss: 209.5572\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 115.80585\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.7126 - val_loss: 118.2039\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 115.80585\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.5520 - val_loss: 122.7412\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 115.80585\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.1605 - val_loss: 125.1377\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 115.80585\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.4884 - val_loss: 139.8657\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 115.80585\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.6680 - val_loss: 296.9140\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 115.80585\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.6691 - val_loss: 161.6030\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 115.80585\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 129.5218 - val_loss: 317.1686\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 115.80585\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.8168 - val_loss: 175.7863\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 115.80585\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.2333 - val_loss: 126.7682\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 115.80585\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.9002 - val_loss: 161.2297\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 115.80585\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.1186 - val_loss: 296.6988\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 115.80585\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.9894 - val_loss: 250.0608\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 115.80585\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.5609 - val_loss: 196.2285\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 115.80585\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 127.4136 - val_loss: 120.7766\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 115.80585\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.2217 - val_loss: 264.2757\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 115.80585\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.4284 - val_loss: 375.9986\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 115.80585\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 126.8939 - val_loss: 249.5509\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 115.80585\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.8943 - val_loss: 159.4639\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 115.80585\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 125.8214 - val_loss: 136.9862\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 115.80585\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.3517 - val_loss: 391.1296\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 115.80585\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.0323 - val_loss: 143.9193\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 115.80585\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 129.2856 - val_loss: 124.0368\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 115.80585\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.7715 - val_loss: 209.3068\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 115.80585\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.5003 - val_loss: 176.0208\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 115.80585\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.1182 - val_loss: 127.7673\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 115.80585\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.4958 - val_loss: 129.0897\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 115.80585\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.4064 - val_loss: 230.5747\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 115.80585\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.6065 - val_loss: 214.8202\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 115.80585\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.0168 - val_loss: 140.3021\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 115.80585\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.5575 - val_loss: 193.2490\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 115.80585\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.7062 - val_loss: 274.6480\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 115.80585\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.8770 - val_loss: 179.0862\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 115.80585\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.9806 - val_loss: 227.4333\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 115.80585\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.6945 - val_loss: 426.1677\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 115.80585\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.3605 - val_loss: 230.3875\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 115.80585\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 112.7672 - val_loss: 127.4391\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 115.80585\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.6207 - val_loss: 301.5902\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 115.80585\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.7351 - val_loss: 275.3079\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 115.80585\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 101.2583 - val_loss: 254.1620\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 115.80585\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 100.4292 - val_loss: 124.0106\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 115.80585\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.7550 - val_loss: 135.9110\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 115.80585\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.6145 - val_loss: 120.7706\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 115.80585\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.5073 - val_loss: 247.1084\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 115.80585\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.2087 - val_loss: 188.8987\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 115.80585\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 99.6273 - val_loss: 181.6037\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 115.80585\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.9376 - val_loss: 123.5248\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 115.80585\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 100.1540 - val_loss: 215.7059\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 115.80585\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.0483 - val_loss: 149.5769\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 115.80585\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.3963 - val_loss: 131.2070\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 115.80585\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.9029 - val_loss: 190.8361\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 115.80585\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.3058 - val_loss: 214.5071\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 115.80585\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 97.3648 - val_loss: 143.6983\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 115.80585\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.8213 - val_loss: 157.3293\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 115.80585\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.9340 - val_loss: 125.2732\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 115.80585\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 100.3560 - val_loss: 262.5417\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 115.80585\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 97.2435 - val_loss: 140.0911\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 115.80585\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 91.9518 - val_loss: 202.4981\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 115.80585\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 94.5678 - val_loss: 142.3350\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 115.80585\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 93.2444 - val_loss: 127.8454\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 115.80585\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 94.3948 - val_loss: 217.9840\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 115.80585\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.2968 - val_loss: 149.2489\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 115.80585\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.6818 - val_loss: 140.0322\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 115.80585\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.0050 - val_loss: 130.4304\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 115.80585\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.9015 - val_loss: 166.0257\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 115.80585\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.3309 - val_loss: 186.2766\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 115.80585\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.4290 - val_loss: 218.7755\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 115.80585\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 92.9553 - val_loss: 251.6224\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 115.80585\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.1692 - val_loss: 258.7251\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 115.80585\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.8918 - val_loss: 194.5082\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 115.80585\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.2592 - val_loss: 138.4695\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 115.80585\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.9082 - val_loss: 217.8544\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 115.80585\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.1595 - val_loss: 235.7221\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 115.80585\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 92.6220 - val_loss: 140.3284\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 115.80585\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.3002 - val_loss: 164.9851\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 115.80585\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.6595 - val_loss: 133.2224\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 115.80585\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 86.6400 - val_loss: 128.0376\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 115.80585\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.1453 - val_loss: 130.6276\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 115.80585\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 92.9407 - val_loss: 119.6113\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 115.80585\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.2285 - val_loss: 131.0841\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 115.80585\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.1506 - val_loss: 161.6254\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 115.80585\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 975us/step - loss: 90.6741 - val_loss: 127.1763\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 115.80585\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 86.0223 - val_loss: 134.5542\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 115.80585\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 87.5728 - val_loss: 136.1387\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 115.80585\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.2981 - val_loss: 134.1272\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 115.80585\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.7035 - val_loss: 196.9063\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 115.80585\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.8781 - val_loss: 173.5835\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 115.80585\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.6290 - val_loss: 138.9740\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 115.80585\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.9966 - val_loss: 187.8746\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 115.80585\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 86.8816 - val_loss: 241.8331\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 115.80585\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 87.1082 - val_loss: 122.1389\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 115.80585\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 83.8744 - val_loss: 206.7914\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 115.80585\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 86.0923 - val_loss: 189.2349\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 115.80585\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.0108 - val_loss: 150.2199\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 115.80585\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.3657 - val_loss: 143.9694\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 115.80585\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.9158 - val_loss: 169.8241\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 115.80585\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.1961 - val_loss: 135.6914\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 115.80585\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.7247 - val_loss: 207.4942\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 115.80585\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 358.3260 - val_loss: 287.8205\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 287.82053, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 191.3765 - val_loss: 278.1681\n",
      "\n",
      "Epoch 00002: val_loss improved from 287.82053 to 278.16809, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 182.3389 - val_loss: 321.4232\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 278.16809\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 181.4391 - val_loss: 347.4763\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 278.16809\n",
      "Epoch 5/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 178.4208 - val_loss: 186.3105\n",
      "\n",
      "Epoch 00005: val_loss improved from 278.16809 to 186.31050, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 189.3341 - val_loss: 163.4106\n",
      "\n",
      "Epoch 00006: val_loss improved from 186.31050 to 163.41064, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 966us/step - loss: 177.5512 - val_loss: 150.0668\n",
      "\n",
      "Epoch 00007: val_loss improved from 163.41064 to 150.06680, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 183.2894 - val_loss: 506.5359\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 150.06680\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 176.2054 - val_loss: 138.5802\n",
      "\n",
      "Epoch 00009: val_loss improved from 150.06680 to 138.58020, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 186.2751 - val_loss: 321.1992\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 138.58020\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 180.6833 - val_loss: 148.2145\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 138.58020\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 176.0674 - val_loss: 458.0760\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 138.58020\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 188.7847 - val_loss: 290.3085\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 138.58020\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 173.8091 - val_loss: 184.4731\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 138.58020\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 176.0513 - val_loss: 561.8373\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 138.58020\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 188.5201 - val_loss: 409.5057\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 138.58020\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 175.9734 - val_loss: 272.0710\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 138.58020\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 180.2426 - val_loss: 533.2075\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 138.58020\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 176.6499 - val_loss: 428.9057\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 138.58020\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 188.5091 - val_loss: 397.3726\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 138.58020\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 180.7883 - val_loss: 585.4655\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 138.58020\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 184.0672 - val_loss: 475.9057\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 138.58020\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 182.3953 - val_loss: 129.6736\n",
      "\n",
      "Epoch 00023: val_loss improved from 138.58020 to 129.67360, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 176.6556 - val_loss: 379.3256\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 129.67360\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 174.3912 - val_loss: 278.4047\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 129.67360\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 183.5412 - val_loss: 131.4068\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 129.67360\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 177.4695 - val_loss: 380.5743\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 129.67360\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 179.5226 - val_loss: 363.2197\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 129.67360\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 179.0799 - val_loss: 135.2593\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 129.67360\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.9980 - val_loss: 398.2065\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 129.67360\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 177.5827 - val_loss: 490.5946\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 129.67360\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 971us/step - loss: 172.9970 - val_loss: 130.6994\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 129.67360\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 987us/step - loss: 167.8829 - val_loss: 334.2357\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 129.67360\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 173.8199 - val_loss: 239.0660\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 129.67360\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 984us/step - loss: 156.4174 - val_loss: 128.2720\n",
      "\n",
      "Epoch 00035: val_loss improved from 129.67360 to 128.27196, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 993us/step - loss: 167.1823 - val_loss: 347.5021\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 128.27196\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 995us/step - loss: 167.2246 - val_loss: 153.6606\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 128.27196\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.6612 - val_loss: 341.3849\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 128.27196\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.3578 - val_loss: 228.3167\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 128.27196\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.8486 - val_loss: 550.2838\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 128.27196\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.1408 - val_loss: 382.4508\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 128.27196\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 995us/step - loss: 156.4890 - val_loss: 363.9755\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 128.27196\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 163.6129 - val_loss: 326.5996\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 128.27196\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 160.1647 - val_loss: 299.5435\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 128.27196\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.5822 - val_loss: 139.4789\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 128.27196\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.1297 - val_loss: 212.9087\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 128.27196\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 168.7422 - val_loss: 149.1557\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 128.27196\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 163.2946 - val_loss: 350.0226\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 128.27196\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 164.8335 - val_loss: 385.0393\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 128.27196\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.5585 - val_loss: 145.3945\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 128.27196\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.7032 - val_loss: 490.7184\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 128.27196\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 161.2301 - val_loss: 132.0139\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 128.27196\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.0944 - val_loss: 209.6071\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 128.27196\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.0727 - val_loss: 156.7543\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 128.27196\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.1564 - val_loss: 147.7786\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 128.27196\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.1432 - val_loss: 339.6477\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 128.27196\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.5671 - val_loss: 312.3167\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 128.27196\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.2975 - val_loss: 210.8393\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 128.27196\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.0692 - val_loss: 340.9788\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 128.27196\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.1552 - val_loss: 137.4674\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 128.27196\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.6620 - val_loss: 401.3824\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 128.27196\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.4645 - val_loss: 315.2758\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 128.27196\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.0429 - val_loss: 146.3847\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 128.27196\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.9815 - val_loss: 166.2318\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 128.27196\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.5431 - val_loss: 155.8716\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 128.27196\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.1907 - val_loss: 228.1329\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 128.27196\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.0552 - val_loss: 303.4761\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 128.27196\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.7497 - val_loss: 356.1831\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 128.27196\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.0853 - val_loss: 152.8485\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 128.27196\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.6732 - val_loss: 148.1666\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 128.27196\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.0954 - val_loss: 318.4718\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 128.27196\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.3649 - val_loss: 164.8591\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 128.27196\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.1049 - val_loss: 132.3894\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 128.27196\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.5874 - val_loss: 128.4056\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 128.27196\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.3385 - val_loss: 137.5017\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 128.27196\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 127.9604 - val_loss: 189.8332\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 128.27196\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 128.7055 - val_loss: 205.2622\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 128.27196\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.1691 - val_loss: 164.2777\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 128.27196\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.1995 - val_loss: 215.8588\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 128.27196\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 125.5234 - val_loss: 365.2805\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 128.27196\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 128.7802 - val_loss: 130.4682\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 128.27196\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.1329 - val_loss: 149.3609\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 128.27196\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.1405 - val_loss: 274.3641\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 128.27196\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 128.4711 - val_loss: 175.3768\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 128.27196\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 131.4898 - val_loss: 164.1063\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 128.27196\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.9430 - val_loss: 348.7327\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 128.27196\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.0472 - val_loss: 177.9585\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 128.27196\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 129.0704 - val_loss: 143.0593\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 128.27196\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.5410 - val_loss: 149.9696\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 128.27196\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.9634 - val_loss: 322.9962\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 128.27196\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.9739 - val_loss: 157.2110\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 128.27196\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 125.1171 - val_loss: 164.6404\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 128.27196\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.5412 - val_loss: 245.7744\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 128.27196\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.9629 - val_loss: 149.7606\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 128.27196\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.6195 - val_loss: 125.2787\n",
      "\n",
      "Epoch 00095: val_loss improved from 128.27196 to 125.27871, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.9082 - val_loss: 133.2370\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 125.27871\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.6648 - val_loss: 142.4373\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 125.27871\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 112.1386 - val_loss: 143.7978\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 125.27871\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 112.3875 - val_loss: 127.6994\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 125.27871\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.8075 - val_loss: 405.6880\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 125.27871\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.8144 - val_loss: 186.8955\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 125.27871\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.0274 - val_loss: 127.9885\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 125.27871\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.9183 - val_loss: 139.7453\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 125.27871\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 112.6575 - val_loss: 180.7748\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 125.27871\n",
      "Epoch 105/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 111.1483 - val_loss: 345.9259\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 125.27871\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.4850 - val_loss: 282.1147\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 125.27871\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 993us/step - loss: 111.8888 - val_loss: 185.6023\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 125.27871\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.5133 - val_loss: 266.9086\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 125.27871\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.5233 - val_loss: 322.1219\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 125.27871\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.8154 - val_loss: 216.9863\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 125.27871\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.9985 - val_loss: 223.5265\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 125.27871\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.4938 - val_loss: 156.9224\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 125.27871\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.4446 - val_loss: 123.4552\n",
      "\n",
      "Epoch 00113: val_loss improved from 125.27871 to 123.45519, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.6852 - val_loss: 152.3451\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 123.45519\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.8275 - val_loss: 265.3565\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 123.45519\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.8793 - val_loss: 125.1310\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 123.45519\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.5978 - val_loss: 139.5736\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 123.45519\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 100.9902 - val_loss: 323.0890\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 123.45519\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.3462 - val_loss: 136.1118\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 123.45519\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.7477 - val_loss: 158.3504\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 123.45519\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.6651 - val_loss: 305.5112\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 123.45519\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.1309 - val_loss: 259.9346\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 123.45519\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.0846 - val_loss: 133.3853\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 123.45519\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.8727 - val_loss: 265.7546\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 123.45519\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.0153 - val_loss: 163.8946\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 123.45519\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.3965 - val_loss: 234.2540\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 123.45519\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.6579 - val_loss: 185.4129\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 123.45519\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.6930 - val_loss: 229.6632\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 123.45519\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.6966 - val_loss: 389.6505\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 123.45519\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.4099 - val_loss: 162.3610\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 123.45519\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.4238 - val_loss: 145.3212\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 123.45519\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 100.6327 - val_loss: 191.7189\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 123.45519\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.2993 - val_loss: 131.1850\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 123.45519\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 101.5108 - val_loss: 163.9448\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 123.45519\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.4796 - val_loss: 139.2563\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 123.45519\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.7972 - val_loss: 254.4138\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 123.45519\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.1336 - val_loss: 147.0620\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 123.45519\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.9689 - val_loss: 179.9435\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 123.45519\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.2121 - val_loss: 135.9741\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 123.45519\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 101.1540 - val_loss: 142.7365\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 123.45519\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.7241 - val_loss: 121.9034\n",
      "\n",
      "Epoch 00141: val_loss improved from 123.45519 to 121.90341, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.4228 - val_loss: 133.2983\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 121.90341\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.7809 - val_loss: 176.4735\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 121.90341\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.7580 - val_loss: 130.3847\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 121.90341\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 95.8422 - val_loss: 240.7597\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 121.90341\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.1734 - val_loss: 162.2396\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 121.90341\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.6692 - val_loss: 137.4398\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 121.90341\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.9142 - val_loss: 163.6378\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 121.90341\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 95.8942 - val_loss: 142.7342\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 121.90341\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.7628 - val_loss: 151.9751\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 121.90341\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.7368 - val_loss: 302.3679\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 121.90341\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.0861 - val_loss: 180.3363\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 121.90341\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 92.7936 - val_loss: 174.0054\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 121.90341\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.3078 - val_loss: 151.4217\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 121.90341\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.7450 - val_loss: 159.9440\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 121.90341\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 97.1055 - val_loss: 151.9582\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 121.90341\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.5404 - val_loss: 151.3559\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 121.90341\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.3851 - val_loss: 186.2747\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 121.90341\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.0113 - val_loss: 197.2105\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 121.90341\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.3104 - val_loss: 267.4684\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 121.90341\n",
      "Epoch 161/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.7285 - val_loss: 166.4107\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 121.90341\n",
      "Epoch 162/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.7337 - val_loss: 174.0598\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 121.90341\n",
      "Epoch 163/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 95.3726 - val_loss: 131.7104\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 121.90341\n",
      "Epoch 164/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.6057 - val_loss: 131.4697\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 121.90341\n",
      "Epoch 165/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.8206 - val_loss: 113.1479\n",
      "\n",
      "Epoch 00165: val_loss improved from 121.90341 to 113.14791, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 166/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 92.4231 - val_loss: 136.1773\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 113.14791\n",
      "Epoch 167/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.3273 - val_loss: 178.2337\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 113.14791\n",
      "Epoch 168/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.5998 - val_loss: 148.1259\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 113.14791\n",
      "Epoch 169/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.7089 - val_loss: 214.0114\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 113.14791\n",
      "Epoch 170/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 95.5204 - val_loss: 228.9419\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 113.14791\n",
      "Epoch 171/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.8439 - val_loss: 125.9588\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 113.14791\n",
      "Epoch 172/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.1801 - val_loss: 190.1284\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 113.14791\n",
      "Epoch 173/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.5714 - val_loss: 157.2889\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 113.14791\n",
      "Epoch 174/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.3342 - val_loss: 146.1511\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 113.14791\n",
      "Epoch 175/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.5923 - val_loss: 133.5782\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 113.14791\n",
      "Epoch 176/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.1629 - val_loss: 188.9503\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 113.14791\n",
      "Epoch 177/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.5634 - val_loss: 160.7267\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 113.14791\n",
      "Epoch 178/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.5555 - val_loss: 253.1770\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 113.14791\n",
      "Epoch 179/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.0720 - val_loss: 171.9153\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 113.14791\n",
      "Epoch 180/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.3867 - val_loss: 141.3116\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 113.14791\n",
      "Epoch 181/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.5767 - val_loss: 135.0631\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 113.14791\n",
      "Epoch 182/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.5636 - val_loss: 142.0979\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 113.14791\n",
      "Epoch 183/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.5862 - val_loss: 144.1286\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 113.14791\n",
      "Epoch 184/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 89.1712 - val_loss: 133.7308\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 113.14791\n",
      "Epoch 185/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.3726 - val_loss: 156.1969\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 113.14791\n",
      "Epoch 186/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.2099 - val_loss: 209.0056\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 113.14791\n",
      "Epoch 187/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.6655 - val_loss: 304.6875\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 113.14791\n",
      "Epoch 188/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.2927 - val_loss: 136.8222\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 113.14791\n",
      "Epoch 189/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.0024 - val_loss: 151.6380\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 113.14791\n",
      "Epoch 190/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 87.7897 - val_loss: 149.4974\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 113.14791\n",
      "Epoch 191/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 85.8995 - val_loss: 146.8207\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 113.14791\n",
      "Epoch 192/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.6908 - val_loss: 160.0444\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 113.14791\n",
      "Epoch 193/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 85.7429 - val_loss: 131.3268\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 113.14791\n",
      "Epoch 194/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.4499 - val_loss: 147.8199\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 113.14791\n",
      "Epoch 195/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.2035 - val_loss: 136.7220\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 113.14791\n",
      "Epoch 196/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.5149 - val_loss: 126.7673\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 113.14791\n",
      "Epoch 197/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.9166 - val_loss: 140.8616\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 113.14791\n",
      "Epoch 198/10000\n",
      "89/89 [==============================] - 0s 973us/step - loss: 87.4107 - val_loss: 133.7943\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 113.14791\n",
      "Epoch 199/10000\n",
      "89/89 [==============================] - 0s 986us/step - loss: 90.4924 - val_loss: 145.1235\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 113.14791\n",
      "Epoch 200/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 85.3491 - val_loss: 195.8183\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 113.14791\n",
      "Epoch 201/10000\n",
      "89/89 [==============================] - 0s 1000us/step - loss: 87.8270 - val_loss: 184.9080\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 113.14791\n",
      "Epoch 202/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.1650 - val_loss: 160.9640\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 113.14791\n",
      "Epoch 203/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 86.7930 - val_loss: 241.6142\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 113.14791\n",
      "Epoch 204/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.4539 - val_loss: 162.9926\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 113.14791\n",
      "Epoch 205/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.2008 - val_loss: 154.0613\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 113.14791\n",
      "Epoch 206/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 84.4542 - val_loss: 172.5110\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 113.14791\n",
      "Epoch 207/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.2908 - val_loss: 138.2167\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 113.14791\n",
      "Epoch 208/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.7388 - val_loss: 156.9862\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 113.14791\n",
      "Epoch 209/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 83.9155 - val_loss: 156.6578\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 113.14791\n",
      "Epoch 210/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.1297 - val_loss: 128.4116\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 113.14791\n",
      "Epoch 211/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.3170 - val_loss: 240.0517\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 113.14791\n",
      "Epoch 212/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 85.9164 - val_loss: 144.3306\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 113.14791\n",
      "Epoch 213/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.2501 - val_loss: 198.8932\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 113.14791\n",
      "Epoch 214/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 83.8421 - val_loss: 369.8397\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 113.14791\n",
      "Epoch 215/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 86.4661 - val_loss: 306.4464\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 113.14791\n",
      "Epoch 216/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.4405 - val_loss: 134.2468\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 113.14791\n",
      "Epoch 217/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.4749 - val_loss: 131.3920\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 113.14791\n",
      "Epoch 218/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.3593 - val_loss: 199.0134\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 113.14791\n",
      "Epoch 219/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.1102 - val_loss: 154.5152\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 113.14791\n",
      "Epoch 220/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.6187 - val_loss: 192.4653\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 113.14791\n",
      "Epoch 221/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.1800 - val_loss: 172.9997\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 113.14791\n",
      "Epoch 222/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.6499 - val_loss: 124.1852\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 113.14791\n",
      "Epoch 223/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.9949 - val_loss: 130.5741\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 113.14791\n",
      "Epoch 224/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.4037 - val_loss: 233.6362\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 113.14791\n",
      "Epoch 225/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.5434 - val_loss: 159.4725\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 113.14791\n",
      "Epoch 226/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 83.9963 - val_loss: 166.6522\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 113.14791\n",
      "Epoch 227/10000\n",
      "89/89 [==============================] - 0s 990us/step - loss: 82.8634 - val_loss: 127.3803\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 113.14791\n",
      "Epoch 228/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.5664 - val_loss: 119.0210\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 113.14791\n",
      "Epoch 229/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.9645 - val_loss: 121.5591\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 113.14791\n",
      "Epoch 230/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.8619 - val_loss: 127.1841\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 113.14791\n",
      "Epoch 231/10000\n",
      "89/89 [==============================] - 0s 991us/step - loss: 80.4982 - val_loss: 338.0392\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 113.14791\n",
      "Epoch 232/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.4605 - val_loss: 135.0997\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 113.14791\n",
      "Epoch 233/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.9519 - val_loss: 144.3331\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 113.14791\n",
      "Epoch 234/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.1013 - val_loss: 182.9346\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 113.14791\n",
      "Epoch 235/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.6716 - val_loss: 142.7230\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 113.14791\n",
      "Epoch 236/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.2266 - val_loss: 135.6364\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 113.14791\n",
      "Epoch 237/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.7313 - val_loss: 136.5230\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 113.14791\n",
      "Epoch 238/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.4101 - val_loss: 140.7926\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 113.14791\n",
      "Epoch 239/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.5121 - val_loss: 200.2575\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 113.14791\n",
      "Epoch 240/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.0927 - val_loss: 151.9109\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 113.14791\n",
      "Epoch 241/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.1833 - val_loss: 236.2460\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 113.14791\n",
      "Epoch 242/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 83.8269 - val_loss: 303.5984\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 113.14791\n",
      "Epoch 243/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.9418 - val_loss: 196.6563\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 113.14791\n",
      "Epoch 244/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.8314 - val_loss: 130.2212\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 113.14791\n",
      "Epoch 245/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.2374 - val_loss: 155.2983\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 113.14791\n",
      "Epoch 246/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.9302 - val_loss: 159.2785\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 113.14791\n",
      "Epoch 247/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.3024 - val_loss: 150.3914\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 113.14791\n",
      "Epoch 248/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.0775 - val_loss: 152.5425\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 113.14791\n",
      "Epoch 249/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.3567 - val_loss: 179.2017\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 113.14791\n",
      "Epoch 250/10000\n",
      "89/89 [==============================] - 0s 999us/step - loss: 79.6770 - val_loss: 237.6877\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 113.14791\n",
      "Epoch 251/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.4170 - val_loss: 137.5370\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 113.14791\n",
      "Epoch 252/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.6730 - val_loss: 174.2038\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 113.14791\n",
      "Epoch 253/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.8314 - val_loss: 143.5946\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 113.14791\n",
      "Epoch 254/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.1986 - val_loss: 144.8516\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 113.14791\n",
      "Epoch 255/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.0220 - val_loss: 129.4715\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 113.14791\n",
      "Epoch 256/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 72.5220 - val_loss: 148.2521\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 113.14791\n",
      "Epoch 257/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.6579 - val_loss: 170.0291\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 113.14791\n",
      "Epoch 258/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.6504 - val_loss: 158.9898\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 113.14791\n",
      "Epoch 259/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.1796 - val_loss: 339.7875\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 113.14791\n",
      "Epoch 260/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.0569 - val_loss: 174.6453\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 113.14791\n",
      "Epoch 261/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.4170 - val_loss: 141.3436\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 113.14791\n",
      "Epoch 262/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.2221 - val_loss: 144.4028\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 113.14791\n",
      "Epoch 263/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.5663 - val_loss: 147.5185\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 113.14791\n",
      "Epoch 264/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.8967 - val_loss: 208.9526\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 113.14791\n",
      "Epoch 265/10000\n",
      "89/89 [==============================] - 0s 962us/step - loss: 78.1107 - val_loss: 170.4736\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 113.14791\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 366.8545 - val_loss: 167.1242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 167.12422, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 937us/step - loss: 203.8533 - val_loss: 295.2020\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 167.12422\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 958us/step - loss: 198.1120 - val_loss: 219.4589\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 167.12422\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 973us/step - loss: 195.7588 - val_loss: 489.9492\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 167.12422\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 956us/step - loss: 187.7137 - val_loss: 401.0147\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 167.12422\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 959us/step - loss: 191.0336 - val_loss: 370.6882\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 167.12422\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 187.0123 - val_loss: 263.8360\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 167.12422\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 970us/step - loss: 197.1606 - val_loss: 214.6938\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 167.12422\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 195.5946 - val_loss: 222.2100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 167.12422\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 187.2154 - val_loss: 217.4828\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 167.12422\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 194.5331 - val_loss: 244.6026\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 167.12422\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 184.5287 - val_loss: 213.8696\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 167.12422\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 188.1547 - val_loss: 270.7478\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 167.12422\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 993us/step - loss: 186.6905 - val_loss: 288.0182\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 167.12422\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1000us/step - loss: 181.0004 - val_loss: 460.0891\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 167.12422\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 187.1208 - val_loss: 188.4162\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 167.12422\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 188.4115 - val_loss: 515.5096\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 167.12422\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 184.7058 - val_loss: 531.2524\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 167.12422\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 189.8456 - val_loss: 179.9313\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 167.12422\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 187.4495 - val_loss: 459.2072\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 167.12422\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 190.9949 - val_loss: 362.2895\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 167.12422\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 184.1409 - val_loss: 267.5776\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 167.12422\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 179.4901 - val_loss: 136.0444\n",
      "\n",
      "Epoch 00023: val_loss improved from 167.12422 to 136.04445, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 179.9433 - val_loss: 443.7434\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 136.04445\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 180.2688 - val_loss: 220.3343\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 136.04445\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 188.2069 - val_loss: 289.9944\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 136.04445\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 184.2121 - val_loss: 300.3734\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 136.04445\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 181.8834 - val_loss: 140.2714\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 136.04445\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 174.6671 - val_loss: 158.4474\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 136.04445\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 175.1385 - val_loss: 140.7347\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 136.04445\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 180.3186 - val_loss: 271.4611\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 136.04445\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 183.4050 - val_loss: 439.1563\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 136.04445\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 178.0893 - val_loss: 158.1584\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 136.04445\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 184.0234 - val_loss: 199.1420\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 136.04445\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 182.5319 - val_loss: 332.7146\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 136.04445\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 173.2394 - val_loss: 291.8562\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 136.04445\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 180.0471 - val_loss: 174.8909\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 136.04445\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 166.1687 - val_loss: 202.2923\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 136.04445\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 171.7554 - val_loss: 150.1986\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 136.04445\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 168.2335 - val_loss: 316.1165\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 136.04445\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 180.6724 - val_loss: 381.2850\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 136.04445\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 175.4775 - val_loss: 337.6534\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 136.04445\n",
      "Epoch 43/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 162.9086 - val_loss: 168.9123\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 136.04445\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 176.2460 - val_loss: 131.1947\n",
      "\n",
      "Epoch 00044: val_loss improved from 136.04445 to 131.19473, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 173.8951 - val_loss: 425.9864\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 131.19473\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 167.7618 - val_loss: 159.5234\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 131.19473\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 164.3143 - val_loss: 134.5917\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 131.19473\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 166.6942 - val_loss: 202.4966\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 131.19473\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 160.9977 - val_loss: 449.7902\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 131.19473\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 163.2607 - val_loss: 237.6180\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 131.19473\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 166.7664 - val_loss: 151.2104\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 131.19473\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 159.1452 - val_loss: 249.9602\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 131.19473\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 158.8272 - val_loss: 352.6967\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 131.19473\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 171.9808 - val_loss: 180.1564\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 131.19473\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 158.4100 - val_loss: 213.4571\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 131.19473\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 159.3623 - val_loss: 165.9256\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 131.19473\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 166.7080 - val_loss: 147.4876\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 131.19473\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 165.5962 - val_loss: 314.7276\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 131.19473\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 166.7856 - val_loss: 216.6645\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 131.19473\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 163.3864 - val_loss: 216.6564\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 131.19473\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 163.4106 - val_loss: 199.2640\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 131.19473\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 158.7738 - val_loss: 161.1655\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 131.19473\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.0121 - val_loss: 257.3260\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 131.19473\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 164.1122 - val_loss: 128.6695\n",
      "\n",
      "Epoch 00064: val_loss improved from 131.19473 to 128.66948, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 166.8263 - val_loss: 151.2666\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 128.66948\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 160.0068 - val_loss: 342.1303\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 128.66948\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 158.3608 - val_loss: 145.1871\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 128.66948\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 155.5938 - val_loss: 153.7714\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 128.66948\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 154.6266 - val_loss: 373.9854\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 128.66948\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 160.6030 - val_loss: 164.7484\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 128.66948\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.7995 - val_loss: 138.7525\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 128.66948\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 155.5085 - val_loss: 335.0445\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 128.66948\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 155.7029 - val_loss: 237.7846\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 128.66948\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 158.6089 - val_loss: 237.7997\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 128.66948\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.0624 - val_loss: 136.4331\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 128.66948\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 158.0857 - val_loss: 137.2791\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 128.66948\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.4405 - val_loss: 194.7456\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 128.66948\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 153.6080 - val_loss: 123.9089\n",
      "\n",
      "Epoch 00078: val_loss improved from 128.66948 to 123.90893, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 998us/step - loss: 143.5701 - val_loss: 130.1071\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 123.90893\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.0897 - val_loss: 211.9339\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 123.90893\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 152.6301 - val_loss: 119.3248\n",
      "\n",
      "Epoch 00081: val_loss improved from 123.90893 to 119.32481, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 153.2636 - val_loss: 126.8768\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 119.32481\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.1581 - val_loss: 324.3384\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 119.32481\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 154.9320 - val_loss: 175.8504\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 119.32481\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 149.6157 - val_loss: 186.8418\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 119.32481\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 154.0545 - val_loss: 122.8906\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 119.32481\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 152.4829 - val_loss: 273.1163\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 119.32481\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.0265 - val_loss: 178.3765\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 119.32481\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 153.4842 - val_loss: 117.6398\n",
      "\n",
      "Epoch 00089: val_loss improved from 119.32481 to 117.63978, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 152.0369 - val_loss: 209.3967\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 117.63978\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 150.4951 - val_loss: 426.8577\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 117.63978\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 155.0905 - val_loss: 175.6961\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 117.63978\n",
      "Epoch 93/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 151.8563 - val_loss: 159.2295\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 117.63978\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 151.2739 - val_loss: 169.8822\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 117.63978\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.0135 - val_loss: 272.6266\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 117.63978\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 149.8197 - val_loss: 119.6813\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 117.63978\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.0291 - val_loss: 345.0620\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 117.63978\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.7327 - val_loss: 231.6067\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 117.63978\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.3468 - val_loss: 362.3291\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 117.63978\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.0188 - val_loss: 188.5424\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 117.63978\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 149.1843 - val_loss: 216.5618\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 117.63978\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.0282 - val_loss: 264.7301\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 117.63978\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.9746 - val_loss: 311.5406\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 117.63978\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.0950 - val_loss: 188.0387\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 117.63978\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 152.0231 - val_loss: 251.3539\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 117.63978\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.2362 - val_loss: 363.3878\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 117.63978\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.9697 - val_loss: 251.5944\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 117.63978\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.4024 - val_loss: 236.0723\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 117.63978\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 149.5261 - val_loss: 233.8495\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 117.63978\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.1139 - val_loss: 117.8867\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 117.63978\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.2118 - val_loss: 256.9691\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 117.63978\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 150.1091 - val_loss: 326.9694\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 117.63978\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.2286 - val_loss: 300.9998\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 117.63978\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 143.5653 - val_loss: 501.6635\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 117.63978\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 150.8174 - val_loss: 286.2199\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 117.63978\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.5684 - val_loss: 116.5571\n",
      "\n",
      "Epoch 00116: val_loss improved from 117.63978 to 116.55705, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 151.2832 - val_loss: 120.6014\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 116.55705\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.5007 - val_loss: 204.8781\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 116.55705\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.3638 - val_loss: 183.2020\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 116.55705\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.1349 - val_loss: 352.2937\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 116.55705\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 147.8805 - val_loss: 135.0662\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 116.55705\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 135.9782 - val_loss: 334.6240\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 116.55705\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.0601 - val_loss: 212.9768\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 116.55705\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.4912 - val_loss: 136.4640\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 116.55705\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.4476 - val_loss: 163.6007\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 116.55705\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.2081 - val_loss: 123.4183\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 116.55705\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.8590 - val_loss: 131.3280\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 116.55705\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 147.3754 - val_loss: 186.5901\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 116.55705\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.1886 - val_loss: 189.0804\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 116.55705\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.3240 - val_loss: 286.8188\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 116.55705\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 141.2916 - val_loss: 403.1696\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 116.55705\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.9425 - val_loss: 138.5080\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 116.55705\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.6048 - val_loss: 118.8161\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 116.55705\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 137.6844 - val_loss: 157.6953\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 116.55705\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.6496 - val_loss: 222.8695\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 116.55705\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.2821 - val_loss: 390.5993\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 116.55705\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.8412 - val_loss: 173.0529\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 116.55705\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.0406 - val_loss: 319.8840\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 116.55705\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 149.9918 - val_loss: 193.2127\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 116.55705\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.2563 - val_loss: 420.2559\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 116.55705\n",
      "Epoch 141/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 137.2718 - val_loss: 482.9219\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 116.55705\n",
      "Epoch 142/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.1016 - val_loss: 320.2119\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 116.55705\n",
      "Epoch 143/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 143.6770 - val_loss: 264.9321\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 116.55705\n",
      "Epoch 144/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 134.7947 - val_loss: 153.5430\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 116.55705\n",
      "Epoch 145/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 141.2386 - val_loss: 116.3461\n",
      "\n",
      "Epoch 00145: val_loss improved from 116.55705 to 116.34608, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 146/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 141.3436 - val_loss: 143.1397\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 116.34608\n",
      "Epoch 147/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 130.3630 - val_loss: 169.5932\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 116.34608\n",
      "Epoch 148/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.5666 - val_loss: 121.0788\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 116.34608\n",
      "Epoch 149/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 134.4442 - val_loss: 119.2960\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 116.34608\n",
      "Epoch 150/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 131.1751 - val_loss: 146.3900\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 116.34608\n",
      "Epoch 151/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 130.0988 - val_loss: 119.0853\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 116.34608\n",
      "Epoch 152/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.2149 - val_loss: 164.5677\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 116.34608\n",
      "Epoch 153/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 135.7146 - val_loss: 115.3344\n",
      "\n",
      "Epoch 00153: val_loss improved from 116.34608 to 115.33444, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 154/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 129.0285 - val_loss: 300.2771\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 115.33444\n",
      "Epoch 155/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.4209 - val_loss: 177.7187\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 115.33444\n",
      "Epoch 156/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.2983 - val_loss: 149.9065\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 115.33444\n",
      "Epoch 157/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 132.0278 - val_loss: 142.6511\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 115.33444\n",
      "Epoch 158/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 130.9549 - val_loss: 125.7437\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 115.33444\n",
      "Epoch 159/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 127.6251 - val_loss: 159.2393\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 115.33444\n",
      "Epoch 160/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 124.8556 - val_loss: 179.3545\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 115.33444\n",
      "Epoch 161/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.1953 - val_loss: 134.1714\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 115.33444\n",
      "Epoch 162/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 125.5991 - val_loss: 202.3940\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 115.33444\n",
      "Epoch 163/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.4932 - val_loss: 242.7873\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 115.33444\n",
      "Epoch 164/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 129.6989 - val_loss: 189.7650\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 115.33444\n",
      "Epoch 165/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 123.4314 - val_loss: 229.3459\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 115.33444\n",
      "Epoch 166/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 127.1190 - val_loss: 235.8141\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 115.33444\n",
      "Epoch 167/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.8900 - val_loss: 303.6335\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 115.33444\n",
      "Epoch 168/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 124.6938 - val_loss: 110.6801\n",
      "\n",
      "Epoch 00168: val_loss improved from 115.33444 to 110.68011, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 169/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 126.4006 - val_loss: 156.1543\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 110.68011\n",
      "Epoch 170/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 126.0441 - val_loss: 269.5264\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 110.68011\n",
      "Epoch 171/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 124.1172 - val_loss: 185.5003\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 110.68011\n",
      "Epoch 172/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 131.3370 - val_loss: 283.7489\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 110.68011\n",
      "Epoch 173/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 121.4832 - val_loss: 385.0996\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 110.68011\n",
      "Epoch 174/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 124.9330 - val_loss: 294.9361\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 110.68011\n",
      "Epoch 175/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.4943 - val_loss: 128.4089\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 110.68011\n",
      "Epoch 176/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.3059 - val_loss: 286.1000\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 110.68011\n",
      "Epoch 177/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 117.4550 - val_loss: 163.4467\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 110.68011\n",
      "Epoch 178/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 123.7812 - val_loss: 189.4895\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 110.68011\n",
      "Epoch 179/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.0905 - val_loss: 182.6986\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 110.68011\n",
      "Epoch 180/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 123.2751 - val_loss: 208.3716\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 110.68011\n",
      "Epoch 181/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 121.2956 - val_loss: 167.6394\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 110.68011\n",
      "Epoch 182/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 123.9520 - val_loss: 124.3079\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 110.68011\n",
      "Epoch 183/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.9198 - val_loss: 252.6209\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 110.68011\n",
      "Epoch 184/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 116.0279 - val_loss: 119.5134\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 110.68011\n",
      "Epoch 185/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.0719 - val_loss: 330.8952\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 110.68011\n",
      "Epoch 186/10000\n",
      "88/88 [==============================] - 0s 975us/step - loss: 122.4236 - val_loss: 126.0500\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 110.68011\n",
      "Epoch 187/10000\n",
      "88/88 [==============================] - 0s 994us/step - loss: 119.7144 - val_loss: 210.1941\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 110.68011\n",
      "Epoch 188/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.9937 - val_loss: 174.7251\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 110.68011\n",
      "Epoch 189/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.1848 - val_loss: 230.6510\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 110.68011\n",
      "Epoch 190/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 121.0182 - val_loss: 142.4279\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 110.68011\n",
      "Epoch 191/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.8487 - val_loss: 121.0312\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 110.68011\n",
      "Epoch 192/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.8120 - val_loss: 177.1928\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 110.68011\n",
      "Epoch 193/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.3209 - val_loss: 227.3413\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 110.68011\n",
      "Epoch 194/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 117.6675 - val_loss: 258.7392\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 110.68011\n",
      "Epoch 195/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 121.6450 - val_loss: 236.3620\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 110.68011\n",
      "Epoch 196/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.2609 - val_loss: 195.8178\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 110.68011\n",
      "Epoch 197/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 116.3729 - val_loss: 236.5613\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 110.68011\n",
      "Epoch 198/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.8501 - val_loss: 217.7859\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 110.68011\n",
      "Epoch 199/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.1382 - val_loss: 127.8895\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 110.68011\n",
      "Epoch 200/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 116.4317 - val_loss: 133.2972\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 110.68011\n",
      "Epoch 201/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 117.0497 - val_loss: 157.9978\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 110.68011\n",
      "Epoch 202/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 117.2384 - val_loss: 232.8864\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 110.68011\n",
      "Epoch 203/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.8027 - val_loss: 197.6278\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 110.68011\n",
      "Epoch 204/10000\n",
      "88/88 [==============================] - ETA: 0s - loss: 118.754 - 0s 1ms/step - loss: 116.4705 - val_loss: 146.7401\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 110.68011\n",
      "Epoch 205/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 121.0032 - val_loss: 113.3750\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 110.68011\n",
      "Epoch 206/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.9067 - val_loss: 237.2484\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 110.68011\n",
      "Epoch 207/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.3337 - val_loss: 165.0708\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 110.68011\n",
      "Epoch 208/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 112.5115 - val_loss: 109.2509\n",
      "\n",
      "Epoch 00208: val_loss improved from 110.68011 to 109.25090, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 209/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 117.6080 - val_loss: 173.9966\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 109.25090\n",
      "Epoch 210/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 117.9337 - val_loss: 109.8170\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 109.25090\n",
      "Epoch 211/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 114.4932 - val_loss: 190.1921\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 109.25090\n",
      "Epoch 212/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 111.2472 - val_loss: 108.8436\n",
      "\n",
      "Epoch 00212: val_loss improved from 109.25090 to 108.84360, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 213/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 113.1460 - val_loss: 337.9764\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 108.84360\n",
      "Epoch 214/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 115.9449 - val_loss: 136.2338\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 108.84360\n",
      "Epoch 215/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 114.5438 - val_loss: 149.5059\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 108.84360\n",
      "Epoch 216/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 113.0858 - val_loss: 238.6393\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 108.84360\n",
      "Epoch 217/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 114.7958 - val_loss: 140.3624\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 108.84360\n",
      "Epoch 218/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.8090 - val_loss: 246.5168\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 108.84360\n",
      "Epoch 219/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 113.9664 - val_loss: 105.0745\n",
      "\n",
      "Epoch 00219: val_loss improved from 108.84360 to 105.07450, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 220/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 113.0504 - val_loss: 235.9244\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 105.07450\n",
      "Epoch 221/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 112.2841 - val_loss: 152.7018\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 105.07450\n",
      "Epoch 222/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.9705 - val_loss: 187.8007\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 105.07450\n",
      "Epoch 223/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 115.0220 - val_loss: 109.7144\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 105.07450\n",
      "Epoch 224/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.6428 - val_loss: 283.2970\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 105.07450\n",
      "Epoch 225/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.2831 - val_loss: 121.9465\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 105.07450\n",
      "Epoch 226/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 113.5653 - val_loss: 248.3117\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 105.07450\n",
      "Epoch 227/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 108.1363 - val_loss: 126.6250\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 105.07450\n",
      "Epoch 228/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.1302 - val_loss: 173.2872\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 105.07450\n",
      "Epoch 229/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.5237 - val_loss: 135.7329\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 105.07450\n",
      "Epoch 230/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.1209 - val_loss: 113.9194\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 105.07450\n",
      "Epoch 231/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 105.5462 - val_loss: 110.3241\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 105.07450\n",
      "Epoch 232/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 105.9851 - val_loss: 141.2816\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 105.07450\n",
      "Epoch 233/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.7591 - val_loss: 148.9209\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 105.07450\n",
      "Epoch 234/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.9388 - val_loss: 202.2821\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 105.07450\n",
      "Epoch 235/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.0363 - val_loss: 127.4108\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 105.07450\n",
      "Epoch 236/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.8308 - val_loss: 150.6382\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 105.07450\n",
      "Epoch 237/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.7482 - val_loss: 307.3438\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 105.07450\n",
      "Epoch 238/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.5616 - val_loss: 156.8595\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 105.07450\n",
      "Epoch 239/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.2048 - val_loss: 110.4355\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 105.07450\n",
      "Epoch 240/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.4074 - val_loss: 168.2063\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 105.07450\n",
      "Epoch 241/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 103.9605 - val_loss: 172.6470\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 105.07450\n",
      "Epoch 242/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.1792 - val_loss: 135.1669\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 105.07450\n",
      "Epoch 243/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.6663 - val_loss: 182.6237\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 105.07450\n",
      "Epoch 244/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 103.1843 - val_loss: 206.3197\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 105.07450\n",
      "Epoch 245/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.3173 - val_loss: 119.1426\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 105.07450\n",
      "Epoch 246/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 102.6922 - val_loss: 187.5076\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 105.07450\n",
      "Epoch 247/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 103.5321 - val_loss: 151.4827\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 105.07450\n",
      "Epoch 248/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 105.2425 - val_loss: 109.3904\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 105.07450\n",
      "Epoch 249/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.2991 - val_loss: 115.4199\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 105.07450\n",
      "Epoch 250/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.7552 - val_loss: 209.0056\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 105.07450\n",
      "Epoch 251/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.8354 - val_loss: 124.8123\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 105.07450\n",
      "Epoch 252/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.8238 - val_loss: 115.5300\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 105.07450\n",
      "Epoch 253/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 103.1076 - val_loss: 167.0825\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 105.07450\n",
      "Epoch 254/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.0335 - val_loss: 187.4819\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 105.07450\n",
      "Epoch 255/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.5093 - val_loss: 107.9529\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 105.07450\n",
      "Epoch 256/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.4153 - val_loss: 242.3813\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 105.07450\n",
      "Epoch 257/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.4693 - val_loss: 116.1035\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 105.07450\n",
      "Epoch 258/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.8634 - val_loss: 137.9798\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 105.07450\n",
      "Epoch 259/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.1456 - val_loss: 116.4220\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 105.07450\n",
      "Epoch 260/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.7342 - val_loss: 145.5296\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 105.07450\n",
      "Epoch 261/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.5640 - val_loss: 241.4450\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 105.07450\n",
      "Epoch 262/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 103.0576 - val_loss: 116.2552\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 105.07450\n",
      "Epoch 263/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.4215 - val_loss: 119.2120\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 105.07450\n",
      "Epoch 264/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 99.9617 - val_loss: 108.8097\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 105.07450\n",
      "Epoch 265/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.0434 - val_loss: 162.7921\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 105.07450\n",
      "Epoch 266/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.9517 - val_loss: 120.6674\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 105.07450\n",
      "Epoch 267/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.6873 - val_loss: 151.2747\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 105.07450\n",
      "Epoch 268/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 99.7041 - val_loss: 184.2706\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 105.07450\n",
      "Epoch 269/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.1313 - val_loss: 111.1331\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 105.07450\n",
      "Epoch 270/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.9854 - val_loss: 106.6125\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 105.07450\n",
      "Epoch 271/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.5113 - val_loss: 107.2841\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 105.07450\n",
      "Epoch 272/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 99.8327 - val_loss: 115.9429\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 105.07450\n",
      "Epoch 273/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.9128 - val_loss: 123.4826\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 105.07450\n",
      "Epoch 274/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.4764 - val_loss: 122.6333\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 105.07450\n",
      "Epoch 275/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 97.2665 - val_loss: 185.0972\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 105.07450\n",
      "Epoch 276/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 97.9525 - val_loss: 185.8705\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 105.07450\n",
      "Epoch 277/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 96.9607 - val_loss: 196.5329\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 105.07450\n",
      "Epoch 278/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.9404 - val_loss: 137.5207\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 105.07450\n",
      "Epoch 279/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 99.2864 - val_loss: 114.7829\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 105.07450\n",
      "Epoch 280/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 96.4415 - val_loss: 109.6821\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 105.07450\n",
      "Epoch 281/10000\n",
      "88/88 [==============================] - ETA: 0s - loss: 101.662 - 0s 1ms/step - loss: 99.4881 - val_loss: 151.8940\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 105.07450\n",
      "Epoch 282/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 102.9143 - val_loss: 112.5051\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 105.07450\n",
      "Epoch 283/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 93.9865 - val_loss: 181.7657\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 105.07450\n",
      "Epoch 284/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 99.5231 - val_loss: 199.0219\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 105.07450\n",
      "Epoch 285/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.8242 - val_loss: 143.2992\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 105.07450\n",
      "Epoch 286/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 97.6396 - val_loss: 177.9146\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 105.07450\n",
      "Epoch 287/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 97.9386 - val_loss: 214.4694\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 105.07450\n",
      "Epoch 288/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 99.9684 - val_loss: 128.3004\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 105.07450\n",
      "Epoch 289/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 97.2730 - val_loss: 233.8658\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 105.07450\n",
      "Epoch 290/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 94.3342 - val_loss: 113.5985\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 105.07450\n",
      "Epoch 291/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 96.6199 - val_loss: 130.1436\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 105.07450\n",
      "Epoch 292/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.9113 - val_loss: 123.9340\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 105.07450\n",
      "Epoch 293/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 91.5118 - val_loss: 118.5222\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 105.07450\n",
      "Epoch 294/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 92.4643 - val_loss: 122.0903\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 105.07450\n",
      "Epoch 295/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 94.7753 - val_loss: 120.6996\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 105.07450\n",
      "Epoch 296/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 97.4229 - val_loss: 128.8035\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 105.07450\n",
      "Epoch 297/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.6841 - val_loss: 124.9807\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 105.07450\n",
      "Epoch 298/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.8939 - val_loss: 191.8595\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 105.07450\n",
      "Epoch 299/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.8883 - val_loss: 118.1191\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 105.07450\n",
      "Epoch 300/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.9971 - val_loss: 122.9470\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 105.07450\n",
      "Epoch 301/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 93.5494 - val_loss: 135.0094\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 105.07450\n",
      "Epoch 302/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 99.2421 - val_loss: 143.4081\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 105.07450\n",
      "Epoch 303/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 96.6293 - val_loss: 184.7305\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 105.07450\n",
      "Epoch 304/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 91.0292 - val_loss: 110.2999\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 105.07450\n",
      "Epoch 305/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 96.6924 - val_loss: 190.0122\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 105.07450\n",
      "Epoch 306/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.0236 - val_loss: 146.5082\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 105.07450\n",
      "Epoch 307/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.6355 - val_loss: 106.3837\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 105.07450\n",
      "Epoch 308/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 94.2744 - val_loss: 127.6494\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 105.07450\n",
      "Epoch 309/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 93.4754 - val_loss: 117.3126\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 105.07450\n",
      "Epoch 310/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 97.3113 - val_loss: 169.0182\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 105.07450\n",
      "Epoch 311/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.8101 - val_loss: 132.7713\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 105.07450\n",
      "Epoch 312/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.3152 - val_loss: 122.9319\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 105.07450\n",
      "Epoch 313/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 94.4016 - val_loss: 137.9558\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 105.07450\n",
      "Epoch 314/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 94.0908 - val_loss: 153.0964\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 105.07450\n",
      "Epoch 315/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 94.5992 - val_loss: 119.2987\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 105.07450\n",
      "Epoch 316/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 94.8980 - val_loss: 190.7740\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 105.07450\n",
      "Epoch 317/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 96.9197 - val_loss: 210.9711\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 105.07450\n",
      "Epoch 318/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 93.1655 - val_loss: 115.9314\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 105.07450\n",
      "Epoch 319/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 91.0305 - val_loss: 105.7337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▊                                                                          | 2/21 [04:09<39:57, 126.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00319: val_loss did not improve from 105.07450\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 519.3298 - val_loss: 62.6458\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 62.64580, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 260.6642 - val_loss: 600.6672\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 62.64580\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 273.0908 - val_loss: 663.4975\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 62.64580\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 976us/step - loss: 279.9654 - val_loss: 555.9874\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 62.64580\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 307.6265 - val_loss: 617.4323\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 62.64580\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 313.4485 - val_loss: 274.4097\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 62.64580\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 306.4168 - val_loss: 354.8002\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 62.64580\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 312.8824 - val_loss: 496.0645\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 62.64580\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 299.4885 - val_loss: 250.1096\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 62.64580\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 310.5352 - val_loss: 652.0412\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 62.64580\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 296.9838 - val_loss: 145.2099\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 62.64580\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 304.6379 - val_loss: 338.2301\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 62.64580\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 307.3917 - val_loss: 599.3435\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 62.64580\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 296.6516 - val_loss: 530.0020\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 62.64580\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 302.7007 - val_loss: 423.4538\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 62.64580\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 293.8926 - val_loss: 36.2410\n",
      "\n",
      "Epoch 00016: val_loss improved from 62.64580 to 36.24096, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 300.2385 - val_loss: 410.4170\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 36.24096\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 319.0233 - val_loss: 270.9728\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 36.24096\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 300.6112 - val_loss: 355.5896\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 36.24096\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 306.7455 - val_loss: 321.1471\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 36.24096\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 304.4568 - val_loss: 182.8268\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 36.24096\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 280.6372 - val_loss: 362.0081\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 36.24096\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 310.1996 - val_loss: 82.8588\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 36.24096\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 292.6169 - val_loss: 105.4507\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 36.24096\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 294.6584 - val_loss: 576.9011\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 36.24096\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 288.4384 - val_loss: 144.9572\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 36.24096\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 297.6328 - val_loss: 43.3351\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 36.24096\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 304.4097 - val_loss: 354.0756\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 36.24096\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 284.7194 - val_loss: 342.8987\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 36.24096\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 279.7115 - val_loss: 213.5445\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 36.24096\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 275.3994 - val_loss: 591.9133\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 36.24096\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 275.9351 - val_loss: 57.2345\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 36.24096\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 257.9197 - val_loss: 383.3761\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 36.24096\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 242.1921 - val_loss: 585.4929\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 36.24096\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 225.6386 - val_loss: 69.5365\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 36.24096\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 240.6288 - val_loss: 174.1108\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 36.24096\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 220.2951 - val_loss: 581.1273\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 36.24096\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.5677 - val_loss: 243.1669\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 36.24096\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 210.5342 - val_loss: 99.3108\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 36.24096\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.5658 - val_loss: 275.8599\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 36.24096\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.6309 - val_loss: 265.2480\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 36.24096\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 206.8924 - val_loss: 92.2526\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 36.24096\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 184.4313 - val_loss: 62.6984\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 36.24096\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 186.3247 - val_loss: 100.3972\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 36.24096\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 176.6795 - val_loss: 504.3549\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 36.24096\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 174.6115 - val_loss: 141.7281\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 36.24096\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 161.4345 - val_loss: 341.2821\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 36.24096\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 158.2154 - val_loss: 309.9269\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 36.24096\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.3286 - val_loss: 77.0189\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 36.24096\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.7039 - val_loss: 81.9129\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 36.24096\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.0703 - val_loss: 399.4686\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 36.24096\n",
      "Epoch 52/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 125.3266 - val_loss: 208.3962\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 36.24096\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.9296 - val_loss: 189.7889\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 36.24096\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 121.5453 - val_loss: 84.6846\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 36.24096\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 125.3246 - val_loss: 168.0552\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 36.24096\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.6711 - val_loss: 143.8784\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 36.24096\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.7642 - val_loss: 116.7411\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 36.24096\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.0325 - val_loss: 150.7910\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 36.24096\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.7998 - val_loss: 277.2068\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 36.24096\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.2147 - val_loss: 167.5861\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 36.24096\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.9643 - val_loss: 285.4894\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 36.24096\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.8965 - val_loss: 282.8793\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 36.24096\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.4701 - val_loss: 112.9407\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 36.24096\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.1849 - val_loss: 121.4903\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 36.24096\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.6638 - val_loss: 173.1047\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 36.24096\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.0912 - val_loss: 178.9803\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 36.24096\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.5230 - val_loss: 243.8007\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 36.24096\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.5021 - val_loss: 166.5530\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 36.24096\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.6886 - val_loss: 335.6466\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 36.24096\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 108.0324 - val_loss: 84.2020\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 36.24096\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 108.1908 - val_loss: 49.1816\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 36.24096\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.9598 - val_loss: 256.4893\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 36.24096\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.7076 - val_loss: 164.1362\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 36.24096\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.9400 - val_loss: 324.1515\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 36.24096\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 102.4345 - val_loss: 210.0175\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 36.24096\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 101.8097 - val_loss: 162.2093\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 36.24096\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.8199 - val_loss: 246.7298\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 36.24096\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.9770 - val_loss: 53.6834\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 36.24096\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.3100 - val_loss: 39.4714\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 36.24096\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.3982 - val_loss: 243.3986\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 36.24096\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.0889 - val_loss: 178.8883\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 36.24096\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 101.5483 - val_loss: 44.1648\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 36.24096\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 101.4369 - val_loss: 59.1884\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 36.24096\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.9423 - val_loss: 195.4836\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 36.24096\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.6002 - val_loss: 206.0938\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 36.24096\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.8820 - val_loss: 126.0434\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 36.24096\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.8578 - val_loss: 37.9408\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 36.24096\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 97.1434 - val_loss: 37.8275\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 36.24096\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.7921 - val_loss: 51.6885\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 36.24096\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 97.3404 - val_loss: 116.2919\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 36.24096\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.4591 - val_loss: 45.9290\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 36.24096\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 101.5050 - val_loss: 267.8003\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 36.24096\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.1049 - val_loss: 347.2679\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 36.24096\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 95.8952 - val_loss: 344.9241\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 36.24096\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.4809 - val_loss: 151.2896\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 36.24096\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.2185 - val_loss: 74.4459\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 36.24096\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.2853 - val_loss: 182.6249\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 36.24096\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 97.1056 - val_loss: 168.0232\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 36.24096\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.2635 - val_loss: 153.3208\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 36.24096\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 101.2525 - val_loss: 154.0363\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 36.24096\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.7584 - val_loss: 82.8736\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 36.24096\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.7665 - val_loss: 186.2219\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 36.24096\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.5319 - val_loss: 97.0525\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 36.24096\n",
      "Epoch 104/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 101.0358 - val_loss: 300.8469\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 36.24096\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 97.4981 - val_loss: 205.3364\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 36.24096\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 97.6599 - val_loss: 33.6069\n",
      "\n",
      "Epoch 00106: val_loss improved from 36.24096 to 33.60688, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 100.9234 - val_loss: 216.4120\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 33.60688\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 95.9228 - val_loss: 270.9525\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 33.60688\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.4479 - val_loss: 213.2512\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 33.60688\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.6288 - val_loss: 57.5668\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 33.60688\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.3342 - val_loss: 55.6544\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 33.60688\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 95.7360 - val_loss: 235.2123\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 33.60688\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.8137 - val_loss: 237.4171\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 33.60688\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.0030 - val_loss: 97.9962\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 33.60688\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 97.9430 - val_loss: 66.9410\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 33.60688\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 97.0828 - val_loss: 315.9857\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 33.60688\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 95.3325 - val_loss: 136.7921\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 33.60688\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.0785 - val_loss: 155.9608\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 33.60688\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.2878 - val_loss: 152.4173\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 33.60688\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.5466 - val_loss: 53.0677\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 33.60688\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 95.4464 - val_loss: 163.1236\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 33.60688\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.0018 - val_loss: 54.4618\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 33.60688\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 87.2362 - val_loss: 46.8740\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 33.60688\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 87.2351 - val_loss: 32.6359\n",
      "\n",
      "Epoch 00124: val_loss improved from 33.60688 to 32.63586, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.5643 - val_loss: 295.4880\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 32.63586\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 95.8500 - val_loss: 203.2538\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 32.63586\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.9034 - val_loss: 36.5278\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 32.63586\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.9086 - val_loss: 179.1850\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 32.63586\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.9198 - val_loss: 252.6269\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 32.63586\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.6264 - val_loss: 37.9875\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 32.63586\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 86.1533 - val_loss: 79.1721\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 32.63586\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.4834 - val_loss: 161.6906\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 32.63586\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.3096 - val_loss: 260.4618\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 32.63586\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.1163 - val_loss: 41.3645\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 32.63586\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.0220 - val_loss: 33.3757\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 32.63586\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.1656 - val_loss: 47.3071\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 32.63586\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.4758 - val_loss: 66.9526\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 32.63586\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.8803 - val_loss: 162.7313\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 32.63586\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.9980 - val_loss: 33.7012\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 32.63586\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.1322 - val_loss: 45.7318\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 32.63586\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 83.7429 - val_loss: 256.2476\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 32.63586\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.4963 - val_loss: 71.1038\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 32.63586\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 90.8501 - val_loss: 51.6075\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 32.63586\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.2832 - val_loss: 43.2524\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 32.63586\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 87.4688 - val_loss: 192.9316\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 32.63586\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 87.6385 - val_loss: 124.4595\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 32.63586\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 86.5448 - val_loss: 227.4682\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 32.63586\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.8806 - val_loss: 55.7682\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 32.63586\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 85.0256 - val_loss: 119.0016\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 32.63586\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.5934 - val_loss: 46.7396\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 32.63586\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 85.0067 - val_loss: 59.0295\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 32.63586\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.6632 - val_loss: 131.0011\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 32.63586\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.8806 - val_loss: 59.5267\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 32.63586\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 86.3172 - val_loss: 42.0176\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 32.63586\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.6765 - val_loss: 288.2548\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 32.63586\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 85.5800 - val_loss: 188.3367\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 32.63586\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.8937 - val_loss: 37.7296\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 32.63586\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 83.0844 - val_loss: 110.5736\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 32.63586\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.5863 - val_loss: 55.8014\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 32.63586\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 86.9758 - val_loss: 72.2526\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 32.63586\n",
      "Epoch 161/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 87.7979 - val_loss: 118.9588\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 32.63586\n",
      "Epoch 162/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.8185 - val_loss: 36.6843\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 32.63586\n",
      "Epoch 163/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.9615 - val_loss: 80.0375\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 32.63586\n",
      "Epoch 164/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.2993 - val_loss: 50.5455\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 32.63586\n",
      "Epoch 165/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.1384 - val_loss: 71.8576\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 32.63586\n",
      "Epoch 166/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.0462 - val_loss: 158.1806\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 32.63586\n",
      "Epoch 167/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.5793 - val_loss: 124.4434\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 32.63586\n",
      "Epoch 168/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.2895 - val_loss: 46.7503\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 32.63586\n",
      "Epoch 169/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.7596 - val_loss: 96.4055\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 32.63586\n",
      "Epoch 170/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.8176 - val_loss: 197.2994\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 32.63586\n",
      "Epoch 171/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.2787 - val_loss: 239.8327\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 32.63586\n",
      "Epoch 172/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 83.1194 - val_loss: 96.4759\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 32.63586\n",
      "Epoch 173/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.9951 - val_loss: 108.8441\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 32.63586\n",
      "Epoch 174/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 84.5493 - val_loss: 127.1007\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 32.63586\n",
      "Epoch 175/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.0872 - val_loss: 36.1163\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 32.63586\n",
      "Epoch 176/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.5166 - val_loss: 155.8568\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 32.63586\n",
      "Epoch 177/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.2978 - val_loss: 286.4152\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 32.63586\n",
      "Epoch 178/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.1350 - val_loss: 68.0081\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 32.63586\n",
      "Epoch 179/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 83.6050 - val_loss: 103.6847\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 32.63586\n",
      "Epoch 180/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.6585 - val_loss: 133.1432\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 32.63586\n",
      "Epoch 181/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.9313 - val_loss: 133.5782\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 32.63586\n",
      "Epoch 182/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.8687 - val_loss: 67.4564\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 32.63586\n",
      "Epoch 183/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.3451 - val_loss: 181.9769\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 32.63586\n",
      "Epoch 184/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.5680 - val_loss: 117.5014\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 32.63586\n",
      "Epoch 185/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.4692 - val_loss: 191.3651\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 32.63586\n",
      "Epoch 186/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.6853 - val_loss: 107.1016\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 32.63586\n",
      "Epoch 187/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.3760 - val_loss: 59.6581\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 32.63586\n",
      "Epoch 188/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.1754 - val_loss: 87.3783\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 32.63586\n",
      "Epoch 189/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.5567 - val_loss: 126.0851\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 32.63586\n",
      "Epoch 190/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.8048 - val_loss: 160.4841\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 32.63586\n",
      "Epoch 191/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 83.1795 - val_loss: 134.3642\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 32.63586\n",
      "Epoch 192/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.1439 - val_loss: 294.8573\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 32.63586\n",
      "Epoch 193/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.2766 - val_loss: 153.9401\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 32.63586\n",
      "Epoch 194/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.4409 - val_loss: 127.2221\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 32.63586\n",
      "Epoch 195/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.0976 - val_loss: 215.7862\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 32.63586\n",
      "Epoch 196/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.0134 - val_loss: 36.7401\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 32.63586\n",
      "Epoch 197/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.1846 - val_loss: 81.9079\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 32.63586\n",
      "Epoch 198/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.0942 - val_loss: 217.4225\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 32.63586\n",
      "Epoch 199/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.0509 - val_loss: 58.5862\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 32.63586\n",
      "Epoch 200/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.4996 - val_loss: 120.5850\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 32.63586\n",
      "Epoch 201/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 81.4068 - val_loss: 156.6713\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 32.63586\n",
      "Epoch 202/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.1446 - val_loss: 180.6227\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 32.63586\n",
      "Epoch 203/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.1374 - val_loss: 34.4951\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 32.63586\n",
      "Epoch 204/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.5393 - val_loss: 190.8331\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 32.63586\n",
      "Epoch 205/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.0265 - val_loss: 142.9727\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 32.63586\n",
      "Epoch 206/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.6535 - val_loss: 90.7958\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 32.63586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.4051 - val_loss: 32.7272\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 32.63586\n",
      "Epoch 208/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.2603 - val_loss: 145.0638\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 32.63586\n",
      "Epoch 209/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.5233 - val_loss: 76.6109\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 32.63586\n",
      "Epoch 210/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.1212 - val_loss: 162.3111\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 32.63586\n",
      "Epoch 211/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.0984 - val_loss: 87.2102\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 32.63586\n",
      "Epoch 212/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.1315 - val_loss: 30.9819\n",
      "\n",
      "Epoch 00212: val_loss improved from 32.63586 to 30.98188, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 213/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.9782 - val_loss: 242.6509\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 30.98188\n",
      "Epoch 214/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.2060 - val_loss: 48.0861\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 30.98188\n",
      "Epoch 215/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.8658 - val_loss: 75.2052\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 30.98188\n",
      "Epoch 216/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.2909 - val_loss: 90.9252\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 30.98188\n",
      "Epoch 217/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.8489 - val_loss: 83.9293\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 30.98188\n",
      "Epoch 218/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.0632 - val_loss: 129.8204\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 30.98188\n",
      "Epoch 219/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.7129 - val_loss: 35.1947\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 30.98188\n",
      "Epoch 220/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.6497 - val_loss: 88.7824\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 30.98188\n",
      "Epoch 221/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 72.2526 - val_loss: 121.2777\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 30.98188\n",
      "Epoch 222/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.1409 - val_loss: 58.8302\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 30.98188\n",
      "Epoch 223/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.8231 - val_loss: 186.5076\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 30.98188\n",
      "Epoch 224/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 73.2805 - val_loss: 78.1986\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 30.98188\n",
      "Epoch 225/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.3310 - val_loss: 35.2566\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 30.98188\n",
      "Epoch 226/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.1328 - val_loss: 79.5725\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 30.98188\n",
      "Epoch 227/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.5863 - val_loss: 70.7248\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 30.98188\n",
      "Epoch 228/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.7936 - val_loss: 205.5345\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 30.98188\n",
      "Epoch 229/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.6685 - val_loss: 106.2481\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 30.98188\n",
      "Epoch 230/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.2723 - val_loss: 251.5855\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 30.98188\n",
      "Epoch 231/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.4134 - val_loss: 152.3076\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 30.98188\n",
      "Epoch 232/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.5934 - val_loss: 58.2334\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 30.98188\n",
      "Epoch 233/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.1187 - val_loss: 148.8114\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 30.98188\n",
      "Epoch 234/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 73.9792 - val_loss: 61.9055\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 30.98188\n",
      "Epoch 235/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 72.4994 - val_loss: 37.0933\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 30.98188\n",
      "Epoch 236/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.7812 - val_loss: 107.3421\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 30.98188\n",
      "Epoch 237/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.5540 - val_loss: 36.4206\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 30.98188\n",
      "Epoch 238/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.7636 - val_loss: 127.0225\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 30.98188\n",
      "Epoch 239/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.6249 - val_loss: 157.8712\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 30.98188\n",
      "Epoch 240/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 73.6669 - val_loss: 139.5002\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 30.98188\n",
      "Epoch 241/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.2356 - val_loss: 165.4185\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 30.98188\n",
      "Epoch 242/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.8885 - val_loss: 63.4286\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 30.98188\n",
      "Epoch 243/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.2327 - val_loss: 61.8503\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 30.98188\n",
      "Epoch 244/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.6910 - val_loss: 77.7258\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 30.98188\n",
      "Epoch 245/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.1698 - val_loss: 72.3383\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 30.98188\n",
      "Epoch 246/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.8173 - val_loss: 52.9250\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 30.98188\n",
      "Epoch 247/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.4209 - val_loss: 98.4406\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 30.98188\n",
      "Epoch 248/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 72.0853 - val_loss: 33.8248\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 30.98188\n",
      "Epoch 249/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 78.0057 - val_loss: 34.6219\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 30.98188\n",
      "Epoch 250/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.3474 - val_loss: 36.4164\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 30.98188\n",
      "Epoch 251/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.7919 - val_loss: 74.9512\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 30.98188\n",
      "Epoch 252/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.1248 - val_loss: 90.7783\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 30.98188\n",
      "Epoch 253/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.7391 - val_loss: 69.0172\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 30.98188\n",
      "Epoch 254/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.0208 - val_loss: 123.9927\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 30.98188\n",
      "Epoch 255/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 71.1799 - val_loss: 49.1736\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 30.98188\n",
      "Epoch 256/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.5111 - val_loss: 93.9553\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 30.98188\n",
      "Epoch 257/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.3024 - val_loss: 86.5693\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 30.98188\n",
      "Epoch 258/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 82.0693 - val_loss: 111.5531\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 30.98188\n",
      "Epoch 259/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.8812 - val_loss: 37.0880\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 30.98188\n",
      "Epoch 260/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.0299 - val_loss: 214.3320\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 30.98188\n",
      "Epoch 261/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.8185 - val_loss: 81.1114\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 30.98188\n",
      "Epoch 262/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 72.8532 - val_loss: 168.0133\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 30.98188\n",
      "Epoch 263/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 73.1314 - val_loss: 140.9482\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 30.98188\n",
      "Epoch 264/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.7925 - val_loss: 214.9063\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 30.98188\n",
      "Epoch 265/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.5912 - val_loss: 158.8763\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 30.98188\n",
      "Epoch 266/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.7540 - val_loss: 184.3763\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 30.98188\n",
      "Epoch 267/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.9888 - val_loss: 43.8226\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 30.98188\n",
      "Epoch 268/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.4523 - val_loss: 39.7085\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 30.98188\n",
      "Epoch 269/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 80.1101 - val_loss: 34.6276\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 30.98188\n",
      "Epoch 270/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 79.2901 - val_loss: 153.0990\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 30.98188\n",
      "Epoch 271/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.6763 - val_loss: 127.6552\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 30.98188\n",
      "Epoch 272/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.3513 - val_loss: 173.4173\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 30.98188\n",
      "Epoch 273/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.9614 - val_loss: 36.5189\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 30.98188\n",
      "Epoch 274/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 72.7657 - val_loss: 77.8017\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 30.98188\n",
      "Epoch 275/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.6950 - val_loss: 44.7943\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 30.98188\n",
      "Epoch 276/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.4471 - val_loss: 72.0788\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 30.98188\n",
      "Epoch 277/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.3453 - val_loss: 39.6386\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 30.98188\n",
      "Epoch 278/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 71.0422 - val_loss: 124.8726\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 30.98188\n",
      "Epoch 279/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.1403 - val_loss: 70.6075\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 30.98188\n",
      "Epoch 280/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.9866 - val_loss: 48.6250\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 30.98188\n",
      "Epoch 281/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 66.5471 - val_loss: 40.0116\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 30.98188\n",
      "Epoch 282/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 72.5217 - val_loss: 33.4934\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 30.98188\n",
      "Epoch 283/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.3674 - val_loss: 102.2954\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 30.98188\n",
      "Epoch 284/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.4706 - val_loss: 43.3110\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 30.98188\n",
      "Epoch 285/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.9424 - val_loss: 64.9743\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 30.98188\n",
      "Epoch 286/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.0009 - val_loss: 155.7402\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 30.98188\n",
      "Epoch 287/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 73.5399 - val_loss: 185.5360\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 30.98188\n",
      "Epoch 288/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.8995 - val_loss: 271.3553\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 30.98188\n",
      "Epoch 289/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.1474 - val_loss: 69.5764\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 30.98188\n",
      "Epoch 290/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.5965 - val_loss: 58.5316\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 30.98188\n",
      "Epoch 291/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.9947 - val_loss: 198.2423\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 30.98188\n",
      "Epoch 292/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 73.5525 - val_loss: 57.5332\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 30.98188\n",
      "Epoch 293/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.7343 - val_loss: 117.9632\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 30.98188\n",
      "Epoch 294/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 71.4084 - val_loss: 44.6553\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 30.98188\n",
      "Epoch 295/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 72.3027 - val_loss: 70.4350\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 30.98188\n",
      "Epoch 296/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.0561 - val_loss: 167.4980\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 30.98188\n",
      "Epoch 297/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.6569 - val_loss: 43.0078\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 30.98188\n",
      "Epoch 298/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 70.8902 - val_loss: 50.3009\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 30.98188\n",
      "Epoch 299/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.5488 - val_loss: 46.6053\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 30.98188\n",
      "Epoch 300/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 77.5179 - val_loss: 43.4017\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 30.98188\n",
      "Epoch 301/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 73.3418 - val_loss: 102.1638\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 30.98188\n",
      "Epoch 302/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 75.9655 - val_loss: 51.7008\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 30.98188\n",
      "Epoch 303/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.1782 - val_loss: 94.2170\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 30.98188\n",
      "Epoch 304/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 74.1093 - val_loss: 231.9432\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 30.98188\n",
      "Epoch 305/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 70.4455 - val_loss: 104.4647\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 30.98188\n",
      "Epoch 306/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 76.8947 - val_loss: 67.2407\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 30.98188\n",
      "Epoch 307/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 72.3929 - val_loss: 63.8428\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 30.98188\n",
      "Epoch 308/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 72.7996 - val_loss: 58.4768\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 30.98188\n",
      "Epoch 309/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 71.6175 - val_loss: 62.9352\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 30.98188\n",
      "Epoch 310/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 72.0391 - val_loss: 49.6982\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 30.98188\n",
      "Epoch 311/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 76.8256 - val_loss: 142.9963\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 30.98188\n",
      "Epoch 312/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 72.8638 - val_loss: 149.0864\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 30.98188\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 409.7506 - val_loss: 461.9822\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 461.98224, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 271.9313 - val_loss: 213.9387\n",
      "\n",
      "Epoch 00002: val_loss improved from 461.98224 to 213.93871, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 286.0541 - val_loss: 632.0330\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 213.93871\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 309.7660 - val_loss: 665.3052\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 213.93871\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 285.9666 - val_loss: 347.1494\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 213.93871\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 291.5837 - val_loss: 621.8723\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 213.93871\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 292.1528 - val_loss: 377.2306\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 213.93871\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 285.0219 - val_loss: 293.1692\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 213.93871\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 998us/step - loss: 304.9993 - val_loss: 221.2074\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 213.93871\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 286.6166 - val_loss: 274.5469\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 213.93871\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 280.2424 - val_loss: 372.6136\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 213.93871\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 268.1577 - val_loss: 185.7779\n",
      "\n",
      "Epoch 00012: val_loss improved from 213.93871 to 185.77792, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 271.0098 - val_loss: 616.3259\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 185.77792\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 305.5654 - val_loss: 525.4993\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 185.77792\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 272.2878 - val_loss: 315.7369\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 185.77792\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 289.4303 - val_loss: 457.7076\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 185.77792\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 278.9366 - val_loss: 192.1239\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 185.77792\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 273.3505 - val_loss: 153.2845\n",
      "\n",
      "Epoch 00018: val_loss improved from 185.77792 to 153.28448, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 282.9872 - val_loss: 493.2779\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 153.28448\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 265.5780 - val_loss: 184.6140\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 153.28448\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 285.0859 - val_loss: 434.5137\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 153.28448\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 279.7645 - val_loss: 633.2061\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 153.28448\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 274.1096 - val_loss: 535.4888\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 153.28448\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 286.2540 - val_loss: 181.4762\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 153.28448\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 283.6044 - val_loss: 40.2418\n",
      "\n",
      "Epoch 00025: val_loss improved from 153.28448 to 40.24176, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 248.7879 - val_loss: 475.6548\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 40.24176\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 292.4838 - val_loss: 270.9685\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 40.24176\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 282.5076 - val_loss: 438.5010\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 40.24176\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 274.8308 - val_loss: 64.7871\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 40.24176\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 227.3938 - val_loss: 525.2249\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 40.24176\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 256.4087 - val_loss: 50.1923\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 40.24176\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 255.8987 - val_loss: 64.4945\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 40.24176\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 252.6236 - val_loss: 432.5574\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 40.24176\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 246.5494 - val_loss: 193.2884\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 40.24176\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.7794 - val_loss: 518.7916\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 40.24176\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.3607 - val_loss: 120.2039\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 40.24176\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 235.4896 - val_loss: 645.1310\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 40.24176\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 246.3458 - val_loss: 275.2562\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 40.24176\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 221.5900 - val_loss: 482.7356\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 40.24176\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 220.1703 - val_loss: 427.7372\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 40.24176\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.8292 - val_loss: 134.1405\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 40.24176\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.6700 - val_loss: 147.1028\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 40.24176\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 193.3473 - val_loss: 503.5301\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 40.24176\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 178.0101 - val_loss: 551.8121\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 40.24176\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 183.8740 - val_loss: 72.6520\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 40.24176\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 184.0637 - val_loss: 231.8029\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 40.24176\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.5604 - val_loss: 427.6758\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 40.24176\n",
      "Epoch 48/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 168.7229 - val_loss: 165.3546\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 40.24176\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 168.8552 - val_loss: 162.0192\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 40.24176\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 162.4201 - val_loss: 202.1952\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 40.24176\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 151.3102 - val_loss: 360.1073\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 40.24176\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.5867 - val_loss: 105.3216\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 40.24176\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.4135 - val_loss: 98.7937\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 40.24176\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.6777 - val_loss: 325.5126\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 40.24176\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 131.0285 - val_loss: 192.3301\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 40.24176\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.6636 - val_loss: 103.7310\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 40.24176\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 131.2787 - val_loss: 179.3547\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 40.24176\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.0332 - val_loss: 278.4598\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 40.24176\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.3245 - val_loss: 68.0014\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 40.24176\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 126.0749 - val_loss: 361.8762\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 40.24176\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 127.7266 - val_loss: 65.3220\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 40.24176\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.0708 - val_loss: 248.6571\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 40.24176\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.2280 - val_loss: 103.4007\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 40.24176\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.2919 - val_loss: 212.8636\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 40.24176\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.0974 - val_loss: 319.0815\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 40.24176\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.1249 - val_loss: 75.1937\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 40.24176\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.2824 - val_loss: 393.4941\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 40.24176\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.4479 - val_loss: 64.3758\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 40.24176\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.9508 - val_loss: 233.8370\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 40.24176\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.3052 - val_loss: 379.0048\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 40.24176\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.6348 - val_loss: 73.4200\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 40.24176\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.7291 - val_loss: 114.8210\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 40.24176\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.2821 - val_loss: 246.6832\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 40.24176\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.0281 - val_loss: 102.3204\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 40.24176\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.2518 - val_loss: 157.5412\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 40.24176\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.3949 - val_loss: 268.5645\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 40.24176\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.5197 - val_loss: 314.4611\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 40.24176\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.3000 - val_loss: 236.8171\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 40.24176\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.2658 - val_loss: 160.9280\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 40.24176\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.7675 - val_loss: 133.1039\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 40.24176\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 100.6099 - val_loss: 243.6793\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 40.24176\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.9958 - val_loss: 187.5020\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 40.24176\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.9010 - val_loss: 103.9328\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 40.24176\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.7752 - val_loss: 217.7424\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 40.24176\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.1195 - val_loss: 180.9430\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 40.24176\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.2913 - val_loss: 139.4750\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 40.24176\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.8535 - val_loss: 149.5501\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 40.24176\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.4035 - val_loss: 386.3355\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 40.24176\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.4499 - val_loss: 95.2631\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 40.24176\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.9600 - val_loss: 169.3497\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 40.24176\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.6901 - val_loss: 245.0842\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 40.24176\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.6177 - val_loss: 311.6554\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 40.24176\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.4854 - val_loss: 87.2143\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 40.24176\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.1994 - val_loss: 137.8103\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 40.24176\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.4564 - val_loss: 187.2385\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 40.24176\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.4899 - val_loss: 217.5568\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 40.24176\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 100.0218 - val_loss: 103.3198\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 40.24176\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.1908 - val_loss: 259.8912\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 40.24176\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 99.7305 - val_loss: 84.0273\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 40.24176\n",
      "Epoch 100/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 100.6946 - val_loss: 127.4985\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 40.24176\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.0267 - val_loss: 186.5769\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 40.24176\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 101.6330 - val_loss: 345.3176\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 40.24176\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.2338 - val_loss: 305.7582\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 40.24176\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.5450 - val_loss: 109.5647\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 40.24176\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 92.9972 - val_loss: 228.7827\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 40.24176\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 98.3250 - val_loss: 319.2523\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 40.24176\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 95.5084 - val_loss: 96.7797\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 40.24176\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.6519 - val_loss: 357.2498\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 40.24176\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 92.4376 - val_loss: 112.9990\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 40.24176\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 97.9002 - val_loss: 343.0996\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 40.24176\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.1616 - val_loss: 192.1317\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 40.24176\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 92.6417 - val_loss: 97.6159\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 40.24176\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.3257 - val_loss: 278.0036\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 40.24176\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 92.1533 - val_loss: 254.9811\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 40.24176\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 94.8392 - val_loss: 83.8778\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 40.24176\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 93.9561 - val_loss: 202.5567\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 40.24176\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.2436 - val_loss: 67.7245\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 40.24176\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 92.4783 - val_loss: 144.6268\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 40.24176\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.1596 - val_loss: 85.6114\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 40.24176\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 91.5315 - val_loss: 146.2258\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 40.24176\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.9855 - val_loss: 137.8122\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 40.24176\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.5817 - val_loss: 308.3381\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 40.24176\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 88.3216 - val_loss: 233.0549\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 40.24176\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.1703 - val_loss: 172.7222\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 40.24176\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 89.3425 - val_loss: 292.0446\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 40.24176\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 524.7381 - val_loss: 85.1591\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 85.15913, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 254.0484 - val_loss: 682.5594\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 85.15913\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 264.2173 - val_loss: 572.2755\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 85.15913\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 268.6377 - val_loss: 658.6256\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 85.15913\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 245.2171 - val_loss: 474.1864\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 85.15913\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 290.3474 - val_loss: 593.8611\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 85.15913\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 276.8958 - val_loss: 76.1696\n",
      "\n",
      "Epoch 00007: val_loss improved from 85.15913 to 76.16959, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 287.5111 - val_loss: 368.2928\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 76.16959\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 257.2275 - val_loss: 617.5417\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 76.16959\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 285.1947 - val_loss: 264.6246\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 76.16959\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 289.7322 - val_loss: 421.9120\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 76.16959\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.3313 - val_loss: 677.7957\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 76.16959\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 280.4481 - val_loss: 309.3278\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 76.16959\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 285.0106 - val_loss: 505.6859\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 76.16959\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 282.2896 - val_loss: 658.3192\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 76.16959\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 273.9494 - val_loss: 607.6495\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 76.16959\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.0017 - val_loss: 463.4305\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 76.16959\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 268.8264 - val_loss: 54.9792\n",
      "\n",
      "Epoch 00018: val_loss improved from 76.16959 to 54.97916, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 293.8698 - val_loss: 135.2411\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 54.97916\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 265.0799 - val_loss: 205.3271\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 54.97916\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 267.7331 - val_loss: 360.6555\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 54.97916\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 250.4378 - val_loss: 408.9991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 54.97916\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 283.9387 - val_loss: 141.6256\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 54.97916\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 241.9569 - val_loss: 573.6453\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 54.97916\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.2214 - val_loss: 471.2386\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 54.97916\n",
      "Epoch 26/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 239.9913 - val_loss: 178.0584\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 54.97916\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 240.6572 - val_loss: 622.7238\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 54.97916\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 283.3600 - val_loss: 59.7648\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 54.97916\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 244.3465 - val_loss: 293.9671\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 54.97916\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 249.6598 - val_loss: 247.2713\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 54.97916\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 251.9044 - val_loss: 594.6088\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 54.97916\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 264.6900 - val_loss: 276.6108\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 54.97916\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 256.8884 - val_loss: 329.2650\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 54.97916\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 256.5103 - val_loss: 297.1887\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 54.97916\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 264.6198 - val_loss: 84.9030\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 54.97916\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 215.8286 - val_loss: 108.5576\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 54.97916\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 243.6887 - val_loss: 96.4078\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 54.97916\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 246.0730 - val_loss: 131.0462\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 54.97916\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 255.8994 - val_loss: 602.7023\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 54.97916\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.6116 - val_loss: 271.3207\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 54.97916\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 246.0232 - val_loss: 590.0797\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 54.97916\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 233.1733 - val_loss: 93.2374\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 54.97916\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 237.0073 - val_loss: 512.3439\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 54.97916\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 217.4179 - val_loss: 346.3129\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 54.97916\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 227.8712 - val_loss: 577.2146\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 54.97916\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 238.3320 - val_loss: 469.6064\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 54.97916\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 215.8241 - val_loss: 431.1317\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 54.97916\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 219.8870 - val_loss: 166.3297\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 54.97916\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 207.3581 - val_loss: 526.5647\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 54.97916\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 194.3206 - val_loss: 338.8475\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 54.97916\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 198.5653 - val_loss: 183.9182\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 54.97916\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 195.8822 - val_loss: 44.5080\n",
      "\n",
      "Epoch 00052: val_loss improved from 54.97916 to 44.50803, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 180.0469 - val_loss: 598.0416\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 44.50803\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 164.9706 - val_loss: 262.2514\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 44.50803\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 180.8163 - val_loss: 61.9637\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 44.50803\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 163.7952 - val_loss: 457.1598\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 44.50803\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 162.4822 - val_loss: 95.1181\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 44.50803\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 152.3811 - val_loss: 161.5943\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 44.50803\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 147.0156 - val_loss: 469.6451\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 44.50803\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.9297 - val_loss: 212.6949\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 44.50803\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 138.2614 - val_loss: 202.0615\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 44.50803\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.1271 - val_loss: 455.8750\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 44.50803\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 143.6879 - val_loss: 230.0806\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 44.50803\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 131.8602 - val_loss: 169.6676\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 44.50803\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 134.1992 - val_loss: 363.3262\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 44.50803\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 129.5307 - val_loss: 153.0638\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 44.50803\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 132.7628 - val_loss: 214.4464\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 44.50803\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 124.2182 - val_loss: 231.7979\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 44.50803\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 126.0944 - val_loss: 356.9041\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 44.50803\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 125.1533 - val_loss: 95.5123\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 44.50803\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 122.2335 - val_loss: 143.9958\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 44.50803\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 126.1402 - val_loss: 360.8529\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 44.50803\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.0724 - val_loss: 285.5630\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 44.50803\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.5650 - val_loss: 69.6019\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 44.50803\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.3078 - val_loss: 359.1287\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 44.50803\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 114.6593 - val_loss: 110.2908\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 44.50803\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.1786 - val_loss: 287.7447\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 44.50803\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 117.4669 - val_loss: 106.7467\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 44.50803\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 124.6333 - val_loss: 273.7069\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 44.50803\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 115.4121 - val_loss: 247.2383\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 44.50803\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 114.8254 - val_loss: 156.8289\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 44.50803\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 112.3098 - val_loss: 313.7990\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 44.50803\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 113.2112 - val_loss: 145.9343\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 44.50803\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 113.1808 - val_loss: 93.2326\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 44.50803\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 115.6634 - val_loss: 296.4366\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 44.50803\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 112.1633 - val_loss: 244.0540\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 44.50803\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 113.2289 - val_loss: 235.9762\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 44.50803\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 112.0118 - val_loss: 121.6742\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 44.50803\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.2592 - val_loss: 255.8730\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 44.50803\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.5264 - val_loss: 127.3871\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 44.50803\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 112.4601 - val_loss: 173.0721\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 44.50803\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 108.4322 - val_loss: 334.1112\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 44.50803\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 111.8156 - val_loss: 370.9119\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 44.50803\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 111.2890 - val_loss: 155.4814\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 44.50803\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.9401 - val_loss: 164.8504\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 44.50803\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 105.8297 - val_loss: 243.1256\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 44.50803\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 108.6265 - val_loss: 201.0810\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 44.50803\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 108.3658 - val_loss: 390.7711\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 44.50803\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.3917 - val_loss: 255.5147\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 44.50803\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.0395 - val_loss: 157.6093\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 44.50803\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.2227 - val_loss: 174.4276\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 44.50803\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 102.6992 - val_loss: 196.6045\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 44.50803\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.3829 - val_loss: 156.5672\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 44.50803\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.9821 - val_loss: 273.7130\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 44.50803\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 105.9308 - val_loss: 151.5044\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 44.50803\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.1992 - val_loss: 95.9630\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 44.50803\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 108.3417 - val_loss: 227.8420\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 44.50803\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.1768 - val_loss: 330.0164\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 44.50803\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 103.7663 - val_loss: 81.3091\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 44.50803\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 97.6235 - val_loss: 355.5958\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 44.50803\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.0327 - val_loss: 263.4004\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 44.50803\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.9176 - val_loss: 275.2520\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 44.50803\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.2830 - val_loss: 172.4704\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 44.50803\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 97.2154 - val_loss: 127.5229\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 44.50803\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.9905 - val_loss: 169.2530\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 44.50803\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 99.5433 - val_loss: 295.4075\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 44.50803\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.6677 - val_loss: 81.8755\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 44.50803\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.2182 - val_loss: 109.6639\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 44.50803\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.5105 - val_loss: 139.9858\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 44.50803\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.6897 - val_loss: 139.2843\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 44.50803\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 103.5916 - val_loss: 292.9395\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 44.50803\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.3544 - val_loss: 265.2425\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 44.50803\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 99.7496 - val_loss: 222.7571\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 44.50803\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 96.5473 - val_loss: 191.4462\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 44.50803\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.3219 - val_loss: 286.4182\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 44.50803\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.4355 - val_loss: 94.3878\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 44.50803\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 97.7558 - val_loss: 195.7144\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 44.50803\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.7092 - val_loss: 316.1396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00128: val_loss did not improve from 44.50803\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.6837 - val_loss: 99.7417\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 44.50803\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 94.6786 - val_loss: 156.4381\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 44.50803\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.4883 - val_loss: 216.2503\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 44.50803\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.5578 - val_loss: 347.1448\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 44.50803\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.6949 - val_loss: 112.1319\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 44.50803\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.8175 - val_loss: 95.5863\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 44.50803\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 91.9948 - val_loss: 84.7815\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 44.50803\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.4444 - val_loss: 237.9099\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 44.50803\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.8814 - val_loss: 132.8301\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 44.50803\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 93.3895 - val_loss: 160.6308\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 44.50803\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.1458 - val_loss: 209.5297\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 44.50803\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 89.9595 - val_loss: 154.5239\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 44.50803\n",
      "Epoch 141/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 96.3164 - val_loss: 202.1032\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 44.50803\n",
      "Epoch 142/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 92.1895 - val_loss: 82.2477\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 44.50803\n",
      "Epoch 143/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 90.1684 - val_loss: 347.3289\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 44.50803\n",
      "Epoch 144/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 89.9701 - val_loss: 171.0164\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 44.50803\n",
      "Epoch 145/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 94.2070 - val_loss: 147.0742\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 44.50803\n",
      "Epoch 146/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 94.7207 - val_loss: 264.1762\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 44.50803\n",
      "Epoch 147/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 92.3845 - val_loss: 192.7508\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 44.50803\n",
      "Epoch 148/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.4804 - val_loss: 220.3821\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 44.50803\n",
      "Epoch 149/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 94.0221 - val_loss: 252.3304\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 44.50803\n",
      "Epoch 150/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 95.6911 - val_loss: 113.7523\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 44.50803\n",
      "Epoch 151/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 91.7599 - val_loss: 86.7608\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 44.50803\n",
      "Epoch 152/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 92.2906 - val_loss: 302.4435\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 44.50803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▋                                                                      | 3/21 [06:15<37:44, 125.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 10959.9346 - val_loss: 22392.2695\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 22392.26953, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 10950.9697 - val_loss: 22373.0898\n",
      "\n",
      "Epoch 00002: val_loss improved from 22392.26953 to 22373.08984, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 8249.8125 - val_loss: 7980.6582\n",
      "\n",
      "Epoch 00003: val_loss improved from 22373.08984 to 7980.65820, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3812.2168 - val_loss: 8723.8428\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 7980.65820\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3730.5115 - val_loss: 4165.5742\n",
      "\n",
      "Epoch 00005: val_loss improved from 7980.65820 to 4165.57422, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3743.3408 - val_loss: 12625.9873\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4165.57422\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3527.2371 - val_loss: 12839.1699\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4165.57422\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3747.7866 - val_loss: 6165.7583\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4165.57422\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3487.7417 - val_loss: 8182.3770\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4165.57422\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3449.9519 - val_loss: 12892.7510\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4165.57422\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3641.1841 - val_loss: 8774.9453\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4165.57422\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3557.7041 - val_loss: 5981.7886\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4165.57422\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3692.2539 - val_loss: 5821.0562\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4165.57422\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3359.8818 - val_loss: 11281.6953\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4165.57422\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3634.6353 - val_loss: 8783.9023\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4165.57422\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3516.8552 - val_loss: 4510.0869\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4165.57422\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3748.8484 - val_loss: 9726.6953\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4165.57422\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3653.1873 - val_loss: 6202.3931\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4165.57422\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3477.7129 - val_loss: 7921.6675\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4165.57422\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3666.7185 - val_loss: 12096.5723\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4165.57422\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3553.5083 - val_loss: 7187.5430\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4165.57422\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3538.4058 - val_loss: 6534.2363\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4165.57422\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3670.8455 - val_loss: 5042.7388\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4165.57422\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3734.2539 - val_loss: 4913.5674\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4165.57422\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3428.0869 - val_loss: 6350.5176\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4165.57422\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3681.2524 - val_loss: 4708.0640\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4165.57422\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3629.8384 - val_loss: 4802.6333\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 4165.57422\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3608.0781 - val_loss: 5057.2646\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4165.57422\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 3483.0889 - val_loss: 4595.3823\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 4165.57422\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3514.3328 - val_loss: 4867.9121\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 4165.57422\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3511.9219 - val_loss: 7512.6567\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 4165.57422\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3446.1868 - val_loss: 5315.3208\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 4165.57422\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3647.6709 - val_loss: 6574.6094\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 4165.57422\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3560.7126 - val_loss: 6732.0557\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 4165.57422\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3721.4290 - val_loss: 10550.2012\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 4165.57422\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3508.3149 - val_loss: 11287.8359\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 4165.57422\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3542.0703 - val_loss: 4625.1621\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 4165.57422\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3476.4480 - val_loss: 12373.5215\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 4165.57422\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3671.0032 - val_loss: 8217.0967\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 4165.57422\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3444.8184 - val_loss: 8055.1577\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 4165.57422\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3447.0242 - val_loss: 6971.9062\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 4165.57422\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3487.2324 - val_loss: 4567.0718\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 4165.57422\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3386.7764 - val_loss: 4719.2852\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 4165.57422\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3500.1538 - val_loss: 8951.1016\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 4165.57422\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3399.2476 - val_loss: 9095.3076\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 4165.57422\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3469.5342 - val_loss: 7614.4873\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 4165.57422\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3561.2576 - val_loss: 4677.1934\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 4165.57422\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3540.0828 - val_loss: 9172.7969\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 4165.57422\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3573.6213 - val_loss: 9580.2617\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 4165.57422\n",
      "Epoch 50/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 3613.2129 - val_loss: 5640.0107\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 4165.57422\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3563.5518 - val_loss: 4535.5532\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 4165.57422\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3516.1702 - val_loss: 8161.5977\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 4165.57422\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3413.5830 - val_loss: 4837.6855\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 4165.57422\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3585.9561 - val_loss: 4619.0352\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 4165.57422\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3376.6060 - val_loss: 6909.4683\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 4165.57422\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3356.5078 - val_loss: 6659.8525\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 4165.57422\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3636.2578 - val_loss: 4997.6777\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 4165.57422\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3489.9963 - val_loss: 9780.1133\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 4165.57422\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3519.0420 - val_loss: 4586.4434\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 4165.57422\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3540.6680 - val_loss: 7806.4404\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 4165.57422\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3463.3831 - val_loss: 10028.6533\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 4165.57422\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3559.9890 - val_loss: 7325.8535\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 4165.57422\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3542.3999 - val_loss: 4691.2432\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 4165.57422\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3365.4785 - val_loss: 5915.7129\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 4165.57422\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3489.6743 - val_loss: 4847.6323\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 4165.57422\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3534.3899 - val_loss: 6313.0605\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 4165.57422\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3582.0137 - val_loss: 7372.4785\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 4165.57422\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3552.6663 - val_loss: 8850.9814\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 4165.57422\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3357.3477 - val_loss: 8852.8564\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 4165.57422\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3467.1174 - val_loss: 4350.8374\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 4165.57422\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 3321.5193 - val_loss: 4663.0195\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 4165.57422\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3482.9368 - val_loss: 11704.5400\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 4165.57422\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3437.8772 - val_loss: 5092.6860\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 4165.57422\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3284.5591 - val_loss: 4905.2407\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 4165.57422\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3522.5566 - val_loss: 7637.5664\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 4165.57422\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3287.6016 - val_loss: 4628.4248\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 4165.57422\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3412.3298 - val_loss: 6325.4375\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 4165.57422\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3280.9341 - val_loss: 4832.3979\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 4165.57422\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3330.0032 - val_loss: 5511.5630\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 4165.57422\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3316.2578 - val_loss: 6476.2788\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 4165.57422\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3456.9790 - val_loss: 4357.9204\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 4165.57422\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3277.7100 - val_loss: 6284.5908\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 4165.57422\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3384.9722 - val_loss: 4634.4829\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 4165.57422\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3300.7053 - val_loss: 4427.5376\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 4165.57422\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3296.5085 - val_loss: 8395.0850\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 4165.57422\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3185.4434 - val_loss: 5096.1431\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 4165.57422\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3336.9436 - val_loss: 4874.2593\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 4165.57422\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3238.9373 - val_loss: 4709.6665\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 4165.57422\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3237.5632 - val_loss: 4733.6802\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 4165.57422\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3307.6177 - val_loss: 4527.3564\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 4165.57422\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3417.6167 - val_loss: 7612.2944\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 4165.57422\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3216.1099 - val_loss: 8204.7520\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 4165.57422\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3249.1445 - val_loss: 5052.7324\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 4165.57422\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3095.8311 - val_loss: 4917.4111\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 4165.57422\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3095.9250 - val_loss: 5409.5850\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 4165.57422\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 987us/step - loss: 3218.3252 - val_loss: 5888.5269\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 4165.57422\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3111.3674 - val_loss: 8363.9570\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 4165.57422\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3150.9800 - val_loss: 4362.4429\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 4165.57422\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3138.9482 - val_loss: 4246.6499\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 4165.57422\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3124.8799 - val_loss: 4199.1621\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 4165.57422\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3037.7144 - val_loss: 11695.9150\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 4165.57422\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3145.3330 - val_loss: 5313.7852\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 4165.57422\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3214.7407 - val_loss: 5163.4478\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 4165.57422\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3162.3049 - val_loss: 8487.0703\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 4165.57422\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3222.6221 - val_loss: 4489.7407\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 4165.57422\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 10982.8721 - val_loss: 22393.3398\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 22393.33984, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 10976.5908 - val_loss: 22380.3867\n",
      "\n",
      "Epoch 00002: val_loss improved from 22393.33984 to 22380.38672, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 10732.4922 - val_loss: 6830.3555\n",
      "\n",
      "Epoch 00003: val_loss improved from 22380.38672 to 6830.35547, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3985.1826 - val_loss: 4834.2129\n",
      "\n",
      "Epoch 00004: val_loss improved from 6830.35547 to 4834.21289, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3892.5283 - val_loss: 9010.2979\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4834.21289\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3655.9578 - val_loss: 7181.4336\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4834.21289\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3694.1838 - val_loss: 14437.4941\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4834.21289\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3691.1863 - val_loss: 9493.4648\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4834.21289\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3596.9702 - val_loss: 5816.5508\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4834.21289\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3615.2561 - val_loss: 11594.3604\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4834.21289\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 3659.9722 - val_loss: 4902.7798\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4834.21289\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 3628.5923 - val_loss: 4829.5884\n",
      "\n",
      "Epoch 00012: val_loss improved from 4834.21289 to 4829.58838, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3728.9695 - val_loss: 13003.4922\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4829.58838\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3571.0183 - val_loss: 6263.6724\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4829.58838\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3578.2410 - val_loss: 6310.3374\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4829.58838\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3681.5337 - val_loss: 13856.4004\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4829.58838\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3728.6809 - val_loss: 14783.7061\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4829.58838\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3650.6326 - val_loss: 9098.5625\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4829.58838\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3658.0308 - val_loss: 13808.3350\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4829.58838\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3500.5344 - val_loss: 9750.1445\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4829.58838\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3583.2117 - val_loss: 11021.9648\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4829.58838\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3505.0513 - val_loss: 5627.0312\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4829.58838\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3462.4202 - val_loss: 5037.3691\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4829.58838\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3660.4241 - val_loss: 6875.8589\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4829.58838\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3619.4434 - val_loss: 7320.5762\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4829.58838\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3707.4036 - val_loss: 5162.0015\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4829.58838\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3555.6533 - val_loss: 7909.6948\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 4829.58838\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3496.6340 - val_loss: 13852.2803\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4829.58838\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3598.2288 - val_loss: 10364.7520\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 4829.58838\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3711.3120 - val_loss: 5259.0444\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 4829.58838\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3488.7524 - val_loss: 5066.3066\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 4829.58838\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3632.8184 - val_loss: 7654.2563\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 4829.58838\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3435.4089 - val_loss: 5070.3018\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 4829.58838\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3429.1501 - val_loss: 8954.8867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 4829.58838\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3477.9961 - val_loss: 5266.4424\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 4829.58838\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3353.4409 - val_loss: 13016.0791\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 4829.58838\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3538.6772 - val_loss: 5032.3223\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 4829.58838\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3455.1194 - val_loss: 13771.5273\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 4829.58838\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3571.4822 - val_loss: 10216.1143\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 4829.58838\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3610.2429 - val_loss: 7693.8677\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 4829.58838\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 995us/step - loss: 3526.5627 - val_loss: 5027.3589\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 4829.58838\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3358.1450 - val_loss: 14675.0098\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 4829.58838\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3441.4292 - val_loss: 6126.2437\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 4829.58838\n",
      "Epoch 44/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 3375.5269 - val_loss: 8023.8262\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 4829.58838\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3293.7610 - val_loss: 5097.8438\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 4829.58838\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3428.2026 - val_loss: 5246.7944\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 4829.58838\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3518.4895 - val_loss: 5137.3604\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 4829.58838\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3501.8955 - val_loss: 8959.3271\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 4829.58838\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3517.5083 - val_loss: 5040.7812\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 4829.58838\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3324.7048 - val_loss: 11557.5137\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 4829.58838\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3405.0139 - val_loss: 4537.6279\n",
      "\n",
      "Epoch 00051: val_loss improved from 4829.58838 to 4537.62793, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3464.4009 - val_loss: 9383.3281\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 4537.62793\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3489.6487 - val_loss: 8386.3740\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 4537.62793\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 970us/step - loss: 3306.6885 - val_loss: 5061.1064\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 4537.62793\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3349.7725 - val_loss: 5063.1104\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 4537.62793\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 985us/step - loss: 3493.0100 - val_loss: 10916.1904\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 4537.62793\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3278.9202 - val_loss: 4256.2192\n",
      "\n",
      "Epoch 00057: val_loss improved from 4537.62793 to 4256.21924, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3404.9082 - val_loss: 10518.1289\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 4256.21924\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3425.1143 - val_loss: 4689.4902\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 4256.21924\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3422.2168 - val_loss: 11413.5410\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 4256.21924\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3422.8997 - val_loss: 9014.1611\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 4256.21924\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3272.1802 - val_loss: 13014.9336\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 4256.21924\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3418.3887 - val_loss: 4459.4014\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 4256.21924\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3268.5984 - val_loss: 8723.8555\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 4256.21924\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3326.8896 - val_loss: 9054.6855\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 4256.21924\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3291.1970 - val_loss: 8857.4971\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 4256.21924\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3329.0332 - val_loss: 15445.6113\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 4256.21924\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3331.7146 - val_loss: 7139.7202\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 4256.21924\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3203.9370 - val_loss: 8828.2617\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 4256.21924\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3137.7439 - val_loss: 7349.1074\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 4256.21924\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3494.6265 - val_loss: 8421.9727\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 4256.21924\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3116.1150 - val_loss: 8682.0273\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 4256.21924\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3159.6716 - val_loss: 5023.2241\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 4256.21924\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3369.9512 - val_loss: 4397.8823\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 4256.21924\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3155.8142 - val_loss: 10541.0928\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 4256.21924\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3154.0002 - val_loss: 12904.1016\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 4256.21924\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 985us/step - loss: 3342.7461 - val_loss: 5180.7314\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 4256.21924\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3166.2976 - val_loss: 11259.9863\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 4256.21924\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3239.8228 - val_loss: 4611.1221\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 4256.21924\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3271.4209 - val_loss: 6724.0781\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 4256.21924\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3279.6060 - val_loss: 7900.3164\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 4256.21924\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3128.3694 - val_loss: 5270.9648\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 4256.21924\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3298.7556 - val_loss: 3308.0203\n",
      "\n",
      "Epoch 00083: val_loss improved from 4256.21924 to 3308.02026, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3278.1313 - val_loss: 3713.0044\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 3308.02026\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3346.6404 - val_loss: 4280.9062\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 3308.02026\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3176.7776 - val_loss: 4478.9087\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 3308.02026\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3180.0623 - val_loss: 7898.9023\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 3308.02026\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3224.6367 - val_loss: 5597.4058\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3308.02026\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3249.1826 - val_loss: 7110.2402\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 3308.02026\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3174.6504 - val_loss: 8394.7842\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 3308.02026\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3159.0500 - val_loss: 9055.2939\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3308.02026\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3179.6948 - val_loss: 4283.3379\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 3308.02026\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3145.0830 - val_loss: 6212.0396\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 3308.02026\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3088.0247 - val_loss: 5179.9863\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3308.02026\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3271.9883 - val_loss: 12657.2803\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3308.02026\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3126.4226 - val_loss: 9179.0127\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 3308.02026\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3081.0945 - val_loss: 8258.8555\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 3308.02026\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3094.1340 - val_loss: 4070.1230\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 3308.02026\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3143.9219 - val_loss: 9609.1396\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 3308.02026\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3069.1541 - val_loss: 4173.0474\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 3308.02026\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3050.3235 - val_loss: 6907.6602\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 3308.02026\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3227.1479 - val_loss: 11874.2734\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 3308.02026\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3127.9473 - val_loss: 9816.7383\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 3308.02026\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3022.8135 - val_loss: 4188.2358\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 3308.02026\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3204.6174 - val_loss: 9296.3203\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 3308.02026\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3129.2605 - val_loss: 8501.8896\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 3308.02026\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3042.1555 - val_loss: 4759.5474\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 3308.02026\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3119.0820 - val_loss: 5540.1567\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 3308.02026\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3020.5945 - val_loss: 6514.8813\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 3308.02026\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3074.3987 - val_loss: 9732.9248\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 3308.02026\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3144.2771 - val_loss: 12540.4746\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 3308.02026\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3024.8096 - val_loss: 3687.9607\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 3308.02026\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3014.1121 - val_loss: 8973.0498\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 3308.02026\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3006.6880 - val_loss: 7851.6099\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 3308.02026\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2949.2041 - val_loss: 7023.0786\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 3308.02026\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3069.0559 - val_loss: 6264.2993\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 3308.02026\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3076.4617 - val_loss: 6139.2588\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 3308.02026\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3052.8274 - val_loss: 6392.6567\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 3308.02026\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2991.9294 - val_loss: 8177.4312\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 3308.02026\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2891.6238 - val_loss: 3988.7402\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 3308.02026\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3034.8994 - val_loss: 5497.8965\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 3308.02026\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2998.5757 - val_loss: 8438.4941\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 3308.02026\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2989.0686 - val_loss: 4580.8477\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 3308.02026\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2964.9048 - val_loss: 5398.4170\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 3308.02026\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2996.7385 - val_loss: 4967.3208\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 3308.02026\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2897.8545 - val_loss: 7478.2651\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 3308.02026\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2942.3074 - val_loss: 8276.4385\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 3308.02026\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2921.1140 - val_loss: 6713.0664\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 3308.02026\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2995.5742 - val_loss: 3283.5010\n",
      "\n",
      "Epoch 00129: val_loss improved from 3308.02026 to 3283.50098, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2942.5771 - val_loss: 5611.8096\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 3283.50098\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3035.5544 - val_loss: 13489.7266\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 3283.50098\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3188.5535 - val_loss: 6604.1143\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 3283.50098\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2916.3486 - val_loss: 7798.5029\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 3283.50098\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2881.5984 - val_loss: 5391.5601\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 3283.50098\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2866.6277 - val_loss: 10316.8652\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 3283.50098\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2919.5837 - val_loss: 5547.3511\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 3283.50098\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2912.5515 - val_loss: 6261.8906\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 3283.50098\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2852.5430 - val_loss: 5645.0645\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 3283.50098\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2855.0449 - val_loss: 4967.2349\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 3283.50098\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2921.9829 - val_loss: 7745.1533\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 3283.50098\n",
      "Epoch 141/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2861.8000 - val_loss: 8215.1885\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 3283.50098\n",
      "Epoch 142/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2832.6521 - val_loss: 4259.7822\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 3283.50098\n",
      "Epoch 143/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 2853.9377 - val_loss: 8236.8057\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 3283.50098\n",
      "Epoch 144/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2876.9463 - val_loss: 3439.3479\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 3283.50098\n",
      "Epoch 145/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2915.7651 - val_loss: 10720.0508\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 3283.50098\n",
      "Epoch 146/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2860.5818 - val_loss: 6195.1738\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 3283.50098\n",
      "Epoch 147/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2824.7014 - val_loss: 7675.7681\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 3283.50098\n",
      "Epoch 148/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2830.1738 - val_loss: 11578.2822\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 3283.50098\n",
      "Epoch 149/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2768.3967 - val_loss: 10029.0928\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 3283.50098\n",
      "Epoch 150/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2825.2339 - val_loss: 9355.6064\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 3283.50098\n",
      "Epoch 151/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2860.1567 - val_loss: 4502.2920\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 3283.50098\n",
      "Epoch 152/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2828.6311 - val_loss: 4600.7876\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 3283.50098\n",
      "Epoch 153/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2719.7649 - val_loss: 8843.1309\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 3283.50098\n",
      "Epoch 154/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2774.6545 - val_loss: 7323.0352\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 3283.50098\n",
      "Epoch 155/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2834.9258 - val_loss: 10732.8213\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 3283.50098\n",
      "Epoch 156/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2801.5627 - val_loss: 5309.4756\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 3283.50098\n",
      "Epoch 157/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2742.9460 - val_loss: 9750.2451\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 3283.50098\n",
      "Epoch 158/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2751.8403 - val_loss: 8011.4614\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 3283.50098\n",
      "Epoch 159/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2799.1533 - val_loss: 9886.4844\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 3283.50098\n",
      "Epoch 160/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2836.9355 - val_loss: 4919.1362\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 3283.50098\n",
      "Epoch 161/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2823.4739 - val_loss: 6242.0000\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 3283.50098\n",
      "Epoch 162/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2743.5391 - val_loss: 4439.2441\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 3283.50098\n",
      "Epoch 163/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2740.5396 - val_loss: 4214.9146\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 3283.50098\n",
      "Epoch 164/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2707.3691 - val_loss: 4906.0972\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 3283.50098\n",
      "Epoch 165/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2833.7461 - val_loss: 9973.6064\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 3283.50098\n",
      "Epoch 166/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2708.0991 - val_loss: 10842.1689\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 3283.50098\n",
      "Epoch 167/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2737.1750 - val_loss: 10274.5557\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 3283.50098\n",
      "Epoch 168/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2804.7231 - val_loss: 9955.3379\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 3283.50098\n",
      "Epoch 169/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2783.4204 - val_loss: 5980.1035\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 3283.50098\n",
      "Epoch 170/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2747.3354 - val_loss: 8696.5479\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 3283.50098\n",
      "Epoch 171/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2773.1340 - val_loss: 8700.1172\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 3283.50098\n",
      "Epoch 172/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2746.4526 - val_loss: 9139.5439\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 3283.50098\n",
      "Epoch 173/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2760.3142 - val_loss: 8328.6504\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 3283.50098\n",
      "Epoch 174/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2732.1492 - val_loss: 6432.8735\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 3283.50098\n",
      "Epoch 175/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2712.7637 - val_loss: 3953.6682\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 3283.50098\n",
      "Epoch 176/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2782.2041 - val_loss: 10442.0244\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 3283.50098\n",
      "Epoch 177/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2765.1011 - val_loss: 7376.8105\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 3283.50098\n",
      "Epoch 178/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2748.2703 - val_loss: 6530.3374\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 3283.50098\n",
      "Epoch 179/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2718.9358 - val_loss: 7775.2168\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 3283.50098\n",
      "Epoch 180/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2752.7993 - val_loss: 8178.6826\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 3283.50098\n",
      "Epoch 181/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2733.5420 - val_loss: 8128.9033\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 3283.50098\n",
      "Epoch 182/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2727.7905 - val_loss: 9307.3311\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 3283.50098\n",
      "Epoch 183/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2649.9216 - val_loss: 7754.2036\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 3283.50098\n",
      "Epoch 184/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2725.9573 - val_loss: 11293.5840\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 3283.50098\n",
      "Epoch 185/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2681.8816 - val_loss: 7493.4795\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 3283.50098\n",
      "Epoch 186/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2780.6123 - val_loss: 4854.7485\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 3283.50098\n",
      "Epoch 187/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2736.9907 - val_loss: 3468.5884\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 3283.50098\n",
      "Epoch 188/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2740.4556 - val_loss: 11723.0127\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 3283.50098\n",
      "Epoch 189/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2745.6050 - val_loss: 8915.9424\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 3283.50098\n",
      "Epoch 190/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2693.4026 - val_loss: 7066.0957\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 3283.50098\n",
      "Epoch 191/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2672.6072 - val_loss: 13029.4688\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 3283.50098\n",
      "Epoch 192/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2784.3894 - val_loss: 3893.6660\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 3283.50098\n",
      "Epoch 193/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 2673.7021 - val_loss: 12262.6396\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 3283.50098\n",
      "Epoch 194/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2697.3713 - val_loss: 8654.6758\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 3283.50098\n",
      "Epoch 195/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2687.1951 - val_loss: 6911.8618\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 3283.50098\n",
      "Epoch 196/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2693.7209 - val_loss: 5236.9126\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 3283.50098\n",
      "Epoch 197/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2749.8364 - val_loss: 11456.0703\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 3283.50098\n",
      "Epoch 198/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2737.9529 - val_loss: 7353.1177\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 3283.50098\n",
      "Epoch 199/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2686.9192 - val_loss: 3810.6013\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 3283.50098\n",
      "Epoch 200/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2711.5095 - val_loss: 4512.7017\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 3283.50098\n",
      "Epoch 201/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2647.3525 - val_loss: 8344.1709\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 3283.50098\n",
      "Epoch 202/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2671.2146 - val_loss: 7957.0718\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 3283.50098\n",
      "Epoch 203/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2673.2874 - val_loss: 4030.1257\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 3283.50098\n",
      "Epoch 204/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2719.2544 - val_loss: 5020.2119\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 3283.50098\n",
      "Epoch 205/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2700.8284 - val_loss: 7148.7520\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 3283.50098\n",
      "Epoch 206/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2685.6040 - val_loss: 4210.6479\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 3283.50098\n",
      "Epoch 207/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2656.6912 - val_loss: 9413.4648\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 3283.50098\n",
      "Epoch 208/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2682.0703 - val_loss: 6535.8755\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 3283.50098\n",
      "Epoch 209/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2694.9070 - val_loss: 4269.7744\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 3283.50098\n",
      "Epoch 210/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2732.0237 - val_loss: 10641.5391\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 3283.50098\n",
      "Epoch 211/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2713.1394 - val_loss: 3815.7861\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 3283.50098\n",
      "Epoch 212/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2660.4470 - val_loss: 6008.0308\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 3283.50098\n",
      "Epoch 213/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2666.4810 - val_loss: 6948.9746\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 3283.50098\n",
      "Epoch 214/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2654.0078 - val_loss: 6802.0132\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 3283.50098\n",
      "Epoch 215/10000\n",
      "88/88 [==============================] - 0s 986us/step - loss: 2665.4946 - val_loss: 3691.2910\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 3283.50098\n",
      "Epoch 216/10000\n",
      "88/88 [==============================] - 0s 1000us/step - loss: 2731.7319 - val_loss: 9546.9453\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 3283.50098\n",
      "Epoch 217/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2704.5249 - val_loss: 5213.1504\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 3283.50098\n",
      "Epoch 218/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2623.2258 - val_loss: 6730.4043\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 3283.50098\n",
      "Epoch 219/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2638.7207 - val_loss: 9908.4199\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 3283.50098\n",
      "Epoch 220/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2676.5640 - val_loss: 8976.9883\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 3283.50098\n",
      "Epoch 221/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2643.9119 - val_loss: 9963.2070\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 3283.50098\n",
      "Epoch 222/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2630.7327 - val_loss: 9808.2178\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 3283.50098\n",
      "Epoch 223/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2614.3018 - val_loss: 9871.4561\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 3283.50098\n",
      "Epoch 224/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2644.8748 - val_loss: 7501.2095\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 3283.50098\n",
      "Epoch 225/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2661.3950 - val_loss: 7913.8901\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 3283.50098\n",
      "Epoch 226/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2630.9707 - val_loss: 8783.8945\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 3283.50098\n",
      "Epoch 227/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2603.5017 - val_loss: 4118.8242\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 3283.50098\n",
      "Epoch 228/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2677.1099 - val_loss: 6750.2715\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 3283.50098\n",
      "Epoch 229/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2650.9207 - val_loss: 7787.4937\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 3283.50098\n",
      "Epoch 1/10000\n",
      "87/87 [==============================] - 1s 3ms/step - loss: 11016.3926 - val_loss: 22391.6055\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 22391.60547, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11003.5859 - val_loss: 22343.9453\n",
      "\n",
      "Epoch 00002: val_loss improved from 22391.60547 to 22343.94531, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 5910.8091 - val_loss: 10098.2559\n",
      "\n",
      "Epoch 00003: val_loss improved from 22343.94531 to 10098.25586, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3894.3223 - val_loss: 8690.2080\n",
      "\n",
      "Epoch 00004: val_loss improved from 10098.25586 to 8690.20801, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3849.9187 - val_loss: 10038.1338\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 8690.20801\n",
      "Epoch 6/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3678.4382 - val_loss: 12227.6475\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 8690.20801\n",
      "Epoch 7/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3833.8267 - val_loss: 5672.3496\n",
      "\n",
      "Epoch 00007: val_loss improved from 8690.20801 to 5672.34961, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 8/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3782.7517 - val_loss: 6353.2808\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 5672.34961\n",
      "Epoch 9/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3792.1602 - val_loss: 13620.0977\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 5672.34961\n",
      "Epoch 10/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3967.3757 - val_loss: 9931.7393\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 5672.34961\n",
      "Epoch 11/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3697.2229 - val_loss: 10065.1611\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 5672.34961\n",
      "Epoch 12/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3674.8367 - val_loss: 9757.0381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_loss did not improve from 5672.34961\n",
      "Epoch 13/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3788.2468 - val_loss: 6807.3086\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 5672.34961\n",
      "Epoch 14/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3835.9089 - val_loss: 10696.1035\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 5672.34961\n",
      "Epoch 15/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3645.5159 - val_loss: 8133.9717\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 5672.34961\n",
      "Epoch 16/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3655.5225 - val_loss: 6385.2080\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 5672.34961\n",
      "Epoch 17/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3667.5112 - val_loss: 9855.2402\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 5672.34961\n",
      "Epoch 18/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3721.6650 - val_loss: 10246.7510\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 5672.34961\n",
      "Epoch 19/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3602.8374 - val_loss: 11560.0254\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 5672.34961\n",
      "Epoch 20/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3764.5928 - val_loss: 13620.3799\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 5672.34961\n",
      "Epoch 21/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3742.5090 - val_loss: 12179.3516\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 5672.34961\n",
      "Epoch 22/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3749.7637 - val_loss: 12490.8008\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 5672.34961\n",
      "Epoch 23/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3640.5627 - val_loss: 11019.5508\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 5672.34961\n",
      "Epoch 24/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3748.8997 - val_loss: 6518.4175\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 5672.34961\n",
      "Epoch 25/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3626.8887 - val_loss: 5307.8779\n",
      "\n",
      "Epoch 00025: val_loss improved from 5672.34961 to 5307.87793, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 26/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3744.4468 - val_loss: 8218.1445\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 5307.87793\n",
      "Epoch 27/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3483.1309 - val_loss: 14945.0371\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 5307.87793\n",
      "Epoch 28/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3842.0762 - val_loss: 12145.8320\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 5307.87793\n",
      "Epoch 29/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3653.6995 - val_loss: 6378.2520\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 5307.87793\n",
      "Epoch 30/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3659.9270 - val_loss: 4772.2832\n",
      "\n",
      "Epoch 00030: val_loss improved from 5307.87793 to 4772.28320, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 31/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3689.5212 - val_loss: 9330.7998\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 4772.28320\n",
      "Epoch 32/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3539.5024 - val_loss: 6333.4287\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 4772.28320\n",
      "Epoch 33/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3738.9080 - val_loss: 7735.7363\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 4772.28320\n",
      "Epoch 34/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3552.7456 - val_loss: 12351.0088\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 4772.28320\n",
      "Epoch 35/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3635.8066 - val_loss: 5882.1401\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 4772.28320\n",
      "Epoch 36/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3607.5608 - val_loss: 10544.5371\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 4772.28320\n",
      "Epoch 37/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3756.6973 - val_loss: 9461.3936\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 4772.28320\n",
      "Epoch 38/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3619.6936 - val_loss: 7810.0854\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 4772.28320\n",
      "Epoch 39/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3670.5273 - val_loss: 12641.5049\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 4772.28320\n",
      "Epoch 40/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3686.3154 - val_loss: 10562.5752\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 4772.28320\n",
      "Epoch 41/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3523.6018 - val_loss: 11629.5342\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 4772.28320\n",
      "Epoch 42/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3554.3733 - val_loss: 14503.8750\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 4772.28320\n",
      "Epoch 43/10000\n",
      "87/87 [==============================] - 0s 994us/step - loss: 3623.8508 - val_loss: 8715.7939\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 4772.28320\n",
      "Epoch 44/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3510.7266 - val_loss: 10363.9961\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 4772.28320\n",
      "Epoch 45/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3609.9624 - val_loss: 8767.1523\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 4772.28320\n",
      "Epoch 46/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3544.9683 - val_loss: 15028.2695\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 4772.28320\n",
      "Epoch 47/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3670.4670 - val_loss: 13158.0273\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 4772.28320\n",
      "Epoch 48/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3643.8547 - val_loss: 10540.4492\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 4772.28320\n",
      "Epoch 49/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3705.7080 - val_loss: 10182.0967\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 4772.28320\n",
      "Epoch 50/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3641.9553 - val_loss: 8534.1143\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 4772.28320\n",
      "Epoch 51/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3646.4028 - val_loss: 11475.8066\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 4772.28320\n",
      "Epoch 52/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3611.6228 - val_loss: 11409.2412\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 4772.28320\n",
      "Epoch 53/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3730.0386 - val_loss: 7137.3525\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 4772.28320\n",
      "Epoch 54/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3471.4761 - val_loss: 8910.4004\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 4772.28320\n",
      "Epoch 55/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3674.1489 - val_loss: 13184.9502\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 4772.28320\n",
      "Epoch 56/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3721.4558 - val_loss: 11889.0459\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 4772.28320\n",
      "Epoch 57/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3506.9058 - val_loss: 6712.4287\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 4772.28320\n",
      "Epoch 58/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3513.1130 - val_loss: 9260.9355\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 4772.28320\n",
      "Epoch 59/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3693.0447 - val_loss: 13281.8613\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 4772.28320\n",
      "Epoch 60/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3626.0376 - val_loss: 8463.5332\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 4772.28320\n",
      "Epoch 61/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3673.8533 - val_loss: 9772.6348\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 4772.28320\n",
      "Epoch 62/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3695.4434 - val_loss: 6126.8867\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 4772.28320\n",
      "Epoch 63/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3558.3733 - val_loss: 7754.8276\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 4772.28320\n",
      "Epoch 64/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3620.9976 - val_loss: 10198.8457\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 4772.28320\n",
      "Epoch 65/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3707.3101 - val_loss: 11924.6191\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 4772.28320\n",
      "Epoch 66/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3575.7427 - val_loss: 11382.9521\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 4772.28320\n",
      "Epoch 67/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3721.7476 - val_loss: 11105.8096\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 4772.28320\n",
      "Epoch 68/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3535.0205 - val_loss: 10064.0117\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 4772.28320\n",
      "Epoch 69/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3467.8213 - val_loss: 5852.7368\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 4772.28320\n",
      "Epoch 70/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3635.9309 - val_loss: 4824.1670\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 4772.28320\n",
      "Epoch 71/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3620.0415 - val_loss: 10190.6182\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 4772.28320\n",
      "Epoch 72/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3601.0166 - val_loss: 15036.0508\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 4772.28320\n",
      "Epoch 73/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3640.7891 - val_loss: 5734.8623\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 4772.28320\n",
      "Epoch 74/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3491.4136 - val_loss: 11298.6084\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 4772.28320\n",
      "Epoch 75/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3524.0657 - val_loss: 8410.5186\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 4772.28320\n",
      "Epoch 76/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3557.2822 - val_loss: 7093.4004\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 4772.28320\n",
      "Epoch 77/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3575.1331 - val_loss: 6020.2202\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 4772.28320\n",
      "Epoch 78/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3550.4607 - val_loss: 9395.3076\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 4772.28320\n",
      "Epoch 79/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3400.3135 - val_loss: 6010.4829\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 4772.28320\n",
      "Epoch 80/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3692.0024 - val_loss: 10151.9385\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 4772.28320\n",
      "Epoch 81/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3568.9368 - val_loss: 10153.5293\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 4772.28320\n",
      "Epoch 82/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3462.2908 - val_loss: 13894.0996\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 4772.28320\n",
      "Epoch 83/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3617.0068 - val_loss: 5599.2607\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 4772.28320\n",
      "Epoch 84/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3501.1221 - val_loss: 10009.9229\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 4772.28320\n",
      "Epoch 85/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3434.0791 - val_loss: 9725.6992\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 4772.28320\n",
      "Epoch 86/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3504.5845 - val_loss: 8262.2080\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 4772.28320\n",
      "Epoch 87/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3504.6777 - val_loss: 8173.2227\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 4772.28320\n",
      "Epoch 88/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3482.5947 - val_loss: 8931.9717\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 4772.28320\n",
      "Epoch 89/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3640.9204 - val_loss: 6996.0205\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 4772.28320\n",
      "Epoch 90/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3620.2144 - val_loss: 5466.2031\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 4772.28320\n",
      "Epoch 91/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3491.5046 - val_loss: 9206.8574\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 4772.28320\n",
      "Epoch 92/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3448.9163 - val_loss: 11137.0889\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 4772.28320\n",
      "Epoch 93/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3535.9631 - val_loss: 9197.8496\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 4772.28320\n",
      "Epoch 94/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3428.4270 - val_loss: 8725.5215\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 4772.28320\n",
      "Epoch 95/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3374.8215 - val_loss: 8554.1455\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 4772.28320\n",
      "Epoch 96/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3301.4744 - val_loss: 5888.0557\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 4772.28320\n",
      "Epoch 97/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3335.1843 - val_loss: 7904.6475\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 4772.28320\n",
      "Epoch 98/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3450.4414 - val_loss: 5961.7280\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 4772.28320\n",
      "Epoch 99/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3354.8547 - val_loss: 6028.5239\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 4772.28320\n",
      "Epoch 100/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3556.2214 - val_loss: 12225.2012\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 4772.28320\n",
      "Epoch 101/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3439.7703 - val_loss: 10805.6953\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 4772.28320\n",
      "Epoch 102/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3419.7412 - val_loss: 12287.8848\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 4772.28320\n",
      "Epoch 103/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3537.8013 - val_loss: 11511.8613\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 4772.28320\n",
      "Epoch 104/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3461.8469 - val_loss: 6110.2275\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 4772.28320\n",
      "Epoch 105/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3466.0046 - val_loss: 14277.6025\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 4772.28320\n",
      "Epoch 106/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3488.9490 - val_loss: 6187.1499\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 4772.28320\n",
      "Epoch 107/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3362.0596 - val_loss: 9690.1943\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 4772.28320\n",
      "Epoch 108/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3372.4753 - val_loss: 7448.6191\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 4772.28320\n",
      "Epoch 109/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3452.1294 - val_loss: 4288.4692\n",
      "\n",
      "Epoch 00109: val_loss improved from 4772.28320 to 4288.46924, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 110/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3308.8862 - val_loss: 14396.4883\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 4288.46924\n",
      "Epoch 111/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3492.5205 - val_loss: 6888.0098\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 4288.46924\n",
      "Epoch 112/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 3329.6001 - val_loss: 5748.3281\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 4288.46924\n",
      "Epoch 113/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3346.0701 - val_loss: 8930.6104\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 4288.46924\n",
      "Epoch 114/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3287.9526 - val_loss: 8311.7373\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 4288.46924\n",
      "Epoch 115/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3383.1030 - val_loss: 6766.6289\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 4288.46924\n",
      "Epoch 116/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3364.9768 - val_loss: 7342.5493\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 4288.46924\n",
      "Epoch 117/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3170.9761 - val_loss: 8645.8740\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 4288.46924\n",
      "Epoch 118/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3311.0769 - val_loss: 10771.9951\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 4288.46924\n",
      "Epoch 119/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3226.7559 - val_loss: 5774.5283\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 4288.46924\n",
      "Epoch 120/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3316.4133 - val_loss: 6968.0020\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 4288.46924\n",
      "Epoch 121/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3261.9934 - val_loss: 7577.5781\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 4288.46924\n",
      "Epoch 122/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3276.2815 - val_loss: 7458.6816\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 4288.46924\n",
      "Epoch 123/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3250.4368 - val_loss: 5510.9912\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 4288.46924\n",
      "Epoch 124/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3329.1704 - val_loss: 6763.9038\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 4288.46924\n",
      "Epoch 125/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3335.0337 - val_loss: 11909.8428\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 4288.46924\n",
      "Epoch 126/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3255.7131 - val_loss: 11955.9180\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 4288.46924\n",
      "Epoch 127/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3330.7410 - val_loss: 10116.3564\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 4288.46924\n",
      "Epoch 128/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3306.1523 - val_loss: 9041.6885\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 4288.46924\n",
      "Epoch 129/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3232.7637 - val_loss: 5689.2583\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 4288.46924\n",
      "Epoch 130/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3331.7583 - val_loss: 7309.0811\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 4288.46924\n",
      "Epoch 131/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3214.0337 - val_loss: 5534.1299\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 4288.46924\n",
      "Epoch 132/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3154.0088 - val_loss: 5315.6152\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 4288.46924\n",
      "Epoch 133/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3178.8406 - val_loss: 8331.6309\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 4288.46924\n",
      "Epoch 134/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3159.7283 - val_loss: 8290.7490\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 4288.46924\n",
      "Epoch 135/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3260.0488 - val_loss: 8003.7173\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 4288.46924\n",
      "Epoch 136/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3184.0051 - val_loss: 9397.8203\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 4288.46924\n",
      "Epoch 137/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3217.8962 - val_loss: 10399.4404\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 4288.46924\n",
      "Epoch 138/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3159.0295 - val_loss: 10208.0166\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 4288.46924\n",
      "Epoch 139/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3220.6350 - val_loss: 7158.4775\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 4288.46924\n",
      "Epoch 140/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3157.8606 - val_loss: 8693.1914\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 4288.46924\n",
      "Epoch 141/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3043.2185 - val_loss: 11892.3691\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 4288.46924\n",
      "Epoch 142/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3111.3657 - val_loss: 6037.9033\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 4288.46924\n",
      "Epoch 143/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3141.3997 - val_loss: 9124.3574\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 4288.46924\n",
      "Epoch 144/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3086.1836 - val_loss: 6517.2749\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 4288.46924\n",
      "Epoch 145/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3232.6323 - val_loss: 4967.4844\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 4288.46924\n",
      "Epoch 146/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3136.6265 - val_loss: 10481.0088\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 4288.46924\n",
      "Epoch 147/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3168.4834 - val_loss: 9114.5801\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 4288.46924\n",
      "Epoch 148/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3105.5713 - val_loss: 7101.9277\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 4288.46924\n",
      "Epoch 149/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3069.9067 - val_loss: 6112.5430\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 4288.46924\n",
      "Epoch 150/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3114.1177 - val_loss: 11664.5010\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 4288.46924\n",
      "Epoch 151/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3135.2644 - val_loss: 4038.1260\n",
      "\n",
      "Epoch 00151: val_loss improved from 4288.46924 to 4038.12598, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 152/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3159.2258 - val_loss: 4825.1055\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 4038.12598\n",
      "Epoch 153/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3043.8472 - val_loss: 8381.7803\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 4038.12598\n",
      "Epoch 154/10000\n",
      "87/87 [==============================] - 0s 954us/step - loss: 3063.4961 - val_loss: 11807.2236\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 4038.12598\n",
      "Epoch 155/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3110.2024 - val_loss: 5626.2383\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 4038.12598\n",
      "Epoch 156/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3027.3206 - val_loss: 5764.0566\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 4038.12598\n",
      "Epoch 157/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3043.6941 - val_loss: 8211.1777\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 4038.12598\n",
      "Epoch 158/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3042.8955 - val_loss: 5605.0239\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 4038.12598\n",
      "Epoch 159/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3064.6704 - val_loss: 10661.6084\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 4038.12598\n",
      "Epoch 160/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3084.8638 - val_loss: 8874.0439\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 4038.12598\n",
      "Epoch 161/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3037.6135 - val_loss: 8436.5566\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 4038.12598\n",
      "Epoch 162/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 3085.8503 - val_loss: 7814.2769\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 4038.12598\n",
      "Epoch 163/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3185.9268 - val_loss: 5748.1108\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 4038.12598\n",
      "Epoch 164/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3026.8579 - val_loss: 3854.9363\n",
      "\n",
      "Epoch 00164: val_loss improved from 4038.12598 to 3854.93628, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 165/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2993.5952 - val_loss: 11582.0176\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 3854.93628\n",
      "Epoch 166/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2983.7004 - val_loss: 4323.6230\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 3854.93628\n",
      "Epoch 167/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2928.6038 - val_loss: 4825.4824\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 3854.93628\n",
      "Epoch 168/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2965.7356 - val_loss: 7054.0840\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 3854.93628\n",
      "Epoch 169/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2983.8630 - val_loss: 5842.5396\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 3854.93628\n",
      "Epoch 170/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3081.4270 - val_loss: 8613.5352\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 3854.93628\n",
      "Epoch 171/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2895.0698 - val_loss: 4999.3384\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 3854.93628\n",
      "Epoch 172/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3023.8865 - val_loss: 5028.3848\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 3854.93628\n",
      "Epoch 173/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2999.4556 - val_loss: 10223.0410\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 3854.93628\n",
      "Epoch 174/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2877.0891 - val_loss: 10389.9043\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 3854.93628\n",
      "Epoch 175/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 3015.1997 - val_loss: 9714.8262\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 3854.93628\n",
      "Epoch 176/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2888.9099 - val_loss: 7294.2881\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 3854.93628\n",
      "Epoch 177/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2949.0420 - val_loss: 9491.7510\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 3854.93628\n",
      "Epoch 178/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2925.6567 - val_loss: 12078.3711\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 3854.93628\n",
      "Epoch 179/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2988.0908 - val_loss: 8759.1504\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 3854.93628\n",
      "Epoch 180/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2924.2083 - val_loss: 7698.1890\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 3854.93628\n",
      "Epoch 181/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2940.3855 - val_loss: 8272.5752\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 3854.93628\n",
      "Epoch 182/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2938.2437 - val_loss: 7147.3525\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 3854.93628\n",
      "Epoch 183/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2880.8496 - val_loss: 6187.1069\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 3854.93628\n",
      "Epoch 184/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2925.5623 - val_loss: 5870.9570\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 3854.93628\n",
      "Epoch 185/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2924.6067 - val_loss: 8746.1006\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 3854.93628\n",
      "Epoch 186/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2897.4226 - val_loss: 11663.7715\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 3854.93628\n",
      "Epoch 187/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2888.7896 - val_loss: 8917.0693\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 3854.93628\n",
      "Epoch 188/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2906.2683 - val_loss: 7934.0674\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 3854.93628\n",
      "Epoch 189/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2859.6697 - val_loss: 6535.2339\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 3854.93628\n",
      "Epoch 190/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2913.4805 - val_loss: 8279.4023\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 3854.93628\n",
      "Epoch 191/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2897.5396 - val_loss: 8698.7158\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 3854.93628\n",
      "Epoch 192/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2907.6052 - val_loss: 10292.7764\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 3854.93628\n",
      "Epoch 193/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2945.2510 - val_loss: 8682.2090\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 3854.93628\n",
      "Epoch 194/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2867.5356 - val_loss: 8532.0449\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 3854.93628\n",
      "Epoch 195/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2987.9517 - val_loss: 10925.4521\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 3854.93628\n",
      "Epoch 196/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2840.0239 - val_loss: 10217.5898\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 3854.93628\n",
      "Epoch 197/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2915.6658 - val_loss: 6215.4595\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 3854.93628\n",
      "Epoch 198/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2823.2607 - val_loss: 8981.0684\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 3854.93628\n",
      "Epoch 199/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2860.3340 - val_loss: 6842.4282\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 3854.93628\n",
      "Epoch 200/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2890.0220 - val_loss: 9124.1035\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 3854.93628\n",
      "Epoch 201/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2878.0916 - val_loss: 9097.1221\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 3854.93628\n",
      "Epoch 202/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2860.7473 - val_loss: 3959.5525\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 3854.93628\n",
      "Epoch 203/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2950.5068 - val_loss: 8862.3115\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 3854.93628\n",
      "Epoch 204/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2906.3772 - val_loss: 8069.8394\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 3854.93628\n",
      "Epoch 205/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2845.6094 - val_loss: 7921.3340\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 3854.93628\n",
      "Epoch 206/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2850.1487 - val_loss: 10533.4287\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 3854.93628\n",
      "Epoch 207/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2834.6038 - val_loss: 10499.1523\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 3854.93628\n",
      "Epoch 208/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2885.8774 - val_loss: 8248.1826\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 3854.93628\n",
      "Epoch 209/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2861.5894 - val_loss: 9684.0537\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 3854.93628\n",
      "Epoch 210/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2774.6206 - val_loss: 9140.3535\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 3854.93628\n",
      "Epoch 211/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2830.1890 - val_loss: 8099.5596\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 3854.93628\n",
      "Epoch 212/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 2847.1357 - val_loss: 8710.2939\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 3854.93628\n",
      "Epoch 213/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2845.3667 - val_loss: 6969.1475\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 3854.93628\n",
      "Epoch 214/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2863.7893 - val_loss: 5818.6660\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 3854.93628\n",
      "Epoch 215/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2809.2893 - val_loss: 6574.9077\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 3854.93628\n",
      "Epoch 216/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2847.6589 - val_loss: 7489.4595\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 3854.93628\n",
      "Epoch 217/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2815.5439 - val_loss: 8011.7900\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 3854.93628\n",
      "Epoch 218/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2824.6211 - val_loss: 9328.7559\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 3854.93628\n",
      "Epoch 219/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2864.3081 - val_loss: 7095.4800\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 3854.93628\n",
      "Epoch 220/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2829.7368 - val_loss: 10203.6592\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 3854.93628\n",
      "Epoch 221/10000\n",
      "87/87 [==============================] - ETA: 0s - loss: 3024.72 - 0s 1ms/step - loss: 2855.7195 - val_loss: 9283.8389\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 3854.93628\n",
      "Epoch 222/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2820.4036 - val_loss: 9278.3926\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 3854.93628\n",
      "Epoch 223/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2813.7693 - val_loss: 9018.4336\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 3854.93628\n",
      "Epoch 224/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2799.6482 - val_loss: 8647.3330\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 3854.93628\n",
      "Epoch 225/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2839.7761 - val_loss: 8429.5439\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 3854.93628\n",
      "Epoch 226/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2809.2615 - val_loss: 8163.0073\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 3854.93628\n",
      "Epoch 227/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2795.8657 - val_loss: 9274.3926\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 3854.93628\n",
      "Epoch 228/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2811.0364 - val_loss: 6372.2002\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 3854.93628\n",
      "Epoch 229/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2810.1338 - val_loss: 6999.1274\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 3854.93628\n",
      "Epoch 230/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2881.5852 - val_loss: 5853.9404\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 3854.93628\n",
      "Epoch 231/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2848.4949 - val_loss: 4336.9517\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 3854.93628\n",
      "Epoch 232/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2840.7087 - val_loss: 5497.1021\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 3854.93628\n",
      "Epoch 233/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2853.3809 - val_loss: 7858.3936\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 3854.93628\n",
      "Epoch 234/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2738.9597 - val_loss: 5423.0171\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 3854.93628\n",
      "Epoch 235/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2817.7246 - val_loss: 8632.3984\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 3854.93628\n",
      "Epoch 236/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2793.5864 - val_loss: 7165.2231\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 3854.93628\n",
      "Epoch 237/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2737.2876 - val_loss: 7937.1724\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 3854.93628\n",
      "Epoch 238/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2779.5876 - val_loss: 11722.3066\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 3854.93628\n",
      "Epoch 239/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2777.3748 - val_loss: 6070.5742\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 3854.93628\n",
      "Epoch 240/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2808.6731 - val_loss: 9969.9189\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 3854.93628\n",
      "Epoch 241/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2812.2781 - val_loss: 6357.6265\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 3854.93628\n",
      "Epoch 242/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2795.9712 - val_loss: 8436.5215\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 3854.93628\n",
      "Epoch 243/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2828.4214 - val_loss: 10830.2559\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 3854.93628\n",
      "Epoch 244/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2804.2217 - val_loss: 9751.7646\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 3854.93628\n",
      "Epoch 245/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2754.4233 - val_loss: 8996.2471\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 3854.93628\n",
      "Epoch 246/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2801.6243 - val_loss: 5631.7002\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 3854.93628\n",
      "Epoch 247/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2820.6003 - val_loss: 11519.3809\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 3854.93628\n",
      "Epoch 248/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2790.3210 - val_loss: 7346.3979\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 3854.93628\n",
      "Epoch 249/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2765.0466 - val_loss: 7169.3862\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 3854.93628\n",
      "Epoch 250/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2792.9915 - val_loss: 8711.3545\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 3854.93628\n",
      "Epoch 251/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2770.0254 - val_loss: 7215.9424\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 3854.93628\n",
      "Epoch 252/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2765.6206 - val_loss: 6561.2202\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 3854.93628\n",
      "Epoch 253/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2765.9031 - val_loss: 9499.5088\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 3854.93628\n",
      "Epoch 254/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2792.1685 - val_loss: 7472.0957\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 3854.93628\n",
      "Epoch 255/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2783.4031 - val_loss: 9903.5986\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 3854.93628\n",
      "Epoch 256/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2739.4036 - val_loss: 9833.5791\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 3854.93628\n",
      "Epoch 257/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2791.2739 - val_loss: 7715.9380\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 3854.93628\n",
      "Epoch 258/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2758.8171 - val_loss: 9021.6572\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 3854.93628\n",
      "Epoch 259/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2775.0183 - val_loss: 9833.3135\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 3854.93628\n",
      "Epoch 260/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2751.2612 - val_loss: 10088.0176\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 3854.93628\n",
      "Epoch 261/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2759.3191 - val_loss: 6780.3848\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 3854.93628\n",
      "Epoch 262/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 2695.0452 - val_loss: 6230.8955\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 3854.93628\n",
      "Epoch 263/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2789.9595 - val_loss: 7639.9805\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 3854.93628\n",
      "Epoch 264/10000\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 2772.5371 - val_loss: 7520.4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▌                                                                  | 4/21 [07:40<31:09, 109.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00264: val_loss did not improve from 3854.93628\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 3113.7935 - val_loss: 2582.5684\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2582.56836, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2904.3401 - val_loss: 4566.3442\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2582.56836\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 2776.0522 - val_loss: 1736.4192\n",
      "\n",
      "Epoch 00003: val_loss improved from 2582.56836 to 1736.41919, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3109.6128 - val_loss: 4634.5977\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1736.41919\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3028.2871 - val_loss: 3670.9851\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1736.41919\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3104.9050 - val_loss: 4401.3623\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1736.41919\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3110.8916 - val_loss: 4600.2026\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1736.41919\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2826.3049 - val_loss: 2474.2021\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1736.41919\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2478.5461 - val_loss: 4733.7388\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1736.41919\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2527.7539 - val_loss: 4168.6660\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1736.41919\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2371.4915 - val_loss: 1720.6423\n",
      "\n",
      "Epoch 00011: val_loss improved from 1736.41919 to 1720.64233, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2249.9434 - val_loss: 3850.0649\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1720.64233\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2209.9451 - val_loss: 4458.1333\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1720.64233\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2128.2092 - val_loss: 4272.9814\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1720.64233\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2239.7903 - val_loss: 4147.4492\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1720.64233\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1881.8956 - val_loss: 2698.7544\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1720.64233\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2104.0034 - val_loss: 2491.8623\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1720.64233\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2128.2568 - val_loss: 3656.3501\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1720.64233\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2035.1384 - val_loss: 10563.9199\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1720.64233\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2207.8521 - val_loss: 2659.3467\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1720.64233\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2013.5977 - val_loss: 9429.9766\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1720.64233\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2012.9596 - val_loss: 4151.2378\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1720.64233\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2135.0769 - val_loss: 2769.3728\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1720.64233\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1976.7865 - val_loss: 3774.9387\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1720.64233\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2120.2859 - val_loss: 4515.4009\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1720.64233\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2076.0510 - val_loss: 2372.2117\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1720.64233\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1861.9976 - val_loss: 3174.1140\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1720.64233\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1966.1724 - val_loss: 4400.0752\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1720.64233\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1848.2385 - val_loss: 3952.2520\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1720.64233\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2009.4226 - val_loss: 1361.5010\n",
      "\n",
      "Epoch 00030: val_loss improved from 1720.64233 to 1361.50098, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1909.8729 - val_loss: 2840.4194\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1361.50098\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2047.2932 - val_loss: 1610.9235\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1361.50098\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2038.4227 - val_loss: 1345.4370\n",
      "\n",
      "Epoch 00033: val_loss improved from 1361.50098 to 1345.43701, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1793.4792 - val_loss: 3718.1130\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1345.43701\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1741.4465 - val_loss: 3609.8022\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1345.43701\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1856.0894 - val_loss: 2282.0776\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1345.43701\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1774.0364 - val_loss: 3260.2900\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1345.43701\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1620.8584 - val_loss: 1529.4563\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1345.43701\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1630.2101 - val_loss: 2944.5356\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1345.43701\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1696.2828 - val_loss: 6049.0239\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1345.43701\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1524.7433 - val_loss: 1940.8673\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1345.43701\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 885.8812 - val_loss: 1093.7010\n",
      "\n",
      "Epoch 00042: val_loss improved from 1345.43701 to 1093.70105, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 838.0574 - val_loss: 1160.9069\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1093.70105\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 826.7341 - val_loss: 1054.0481\n",
      "\n",
      "Epoch 00044: val_loss improved from 1093.70105 to 1054.04810, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 852.4680 - val_loss: 976.1163\n",
      "\n",
      "Epoch 00045: val_loss improved from 1054.04810 to 976.11633, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.7657 - val_loss: 919.9672\n",
      "\n",
      "Epoch 00046: val_loss improved from 976.11633 to 919.96716, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.0610 - val_loss: 956.1828\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 919.96716\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.0265 - val_loss: 911.7355\n",
      "\n",
      "Epoch 00048: val_loss improved from 919.96716 to 911.73547, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.7831 - val_loss: 901.7606\n",
      "\n",
      "Epoch 00049: val_loss improved from 911.73547 to 901.76056, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 876.0724 - val_loss: 1143.5939\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 901.76056\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 881.9315 - val_loss: 830.5775\n",
      "\n",
      "Epoch 00051: val_loss improved from 901.76056 to 830.57751, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.9869 - val_loss: 854.4924\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 830.57751\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.6049 - val_loss: 924.7972\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 830.57751\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.4653 - val_loss: 960.4849\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 830.57751\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.5220 - val_loss: 839.0294\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 830.57751\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 876.4891 - val_loss: 960.4733\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 830.57751\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.8930 - val_loss: 903.0002\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 830.57751\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.2153 - val_loss: 926.6036\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 830.57751\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 875.4994 - val_loss: 794.2464\n",
      "\n",
      "Epoch 00059: val_loss improved from 830.57751 to 794.24640, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 878.0237 - val_loss: 712.9850\n",
      "\n",
      "Epoch 00060: val_loss improved from 794.24640 to 712.98499, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.5520 - val_loss: 941.2046\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 712.98499\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.9867 - val_loss: 969.5674\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 712.98499\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.9833 - val_loss: 899.8199\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 712.98499\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.5049 - val_loss: 1037.1625\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 712.98499\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.6260 - val_loss: 815.7381\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 712.98499\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.7245 - val_loss: 911.1811\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 712.98499\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.4045 - val_loss: 744.4320\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 712.98499\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 880.0010 - val_loss: 1020.8973\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 712.98499\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 878.4776 - val_loss: 737.8967\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 712.98499\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.2537 - val_loss: 1046.6128\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 712.98499\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 880.2758 - val_loss: 821.5222\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 712.98499\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.6772 - val_loss: 853.4138\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 712.98499\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.1452 - val_loss: 847.0125\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 712.98499\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.6824 - val_loss: 866.1541\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 712.98499\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.4974 - val_loss: 923.8289\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 712.98499\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.7404 - val_loss: 1060.0028\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 712.98499\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 880.2427 - val_loss: 852.2445\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 712.98499\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.8557 - val_loss: 875.9286\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 712.98499\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.3098 - val_loss: 795.6971\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 712.98499\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.7147 - val_loss: 961.5217\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 712.98499\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.4810 - val_loss: 1038.8553\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 712.98499\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.7310 - val_loss: 830.5958\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 712.98499\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.3333 - val_loss: 904.6760\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 712.98499\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 879.1435 - val_loss: 898.5931\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 712.98499\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.9191 - val_loss: 958.9081\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 712.98499\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.2924 - val_loss: 931.5343\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 712.98499\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.7587 - val_loss: 913.0432\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 712.98499\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.3287 - val_loss: 1011.8389\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 712.98499\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.7839 - val_loss: 985.0120\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 712.98499\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 880.0269 - val_loss: 983.7248\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 712.98499\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.4563 - val_loss: 902.0700\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 712.98499\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.2867 - val_loss: 951.1771\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 712.98499\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 879.2482 - val_loss: 978.9709\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 712.98499\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 879.3097 - val_loss: 846.4644\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 712.98499\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 879.3179 - val_loss: 962.7626\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 712.98499\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 881.0582 - val_loss: 924.2965\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 712.98499\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.7209 - val_loss: 1002.0407\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 712.98499\n",
      "Epoch 98/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 878.9337 - val_loss: 882.8934\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 712.98499\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.9747 - val_loss: 851.4579\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 712.98499\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.5703 - val_loss: 908.1951\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 712.98499\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.8130 - val_loss: 931.1945\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 712.98499\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.3946 - val_loss: 920.9952\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 712.98499\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.8632 - val_loss: 931.6221\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 712.98499\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.0022 - val_loss: 874.7611\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 712.98499\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.3205 - val_loss: 910.7983\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 712.98499\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.3079 - val_loss: 933.3745\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 712.98499\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.7816 - val_loss: 830.2018\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 712.98499\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.2460 - val_loss: 954.7430\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 712.98499\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.6280 - val_loss: 895.2087\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 712.98499\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.6653 - val_loss: 955.8667\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 712.98499\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.8240 - val_loss: 916.5137\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 712.98499\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.4673 - val_loss: 771.9799\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 712.98499\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.2143 - val_loss: 954.9280\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 712.98499\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.8683 - val_loss: 835.6877\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 712.98499\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.3348 - val_loss: 921.9871\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 712.98499\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.2285 - val_loss: 907.7648\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 712.98499\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.5969 - val_loss: 764.1672\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 712.98499\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 880.9197 - val_loss: 909.3703\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 712.98499\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.5195 - val_loss: 978.0123\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 712.98499\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.2233 - val_loss: 925.9501\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 712.98499\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.8115 - val_loss: 819.2831\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 712.98499\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.5983 - val_loss: 955.0695\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 712.98499\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.6798 - val_loss: 885.8429\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 712.98499\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.8801 - val_loss: 908.8537\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 712.98499\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.5883 - val_loss: 791.9568\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 712.98499\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.7603 - val_loss: 875.4880\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 712.98499\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.7582 - val_loss: 819.5994\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 712.98499\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.2953 - val_loss: 798.8056\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 712.98499\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.9014 - val_loss: 970.3508\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 712.98499\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 880.0834 - val_loss: 788.2162\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 712.98499\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.9095 - val_loss: 871.7186\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 712.98499\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.6070 - val_loss: 916.0380\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 712.98499\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 880.3878 - val_loss: 873.3762\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 712.98499\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.6577 - val_loss: 892.1351\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 712.98499\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.4985 - val_loss: 952.3082\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 712.98499\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.2108 - val_loss: 888.1959\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 712.98499\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.8675 - val_loss: 898.7467\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 712.98499\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.7010 - val_loss: 794.6160\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 712.98499\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.5414 - val_loss: 898.6569\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 712.98499\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 876.4755 - val_loss: 859.0915\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 712.98499\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.2866 - val_loss: 852.8842\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 712.98499\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.7486 - val_loss: 872.1902\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 712.98499\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.4548 - val_loss: 857.5772\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 712.98499\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.1939 - val_loss: 863.9238\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 712.98499\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.3003 - val_loss: 1064.1145\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 712.98499\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.9287 - val_loss: 860.4567\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 712.98499\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.4767 - val_loss: 845.8602\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 712.98499\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.0613 - val_loss: 852.0244\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 712.98499\n",
      "Epoch 149/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 879.0936 - val_loss: 896.1785\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 712.98499\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.8582 - val_loss: 894.7083\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 712.98499\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.1319 - val_loss: 888.3047\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 712.98499\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 880.6061 - val_loss: 799.9886\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 712.98499\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.2102 - val_loss: 974.7159\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 712.98499\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.1719 - val_loss: 984.9359\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 712.98499\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.5381 - val_loss: 829.7966\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 712.98499\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.6108 - val_loss: 1026.1697\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 712.98499\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.9655 - val_loss: 1012.4673\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 712.98499\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.2969 - val_loss: 1014.5792\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 712.98499\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.3010 - val_loss: 992.7534\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 712.98499\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.8875 - val_loss: 941.0106\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 712.98499\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 3086.4153 - val_loss: 3894.7351\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3894.73511, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2922.9939 - val_loss: 4703.3076\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3894.73511\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2956.6106 - val_loss: 4558.7251\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3894.73511\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 974us/step - loss: 2909.0286 - val_loss: 2301.9563\n",
      "\n",
      "Epoch 00004: val_loss improved from 3894.73511 to 2301.95630, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 996us/step - loss: 3007.5667 - val_loss: 4387.9121\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2301.95630\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 997us/step - loss: 2960.8247 - val_loss: 3104.7185\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2301.95630\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2945.6504 - val_loss: 4625.0942\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2301.95630\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3135.3823 - val_loss: 4560.4448\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2301.95630\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2797.8142 - val_loss: 3809.1941\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2301.95630\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2594.9453 - val_loss: 4574.8613\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2301.95630\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2399.9016 - val_loss: 3586.6382\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2301.95630\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2273.7183 - val_loss: 799.5767\n",
      "\n",
      "Epoch 00012: val_loss improved from 2301.95630 to 799.57672, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2456.5850 - val_loss: 2374.6077\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 799.57672\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2334.9675 - val_loss: 4478.0913\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 799.57672\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2144.3237 - val_loss: 4493.3076\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 799.57672\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2117.1289 - val_loss: 1044.2241\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 799.57672\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2100.6821 - val_loss: 1256.0258\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 799.57672\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2171.7234 - val_loss: 3817.5310\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 799.57672\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1987.6688 - val_loss: 2682.2732\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 799.57672\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2079.2097 - val_loss: 4298.9209\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 799.57672\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 2003.1904 - val_loss: 534.1074\n",
      "\n",
      "Epoch 00021: val_loss improved from 799.57672 to 534.10736, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1784.7648 - val_loss: 4270.2085\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 534.10736\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2025.0536 - val_loss: 2843.1653\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 534.10736\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2101.1379 - val_loss: 2701.5232\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 534.10736\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1997.5438 - val_loss: 3952.5571\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 534.10736\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1985.6018 - val_loss: 1971.4589\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 534.10736\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1871.6278 - val_loss: 2400.1206\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 534.10736\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1778.1064 - val_loss: 3396.2310\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 534.10736\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1988.9646 - val_loss: 3488.7385\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 534.10736\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1754.3870 - val_loss: 884.0150\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 534.10736\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1912.1461 - val_loss: 3514.1040\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 534.10736\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1822.5283 - val_loss: 4361.6514\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 534.10736\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1885.0042 - val_loss: 1419.9409\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 534.10736\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1839.0685 - val_loss: 4347.0181\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 534.10736\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1814.6353 - val_loss: 4024.8169\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 534.10736\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1769.2605 - val_loss: 3624.8662\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 534.10736\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1812.5662 - val_loss: 1280.8613\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 534.10736\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1733.5215 - val_loss: 486.9188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss improved from 534.10736 to 486.91876, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1717.9916 - val_loss: 1452.9580\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 486.91876\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1882.3304 - val_loss: 3466.4978\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 486.91876\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1772.8765 - val_loss: 791.1889\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 486.91876\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1625.3713 - val_loss: 2154.4294\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 486.91876\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1288.1249 - val_loss: 1811.2964\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 486.91876\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 891.7908 - val_loss: 1205.8015\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 486.91876\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 846.9108 - val_loss: 1116.5464\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 486.91876\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.6274 - val_loss: 807.8094\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 486.91876\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.2529 - val_loss: 873.5538\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 486.91876\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.0914 - val_loss: 1063.3713\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 486.91876\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.3024 - val_loss: 900.3414\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 486.91876\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.0165 - val_loss: 920.5706\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 486.91876\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.2692 - val_loss: 907.4521\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 486.91876\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.9370 - val_loss: 820.2978\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 486.91876\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.5026 - val_loss: 945.0701\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 486.91876\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.9171 - val_loss: 852.1843\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 486.91876\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.1975 - val_loss: 827.0253\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 486.91876\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.1730 - val_loss: 854.3513\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 486.91876\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 880.0505 - val_loss: 838.1516\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 486.91876\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.7199 - val_loss: 893.8152\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 486.91876\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3459 - val_loss: 887.4772\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 486.91876\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.2831 - val_loss: 923.8948\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 486.91876\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.4013 - val_loss: 881.6674\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 486.91876\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.9941 - val_loss: 843.3855\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 486.91876\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.1296 - val_loss: 913.0637\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 486.91876\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6860 - val_loss: 851.7997\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 486.91876\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.0770 - val_loss: 832.6586\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 486.91876\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.9753 - val_loss: 918.5901\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 486.91876\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.9136 - val_loss: 902.6226\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 486.91876\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.7045 - val_loss: 899.7827\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 486.91876\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.2014 - val_loss: 984.3826\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 486.91876\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.4467 - val_loss: 950.0446\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 486.91876\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.1243 - val_loss: 908.2944\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 486.91876\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.1824 - val_loss: 934.5178\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 486.91876\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.4316 - val_loss: 969.9158\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 486.91876\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.6049 - val_loss: 847.2829\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 486.91876\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.7731 - val_loss: 964.8203\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 486.91876\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.5093 - val_loss: 912.7736\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 486.91876\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.0496 - val_loss: 874.9880\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 486.91876\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.3154 - val_loss: 840.0037\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 486.91876\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 993us/step - loss: 879.2919 - val_loss: 879.6024\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 486.91876\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.0937 - val_loss: 1028.2538\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 486.91876\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 881.1127 - val_loss: 914.1158\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 486.91876\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.7798 - val_loss: 918.0730\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 486.91876\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.3325 - val_loss: 882.9603\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 486.91876\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5208 - val_loss: 817.9161\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 486.91876\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.8900 - val_loss: 918.8228\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 486.91876\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 879.9121 - val_loss: 928.0726\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 486.91876\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5873 - val_loss: 889.2668\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 486.91876\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.5084 - val_loss: 945.6066\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 486.91876\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.9009 - val_loss: 868.8836\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 486.91876\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.8458 - val_loss: 883.3879\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 486.91876\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.1787 - val_loss: 861.0725\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 486.91876\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.1861 - val_loss: 913.1998\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 486.91876\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.6219 - val_loss: 1007.5793\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 486.91876\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.3977 - val_loss: 821.7269\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 486.91876\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.0076 - val_loss: 992.7855\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 486.91876\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.3740 - val_loss: 984.2924\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 486.91876\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.1187 - val_loss: 819.6203\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 486.91876\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 881.1606 - val_loss: 903.9774\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 486.91876\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.1125 - val_loss: 871.8610\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 486.91876\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.3405 - val_loss: 843.1155\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 486.91876\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.0897 - val_loss: 837.5159\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 486.91876\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.6612 - val_loss: 917.0717\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 486.91876\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.0737 - val_loss: 853.7121\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 486.91876\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5034 - val_loss: 931.0669\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 486.91876\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.5337 - val_loss: 850.6830\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 486.91876\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.6768 - val_loss: 885.4827\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 486.91876\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.1205 - val_loss: 930.0811\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 486.91876\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.2258 - val_loss: 803.2743\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 486.91876\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.3312 - val_loss: 1010.7417\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 486.91876\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.1912 - val_loss: 895.7541\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 486.91876\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5446 - val_loss: 908.4229\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 486.91876\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.7735 - val_loss: 905.9976\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 486.91876\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.7763 - val_loss: 909.0653\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 486.91876\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6808 - val_loss: 1014.6032\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 486.91876\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.6717 - val_loss: 903.9869\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 486.91876\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.7842 - val_loss: 891.6158\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 486.91876\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.6885 - val_loss: 962.6969\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 486.91876\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.2178 - val_loss: 965.7349\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 486.91876\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.4831 - val_loss: 902.1649\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 486.91876\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.7791 - val_loss: 969.0722\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 486.91876\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.2075 - val_loss: 924.0278\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 486.91876\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.4152 - val_loss: 803.9199\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 486.91876\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.0618 - val_loss: 883.3605\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 486.91876\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.2673 - val_loss: 914.4779\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 486.91876\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.0959 - val_loss: 795.0999\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 486.91876\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.6508 - val_loss: 819.9545\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 486.91876\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.9114 - val_loss: 869.5762\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 486.91876\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.8871 - val_loss: 943.7189\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 486.91876\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5397 - val_loss: 838.1894\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 486.91876\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.1896 - val_loss: 844.9196\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 486.91876\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.1431 - val_loss: 878.0449\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 486.91876\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 881.7741 - val_loss: 937.5568\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 486.91876\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.4524 - val_loss: 899.6241\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 486.91876\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.2760 - val_loss: 874.9260\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 486.91876\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.0009 - val_loss: 840.3865\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 486.91876\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 879.1317 - val_loss: 854.5086\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 486.91876\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.8252 - val_loss: 840.0073\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 486.91876\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.2834 - val_loss: 889.0570\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 486.91876\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 3395.0046 - val_loss: 4774.3652\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4774.36523, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 2ms/step - loss: 2677.8042 - val_loss: 4423.6333\n",
      "\n",
      "Epoch 00002: val_loss improved from 4774.36523 to 4423.63330, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3069.9124 - val_loss: 4714.7397\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4423.63330\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 998us/step - loss: 2927.0833 - val_loss: 3560.4382\n",
      "\n",
      "Epoch 00004: val_loss improved from 4423.63330 to 3560.43823, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2994.0269 - val_loss: 4669.1938\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3560.43823\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2895.5737 - val_loss: 4230.0117\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3560.43823\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3015.7100 - val_loss: 2642.4260\n",
      "\n",
      "Epoch 00007: val_loss improved from 3560.43823 to 2642.42603, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3055.4656 - val_loss: 4611.5386\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2642.42603\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2924.3508 - val_loss: 1713.7484\n",
      "\n",
      "Epoch 00009: val_loss improved from 2642.42603 to 1713.74841, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2954.9453 - val_loss: 4566.7749\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1713.74841\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2901.6685 - val_loss: 971.2424\n",
      "\n",
      "Epoch 00011: val_loss improved from 1713.74841 to 971.24243, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2840.9956 - val_loss: 1741.5149\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 971.24243\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2531.4265 - val_loss: 936.8491\n",
      "\n",
      "Epoch 00013: val_loss improved from 971.24243 to 936.84912, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2272.7720 - val_loss: 4577.0078\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 936.84912\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2604.9985 - val_loss: 4861.0127\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 936.84912\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2791.6453 - val_loss: 4523.6724\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 936.84912\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2457.9800 - val_loss: 14859.8066\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 936.84912\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2419.1562 - val_loss: 4127.7729\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 936.84912\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2069.5269 - val_loss: 3778.6394\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 936.84912\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1942.1660 - val_loss: 3847.3296\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 936.84912\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 2013.4094 - val_loss: 3402.5166\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 936.84912\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1903.6549 - val_loss: 2680.8054\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 936.84912\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1869.0635 - val_loss: 3749.1594\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 936.84912\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2072.2090 - val_loss: 3206.0757\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 936.84912\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1877.7882 - val_loss: 1315.6904\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 936.84912\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2007.7993 - val_loss: 3086.5713\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 936.84912\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1922.8218 - val_loss: 3281.4824\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 936.84912\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1939.1465 - val_loss: 9261.5654\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 936.84912\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1965.8909 - val_loss: 3190.7737\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 936.84912\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1837.9065 - val_loss: 4782.5464\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 936.84912\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1938.3848 - val_loss: 3354.1899\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 936.84912\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1721.2329 - val_loss: 2872.5588\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 936.84912\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1863.4484 - val_loss: 2632.1521\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 936.84912\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1740.7344 - val_loss: 3901.7236\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 936.84912\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1946.7644 - val_loss: 749.5687\n",
      "\n",
      "Epoch 00035: val_loss improved from 936.84912 to 749.56866, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1842.4431 - val_loss: 4480.6206\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 749.56866\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1938.0327 - val_loss: 3690.0671\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 749.56866\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1667.3809 - val_loss: 8480.9062\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 749.56866\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2145.4875 - val_loss: 2164.9590\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 749.56866\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 952.6569 - val_loss: 1046.7379\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 749.56866\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 875.6262 - val_loss: 1111.0157\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 749.56866\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.0181 - val_loss: 1000.6440\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 749.56866\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.6912 - val_loss: 922.2665\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 749.56866\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.2484 - val_loss: 913.5624\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 749.56866\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5792 - val_loss: 801.0184\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 749.56866\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.4254 - val_loss: 854.5593\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 749.56866\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.2618 - val_loss: 1029.9801\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 749.56866\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.7452 - val_loss: 986.8688\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 749.56866\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.1361 - val_loss: 862.1130\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 749.56866\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 875.5204 - val_loss: 922.8351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00050: val_loss did not improve from 749.56866\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6371 - val_loss: 766.3516\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 749.56866\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.2346 - val_loss: 928.2267\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 749.56866\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3619 - val_loss: 860.7828\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 749.56866\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6273 - val_loss: 784.6467\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 749.56866\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.1351 - val_loss: 710.9219\n",
      "\n",
      "Epoch 00055: val_loss improved from 749.56866 to 710.92188, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 881.3578 - val_loss: 746.6392\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 710.92188\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.5280 - val_loss: 824.8525\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 710.92188\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.7812 - val_loss: 1001.0657\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 710.92188\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.3080 - val_loss: 865.7623\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 710.92188\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.9036 - val_loss: 891.7034\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 710.92188\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.6833 - val_loss: 791.5967\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 710.92188\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.2485 - val_loss: 988.6398\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 710.92188\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.8406 - val_loss: 991.1245\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 710.92188\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.1561 - val_loss: 777.0837\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 710.92188\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6132 - val_loss: 725.2084\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 710.92188\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 876.0949 - val_loss: 929.5449\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 710.92188\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3348 - val_loss: 1046.1044\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 710.92188\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.4877 - val_loss: 1014.7366\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 710.92188\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.5876 - val_loss: 948.5045\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 710.92188\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.9189 - val_loss: 996.6091\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 710.92188\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.5779 - val_loss: 1055.5326\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 710.92188\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.2206 - val_loss: 967.4275\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 710.92188\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.2347 - val_loss: 787.3447\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 710.92188\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 876.6810 - val_loss: 902.9299\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 710.92188\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.9912 - val_loss: 803.1735\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 710.92188\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5164 - val_loss: 816.3226\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 710.92188\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5645 - val_loss: 1093.0060\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 710.92188\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.2425 - val_loss: 971.8323\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 710.92188\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3124 - val_loss: 1075.7323\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 710.92188\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.8680 - val_loss: 814.9843\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 710.92188\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.0609 - val_loss: 955.4186\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 710.92188\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5981 - val_loss: 877.3226\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 710.92188\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3697 - val_loss: 960.2726\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 710.92188\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.2752 - val_loss: 1030.2825\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 710.92188\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5720 - val_loss: 998.6373\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 710.92188\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.6399 - val_loss: 806.5584\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 710.92188\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3286 - val_loss: 1082.1290\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 710.92188\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6970 - val_loss: 735.6834\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 710.92188\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5234 - val_loss: 986.0068\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 710.92188\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6710 - val_loss: 708.8239\n",
      "\n",
      "Epoch 00090: val_loss improved from 710.92188 to 708.82391, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.9239 - val_loss: 888.3361\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 708.82391\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.6800 - val_loss: 948.1464\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 708.82391\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.0485 - val_loss: 1052.2859\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 708.82391\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.7919 - val_loss: 815.0758\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 708.82391\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.7180 - val_loss: 1023.3109\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 708.82391\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.6237 - val_loss: 820.3237\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 708.82391\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.4883 - val_loss: 938.6540\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 708.82391\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.7389 - val_loss: 804.0348\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 708.82391\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.4674 - val_loss: 1078.5245\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 708.82391\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.8334 - val_loss: 1013.2299\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 708.82391\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 876.4794 - val_loss: 820.9004\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 708.82391\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.8170 - val_loss: 770.0533\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 708.82391\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.2078 - val_loss: 1153.9003\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 708.82391\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 881.8508 - val_loss: 1034.2476\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 708.82391\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5452 - val_loss: 788.0108\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 708.82391\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.2009 - val_loss: 780.0095\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 708.82391\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 879.0925 - val_loss: 906.1436\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 708.82391\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.7328 - val_loss: 1021.9872\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 708.82391\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.4475 - val_loss: 841.5800\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 708.82391\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.1561 - val_loss: 1038.4481\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 708.82391\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.1724 - val_loss: 950.9996\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 708.82391\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6021 - val_loss: 827.6479\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 708.82391\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3160 - val_loss: 876.3797\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 708.82391\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3131 - val_loss: 981.2545\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 708.82391\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.6057 - val_loss: 812.5906\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 708.82391\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.3840 - val_loss: 996.9087\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 708.82391\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.0479 - val_loss: 987.8668\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 708.82391\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.9844 - val_loss: 818.4095\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 708.82391\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3954 - val_loss: 935.4090\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 708.82391\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 879.0576 - val_loss: 780.7411\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 708.82391\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 878.0803 - val_loss: 996.6750\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 708.82391\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.1962 - val_loss: 1021.5123\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 708.82391\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.1379 - val_loss: 745.1166\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 708.82391\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.0792 - val_loss: 970.7176\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 708.82391\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.1286 - val_loss: 984.1320\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 708.82391\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.5235 - val_loss: 953.2740\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 708.82391\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 877.6554 - val_loss: 887.2952\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 708.82391\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5361 - val_loss: 1036.6906\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 708.82391\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.9416 - val_loss: 960.8204\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 708.82391\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.4168 - val_loss: 1041.2496\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 708.82391\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.5145 - val_loss: 1044.1997\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 708.82391\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.3946 - val_loss: 877.6074\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 708.82391\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3939 - val_loss: 1060.4290\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 708.82391\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.9212 - val_loss: 750.2325\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 708.82391\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.9433 - val_loss: 775.0847\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 708.82391\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.4144 - val_loss: 899.7827\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 708.82391\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.0974 - val_loss: 845.4792\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 708.82391\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.6877 - val_loss: 950.7776\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 708.82391\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6051 - val_loss: 964.6507\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 708.82391\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.8189 - val_loss: 1023.0156\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 708.82391\n",
      "Epoch 141/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 877.5840 - val_loss: 1002.7930\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 708.82391\n",
      "Epoch 142/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.6460 - val_loss: 835.0070\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 708.82391\n",
      "Epoch 143/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.2773 - val_loss: 962.7916\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 708.82391\n",
      "Epoch 144/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.8560 - val_loss: 796.4292\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 708.82391\n",
      "Epoch 145/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.0378 - val_loss: 853.8666\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 708.82391\n",
      "Epoch 146/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6170 - val_loss: 856.4945\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 708.82391\n",
      "Epoch 147/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.9764 - val_loss: 1039.3762\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 708.82391\n",
      "Epoch 148/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.7820 - val_loss: 918.8784\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 708.82391\n",
      "Epoch 149/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.9504 - val_loss: 999.8356\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 708.82391\n",
      "Epoch 150/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5158 - val_loss: 855.3890\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 708.82391\n",
      "Epoch 151/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3765 - val_loss: 846.6369\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 708.82391\n",
      "Epoch 152/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6122 - val_loss: 804.6980\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 708.82391\n",
      "Epoch 153/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.3693 - val_loss: 919.7832\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 708.82391\n",
      "Epoch 154/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5632 - val_loss: 922.4839\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 708.82391\n",
      "Epoch 155/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.1059 - val_loss: 992.4827\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 708.82391\n",
      "Epoch 156/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.4267 - val_loss: 1039.0530\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 708.82391\n",
      "Epoch 157/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 878.7390 - val_loss: 997.1110\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 708.82391\n",
      "Epoch 158/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.6559 - val_loss: 853.6267\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 708.82391\n",
      "Epoch 159/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 877.2979 - val_loss: 844.5916\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 708.82391\n",
      "Epoch 160/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.0140 - val_loss: 792.9822\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 708.82391\n",
      "Epoch 161/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.6002 - val_loss: 816.6397\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 708.82391\n",
      "Epoch 162/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.0841 - val_loss: 1043.7336\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 708.82391\n",
      "Epoch 163/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6501 - val_loss: 832.2444\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 708.82391\n",
      "Epoch 164/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.4241 - val_loss: 937.3789\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 708.82391\n",
      "Epoch 165/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.8297 - val_loss: 762.4424\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 708.82391\n",
      "Epoch 166/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.5378 - val_loss: 851.4961\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 708.82391\n",
      "Epoch 167/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 879.1013 - val_loss: 978.3387\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 708.82391\n",
      "Epoch 168/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.9880 - val_loss: 980.3426\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 708.82391\n",
      "Epoch 169/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.0168 - val_loss: 825.0528\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 708.82391\n",
      "Epoch 170/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.3732 - val_loss: 784.5880\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 708.82391\n",
      "Epoch 171/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 877.8252 - val_loss: 1064.9678\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 708.82391\n",
      "Epoch 172/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.3583 - val_loss: 768.1075\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 708.82391\n",
      "Epoch 173/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.4796 - val_loss: 1037.4432\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 708.82391\n",
      "Epoch 174/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.9010 - val_loss: 826.2595\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 708.82391\n",
      "Epoch 175/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.2626 - val_loss: 942.3528\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 708.82391\n",
      "Epoch 176/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.4382 - val_loss: 1011.6779\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 708.82391\n",
      "Epoch 177/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.4430 - val_loss: 801.2855\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 708.82391\n",
      "Epoch 178/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.0721 - val_loss: 793.2037\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 708.82391\n",
      "Epoch 179/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.0386 - val_loss: 1052.1116\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 708.82391\n",
      "Epoch 180/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.2635 - val_loss: 819.6699\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 708.82391\n",
      "Epoch 181/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5258 - val_loss: 801.0033\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 708.82391\n",
      "Epoch 182/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.5721 - val_loss: 813.6496\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 708.82391\n",
      "Epoch 183/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.6998 - val_loss: 984.9201\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 708.82391\n",
      "Epoch 184/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.0506 - val_loss: 954.6138\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 708.82391\n",
      "Epoch 185/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.4725 - val_loss: 945.6975\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 708.82391\n",
      "Epoch 186/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.7166 - val_loss: 792.1672\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 708.82391\n",
      "Epoch 187/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 879.3538 - val_loss: 995.0184\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 708.82391\n",
      "Epoch 188/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.7687 - val_loss: 986.1908\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 708.82391\n",
      "Epoch 189/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 876.8220 - val_loss: 1054.9586\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 708.82391\n",
      "Epoch 190/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 877.8886 - val_loss: 780.5615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▌                                                              | 5/21 [09:47<30:57, 116.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00190: val_loss did not improve from 708.82391\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 805.9673 - val_loss: 301.1474\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 301.14743, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 553.8965 - val_loss: 1406.4760\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 301.14743\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 974us/step - loss: 572.0496 - val_loss: 491.1003\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 301.14743\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 606.5839 - val_loss: 1066.7795\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 301.14743\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 593.2327 - val_loss: 1107.3286\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 301.14743\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 623.8685 - val_loss: 817.1300\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 301.14743\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 594.6565 - val_loss: 1172.6425\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 301.14743\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 653.2559 - val_loss: 690.3153\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 301.14743\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 609.1739 - val_loss: 985.1738\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 301.14743\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 603.5106 - val_loss: 981.9020\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 301.14743\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 636.4047 - val_loss: 473.2200\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 301.14743\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 651.8586 - val_loss: 792.2228\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 301.14743\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 645.4886 - val_loss: 1310.9714\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 301.14743\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 632.8174 - val_loss: 932.4072\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 301.14743\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 582.0277 - val_loss: 318.4152\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 301.14743\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 586.4344 - val_loss: 741.0988\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 301.14743\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 622.3477 - val_loss: 379.1815\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 301.14743\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 572.0205 - val_loss: 1453.4504\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 301.14743\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 618.2730 - val_loss: 313.9211\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 301.14743\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 587.3381 - val_loss: 1666.7025\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 301.14743\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 610.5287 - val_loss: 1290.5834\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 301.14743\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 568.1896 - val_loss: 1036.7832\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 301.14743\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 564.0222 - val_loss: 639.2230\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 301.14743\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 580.7786 - val_loss: 1345.8051\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 301.14743\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 613.4416 - val_loss: 928.3165\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 301.14743\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 584.3428 - val_loss: 965.0723\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 301.14743\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 598.8698 - val_loss: 411.1764\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 301.14743\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 531.6351 - val_loss: 534.3422\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 301.14743\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 550.3564 - val_loss: 1504.5272\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 301.14743\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 460.0005 - val_loss: 551.7968\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 301.14743\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 435.8859 - val_loss: 338.3252\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 301.14743\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 426.7307 - val_loss: 520.5549\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 301.14743\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 433.0904 - val_loss: 437.2656\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 301.14743\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 384.4828 - val_loss: 1280.9868\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 301.14743\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 397.8555 - val_loss: 320.1917\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 301.14743\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 390.0941 - val_loss: 368.0051\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 301.14743\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 394.2534 - val_loss: 526.3267\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 301.14743\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 375.7121 - val_loss: 1218.4098\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 301.14743\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 410.6035 - val_loss: 340.0423\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 301.14743\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 373.4853 - val_loss: 677.3500\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 301.14743\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 379.4019 - val_loss: 1088.0590\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 301.14743\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 395.1722 - val_loss: 714.0800\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 301.14743\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 375.7094 - val_loss: 399.3958\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 301.14743\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 374.2456 - val_loss: 344.7754\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 301.14743\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 353.8520 - val_loss: 1361.7534\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 301.14743\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 378.5231 - val_loss: 883.4295\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 301.14743\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 366.6916 - val_loss: 1152.9451\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 301.14743\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 357.7662 - val_loss: 1156.9031\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 301.14743\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 370.5563 - val_loss: 495.7730\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 301.14743\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 332.2888 - val_loss: 403.4871\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 301.14743\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 341.2592 - val_loss: 432.8530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: val_loss did not improve from 301.14743\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 336.7867 - val_loss: 932.3141\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 301.14743\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 340.2281 - val_loss: 909.8586\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 301.14743\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 320.3138 - val_loss: 443.2716\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 301.14743\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 308.3014 - val_loss: 1135.6832\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 301.14743\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 268.1145 - val_loss: 907.6086\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 301.14743\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 267.7014 - val_loss: 479.1629\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 301.14743\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 264.0354 - val_loss: 473.7775\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 301.14743\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 262.9548 - val_loss: 361.8528\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 301.14743\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 262.2262 - val_loss: 750.0980\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 301.14743\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 247.3761 - val_loss: 733.0726\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 301.14743\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 257.4276 - val_loss: 704.5236\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 301.14743\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 241.4357 - val_loss: 511.3463\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 301.14743\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 259.4748 - val_loss: 587.2794\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 301.14743\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 249.1441 - val_loss: 429.2684\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 301.14743\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 235.5225 - val_loss: 963.8220\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 301.14743\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 257.5347 - val_loss: 476.1321\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 301.14743\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 249.0199 - val_loss: 776.7381\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 301.14743\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 243.0642 - val_loss: 771.7764\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 301.14743\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 248.0255 - val_loss: 607.3585\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 301.14743\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.6567 - val_loss: 559.3273\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 301.14743\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 254.6329 - val_loss: 1008.3924\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 301.14743\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 242.5191 - val_loss: 587.6598\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 301.14743\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 235.6770 - val_loss: 911.4916\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 301.14743\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 236.7047 - val_loss: 506.2100\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 301.14743\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 238.6674 - val_loss: 361.7999\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 301.14743\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 231.9412 - val_loss: 426.0297\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 301.14743\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 236.5585 - val_loss: 410.4919\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 301.14743\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 223.1324 - val_loss: 421.2111\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 301.14743\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 242.7753 - val_loss: 427.6017\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 301.14743\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.9975 - val_loss: 411.2897\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 301.14743\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 222.8799 - val_loss: 500.5938\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 301.14743\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.0578 - val_loss: 486.5511\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 301.14743\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 222.4445 - val_loss: 418.6292\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 301.14743\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.0252 - val_loss: 843.1406\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 301.14743\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 211.7585 - val_loss: 797.8525\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 301.14743\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 226.0961 - val_loss: 431.6632\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 301.14743\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.0179 - val_loss: 708.7344\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 301.14743\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.1014 - val_loss: 448.2194\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 301.14743\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 220.0474 - val_loss: 1000.4030\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 301.14743\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 222.3661 - val_loss: 429.2327\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 301.14743\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 221.0546 - val_loss: 527.8508\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 301.14743\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 206.1727 - val_loss: 401.0837\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 301.14743\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 219.7968 - val_loss: 447.3178\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 301.14743\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 219.4683 - val_loss: 430.7719\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 301.14743\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 209.9863 - val_loss: 389.1969\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 301.14743\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 209.6944 - val_loss: 527.6932\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 301.14743\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.4261 - val_loss: 389.2918\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 301.14743\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 220.5943 - val_loss: 674.1761\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 301.14743\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 223.3732 - val_loss: 446.7472\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 301.14743\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 213.2040 - val_loss: 783.5103\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 301.14743\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 770.0167 - val_loss: 245.8138\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 245.81377, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 575.6575 - val_loss: 1256.1039\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 245.81377\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 585.2451 - val_loss: 601.5060\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 245.81377\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 555.9155 - val_loss: 588.3373\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 245.81377\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 581.2775 - val_loss: 345.7657\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 245.81377\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 637.6946 - val_loss: 890.1378\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 245.81377\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 983us/step - loss: 630.8235 - val_loss: 1334.1907\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 245.81377\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 591.9178 - val_loss: 607.8549\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 245.81377\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 607.9120 - val_loss: 303.4035\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 245.81377\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 622.6628 - val_loss: 1653.0305\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 245.81377\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 599.0790 - val_loss: 500.3248\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 245.81377\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 606.7394 - val_loss: 277.2563\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 245.81377\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 615.5781 - val_loss: 978.8415\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 245.81377\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 610.0512 - val_loss: 551.4155\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 245.81377\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 541.3195 - val_loss: 340.1133\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 245.81377\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 619.7548 - val_loss: 1085.8029\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 245.81377\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 580.3510 - val_loss: 686.0977\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 245.81377\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 624.2372 - val_loss: 295.5720\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 245.81377\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 590.0114 - val_loss: 842.7605\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 245.81377\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 594.5356 - val_loss: 453.9162\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 245.81377\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 606.8345 - val_loss: 1378.5652\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 245.81377\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 576.3469 - val_loss: 1073.7531\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 245.81377\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 568.2215 - val_loss: 1257.2949\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 245.81377\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 642.2794 - val_loss: 419.5148\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 245.81377\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 555.7560 - val_loss: 1448.4042\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 245.81377\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 571.8268 - val_loss: 679.5644\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 245.81377\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 563.5410 - val_loss: 406.0335\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 245.81377\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 523.8318 - val_loss: 1398.6592\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 245.81377\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 537.8635 - val_loss: 1330.0374\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 245.81377\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 493.9213 - val_loss: 495.2507\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 245.81377\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 460.9834 - val_loss: 387.2376\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 245.81377\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 446.4379 - val_loss: 901.2734\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 245.81377\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 410.9690 - val_loss: 438.4465\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 245.81377\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 399.7934 - val_loss: 397.7562\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 245.81377\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 417.2893 - val_loss: 1061.3657\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 245.81377\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 418.4689 - val_loss: 366.4258\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 245.81377\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 397.9697 - val_loss: 601.7711\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 245.81377\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 394.1572 - val_loss: 1238.6338\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 245.81377\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 408.4452 - val_loss: 1002.5885\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 245.81377\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 383.0080 - val_loss: 444.1179\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 245.81377\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 349.9296 - val_loss: 883.3120\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 245.81377\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 365.8729 - val_loss: 941.7958\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 245.81377\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 385.2323 - val_loss: 1531.7050\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 245.81377\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 390.6278 - val_loss: 1349.8545\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 245.81377\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 362.5528 - val_loss: 931.5359\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 245.81377\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 382.5080 - val_loss: 309.7550\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 245.81377\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 376.3522 - val_loss: 494.9123\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 245.81377\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 323.4024 - val_loss: 679.4166\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 245.81377\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 369.1976 - val_loss: 915.8942\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 245.81377\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 339.5596 - val_loss: 1154.4641\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 245.81377\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 332.2505 - val_loss: 351.2489\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 245.81377\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 363.0435 - val_loss: 1365.4025\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 245.81377\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 320.1186 - val_loss: 889.8979\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 245.81377\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 338.0522 - val_loss: 705.5287\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 245.81377\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 358.1223 - val_loss: 468.3248\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 245.81377\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 310.9227 - val_loss: 419.5853\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 245.81377\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 309.7682 - val_loss: 759.2977\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 245.81377\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 287.1171 - val_loss: 919.1817\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 245.81377\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 264.4224 - val_loss: 1034.4987\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 245.81377\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 264.6944 - val_loss: 496.7998\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 245.81377\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 249.1707 - val_loss: 460.4555\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 245.81377\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 259.7278 - val_loss: 860.5212\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 245.81377\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 273.3189 - val_loss: 1103.6771\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 245.81377\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 257.6166 - val_loss: 745.3805\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 245.81377\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 257.5974 - val_loss: 586.8372\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 245.81377\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 261.7096 - val_loss: 507.1696\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 245.81377\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 254.8588 - val_loss: 492.6330\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 245.81377\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.2649 - val_loss: 703.6358\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 245.81377\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 242.9978 - val_loss: 542.4714\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 245.81377\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 265.7224 - val_loss: 1108.4895\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 245.81377\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 263.9822 - val_loss: 297.1019\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 245.81377\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 249.5885 - val_loss: 570.9479\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 245.81377\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 242.2162 - val_loss: 973.3744\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 245.81377\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 259.5015 - val_loss: 992.2533\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 245.81377\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 245.4287 - val_loss: 1089.3907\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 245.81377\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 236.3123 - val_loss: 955.2305\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 245.81377\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 235.8527 - val_loss: 1190.5001\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 245.81377\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 255.9767 - val_loss: 621.7124\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 245.81377\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.1124 - val_loss: 574.5626\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 245.81377\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.0750 - val_loss: 863.7473\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 245.81377\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 246.8168 - val_loss: 648.1077\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 245.81377\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.5859 - val_loss: 719.3000\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 245.81377\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 227.3793 - val_loss: 1018.3937\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 245.81377\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.1167 - val_loss: 491.4462\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 245.81377\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 254.9585 - val_loss: 366.9607\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 245.81377\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.0436 - val_loss: 440.3979\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 245.81377\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.7040 - val_loss: 543.1998\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 245.81377\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 246.4998 - val_loss: 568.7013\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 245.81377\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.6242 - val_loss: 718.1192\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 245.81377\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 244.9394 - val_loss: 887.6633\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 245.81377\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.6050 - val_loss: 892.1572\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 245.81377\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 227.7002 - val_loss: 892.4472\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 245.81377\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.7556 - val_loss: 366.7493\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 245.81377\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 221.3270 - val_loss: 459.4803\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 245.81377\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.5353 - val_loss: 421.1666\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 245.81377\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 222.8679 - val_loss: 634.1505\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 245.81377\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 219.6650 - val_loss: 1025.4552\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 245.81377\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.2084 - val_loss: 872.2386\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 245.81377\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.8690 - val_loss: 493.2927\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 245.81377\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 216.8508 - val_loss: 801.9417\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 245.81377\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 222.2829 - val_loss: 419.2065\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 245.81377\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 848.2475 - val_loss: 398.0439\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 398.04395, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 523.9650 - val_loss: 275.9668\n",
      "\n",
      "Epoch 00002: val_loss improved from 398.04395 to 275.96677, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 602.2449 - val_loss: 367.8577\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 275.96677\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 563.6735 - val_loss: 254.0591\n",
      "\n",
      "Epoch 00004: val_loss improved from 275.96677 to 254.05908, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 583.7168 - val_loss: 1617.3198\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 254.05908\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 616.5532 - val_loss: 243.3761\n",
      "\n",
      "Epoch 00006: val_loss improved from 254.05908 to 243.37610, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 580.8547 - val_loss: 1663.8562\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 243.37610\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 551.5516 - val_loss: 951.9408\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 243.37610\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 599.9548 - val_loss: 1302.6514\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 243.37610\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 993us/step - loss: 609.4530 - val_loss: 1536.8253\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 243.37610\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 593.0095 - val_loss: 1677.0396\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 243.37610\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 593.0261 - val_loss: 1548.3564\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 243.37610\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 583.4619 - val_loss: 340.5731\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 243.37610\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 593.8606 - val_loss: 727.2269\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 243.37610\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 598.8134 - val_loss: 257.8611\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 243.37610\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 589.2006 - val_loss: 1727.1318\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 243.37610\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 558.8058 - val_loss: 445.5746\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 243.37610\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 567.5585 - val_loss: 1076.2671\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 243.37610\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 585.4606 - val_loss: 1619.4845\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 243.37610\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 564.0384 - val_loss: 505.9465\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 243.37610\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 586.7343 - val_loss: 1016.9783\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 243.37610\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 549.5890 - val_loss: 928.5244\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 243.37610\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 606.6437 - val_loss: 287.9546\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 243.37610\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 537.5366 - val_loss: 929.0468\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 243.37610\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 566.6486 - val_loss: 275.1959\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 243.37610\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 562.8787 - val_loss: 1282.7780\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 243.37610\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 529.9683 - val_loss: 971.6998\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 243.37610\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 547.1093 - val_loss: 829.5137\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 243.37610\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 535.5687 - val_loss: 936.0945\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 243.37610\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 562.3996 - val_loss: 523.6724\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 243.37610\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 580.7385 - val_loss: 363.3346\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 243.37610\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 559.8043 - val_loss: 264.6683\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 243.37610\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 552.1229 - val_loss: 597.7798\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 243.37610\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 554.4612 - val_loss: 282.5382\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 243.37610\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 519.1511 - val_loss: 556.9349\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 243.37610\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 551.9404 - val_loss: 315.4786\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 243.37610\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 498.8956 - val_loss: 1235.7461\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 243.37610\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 495.5767 - val_loss: 268.8562\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 243.37610\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 537.7285 - val_loss: 846.3232\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 243.37610\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 498.0850 - val_loss: 454.4905\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 243.37610\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 500.3586 - val_loss: 1584.8324\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 243.37610\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 488.0172 - val_loss: 924.3585\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 243.37610\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 466.9185 - val_loss: 1272.4841\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 243.37610\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 449.8035 - val_loss: 264.9361\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 243.37610\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 405.1371 - val_loss: 356.3210\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 243.37610\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 400.7009 - val_loss: 1348.8364\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 243.37610\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 411.3588 - val_loss: 416.0623\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 243.37610\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 417.6330 - val_loss: 398.9814\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 243.37610\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 400.1143 - val_loss: 860.1533\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 243.37610\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 372.7462 - val_loss: 1229.2562\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 243.37610\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 359.7299 - val_loss: 1222.2379\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 243.37610\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 364.3273 - val_loss: 1197.6099\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 243.37610\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 382.4144 - val_loss: 959.0324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00053: val_loss did not improve from 243.37610\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 369.4504 - val_loss: 681.7504\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 243.37610\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 377.5945 - val_loss: 1373.6492\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 243.37610\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 371.9041 - val_loss: 867.9716\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 243.37610\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 351.1174 - val_loss: 1373.8158\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 243.37610\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 338.5886 - val_loss: 1536.4719\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 243.37610\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 340.1259 - val_loss: 871.1978\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 243.37610\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 306.4740 - val_loss: 570.6640\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 243.37610\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 291.3702 - val_loss: 458.2454\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 243.37610\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 299.3102 - val_loss: 1145.0524\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 243.37610\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 281.8954 - val_loss: 1074.5677\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 243.37610\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 270.1140 - val_loss: 639.3372\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 243.37610\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 263.3122 - val_loss: 864.3148\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 243.37610\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 283.2071 - val_loss: 856.2985\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 243.37610\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 256.6321 - val_loss: 841.1340\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 243.37610\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 271.0185 - val_loss: 917.4693\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 243.37610\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 244.2498 - val_loss: 924.2499\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 243.37610\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 231.3727 - val_loss: 598.1522\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 243.37610\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 233.0079 - val_loss: 914.3663\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 243.37610\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 238.3085 - val_loss: 495.5531\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 243.37610\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 259.5214 - val_loss: 482.7960\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 243.37610\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 236.5931 - val_loss: 920.5850\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 243.37610\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 255.9066 - val_loss: 659.5814\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 243.37610\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 252.8113 - val_loss: 641.3669\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 243.37610\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 249.3373 - val_loss: 382.3781\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 243.37610\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 241.6025 - val_loss: 778.1047\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 243.37610\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 238.2208 - val_loss: 380.1791\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 243.37610\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 229.9450 - val_loss: 597.5906\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 243.37610\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 235.8413 - val_loss: 446.2465\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 243.37610\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 239.0873 - val_loss: 749.9690\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 243.37610\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 231.2499 - val_loss: 911.5059\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 243.37610\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 234.7246 - val_loss: 904.2969\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 243.37610\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 222.8766 - val_loss: 355.4657\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 243.37610\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 229.2843 - val_loss: 610.4977\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 243.37610\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 221.8313 - val_loss: 509.4836\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 243.37610\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 219.7048 - val_loss: 757.9278\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 243.37610\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 235.6127 - val_loss: 445.0733\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 243.37610\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 213.7353 - val_loss: 653.2766\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 243.37610\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 211.7574 - val_loss: 402.4896\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 243.37610\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 234.5176 - val_loss: 777.7430\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 243.37610\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 246.1055 - val_loss: 398.5332\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 243.37610\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 233.4141 - val_loss: 810.5935\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 243.37610\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 210.4495 - val_loss: 440.6718\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 243.37610\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 213.3335 - val_loss: 757.1922\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 243.37610\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 216.2460 - val_loss: 670.7576\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 243.37610\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 203.8074 - val_loss: 747.4652\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 243.37610\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 203.7847 - val_loss: 531.0129\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 243.37610\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 208.8530 - val_loss: 429.3986\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 243.37610\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 205.1032 - val_loss: 674.7623\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 243.37610\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 202.8499 - val_loss: 599.2349\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 243.37610\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 208.0908 - val_loss: 626.4872\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 243.37610\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 203.9374 - val_loss: 805.0857\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 243.37610\n",
      "Epoch 105/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 202.1151 - val_loss: 706.7014\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 243.37610\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 203.7962 - val_loss: 477.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▍                                                          | 6/21 [11:20<27:00, 108.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00106: val_loss did not improve from 243.37610\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 596.9148 - val_loss: 525.4219\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 525.42194, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 423.8959 - val_loss: 1227.6077\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 525.42194\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 403.2290 - val_loss: 310.5695\n",
      "\n",
      "Epoch 00003: val_loss improved from 525.42194 to 310.56946, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 436.2279 - val_loss: 366.7578\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 310.56946\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 405.6011 - val_loss: 415.7885\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 310.56946\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 406.1520 - val_loss: 584.6196\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 310.56946\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 421.6689 - val_loss: 1435.0441\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 310.56946\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 450.0117 - val_loss: 326.4539\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 310.56946\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 412.8352 - val_loss: 857.4783\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 310.56946\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 386.3407 - val_loss: 1259.7379\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 310.56946\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 423.0947 - val_loss: 373.3058\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 310.56946\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 402.0443 - val_loss: 1058.7567\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 310.56946\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 426.7194 - val_loss: 902.9003\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 310.56946\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 433.7506 - val_loss: 354.2610\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 310.56946\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 389.0464 - val_loss: 995.9970\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 310.56946\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 364.9541 - val_loss: 316.5978\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 310.56946\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 424.0755 - val_loss: 1213.1112\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 310.56946\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 419.3539 - val_loss: 1501.1486\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 310.56946\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 428.3877 - val_loss: 1370.7329\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 310.56946\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 417.2288 - val_loss: 1435.3750\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 310.56946\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 402.8728 - val_loss: 509.2429\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 310.56946\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 412.8338 - val_loss: 445.3032\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 310.56946\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 424.3011 - val_loss: 1390.5017\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 310.56946\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 414.6640 - val_loss: 1175.3149\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 310.56946\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 423.6844 - val_loss: 412.5168\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 310.56946\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 423.4333 - val_loss: 588.1772\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 310.56946\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 408.7138 - val_loss: 1001.8146\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 310.56946\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 372.5126 - val_loss: 469.9134\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 310.56946\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 386.9277 - val_loss: 350.9276\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 310.56946\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 393.8549 - val_loss: 1038.4259\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 310.56946\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 402.1860 - val_loss: 575.0357\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 310.56946\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 342.9861 - val_loss: 553.1730\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 310.56946\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 371.5301 - val_loss: 1417.8409\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 310.56946\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 340.5430 - val_loss: 336.3540\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 310.56946\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 345.4107 - val_loss: 1226.1993\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 310.56946\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 364.2122 - val_loss: 534.7214\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 310.56946\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 358.0069 - val_loss: 784.8857\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 310.56946\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 373.8675 - val_loss: 683.8253\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 310.56946\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 363.3548 - val_loss: 488.3654\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 310.56946\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 336.9579 - val_loss: 1351.6826\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 310.56946\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 325.2945 - val_loss: 1393.8470\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 310.56946\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 347.6558 - val_loss: 1097.8978\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 310.56946\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 300.5283 - val_loss: 1061.4823\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 310.56946\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 302.1519 - val_loss: 1024.1539\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 310.56946\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 274.3008 - val_loss: 571.3219\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 310.56946\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 299.0743 - val_loss: 1028.6013\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 310.56946\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 278.5495 - val_loss: 547.4767\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 310.56946\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 270.4120 - val_loss: 299.5249\n",
      "\n",
      "Epoch 00048: val_loss improved from 310.56946 to 299.52487, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 272.4962 - val_loss: 1117.2811\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 299.52487\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 271.6886 - val_loss: 290.4852\n",
      "\n",
      "Epoch 00050: val_loss improved from 299.52487 to 290.48523, saving model to model\\tmp_checkpoint1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 267.4679 - val_loss: 314.6356\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 290.48523\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 245.0155 - val_loss: 524.4907\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 290.48523\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 226.7827 - val_loss: 1171.0132\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 290.48523\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 262.5897 - val_loss: 1186.6018\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 290.48523\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 240.2019 - val_loss: 319.9249\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 290.48523\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.2397 - val_loss: 310.2613\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 290.48523\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 221.6279 - val_loss: 395.4606\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 290.48523\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 210.2584 - val_loss: 675.4334\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 290.48523\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 205.0798 - val_loss: 1162.1279\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 290.48523\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 208.8969 - val_loss: 597.4342\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 290.48523\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 202.1194 - val_loss: 676.5787\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 290.48523\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 196.0766 - val_loss: 323.8524\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 290.48523\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 197.6158 - val_loss: 613.9432\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 290.48523\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 193.1038 - val_loss: 321.8852\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 290.48523\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 197.8365 - val_loss: 785.7740\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 290.48523\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 209.4843 - val_loss: 673.3424\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 290.48523\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 190.8465 - val_loss: 955.6351\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 290.48523\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 192.3570 - val_loss: 513.3798\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 290.48523\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 186.9878 - val_loss: 691.4333\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 290.48523\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 189.8008 - val_loss: 618.1562\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 290.48523\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 196.1655 - val_loss: 530.1832\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 290.48523\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 188.8466 - val_loss: 292.7129\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 290.48523\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 198.7837 - val_loss: 788.9371\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 290.48523\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.9685 - val_loss: 988.8832\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 290.48523\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 211.2448 - val_loss: 639.9895\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 290.48523\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 198.5062 - val_loss: 1020.5860\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 290.48523\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 196.5179 - val_loss: 662.0421\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 290.48523\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 196.6942 - val_loss: 456.3879\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 290.48523\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 186.5163 - val_loss: 766.5417\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 290.48523\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 198.1259 - val_loss: 837.8416\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 290.48523\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 197.5564 - val_loss: 555.6663\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 290.48523\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 187.6375 - val_loss: 300.4387\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 290.48523\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 192.2627 - val_loss: 666.8381\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 290.48523\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 192.7353 - val_loss: 704.4022\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 290.48523\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 201.9854 - val_loss: 539.9144\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 290.48523\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 196.7927 - val_loss: 330.3510\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 290.48523\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 193.5575 - val_loss: 614.5195\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 290.48523\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 189.2746 - val_loss: 321.3821\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 290.48523\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 178.3936 - val_loss: 511.5166\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 290.48523\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 189.0123 - val_loss: 713.4249\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 290.48523\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 200.9323 - val_loss: 864.5847\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 290.48523\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 192.6056 - val_loss: 304.1439\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 290.48523\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 187.0736 - val_loss: 299.7746\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 290.48523\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 186.6979 - val_loss: 542.8390\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 290.48523\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 194.1122 - val_loss: 798.6933\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 290.48523\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 185.4883 - val_loss: 349.0033\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 290.48523\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 180.9168 - val_loss: 502.8087\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 290.48523\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 183.5102 - val_loss: 432.3159\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 290.48523\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 184.7720 - val_loss: 511.2268\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 290.48523\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 180.1030 - val_loss: 698.2269\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 290.48523\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 182.3653 - val_loss: 749.9801\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 290.48523\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 177.2912 - val_loss: 556.7201\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 290.48523\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - ETA: 0s - loss: 169.130 - 0s 1ms/step - loss: 179.3574 - val_loss: 844.3143\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 290.48523\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 175.6570 - val_loss: 267.8240\n",
      "\n",
      "Epoch 00104: val_loss improved from 290.48523 to 267.82397, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 185.9731 - val_loss: 901.7039\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 267.82397\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 175.3961 - val_loss: 559.3438\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 267.82397\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 185.3578 - val_loss: 406.1152\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 267.82397\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 174.3111 - val_loss: 821.8074\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 267.82397\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 170.0842 - val_loss: 700.2025\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 267.82397\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 173.9872 - val_loss: 615.5955\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 267.82397\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 168.8045 - val_loss: 296.6936\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 267.82397\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 177.5980 - val_loss: 356.7480\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 267.82397\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 179.3327 - val_loss: 686.3607\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 267.82397\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 175.8243 - val_loss: 569.7529\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 267.82397\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.3983 - val_loss: 1212.2479\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 267.82397\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 182.9351 - val_loss: 799.9047\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 267.82397\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.0222 - val_loss: 634.8937\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 267.82397\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 172.4159 - val_loss: 733.7877\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 267.82397\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.1520 - val_loss: 256.9551\n",
      "\n",
      "Epoch 00119: val_loss improved from 267.82397 to 256.95511, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.6283 - val_loss: 596.3195\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 256.95511\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 177.6268 - val_loss: 508.7521\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 256.95511\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 170.3828 - val_loss: 252.0066\n",
      "\n",
      "Epoch 00122: val_loss improved from 256.95511 to 252.00662, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 174.5449 - val_loss: 302.0678\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 252.00662\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.0695 - val_loss: 624.9267\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 252.00662\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 173.9083 - val_loss: 483.1395\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 252.00662\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 168.4599 - val_loss: 284.8714\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 252.00662\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 168.3873 - val_loss: 1185.6974\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 252.00662\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 172.9839 - val_loss: 316.8857\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 252.00662\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.7257 - val_loss: 686.5218\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 252.00662\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 165.7379 - val_loss: 436.8256\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 252.00662\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 164.9416 - val_loss: 365.7158\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 252.00662\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 161.0218 - val_loss: 773.2199\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 252.00662\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.4722 - val_loss: 542.9880\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 252.00662\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.4438 - val_loss: 314.6848\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 252.00662\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 165.1152 - val_loss: 475.3480\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 252.00662\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 170.0089 - val_loss: 324.2097\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 252.00662\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 165.5107 - val_loss: 642.9749\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 252.00662\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.9524 - val_loss: 643.6132\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 252.00662\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.8551 - val_loss: 647.4464\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 252.00662\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 164.5821 - val_loss: 449.1458\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 252.00662\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.0379 - val_loss: 312.5796\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 252.00662\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 161.1190 - val_loss: 346.5918\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 252.00662\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.1090 - val_loss: 647.3875\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 252.00662\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.2645 - val_loss: 424.6967\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 252.00662\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 163.1647 - val_loss: 506.1928\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 252.00662\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 162.4272 - val_loss: 381.8575\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 252.00662\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.6067 - val_loss: 438.2549\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 252.00662\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 170.5602 - val_loss: 468.7760\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 252.00662\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 162.1870 - val_loss: 241.0403\n",
      "\n",
      "Epoch 00149: val_loss improved from 252.00662 to 241.04031, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 163.3055 - val_loss: 441.7899\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 241.04031\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.4366 - val_loss: 446.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00151: val_loss did not improve from 241.04031\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 165.0476 - val_loss: 587.9519\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 241.04031\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 155.5309 - val_loss: 372.5219\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 241.04031\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 161.9255 - val_loss: 253.5702\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 241.04031\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.9669 - val_loss: 339.0332\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 241.04031\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.4387 - val_loss: 543.8564\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 241.04031\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 163.2165 - val_loss: 748.7280\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 241.04031\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 158.2477 - val_loss: 305.6993\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 241.04031\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.4778 - val_loss: 243.3527\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 241.04031\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 164.7648 - val_loss: 677.5440\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 241.04031\n",
      "Epoch 161/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.9757 - val_loss: 509.6249\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 241.04031\n",
      "Epoch 162/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.9734 - val_loss: 640.7557\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 241.04031\n",
      "Epoch 163/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.1223 - val_loss: 738.9010\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 241.04031\n",
      "Epoch 164/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 162.8218 - val_loss: 296.5063\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 241.04031\n",
      "Epoch 165/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 155.6845 - val_loss: 271.6052\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 241.04031\n",
      "Epoch 166/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 180.8580 - val_loss: 406.2764\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 241.04031\n",
      "Epoch 167/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 177.9630 - val_loss: 376.8639\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 241.04031\n",
      "Epoch 168/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 175.5103 - val_loss: 538.3448\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 241.04031\n",
      "Epoch 169/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 168.4705 - val_loss: 351.9933\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 241.04031\n",
      "Epoch 170/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 178.8644 - val_loss: 479.8921\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 241.04031\n",
      "Epoch 171/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.7335 - val_loss: 352.4211\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 241.04031\n",
      "Epoch 172/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 174.9777 - val_loss: 396.0573\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 241.04031\n",
      "Epoch 173/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 165.1246 - val_loss: 297.1371\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 241.04031\n",
      "Epoch 174/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 170.5983 - val_loss: 303.8598\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 241.04031\n",
      "Epoch 175/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 165.1396 - val_loss: 690.7606\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 241.04031\n",
      "Epoch 176/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.7666 - val_loss: 379.6656\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 241.04031\n",
      "Epoch 177/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 160.8643 - val_loss: 995.7678\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 241.04031\n",
      "Epoch 178/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.3686 - val_loss: 447.9851\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 241.04031\n",
      "Epoch 179/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 161.4534 - val_loss: 472.2303\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 241.04031\n",
      "Epoch 180/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.5102 - val_loss: 874.4665\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 241.04031\n",
      "Epoch 181/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 164.5061 - val_loss: 573.9078\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 241.04031\n",
      "Epoch 182/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 158.8577 - val_loss: 251.8143\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 241.04031\n",
      "Epoch 183/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 155.9410 - val_loss: 766.9183\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 241.04031\n",
      "Epoch 184/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 161.7238 - val_loss: 363.1504\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 241.04031\n",
      "Epoch 185/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 163.6958 - val_loss: 294.1609\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 241.04031\n",
      "Epoch 186/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 162.5647 - val_loss: 431.6169\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 241.04031\n",
      "Epoch 187/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 158.3331 - val_loss: 259.5895\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 241.04031\n",
      "Epoch 188/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 167.5198 - val_loss: 259.2514\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 241.04031\n",
      "Epoch 189/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.4773 - val_loss: 1117.4604\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 241.04031\n",
      "Epoch 190/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 168.5414 - val_loss: 245.6787\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 241.04031\n",
      "Epoch 191/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.1578 - val_loss: 648.1994\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 241.04031\n",
      "Epoch 192/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.3432 - val_loss: 616.9899\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 241.04031\n",
      "Epoch 193/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 160.0621 - val_loss: 569.0497\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 241.04031\n",
      "Epoch 194/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.9778 - val_loss: 518.4231\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 241.04031\n",
      "Epoch 195/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.1808 - val_loss: 311.4492\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 241.04031\n",
      "Epoch 196/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 158.5659 - val_loss: 661.0305\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 241.04031\n",
      "Epoch 197/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 158.6874 - val_loss: 575.2681\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 241.04031\n",
      "Epoch 198/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.3407 - val_loss: 452.2353\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 241.04031\n",
      "Epoch 199/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.6865 - val_loss: 409.9707\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 241.04031\n",
      "Epoch 200/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.2178 - val_loss: 504.2202\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 241.04031\n",
      "Epoch 201/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 161.6139 - val_loss: 774.4507\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 241.04031\n",
      "Epoch 202/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 158.7345 - val_loss: 443.8009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00202: val_loss did not improve from 241.04031\n",
      "Epoch 203/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.0931 - val_loss: 332.3482\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 241.04031\n",
      "Epoch 204/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 151.5817 - val_loss: 318.0590\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 241.04031\n",
      "Epoch 205/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.8319 - val_loss: 933.7861\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 241.04031\n",
      "Epoch 206/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 160.0740 - val_loss: 592.3410\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 241.04031\n",
      "Epoch 207/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.8026 - val_loss: 671.3060\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 241.04031\n",
      "Epoch 208/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 152.1322 - val_loss: 808.8543\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 241.04031\n",
      "Epoch 209/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.3221 - val_loss: 477.9220\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 241.04031\n",
      "Epoch 210/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 151.3833 - val_loss: 231.5119\n",
      "\n",
      "Epoch 00210: val_loss improved from 241.04031 to 231.51192, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 211/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.0388 - val_loss: 828.1595\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 231.51192\n",
      "Epoch 212/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.9971 - val_loss: 665.0153\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 231.51192\n",
      "Epoch 213/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.7644 - val_loss: 764.3217\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 231.51192\n",
      "Epoch 214/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.6409 - val_loss: 660.4340\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 231.51192\n",
      "Epoch 215/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.9456 - val_loss: 497.3690\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 231.51192\n",
      "Epoch 216/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.4972 - val_loss: 373.1287\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 231.51192\n",
      "Epoch 217/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.9115 - val_loss: 272.7515\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 231.51192\n",
      "Epoch 218/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.0241 - val_loss: 873.7466\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 231.51192\n",
      "Epoch 219/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.5064 - val_loss: 241.0248\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 231.51192\n",
      "Epoch 220/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 158.6952 - val_loss: 482.9337\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 231.51192\n",
      "Epoch 221/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.6643 - val_loss: 284.7270\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 231.51192\n",
      "Epoch 222/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 151.2590 - val_loss: 572.2862\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 231.51192\n",
      "Epoch 223/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.8315 - val_loss: 674.0101\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 231.51192\n",
      "Epoch 224/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.1004 - val_loss: 470.6011\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 231.51192\n",
      "Epoch 225/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.6238 - val_loss: 957.9562\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 231.51192\n",
      "Epoch 226/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.4014 - val_loss: 334.4198\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 231.51192\n",
      "Epoch 227/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.5029 - val_loss: 608.6889\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 231.51192\n",
      "Epoch 228/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.3705 - val_loss: 408.8131\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 231.51192\n",
      "Epoch 229/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.1697 - val_loss: 346.0334\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 231.51192\n",
      "Epoch 230/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.5808 - val_loss: 662.7807\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 231.51192\n",
      "Epoch 231/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.0583 - val_loss: 659.6653\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 231.51192\n",
      "Epoch 232/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.8918 - val_loss: 761.6667\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 231.51192\n",
      "Epoch 233/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.4840 - val_loss: 689.0227\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 231.51192\n",
      "Epoch 234/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 152.4614 - val_loss: 1006.5083\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 231.51192\n",
      "Epoch 235/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 151.7451 - val_loss: 943.4951\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 231.51192\n",
      "Epoch 236/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.1281 - val_loss: 526.8906\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 231.51192\n",
      "Epoch 237/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.6210 - val_loss: 633.3808\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 231.51192\n",
      "Epoch 238/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 151.8385 - val_loss: 536.4283\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 231.51192\n",
      "Epoch 239/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.7506 - val_loss: 642.5016\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 231.51192\n",
      "Epoch 240/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.6070 - val_loss: 340.3773\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 231.51192\n",
      "Epoch 241/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 154.2268 - val_loss: 384.8130\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 231.51192\n",
      "Epoch 242/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.0327 - val_loss: 853.0952\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 231.51192\n",
      "Epoch 243/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.7302 - val_loss: 535.6028\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 231.51192\n",
      "Epoch 244/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.4198 - val_loss: 796.7159\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 231.51192\n",
      "Epoch 245/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.5431 - val_loss: 341.3329\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 231.51192\n",
      "Epoch 246/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.0345 - val_loss: 797.0851\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 231.51192\n",
      "Epoch 247/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.9642 - val_loss: 269.2753\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 231.51192\n",
      "Epoch 248/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.4908 - val_loss: 683.5874\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 231.51192\n",
      "Epoch 249/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.1209 - val_loss: 371.1620\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 231.51192\n",
      "Epoch 250/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.7955 - val_loss: 743.2814\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 231.51192\n",
      "Epoch 251/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.8271 - val_loss: 745.3123\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 231.51192\n",
      "Epoch 252/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.8764 - val_loss: 259.9057\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 231.51192\n",
      "Epoch 253/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.9243 - val_loss: 632.9766\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 231.51192\n",
      "Epoch 254/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.2118 - val_loss: 1019.0196\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 231.51192\n",
      "Epoch 255/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.2436 - val_loss: 405.8370\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 231.51192\n",
      "Epoch 256/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.9356 - val_loss: 750.7433\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 231.51192\n",
      "Epoch 257/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.5123 - val_loss: 935.5410\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 231.51192\n",
      "Epoch 258/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.1205 - val_loss: 249.8372\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 231.51192\n",
      "Epoch 259/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 151.5288 - val_loss: 466.6704\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 231.51192\n",
      "Epoch 260/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.1832 - val_loss: 452.1473\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 231.51192\n",
      "Epoch 261/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.6760 - val_loss: 407.1099\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 231.51192\n",
      "Epoch 262/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.6919 - val_loss: 806.0778\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 231.51192\n",
      "Epoch 263/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.6536 - val_loss: 388.6543\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 231.51192\n",
      "Epoch 264/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.8132 - val_loss: 365.5504\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 231.51192\n",
      "Epoch 265/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.9392 - val_loss: 211.2107\n",
      "\n",
      "Epoch 00265: val_loss improved from 231.51192 to 211.21066, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 266/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.7312 - val_loss: 716.3161\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 211.21066\n",
      "Epoch 267/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 152.1275 - val_loss: 739.2787\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 211.21066\n",
      "Epoch 268/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.3271 - val_loss: 489.9626\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 211.21066\n",
      "Epoch 269/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.4187 - val_loss: 349.6070\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 211.21066\n",
      "Epoch 270/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.1779 - val_loss: 397.6723\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 211.21066\n",
      "Epoch 271/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.6790 - val_loss: 928.7328\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 211.21066\n",
      "Epoch 272/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.8405 - val_loss: 722.2592\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 211.21066\n",
      "Epoch 273/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.9160 - val_loss: 624.5933\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 211.21066\n",
      "Epoch 274/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.3583 - val_loss: 334.1282\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 211.21066\n",
      "Epoch 275/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.1798 - val_loss: 563.3916\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 211.21066\n",
      "Epoch 276/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.2607 - val_loss: 611.0201\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 211.21066\n",
      "Epoch 277/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.3218 - val_loss: 474.3810\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 211.21066\n",
      "Epoch 278/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.5197 - val_loss: 604.1775\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 211.21066\n",
      "Epoch 279/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.5285 - val_loss: 655.5846\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 211.21066\n",
      "Epoch 280/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.9523 - val_loss: 527.7036\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 211.21066\n",
      "Epoch 281/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.9975 - val_loss: 257.6372\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 211.21066\n",
      "Epoch 282/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.7601 - val_loss: 885.9891\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 211.21066\n",
      "Epoch 283/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.0448 - val_loss: 991.8267\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 211.21066\n",
      "Epoch 284/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.4821 - val_loss: 502.1304\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 211.21066\n",
      "Epoch 285/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.9696 - val_loss: 953.0605\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 211.21066\n",
      "Epoch 286/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.3687 - val_loss: 468.5301\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 211.21066\n",
      "Epoch 287/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.1185 - val_loss: 253.9338\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 211.21066\n",
      "Epoch 288/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.1088 - val_loss: 630.9199\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 211.21066\n",
      "Epoch 289/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.2209 - val_loss: 665.4959\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 211.21066\n",
      "Epoch 290/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.6630 - val_loss: 766.8447\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 211.21066\n",
      "Epoch 291/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.5286 - val_loss: 212.0685\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 211.21066\n",
      "Epoch 292/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.4949 - val_loss: 854.5469\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 211.21066\n",
      "Epoch 293/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.6066 - val_loss: 208.3858\n",
      "\n",
      "Epoch 00293: val_loss improved from 211.21066 to 208.38582, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 294/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.1009 - val_loss: 319.6972\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 208.38582\n",
      "Epoch 295/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.3733 - val_loss: 940.6627\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 208.38582\n",
      "Epoch 296/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.1098 - val_loss: 290.7705\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 208.38582\n",
      "Epoch 297/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.5499 - val_loss: 348.0002\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 208.38582\n",
      "Epoch 298/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.8130 - val_loss: 563.3546\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 208.38582\n",
      "Epoch 299/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.8381 - val_loss: 699.6921\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 208.38582\n",
      "Epoch 300/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.7001 - val_loss: 700.1422\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 208.38582\n",
      "Epoch 301/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.8394 - val_loss: 237.0610\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 208.38582\n",
      "Epoch 302/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.7987 - val_loss: 549.4988\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 208.38582\n",
      "Epoch 303/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 140.8184 - val_loss: 545.7572\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 208.38582\n",
      "Epoch 304/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.7291 - val_loss: 577.4214\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 208.38582\n",
      "Epoch 305/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.7223 - val_loss: 867.5101\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 208.38582\n",
      "Epoch 306/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.6808 - val_loss: 288.8899\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 208.38582\n",
      "Epoch 307/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.8068 - val_loss: 321.2996\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 208.38582\n",
      "Epoch 308/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.8795 - val_loss: 227.0032\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 208.38582\n",
      "Epoch 309/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.6586 - val_loss: 215.8422\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 208.38582\n",
      "Epoch 310/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.1903 - val_loss: 494.6402\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 208.38582\n",
      "Epoch 311/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.4026 - val_loss: 418.0322\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 208.38582\n",
      "Epoch 312/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.6056 - val_loss: 679.0740\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 208.38582\n",
      "Epoch 313/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.8350 - val_loss: 206.8056\n",
      "\n",
      "Epoch 00313: val_loss improved from 208.38582 to 206.80565, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 314/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.8517 - val_loss: 816.0865\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 206.80565\n",
      "Epoch 315/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.3830 - val_loss: 503.2119\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 206.80565\n",
      "Epoch 316/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.6005 - val_loss: 583.8331\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 206.80565\n",
      "Epoch 317/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.3094 - val_loss: 532.9565\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 206.80565\n",
      "Epoch 318/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.3765 - val_loss: 603.7049\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 206.80565\n",
      "Epoch 319/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.7987 - val_loss: 754.3785\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 206.80565\n",
      "Epoch 320/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.6656 - val_loss: 262.9133\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 206.80565\n",
      "Epoch 321/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.3775 - val_loss: 522.3510\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 206.80565\n",
      "Epoch 322/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.2733 - val_loss: 521.4291\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 206.80565\n",
      "Epoch 323/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.2216 - val_loss: 776.1278\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 206.80565\n",
      "Epoch 324/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.3444 - val_loss: 702.6426\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 206.80565\n",
      "Epoch 325/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.3751 - val_loss: 438.1922\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 206.80565\n",
      "Epoch 326/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.7393 - val_loss: 511.1129\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 206.80565\n",
      "Epoch 327/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.9062 - val_loss: 654.0311\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 206.80565\n",
      "Epoch 328/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.2011 - val_loss: 852.6763\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 206.80565\n",
      "Epoch 329/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.3308 - val_loss: 306.4543\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 206.80565\n",
      "Epoch 330/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.8132 - val_loss: 478.5741\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 206.80565\n",
      "Epoch 331/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.9749 - val_loss: 417.8780\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 206.80565\n",
      "Epoch 332/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.4360 - val_loss: 624.6418\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 206.80565\n",
      "Epoch 333/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.1814 - val_loss: 334.3998\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 206.80565\n",
      "Epoch 334/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.5951 - val_loss: 415.3707\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 206.80565\n",
      "Epoch 335/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.3129 - val_loss: 425.3770\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 206.80565\n",
      "Epoch 336/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.8280 - val_loss: 409.0556\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 206.80565\n",
      "Epoch 337/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.3934 - val_loss: 292.1799\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 206.80565\n",
      "Epoch 338/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.4036 - val_loss: 306.8021\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 206.80565\n",
      "Epoch 339/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.6434 - val_loss: 866.4618\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 206.80565\n",
      "Epoch 340/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.8268 - val_loss: 845.4531\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 206.80565\n",
      "Epoch 341/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.5373 - val_loss: 634.1806\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 206.80565\n",
      "Epoch 342/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.4252 - val_loss: 832.2301\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 206.80565\n",
      "Epoch 343/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.0146 - val_loss: 217.1314\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 206.80565\n",
      "Epoch 344/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.6351 - val_loss: 675.1014\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 206.80565\n",
      "Epoch 345/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.3057 - val_loss: 670.1575\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 206.80565\n",
      "Epoch 346/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.9990 - val_loss: 593.1960\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 206.80565\n",
      "Epoch 347/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.6482 - val_loss: 480.0587\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 206.80565\n",
      "Epoch 348/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.4603 - val_loss: 257.4342\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 206.80565\n",
      "Epoch 349/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.4098 - val_loss: 271.4301\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 206.80565\n",
      "Epoch 350/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.4543 - val_loss: 395.5771\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 206.80565\n",
      "Epoch 351/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.3304 - val_loss: 260.6380\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 206.80565\n",
      "Epoch 352/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.5759 - val_loss: 611.5209\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 206.80565\n",
      "Epoch 353/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.9703 - val_loss: 204.1020\n",
      "\n",
      "Epoch 00353: val_loss improved from 206.80565 to 204.10197, saving model to model\\tmp_checkpoint1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.2793 - val_loss: 552.1533\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 204.10197\n",
      "Epoch 355/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.0877 - val_loss: 388.8445\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 204.10197\n",
      "Epoch 356/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.3741 - val_loss: 319.1062\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 204.10197\n",
      "Epoch 357/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.7570 - val_loss: 571.8870\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 204.10197\n",
      "Epoch 358/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.0875 - val_loss: 505.8784\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 204.10197\n",
      "Epoch 359/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.5965 - val_loss: 325.4596\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 204.10197\n",
      "Epoch 360/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.4139 - val_loss: 258.1313\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 204.10197\n",
      "Epoch 361/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.0074 - val_loss: 505.2289\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 204.10197\n",
      "Epoch 362/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.9397 - val_loss: 897.5750\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 204.10197\n",
      "Epoch 363/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.7470 - val_loss: 664.9238\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 204.10197\n",
      "Epoch 364/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.8454 - val_loss: 619.6746\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 204.10197\n",
      "Epoch 365/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.2882 - val_loss: 231.6969\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 204.10197\n",
      "Epoch 366/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.1400 - val_loss: 661.3480\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 204.10197\n",
      "Epoch 367/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.6609 - val_loss: 206.5235\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 204.10197\n",
      "Epoch 368/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.5427 - val_loss: 732.8514\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 204.10197\n",
      "Epoch 369/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.7763 - val_loss: 482.3790\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 204.10197\n",
      "Epoch 370/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.2130 - val_loss: 448.8861\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 204.10197\n",
      "Epoch 371/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.5479 - val_loss: 402.0172\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 204.10197\n",
      "Epoch 372/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.3275 - val_loss: 472.1292\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 204.10197\n",
      "Epoch 373/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.5748 - val_loss: 883.3484\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 204.10197\n",
      "Epoch 374/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.9419 - val_loss: 622.1058\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 204.10197\n",
      "Epoch 375/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.5915 - val_loss: 495.5045\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 204.10197\n",
      "Epoch 376/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.7105 - val_loss: 670.4261\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 204.10197\n",
      "Epoch 377/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.2497 - val_loss: 536.3599\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 204.10197\n",
      "Epoch 378/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.2726 - val_loss: 736.5989\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 204.10197\n",
      "Epoch 379/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.6452 - val_loss: 195.7985\n",
      "\n",
      "Epoch 00379: val_loss improved from 204.10197 to 195.79852, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 380/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.9479 - val_loss: 614.0637\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 195.79852\n",
      "Epoch 381/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.9667 - val_loss: 608.8233\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 195.79852\n",
      "Epoch 382/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.0891 - val_loss: 626.7966\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 195.79852\n",
      "Epoch 383/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.6643 - val_loss: 201.6619\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 195.79852\n",
      "Epoch 384/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.8472 - val_loss: 691.2321\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 195.79852\n",
      "Epoch 385/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.4311 - val_loss: 199.5807\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 195.79852\n",
      "Epoch 386/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.3380 - val_loss: 672.7382\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 195.79852\n",
      "Epoch 387/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.9387 - val_loss: 458.7274\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 195.79852\n",
      "Epoch 388/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.9685 - val_loss: 647.5684\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 195.79852\n",
      "Epoch 389/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.7139 - val_loss: 397.3494\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 195.79852\n",
      "Epoch 390/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.2067 - val_loss: 717.4682\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 195.79852\n",
      "Epoch 391/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.2926 - val_loss: 227.5193\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 195.79852\n",
      "Epoch 392/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.2242 - val_loss: 436.7242\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 195.79852\n",
      "Epoch 393/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.5569 - val_loss: 325.6420\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 195.79852\n",
      "Epoch 394/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 129.4326 - val_loss: 387.1880\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 195.79852\n",
      "Epoch 395/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.6188 - val_loss: 529.9542\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 195.79852\n",
      "Epoch 396/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.8523 - val_loss: 552.9520\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 195.79852\n",
      "Epoch 397/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.4972 - val_loss: 544.0745\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 195.79852\n",
      "Epoch 398/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.3574 - val_loss: 780.7506\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 195.79852\n",
      "Epoch 399/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.7964 - val_loss: 542.1667\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 195.79852\n",
      "Epoch 400/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.6357 - val_loss: 637.4138\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 195.79852\n",
      "Epoch 401/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.8623 - val_loss: 595.8624\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 195.79852\n",
      "Epoch 402/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.7427 - val_loss: 352.4989\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 195.79852\n",
      "Epoch 403/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.9893 - val_loss: 675.8480\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 195.79852\n",
      "Epoch 404/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.8112 - val_loss: 465.5461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00404: val_loss did not improve from 195.79852\n",
      "Epoch 405/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.4592 - val_loss: 911.1475\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 195.79852\n",
      "Epoch 406/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.3053 - val_loss: 551.7049\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 195.79852\n",
      "Epoch 407/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.9527 - val_loss: 675.1996\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 195.79852\n",
      "Epoch 408/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.2554 - val_loss: 351.1636\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 195.79852\n",
      "Epoch 409/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.8954 - val_loss: 871.9693\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 195.79852\n",
      "Epoch 410/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.6061 - val_loss: 431.6511\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 195.79852\n",
      "Epoch 411/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.9397 - val_loss: 438.9639\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 195.79852\n",
      "Epoch 412/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.9486 - val_loss: 585.6609\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 195.79852\n",
      "Epoch 413/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.4630 - val_loss: 792.6820\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 195.79852\n",
      "Epoch 414/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.0970 - val_loss: 611.6940\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 195.79852\n",
      "Epoch 415/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.3579 - val_loss: 206.8689\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 195.79852\n",
      "Epoch 416/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.4480 - val_loss: 221.6509\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 195.79852\n",
      "Epoch 417/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.0635 - val_loss: 400.6994\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 195.79852\n",
      "Epoch 418/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.2097 - val_loss: 408.2048\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 195.79852\n",
      "Epoch 419/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.2233 - val_loss: 792.1174\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 195.79852\n",
      "Epoch 420/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.6861 - val_loss: 636.3384\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 195.79852\n",
      "Epoch 421/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.3770 - val_loss: 704.5084\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 195.79852\n",
      "Epoch 422/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.1517 - val_loss: 247.1404\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 195.79852\n",
      "Epoch 423/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.2115 - val_loss: 596.5762\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 195.79852\n",
      "Epoch 424/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.2526 - val_loss: 613.0066\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 195.79852\n",
      "Epoch 425/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 131.6388 - val_loss: 733.8800\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 195.79852\n",
      "Epoch 426/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 138.7619 - val_loss: 600.5090\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 195.79852\n",
      "Epoch 427/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.9999 - val_loss: 618.3508\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 195.79852\n",
      "Epoch 428/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.3435 - val_loss: 474.2971\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 195.79852\n",
      "Epoch 429/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 131.9927 - val_loss: 642.2254\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 195.79852\n",
      "Epoch 430/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.7024 - val_loss: 523.1725\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 195.79852\n",
      "Epoch 431/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.7498 - val_loss: 628.6083\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 195.79852\n",
      "Epoch 432/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.7460 - val_loss: 232.8668\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 195.79852\n",
      "Epoch 433/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.7781 - val_loss: 451.4894\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 195.79852\n",
      "Epoch 434/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.1523 - val_loss: 646.4698\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 195.79852\n",
      "Epoch 435/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.1315 - val_loss: 196.0822\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 195.79852\n",
      "Epoch 436/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.9232 - val_loss: 606.6633\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 195.79852\n",
      "Epoch 437/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.0142 - val_loss: 317.8374\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 195.79852\n",
      "Epoch 438/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.4781 - val_loss: 588.3925\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 195.79852\n",
      "Epoch 439/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.3521 - val_loss: 535.3564\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 195.79852\n",
      "Epoch 440/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.0806 - val_loss: 685.4643\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 195.79852\n",
      "Epoch 441/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.4866 - val_loss: 541.2519\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 195.79852\n",
      "Epoch 442/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.7758 - val_loss: 591.7008\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 195.79852\n",
      "Epoch 443/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.4514 - val_loss: 902.1763\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 195.79852\n",
      "Epoch 444/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.0423 - val_loss: 739.1177\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 195.79852\n",
      "Epoch 445/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.1191 - val_loss: 384.0953\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 195.79852\n",
      "Epoch 446/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.9454 - val_loss: 840.2751\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 195.79852\n",
      "Epoch 447/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.6560 - val_loss: 516.4460\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 195.79852\n",
      "Epoch 448/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.8479 - val_loss: 450.8167\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 195.79852\n",
      "Epoch 449/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.6300 - val_loss: 433.7215\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 195.79852\n",
      "Epoch 450/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 129.5652 - val_loss: 442.7355\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 195.79852\n",
      "Epoch 451/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.6949 - val_loss: 670.8535\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 195.79852\n",
      "Epoch 452/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.3397 - val_loss: 868.6711\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 195.79852\n",
      "Epoch 453/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.7441 - val_loss: 386.0930\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 195.79852\n",
      "Epoch 454/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.0762 - val_loss: 845.4794\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 195.79852\n",
      "Epoch 455/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.2590 - val_loss: 581.9412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00455: val_loss did not improve from 195.79852\n",
      "Epoch 456/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.8223 - val_loss: 785.3214\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 195.79852\n",
      "Epoch 457/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.5141 - val_loss: 564.8067\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 195.79852\n",
      "Epoch 458/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.7752 - val_loss: 762.6704\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 195.79852\n",
      "Epoch 459/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.5669 - val_loss: 477.2412\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 195.79852\n",
      "Epoch 460/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.0926 - val_loss: 587.7292\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 195.79852\n",
      "Epoch 461/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.9274 - val_loss: 592.0872\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 195.79852\n",
      "Epoch 462/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.0763 - val_loss: 648.4693\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 195.79852\n",
      "Epoch 463/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 129.7802 - val_loss: 407.2530\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 195.79852\n",
      "Epoch 464/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.7981 - val_loss: 697.2015\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 195.79852\n",
      "Epoch 465/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.2783 - val_loss: 217.5564\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 195.79852\n",
      "Epoch 466/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.0934 - val_loss: 746.3951\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 195.79852\n",
      "Epoch 467/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.2258 - val_loss: 490.2902\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 195.79852\n",
      "Epoch 468/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 127.2895 - val_loss: 314.4032\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 195.79852\n",
      "Epoch 469/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.6346 - val_loss: 708.0129\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 195.79852\n",
      "Epoch 470/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.3927 - val_loss: 772.7254\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 195.79852\n",
      "Epoch 471/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.0664 - val_loss: 628.9014\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 195.79852\n",
      "Epoch 472/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.9279 - val_loss: 688.2242\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 195.79852\n",
      "Epoch 473/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.7667 - val_loss: 849.1161\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 195.79852\n",
      "Epoch 474/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.9979 - val_loss: 465.0004\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 195.79852\n",
      "Epoch 475/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 128.8932 - val_loss: 439.3339\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 195.79852\n",
      "Epoch 476/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 131.5104 - val_loss: 639.5725\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 195.79852\n",
      "Epoch 477/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.1433 - val_loss: 303.5151\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 195.79852\n",
      "Epoch 478/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.4712 - val_loss: 645.9729\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 195.79852\n",
      "Epoch 479/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.2039 - val_loss: 762.0394\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 195.79852\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 672.3076 - val_loss: 785.9666\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 785.96661, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 381.8684 - val_loss: 459.8497\n",
      "\n",
      "Epoch 00002: val_loss improved from 785.96661 to 459.84973, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 395.5286 - val_loss: 1596.1047\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 459.84973\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 392.2363 - val_loss: 831.4386\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 459.84973\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 412.4277 - val_loss: 755.1727\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 459.84973\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 424.0163 - val_loss: 1748.8103\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 459.84973\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 396.5703 - val_loss: 516.2235\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 459.84973\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 428.9945 - val_loss: 684.5112\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 459.84973\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 411.0801 - val_loss: 415.8527\n",
      "\n",
      "Epoch 00009: val_loss improved from 459.84973 to 415.85266, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 437.9819 - val_loss: 1297.0978\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 415.85266\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 399.6187 - val_loss: 2777.6343\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 415.85266\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 439.3064 - val_loss: 947.6219\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 415.85266\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 393.9824 - val_loss: 323.6923\n",
      "\n",
      "Epoch 00013: val_loss improved from 415.85266 to 323.69229, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 413.4207 - val_loss: 1258.6965\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 323.69229\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 443.2593 - val_loss: 1465.2411\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 323.69229\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 418.4488 - val_loss: 1515.3221\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 323.69229\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 415.6387 - val_loss: 301.9230\n",
      "\n",
      "Epoch 00017: val_loss improved from 323.69229 to 301.92303, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 409.0623 - val_loss: 1468.8043\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 301.92303\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 413.7720 - val_loss: 756.6981\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 301.92303\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 414.1348 - val_loss: 1091.5632\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 301.92303\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 406.7057 - val_loss: 1513.5852\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 301.92303\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 383.6398 - val_loss: 308.4887\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 301.92303\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 399.6414 - val_loss: 3000.4451\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 301.92303\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 407.2900 - val_loss: 1660.4714\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 301.92303\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 390.1150 - val_loss: 1457.7230\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 301.92303\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 382.3459 - val_loss: 658.6716\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 301.92303\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 389.3732 - val_loss: 1734.0283\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 301.92303\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 353.0458 - val_loss: 1411.4006\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 301.92303\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 383.3144 - val_loss: 1747.9684\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 301.92303\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 398.9241 - val_loss: 336.5450\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 301.92303\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 374.6692 - val_loss: 1609.2388\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 301.92303\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 406.2265 - val_loss: 913.0464\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 301.92303\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 386.5141 - val_loss: 375.7467\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 301.92303\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 357.6419 - val_loss: 1555.2913\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 301.92303\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 356.3147 - val_loss: 540.8602\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 301.92303\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 331.9352 - val_loss: 1530.8645\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 301.92303\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 317.7689 - val_loss: 594.0606\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 301.92303\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 319.0744 - val_loss: 1846.8757\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 301.92303\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 367.0832 - val_loss: 1472.2878\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 301.92303\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 358.2555 - val_loss: 1092.9778\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 301.92303\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 321.0970 - val_loss: 859.6314\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 301.92303\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 326.2056 - val_loss: 1646.4565\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 301.92303\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 314.4721 - val_loss: 530.6549\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 301.92303\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 309.4686 - val_loss: 818.3621\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 301.92303\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 314.0797 - val_loss: 436.6656\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 301.92303\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 299.9042 - val_loss: 1254.9271\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 301.92303\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 312.0231 - val_loss: 1055.6010\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 301.92303\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 264.8257 - val_loss: 727.3758\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 301.92303\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 295.4821 - val_loss: 1642.2059\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 301.92303\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 306.9580 - val_loss: 1103.9806\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 301.92303\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 273.9344 - val_loss: 358.2845\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 301.92303\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 295.6634 - val_loss: 350.9179\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 301.92303\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 281.3717 - val_loss: 1064.8567\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 301.92303\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 308.6922 - val_loss: 1675.7773\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 301.92303\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 292.0222 - val_loss: 673.5408\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 301.92303\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 277.1585 - val_loss: 1264.0472\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 301.92303\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 291.7900 - val_loss: 1593.9329\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 301.92303\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 298.3993 - val_loss: 1337.2368\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 301.92303\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 274.0725 - val_loss: 2555.8091\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 301.92303\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 294.0620 - val_loss: 281.3974\n",
      "\n",
      "Epoch 00060: val_loss improved from 301.92303 to 281.39737, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.7117 - val_loss: 444.2246\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 281.39737\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 271.2108 - val_loss: 365.6524\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 281.39737\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 271.4031 - val_loss: 649.0936\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 281.39737\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 246.1917 - val_loss: 382.9070\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 281.39737\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 271.9185 - val_loss: 444.4651\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 281.39737\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 250.5798 - val_loss: 995.4979\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 281.39737\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 240.6308 - val_loss: 1363.2965\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 281.39737\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 237.6644 - val_loss: 1290.8220\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 281.39737\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 250.8728 - val_loss: 583.3683\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 281.39737\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 225.2046 - val_loss: 478.5826\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 281.39737\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 226.7922 - val_loss: 1298.9520\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 281.39737\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 228.2394 - val_loss: 1812.1254\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 281.39737\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 222.3523 - val_loss: 935.9832\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 281.39737\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 208.3529 - val_loss: 1287.9285\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 281.39737\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 247.5827 - val_loss: 706.7676\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 281.39737\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 227.3112 - val_loss: 288.4082\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 281.39737\n",
      "Epoch 77/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 2ms/step - loss: 215.7182 - val_loss: 2755.4524\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 281.39737\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 270.3133 - val_loss: 2514.8643\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 281.39737\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 265.6246 - val_loss: 1039.5162\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 281.39737\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 219.2612 - val_loss: 604.6745\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 281.39737\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 230.9673 - val_loss: 1186.1825\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 281.39737\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 269.6468 - val_loss: 971.9638\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 281.39737\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 252.9605 - val_loss: 493.9303\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 281.39737\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 231.6840 - val_loss: 684.4995\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 281.39737\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 240.5921 - val_loss: 944.9568\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 281.39737\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 219.9907 - val_loss: 1121.1064\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 281.39737\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 227.3946 - val_loss: 863.2299\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 281.39737\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 216.3457 - val_loss: 776.7263\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 281.39737\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 206.6755 - val_loss: 1196.1157\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 281.39737\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 209.8189 - val_loss: 1237.7856\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 281.39737\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 214.6481 - val_loss: 910.4305\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 281.39737\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 215.6708 - val_loss: 809.7800\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 281.39737\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 228.3434 - val_loss: 881.3484\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 281.39737\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 205.1321 - val_loss: 1236.0470\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 281.39737\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 254.3371 - val_loss: 285.8069\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 281.39737\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 272.8911 - val_loss: 833.1510\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 281.39737\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 241.8066 - val_loss: 339.7434\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 281.39737\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 237.3504 - val_loss: 357.1732\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 281.39737\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 226.9986 - val_loss: 769.2474\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 281.39737\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 222.7862 - val_loss: 605.3071\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 281.39737\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 219.8587 - val_loss: 948.4069\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 281.39737\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 224.3897 - val_loss: 1054.9558\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 281.39737\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 228.4877 - val_loss: 1018.8928\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 281.39737\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 223.2069 - val_loss: 445.7496\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 281.39737\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 222.4482 - val_loss: 951.1408\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 281.39737\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 223.4078 - val_loss: 436.7370\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 281.39737\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 236.7527 - val_loss: 762.3060\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 281.39737\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 228.4204 - val_loss: 1040.9734\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 281.39737\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 232.8964 - val_loss: 366.9299\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 281.39737\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 224.4744 - val_loss: 384.0414\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 281.39737\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 227.4936 - val_loss: 1251.1647\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 281.39737\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 244.4796 - val_loss: 804.5370\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 281.39737\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 233.0499 - val_loss: 1228.7224\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 281.39737\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 271.4573 - val_loss: 1021.1273\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 281.39737\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.8042 - val_loss: 1050.1747\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 281.39737\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 267.6179 - val_loss: 1034.8317\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 281.39737\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 267.1880 - val_loss: 961.9874\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 281.39737\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.6121 - val_loss: 975.0203\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 281.39737\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.9910 - val_loss: 946.7489\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 281.39737\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 267.2292 - val_loss: 951.6604\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 281.39737\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.7432 - val_loss: 977.0698\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 281.39737\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.6795 - val_loss: 1038.6486\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 281.39737\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 267.2626 - val_loss: 978.3445\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 281.39737\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.7307 - val_loss: 1031.8604\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 281.39737\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 267.0768 - val_loss: 959.0858\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 281.39737\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 266.3184 - val_loss: 1025.1282\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 281.39737\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 266.4877 - val_loss: 935.6559\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 281.39737\n",
      "Epoch 128/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 2ms/step - loss: 266.6739 - val_loss: 1042.2972\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 281.39737\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.7201 - val_loss: 924.4053\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 281.39737\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 267.5006 - val_loss: 954.1336\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 281.39737\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 265.9241 - val_loss: 1027.9921\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 281.39737\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 266.5854 - val_loss: 1024.4871\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 281.39737\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 267.0931 - val_loss: 1000.9787\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 281.39737\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 267.1812 - val_loss: 944.4927\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 281.39737\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 266.7185 - val_loss: 961.6719\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 281.39737\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 266.7863 - val_loss: 1027.2650\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 281.39737\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 266.3961 - val_loss: 929.9479\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 281.39737\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 265.9986 - val_loss: 930.6067\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 281.39737\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 267.5786 - val_loss: 956.1616\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 281.39737\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.2268 - val_loss: 919.7068\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 281.39737\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 267.3989 - val_loss: 1006.3056\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 281.39737\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.5543 - val_loss: 970.3694\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 281.39737\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.7870 - val_loss: 1035.5914\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 281.39737\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.9380 - val_loss: 1024.2288\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 281.39737\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.8704 - val_loss: 1024.8866\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 281.39737\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.1346 - val_loss: 1029.3881\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 281.39737\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.8650 - val_loss: 1009.9312\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 281.39737\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.5010 - val_loss: 1030.4655\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 281.39737\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.7403 - val_loss: 1030.9945\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 281.39737\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.2269 - val_loss: 913.7664\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 281.39737\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 267.0789 - val_loss: 955.4896\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 281.39737\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.7737 - val_loss: 1016.8401\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 281.39737\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.7172 - val_loss: 1041.3920\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 281.39737\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.8853 - val_loss: 969.8123\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 281.39737\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.8692 - val_loss: 1026.7113\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 281.39737\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.8876 - val_loss: 950.7580\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 281.39737\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 267.1583 - val_loss: 1027.9854\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 281.39737\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.7534 - val_loss: 1028.5576\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 281.39737\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 266.9936 - val_loss: 973.1331\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 281.39737\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.8176 - val_loss: 937.1157\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 281.39737\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 689.6506 - val_loss: 1230.7515\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1230.75146, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 415.4884 - val_loss: 259.6746\n",
      "\n",
      "Epoch 00002: val_loss improved from 1230.75146 to 259.67462, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 402.7742 - val_loss: 612.0807\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 259.67462\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 404.6261 - val_loss: 1141.8352\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 259.67462\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 378.4055 - val_loss: 733.0308\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 259.67462\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 370.5667 - val_loss: 265.8583\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 259.67462\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 402.0403 - val_loss: 1357.7222\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 259.67462\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 370.4676 - val_loss: 1145.2833\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 259.67462\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 390.3017 - val_loss: 269.4665\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 259.67462\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 361.6231 - val_loss: 501.8238\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 259.67462\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 402.6849 - val_loss: 1086.2426\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 259.67462\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 388.4910 - val_loss: 322.6074\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 259.67462\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 947us/step - loss: 391.9304 - val_loss: 1194.5990\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 259.67462\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 968us/step - loss: 396.9149 - val_loss: 1489.5302\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 259.67462\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 387.0191 - val_loss: 266.8007\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 259.67462\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 389.6242 - val_loss: 377.6363\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 259.67462\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 395.8286 - val_loss: 1251.5205\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 259.67462\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 377.0717 - val_loss: 578.9279\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 259.67462\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 407.2102 - val_loss: 1601.1981\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 259.67462\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 374.4879 - val_loss: 1245.7719\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 259.67462\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 360.8034 - val_loss: 1541.7443\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 259.67462\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 398.9584 - val_loss: 636.3244\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 259.67462\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 917us/step - loss: 387.9084 - val_loss: 855.9088\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 259.67462\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 378.6823 - val_loss: 1149.3278\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 259.67462\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 366.7093 - val_loss: 257.8320\n",
      "\n",
      "Epoch 00025: val_loss improved from 259.67462 to 257.83200, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 370.8132 - val_loss: 1304.3026\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 257.83200\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 909us/step - loss: 366.7711 - val_loss: 451.4448\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 257.83200\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 945us/step - loss: 358.4041 - val_loss: 478.5144\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 257.83200\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 915us/step - loss: 343.8059 - val_loss: 975.7275\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 257.83200\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 359.6195 - val_loss: 547.7723\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 257.83200\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 351.2210 - val_loss: 1159.3313\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 257.83200\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 327.8213 - val_loss: 263.4611\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 257.83200\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 359.0940 - val_loss: 736.0259\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 257.83200\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 961us/step - loss: 323.9017 - val_loss: 323.7345\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 257.83200\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 330.0012 - val_loss: 577.7200\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 257.83200\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 327.4521 - val_loss: 1203.4000\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 257.83200\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 319.9762 - val_loss: 884.9907\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 257.83200\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 338.2221 - val_loss: 1401.6466\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 257.83200\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 937us/step - loss: 337.3248 - val_loss: 708.5344\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 257.83200\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 309.7484 - val_loss: 237.4814\n",
      "\n",
      "Epoch 00040: val_loss improved from 257.83200 to 237.48137, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 347.8576 - val_loss: 529.1354\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 237.48137\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 303.0655 - val_loss: 1465.1735\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 237.48137\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 968us/step - loss: 339.8094 - val_loss: 324.2235\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 237.48137\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 301.1468 - val_loss: 470.9453\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 237.48137\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 314.7095 - val_loss: 1054.5422\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 237.48137\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 304.9278 - val_loss: 617.9284\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 237.48137\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 295.2671 - val_loss: 722.7639\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 237.48137\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 949us/step - loss: 298.2552 - val_loss: 279.9372\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 237.48137\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 272.0724 - val_loss: 1257.0692\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 237.48137\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 938us/step - loss: 289.8834 - val_loss: 1029.5709\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 237.48137\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 288.6474 - val_loss: 742.1855\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 237.48137\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 281.6841 - val_loss: 307.3686\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 237.48137\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 269.4076 - val_loss: 1157.3284\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 237.48137\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 275.5671 - val_loss: 628.4281\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 237.48137\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 957us/step - loss: 295.5837 - val_loss: 443.2774\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 237.48137\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 985us/step - loss: 280.4940 - val_loss: 1089.9933\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 237.48137\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 284.4278 - val_loss: 1185.9801\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 237.48137\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 273.2993 - val_loss: 503.0518\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 237.48137\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 284.2507 - val_loss: 455.3792\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 237.48137\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 914us/step - loss: 287.1086 - val_loss: 1127.9915\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 237.48137\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 261.7383 - val_loss: 728.7028\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 237.48137\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 927us/step - loss: 263.2663 - val_loss: 599.9324\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 237.48137\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 281.4045 - val_loss: 1083.3533\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 237.48137\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 275.4195 - val_loss: 1209.4248\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 237.48137\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 283.3456 - val_loss: 1440.9652\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 237.48137\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 275.3216 - val_loss: 1212.0312\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 237.48137\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 260.4859 - val_loss: 1155.9994\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 237.48137\n",
      "Epoch 68/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 923us/step - loss: 284.3829 - val_loss: 751.5306\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 237.48137\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 269.3861 - val_loss: 664.1500\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 237.48137\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 261.5501 - val_loss: 771.0945\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 237.48137\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.4834 - val_loss: 883.3918\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 237.48137\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 933us/step - loss: 255.4511 - val_loss: 754.4424\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 237.48137\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 264.4381 - val_loss: 1052.2928\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 237.48137\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 951us/step - loss: 255.5330 - val_loss: 1403.7993\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 237.48137\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.3842 - val_loss: 1327.1853\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 237.48137\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.8529 - val_loss: 1097.9048\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 237.48137\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 245.3550 - val_loss: 565.5413\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 237.48137\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.9910 - val_loss: 249.9751\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 237.48137\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 242.6399 - val_loss: 403.4696\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 237.48137\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 928us/step - loss: 259.0053 - val_loss: 1089.8149\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 237.48137\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 235.2411 - val_loss: 718.3348\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 237.48137\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 946us/step - loss: 248.7825 - val_loss: 852.3652\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 237.48137\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 248.7950 - val_loss: 772.6633\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 237.48137\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 938us/step - loss: 249.6137 - val_loss: 693.2752\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 237.48137\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 246.9308 - val_loss: 1180.5977\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 237.48137\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 242.4924 - val_loss: 248.8389\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 237.48137\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 240.8560 - val_loss: 1067.1821\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 237.48137\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 233.3528 - val_loss: 793.9641\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 237.48137\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 246.9881 - val_loss: 457.4141\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 237.48137\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 233.0556 - val_loss: 1301.0051\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 237.48137\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 239.4317 - val_loss: 729.9274\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 237.48137\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 233.8543 - val_loss: 249.7895\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 237.48137\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 233.2396 - val_loss: 1041.5048\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 237.48137\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 219.1366 - val_loss: 808.5787\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 237.48137\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 218.4020 - val_loss: 810.4533\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 237.48137\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 220.0844 - val_loss: 1178.9116\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 237.48137\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 211.9797 - val_loss: 960.7014\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 237.48137\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 218.2974 - val_loss: 773.9423\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 237.48137\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 212.8379 - val_loss: 878.2340\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 237.48137\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 212.7985 - val_loss: 346.4913\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 237.48137\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 215.5734 - val_loss: 1082.1414\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 237.48137\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 208.0344 - val_loss: 1031.2274\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 237.48137\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 210.5633 - val_loss: 1108.4932\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 237.48137\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 215.8860 - val_loss: 964.7946\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 237.48137\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 209.3539 - val_loss: 836.9645\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 237.48137\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 212.2104 - val_loss: 795.5552\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 237.48137\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 207.3154 - val_loss: 245.4073\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 237.48137\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 207.8374 - val_loss: 1001.3425\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 237.48137\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 202.8828 - val_loss: 1002.8829\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 237.48137\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 207.5237 - val_loss: 922.0170\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 237.48137\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 211.1945 - val_loss: 921.2780\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 237.48137\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 200.1694 - val_loss: 483.8872\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 237.48137\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 214.3258 - val_loss: 626.9116\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 237.48137\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 200.5244 - val_loss: 944.7092\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 237.48137\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 199.3017 - val_loss: 1206.8627\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 237.48137\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 203.0448 - val_loss: 1126.6837\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 237.48137\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 201.6391 - val_loss: 1089.9895\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 237.48137\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 195.5329 - val_loss: 1214.9578\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 237.48137\n",
      "Epoch 119/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 200.7941 - val_loss: 321.0686\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 237.48137\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 204.1645 - val_loss: 433.4868\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 237.48137\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 193.2750 - val_loss: 732.7128\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 237.48137\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 198.2705 - val_loss: 504.0785\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 237.48137\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 198.3174 - val_loss: 311.3282\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 237.48137\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 201.6546 - val_loss: 477.8500\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 237.48137\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 198.2212 - val_loss: 353.9749\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 237.48137\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 201.6207 - val_loss: 283.4788\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 237.48137\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 200.8478 - val_loss: 905.0167\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 237.48137\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 198.3530 - val_loss: 596.5922\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 237.48137\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 192.7384 - val_loss: 330.3843\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 237.48137\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 200.1862 - val_loss: 1036.8767\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 237.48137\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 193.8318 - val_loss: 303.2235\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 237.48137\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 188.8498 - val_loss: 993.6536\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 237.48137\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 193.3382 - val_loss: 304.0790\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 237.48137\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 192.5683 - val_loss: 895.2607\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 237.48137\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 192.9022 - val_loss: 260.7869\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 237.48137\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 192.7150 - val_loss: 763.3613\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 237.48137\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 193.1509 - val_loss: 1070.5764\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 237.48137\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 195.8359 - val_loss: 993.7164\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 237.48137\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 195.0364 - val_loss: 358.0959\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 237.48137\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 191.6791 - val_loss: 283.4112\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 237.48137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████▎                                                      | 7/21 [14:05<29:36, 126.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 412.5173 - val_loss: 365.9610\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 365.96103, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 943us/step - loss: 213.9445 - val_loss: 679.0944\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 365.96103\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 217.4378 - val_loss: 276.9287\n",
      "\n",
      "Epoch 00003: val_loss improved from 365.96103 to 276.92874, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 217.0443 - val_loss: 423.1886\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 276.92874\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 211.4178 - val_loss: 410.1552\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 276.92874\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 203.1667 - val_loss: 649.2731\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 276.92874\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 211.2849 - val_loss: 285.3492\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 276.92874\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.5669 - val_loss: 151.6636\n",
      "\n",
      "Epoch 00008: val_loss improved from 276.92874 to 151.66360, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 215.4405 - val_loss: 125.8925\n",
      "\n",
      "Epoch 00009: val_loss improved from 151.66360 to 125.89251, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 184.4248 - val_loss: 218.8241\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 125.89251\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 199.2513 - val_loss: 454.6448\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 125.89251\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 202.3715 - val_loss: 371.7323\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 125.89251\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 206.4509 - val_loss: 439.8419\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 125.89251\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 201.6297 - val_loss: 622.2111\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 125.89251\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 193.9845 - val_loss: 136.1159\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 125.89251\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 193.0494 - val_loss: 425.0366\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 125.89251\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 202.0454 - val_loss: 639.6779\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 125.89251\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 205.1090 - val_loss: 457.1010\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 125.89251\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 202.7930 - val_loss: 440.1175\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 125.89251\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 192.4747 - val_loss: 107.9495\n",
      "\n",
      "Epoch 00020: val_loss improved from 125.89251 to 107.94953, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 186.5555 - val_loss: 218.3437\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 107.94953\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 182.6231 - val_loss: 634.1729\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 107.94953\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 192.0139 - val_loss: 342.4647\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 107.94953\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 179.3580 - val_loss: 594.7972\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 107.94953\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 188.9064 - val_loss: 116.9673\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 107.94953\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 172.4198 - val_loss: 372.4525\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 107.94953\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 195.5151 - val_loss: 315.7914\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 107.94953\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 178.1442 - val_loss: 133.2241\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 107.94953\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 181.3769 - val_loss: 622.9677\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 107.94953\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 179.7564 - val_loss: 223.6917\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 107.94953\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 180.1879 - val_loss: 112.4887\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 107.94953\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 191.8318 - val_loss: 154.0052\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 107.94953\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 165.2751 - val_loss: 139.8500\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 107.94953\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 168.6922 - val_loss: 151.4889\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 107.94953\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 176.5187 - val_loss: 281.7038\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 107.94953\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.9965 - val_loss: 182.8025\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 107.94953\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 173.4383 - val_loss: 355.1581\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 107.94953\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.3971 - val_loss: 367.8243\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 107.94953\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 164.5675 - val_loss: 295.8947\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 107.94953\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 174.7334 - val_loss: 473.6800\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 107.94953\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.9484 - val_loss: 106.8946\n",
      "\n",
      "Epoch 00041: val_loss improved from 107.94953 to 106.89465, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.3252 - val_loss: 153.3275\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 106.89465\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.3961 - val_loss: 289.4463\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 106.89465\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.0825 - val_loss: 349.2302\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 106.89465\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.4901 - val_loss: 150.2163\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 106.89465\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 155.3668 - val_loss: 250.7221\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 106.89465\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.9655 - val_loss: 242.9994\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 106.89465\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.4718 - val_loss: 213.1124\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 106.89465\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.4978 - val_loss: 107.8919\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 106.89465\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 157.4219 - val_loss: 443.9239\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 106.89465\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.0254 - val_loss: 183.5512\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 106.89465\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.6184 - val_loss: 304.0229\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 106.89465\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.6218 - val_loss: 276.5150\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 106.89465\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.6781 - val_loss: 387.5138\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 106.89465\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.1518 - val_loss: 227.9996\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 106.89465\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.2979 - val_loss: 154.4894\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 106.89465\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.7069 - val_loss: 120.1985\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 106.89465\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.1697 - val_loss: 186.4201\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 106.89465\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.1702 - val_loss: 171.3882\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 106.89465\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.9542 - val_loss: 138.1667\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 106.89465\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 142.1494 - val_loss: 112.5993\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 106.89465\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.0134 - val_loss: 570.0076\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 106.89465\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.8502 - val_loss: 215.2601\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 106.89465\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.6946 - val_loss: 439.1178\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 106.89465\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.6048 - val_loss: 118.1588\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 106.89465\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 127.2138 - val_loss: 444.9641\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 106.89465\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.8694 - val_loss: 126.6201\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 106.89465\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 125.9471 - val_loss: 152.8414\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 106.89465\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 131.8512 - val_loss: 199.4631\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 106.89465\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.4117 - val_loss: 125.6018\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 106.89465\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 127.7279 - val_loss: 117.4025\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 106.89465\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 130.5436 - val_loss: 248.4455\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 106.89465\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 127.1773 - val_loss: 202.5526\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 106.89465\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 126.0867 - val_loss: 388.0335\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 106.89465\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.3574 - val_loss: 400.1476\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 106.89465\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.8179 - val_loss: 335.4466\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 106.89465\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.3197 - val_loss: 179.3453\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 106.89465\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.8823 - val_loss: 359.2894\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 106.89465\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 121.8282 - val_loss: 209.8977\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 106.89465\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.6889 - val_loss: 160.9326\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 106.89465\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.5088 - val_loss: 405.2742\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 106.89465\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 125.8501 - val_loss: 184.8034\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 106.89465\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.3030 - val_loss: 150.5091\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 106.89465\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.1928 - val_loss: 142.3971\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 106.89465\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.1185 - val_loss: 343.7769\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 106.89465\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.0929 - val_loss: 252.8415\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 106.89465\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.6425 - val_loss: 316.0367\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 106.89465\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.6442 - val_loss: 131.4452\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 106.89465\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.4021 - val_loss: 322.6345\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 106.89465\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.7677 - val_loss: 147.4104\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 106.89465\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.6649 - val_loss: 214.4023\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 106.89465\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.8158 - val_loss: 330.4438\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 106.89465\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 112.6071 - val_loss: 241.2977\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 106.89465\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.6385 - val_loss: 297.8503\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 106.89465\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.9836 - val_loss: 272.3207\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 106.89465\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.0616 - val_loss: 129.0726\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 106.89465\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.7064 - val_loss: 171.8600\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 106.89465\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.7465 - val_loss: 429.3353\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 106.89465\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.4033 - val_loss: 273.6515\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 106.89465\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.6043 - val_loss: 337.0465\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 106.89465\n",
      "Epoch 101/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 110.2175 - val_loss: 235.7606\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 106.89465\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.8947 - val_loss: 147.2595\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 106.89465\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.9813 - val_loss: 235.6741\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 106.89465\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.6340 - val_loss: 228.4615\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 106.89465\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.4029 - val_loss: 152.7993\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 106.89465\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.7573 - val_loss: 132.0043\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 106.89465\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.4291 - val_loss: 142.4537\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 106.89465\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.9413 - val_loss: 125.8022\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 106.89465\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.6127 - val_loss: 124.6091\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 106.89465\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.5590 - val_loss: 241.1698\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 106.89465\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.0413 - val_loss: 258.0582\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 106.89465\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 112.3391 - val_loss: 195.1023\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 106.89465\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.4320 - val_loss: 263.4378\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 106.89465\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.8964 - val_loss: 167.8694\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 106.89465\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.9922 - val_loss: 145.1952\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 106.89465\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.2078 - val_loss: 157.1012\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 106.89465\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.7680 - val_loss: 293.1627\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 106.89465\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.7453 - val_loss: 133.5829\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 106.89465\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.9988 - val_loss: 222.4336\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 106.89465\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.6344 - val_loss: 272.8254\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 106.89465\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.7213 - val_loss: 324.1012\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 106.89465\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.4010 - val_loss: 210.5487\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 106.89465\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.5074 - val_loss: 119.6474\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 106.89465\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.3291 - val_loss: 218.9122\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 106.89465\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.9199 - val_loss: 168.0912\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 106.89465\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.7263 - val_loss: 165.9062\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 106.89465\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.1910 - val_loss: 235.0210\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 106.89465\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.2284 - val_loss: 130.9155\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 106.89465\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.3186 - val_loss: 208.8970\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 106.89465\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.7447 - val_loss: 149.8693\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 106.89465\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.4489 - val_loss: 189.1732\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 106.89465\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.4702 - val_loss: 265.0743\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 106.89465\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.0573 - val_loss: 134.3212\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 106.89465\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 102.7462 - val_loss: 168.8232\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 106.89465\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.1003 - val_loss: 176.5216\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 106.89465\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.5974 - val_loss: 184.5427\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 106.89465\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.4042 - val_loss: 270.6769\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 106.89465\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 96.6680 - val_loss: 367.0435\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 106.89465\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 101.9189 - val_loss: 213.6875\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 106.89465\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 101.9790 - val_loss: 195.6303\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 106.89465\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.3044 - val_loss: 210.7416\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 106.89465\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 382.0504 - val_loss: 236.3892\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 236.38918, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 215.6240 - val_loss: 577.0251\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 236.38918\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 208.5928 - val_loss: 548.4831\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 236.38918\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 206.9175 - val_loss: 201.7074\n",
      "\n",
      "Epoch 00004: val_loss improved from 236.38918 to 201.70744, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 213.8301 - val_loss: 254.0342\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 201.70744\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 202.3677 - val_loss: 465.6726\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 201.70744\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 194.3036 - val_loss: 432.6593\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 201.70744\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 211.3776 - val_loss: 493.3411\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 201.70744\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 206.9536 - val_loss: 174.4952\n",
      "\n",
      "Epoch 00009: val_loss improved from 201.70744 to 174.49524, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 219.3861 - val_loss: 122.8422\n",
      "\n",
      "Epoch 00010: val_loss improved from 174.49524 to 122.84221, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 213.9844 - val_loss: 674.2851\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 122.84221\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 209.0658 - val_loss: 363.7567\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 122.84221\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 205.3535 - val_loss: 251.6865\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 122.84221\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 192.4192 - val_loss: 748.5531\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 122.84221\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 193.4987 - val_loss: 367.2914\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 122.84221\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 203.4432 - val_loss: 627.8059\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 122.84221\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 193.3975 - val_loss: 658.5107\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 122.84221\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 195.3290 - val_loss: 712.0538\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 122.84221\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 198.1912 - val_loss: 508.1636\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 122.84221\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 209.8472 - val_loss: 446.0520\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 122.84221\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 200.4502 - val_loss: 274.4210\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 122.84221\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 198.3558 - val_loss: 326.6183\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 122.84221\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 199.8690 - val_loss: 147.3261\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 122.84221\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 198.3449 - val_loss: 206.3034\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 122.84221\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 189.7015 - val_loss: 455.4004\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 122.84221\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 188.7313 - val_loss: 478.0467\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 122.84221\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 194.1597 - val_loss: 273.0942\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 122.84221\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 187.1575 - val_loss: 116.7982\n",
      "\n",
      "Epoch 00028: val_loss improved from 122.84221 to 116.79816, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 190.7443 - val_loss: 161.7197\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 116.79816\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 185.3476 - val_loss: 378.3949\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 116.79816\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 189.3196 - val_loss: 259.9478\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 116.79816\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 188.1138 - val_loss: 271.2999\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 116.79816\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 180.5376 - val_loss: 291.2580\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 116.79816\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 191.6794 - val_loss: 257.1522\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 116.79816\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 187.7651 - val_loss: 127.1227\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 116.79816\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 187.6361 - val_loss: 685.7277\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 116.79816\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 185.7227 - val_loss: 554.3230\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 116.79816\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 183.6477 - val_loss: 237.3294\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 116.79816\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 179.8104 - val_loss: 662.7535\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 116.79816\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 174.9747 - val_loss: 666.8159\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 116.79816\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 166.8188 - val_loss: 435.1319\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 116.79816\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 177.0256 - val_loss: 141.5104\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 116.79816\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 162.7196 - val_loss: 337.3914\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 116.79816\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 171.2349 - val_loss: 122.4010\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 116.79816\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 175.2510 - val_loss: 202.5997\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 116.79816\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 173.7327 - val_loss: 623.6894\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 116.79816\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.4885 - val_loss: 510.4485\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 116.79816\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 165.6230 - val_loss: 133.1669\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 116.79816\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 169.1007 - val_loss: 468.4477\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 116.79816\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 168.5769 - val_loss: 161.4565\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 116.79816\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.0791 - val_loss: 287.9589\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 116.79816\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.3086 - val_loss: 330.1725\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 116.79816\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 170.5602 - val_loss: 167.5054\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 116.79816\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.1720 - val_loss: 442.9037\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 116.79816\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 159.9800 - val_loss: 150.5095\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 116.79816\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 155.0140 - val_loss: 177.4122\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 116.79816\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.1347 - val_loss: 684.9235\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 116.79816\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 163.8856 - val_loss: 442.1480\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 116.79816\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 158.0662 - val_loss: 199.6234\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 116.79816\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.3186 - val_loss: 131.8800\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 116.79816\n",
      "Epoch 61/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 149.4877 - val_loss: 377.4832\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 116.79816\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 153.6052 - val_loss: 529.4799\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 116.79816\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.9043 - val_loss: 117.5871\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 116.79816\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 152.9684 - val_loss: 353.5085\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 116.79816\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 147.1701 - val_loss: 276.0685\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 116.79816\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 156.8000 - val_loss: 399.4334\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 116.79816\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 143.4643 - val_loss: 215.5103\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 116.79816\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 155.1127 - val_loss: 237.3461\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 116.79816\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.4125 - val_loss: 151.7422\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 116.79816\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.1431 - val_loss: 478.6326\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 116.79816\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 144.5088 - val_loss: 399.1832\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 116.79816\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.4351 - val_loss: 461.7469\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 116.79816\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.0414 - val_loss: 376.5986\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 116.79816\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.7626 - val_loss: 435.8267\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 116.79816\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.6043 - val_loss: 117.2843\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 116.79816\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 148.2810 - val_loss: 497.5288\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 116.79816\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 155.6730 - val_loss: 440.3494\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 116.79816\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.7961 - val_loss: 537.4494\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 116.79816\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.3890 - val_loss: 240.6257\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 116.79816\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.6990 - val_loss: 122.2377\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 116.79816\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 146.5003 - val_loss: 331.3005\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 116.79816\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 149.3335 - val_loss: 113.7267\n",
      "\n",
      "Epoch 00082: val_loss improved from 116.79816 to 113.72670, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.0222 - val_loss: 204.4418\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 113.72670\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.2247 - val_loss: 130.4907\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 113.72670\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 140.6124 - val_loss: 174.4709\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 113.72670\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 135.4532 - val_loss: 393.5882\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 113.72670\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.2266 - val_loss: 191.6923\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 113.72670\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.3955 - val_loss: 156.0904\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 113.72670\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 136.4368 - val_loss: 210.9469\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 113.72670\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.6660 - val_loss: 251.4662\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 113.72670\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 137.1106 - val_loss: 128.6246\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 113.72670\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.1544 - val_loss: 157.4030\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 113.72670\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 141.9621 - val_loss: 301.9043\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 113.72670\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 138.5912 - val_loss: 367.4570\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 113.72670\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 134.9985 - val_loss: 215.1519\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 113.72670\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.5113 - val_loss: 484.7500\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 113.72670\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 132.5452 - val_loss: 335.6661\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 113.72670\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 126.7794 - val_loss: 334.5818\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 113.72670\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 139.7279 - val_loss: 116.3387\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 113.72670\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 131.2638 - val_loss: 184.9044\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 113.72670\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 131.8471 - val_loss: 242.4695\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 113.72670\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 131.2204 - val_loss: 263.8743\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 113.72670\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 128.1363 - val_loss: 201.8421\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 113.72670\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 133.0908 - val_loss: 183.0809\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 113.72670\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 125.2089 - val_loss: 119.0981\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 113.72670\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 128.1450 - val_loss: 429.2987\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 113.72670\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.1054 - val_loss: 163.8568\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 113.72670\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.9741 - val_loss: 213.7151\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 113.72670\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 125.2246 - val_loss: 145.8682\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 113.72670\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.9843 - val_loss: 539.4553\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 113.72670\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.3306 - val_loss: 466.4087\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 113.72670\n",
      "Epoch 112/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 125.3846 - val_loss: 217.6671\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 113.72670\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.4865 - val_loss: 129.8764\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 113.72670\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 126.5365 - val_loss: 114.4246\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 113.72670\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.8837 - val_loss: 246.8205\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 113.72670\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.6215 - val_loss: 239.6618\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 113.72670\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.2273 - val_loss: 358.3480\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 113.72670\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.3711 - val_loss: 210.9814\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 113.72670\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 125.7273 - val_loss: 292.4247\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 113.72670\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.1511 - val_loss: 288.8800\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 113.72670\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.4963 - val_loss: 185.3040\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 113.72670\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.6785 - val_loss: 377.8861\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 113.72670\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.6566 - val_loss: 314.3477\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 113.72670\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.4229 - val_loss: 413.8047\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 113.72670\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.5809 - val_loss: 302.2166\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 113.72670\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.3085 - val_loss: 195.6913\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 113.72670\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.6449 - val_loss: 132.3046\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 113.72670\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.3758 - val_loss: 183.3139\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 113.72670\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.1320 - val_loss: 142.9574\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 113.72670\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.8217 - val_loss: 448.6797\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 113.72670\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 112.6535 - val_loss: 229.6172\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 113.72670\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.0323 - val_loss: 286.5938\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 113.72670\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.1461 - val_loss: 153.7994\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 113.72670\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.0550 - val_loss: 159.3031\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 113.72670\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.6190 - val_loss: 393.0307\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 113.72670\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.8532 - val_loss: 336.6414\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 113.72670\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.5818 - val_loss: 493.3427\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 113.72670\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.8139 - val_loss: 375.1774\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 113.72670\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.3648 - val_loss: 153.5467\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 113.72670\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.7104 - val_loss: 162.4366\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 113.72670\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.2783 - val_loss: 242.0726\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 113.72670\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.3918 - val_loss: 140.0578\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 113.72670\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.0195 - val_loss: 396.5076\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 113.72670\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.2437 - val_loss: 171.4948\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 113.72670\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.3123 - val_loss: 571.4464\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 113.72670\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.4493 - val_loss: 365.6298\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 113.72670\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.1767 - val_loss: 312.2056\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 113.72670\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.2233 - val_loss: 342.1983\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 113.72670\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.5954 - val_loss: 261.6003\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 113.72670\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.6859 - val_loss: 287.8121\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 113.72670\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.6213 - val_loss: 190.5177\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 113.72670\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.3599 - val_loss: 137.2268\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 113.72670\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.8536 - val_loss: 265.6601\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 113.72670\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.8433 - val_loss: 168.7567\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 113.72670\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.8863 - val_loss: 130.7293\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 113.72670\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.4499 - val_loss: 335.1049\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 113.72670\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.8715 - val_loss: 271.2393\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 113.72670\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.1254 - val_loss: 224.8763\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 113.72670\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.8072 - val_loss: 119.8251\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 113.72670\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 104.3437 - val_loss: 267.2806\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 113.72670\n",
      "Epoch 161/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 112.4628 - val_loss: 347.4117\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 113.72670\n",
      "Epoch 162/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.6268 - val_loss: 171.5874\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 113.72670\n",
      "Epoch 163/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 110.2913 - val_loss: 118.9428\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 113.72670\n",
      "Epoch 164/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.5555 - val_loss: 462.4216\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 113.72670\n",
      "Epoch 165/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.0238 - val_loss: 363.8395\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 113.72670\n",
      "Epoch 166/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.7745 - val_loss: 225.8821\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 113.72670\n",
      "Epoch 167/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.9539 - val_loss: 330.2083\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 113.72670\n",
      "Epoch 168/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.4075 - val_loss: 236.4747\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 113.72670\n",
      "Epoch 169/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.2062 - val_loss: 280.3394\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 113.72670\n",
      "Epoch 170/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.0536 - val_loss: 222.3478\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 113.72670\n",
      "Epoch 171/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.8149 - val_loss: 138.1095\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 113.72670\n",
      "Epoch 172/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.8578 - val_loss: 459.6350\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 113.72670\n",
      "Epoch 173/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.0870 - val_loss: 243.9745\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 113.72670\n",
      "Epoch 174/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.3074 - val_loss: 199.8044\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 113.72670\n",
      "Epoch 175/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 103.9272 - val_loss: 285.6112\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 113.72670\n",
      "Epoch 176/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.3246 - val_loss: 227.0698\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 113.72670\n",
      "Epoch 177/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.0363 - val_loss: 151.5749\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 113.72670\n",
      "Epoch 178/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.8979 - val_loss: 125.5296\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 113.72670\n",
      "Epoch 179/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.0396 - val_loss: 160.5283\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 113.72670\n",
      "Epoch 180/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.5542 - val_loss: 249.8630\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 113.72670\n",
      "Epoch 181/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.3525 - val_loss: 146.9706\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 113.72670\n",
      "Epoch 182/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.0849 - val_loss: 443.2154\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 113.72670\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 342.9689 - val_loss: 409.8802\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 409.88025, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 236.0936 - val_loss: 536.2562\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 409.88025\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 231.6312 - val_loss: 245.6423\n",
      "\n",
      "Epoch 00003: val_loss improved from 409.88025 to 245.64227, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 229.1541 - val_loss: 275.6612\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 245.64227\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 227.2258 - val_loss: 432.2987\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 245.64227\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 224.3293 - val_loss: 263.5781\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 245.64227\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 225.8967 - val_loss: 663.3497\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 245.64227\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 208.5716 - val_loss: 472.5073\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 245.64227\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 224.6728 - val_loss: 255.4294\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 245.64227\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 213.0744 - val_loss: 249.9598\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 245.64227\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 215.3489 - val_loss: 340.4066\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 245.64227\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 207.4254 - val_loss: 609.5991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 245.64227\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 223.9630 - val_loss: 613.0468\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 245.64227\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 212.5899 - val_loss: 257.0668\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 245.64227\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 216.5003 - val_loss: 313.4009\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 245.64227\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 209.2145 - val_loss: 583.8072\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 245.64227\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 210.8191 - val_loss: 485.4855\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 245.64227\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 197.1696 - val_loss: 357.8576\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 245.64227\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 212.5779 - val_loss: 246.0071\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 245.64227\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 205.5887 - val_loss: 257.8265\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 245.64227\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 203.2161 - val_loss: 318.9576\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 245.64227\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 212.0954 - val_loss: 393.1788\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 245.64227\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 220.3985 - val_loss: 405.1280\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 245.64227\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 190.4652 - val_loss: 293.8993\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 245.64227\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 203.8673 - val_loss: 456.8253\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 245.64227\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 220.2203 - val_loss: 380.8667\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 245.64227\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 197.4492 - val_loss: 297.5856\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 245.64227\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 186.7637 - val_loss: 190.4989\n",
      "\n",
      "Epoch 00028: val_loss improved from 245.64227 to 190.49893, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 196.0264 - val_loss: 397.4476\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 190.49893\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 193.9052 - val_loss: 269.0081\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 190.49893\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 198.4398 - val_loss: 605.6784\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 190.49893\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 205.1842 - val_loss: 373.3931\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 190.49893\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 192.8434 - val_loss: 310.7896\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 190.49893\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 195.5229 - val_loss: 217.1704\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 190.49893\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 194.8192 - val_loss: 423.5503\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 190.49893\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 183.1069 - val_loss: 507.0278\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 190.49893\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 193.2463 - val_loss: 289.5296\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 190.49893\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 187.6635 - val_loss: 227.8079\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 190.49893\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 188.4306 - val_loss: 213.2032\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 190.49893\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 186.6323 - val_loss: 176.1911\n",
      "\n",
      "Epoch 00040: val_loss improved from 190.49893 to 176.19110, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 184.2409 - val_loss: 178.2259\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 176.19110\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 179.5678 - val_loss: 220.2169\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 176.19110\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 193.7433 - val_loss: 622.8987\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 176.19110\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 182.2372 - val_loss: 197.7211\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 176.19110\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 184.3190 - val_loss: 269.5450\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 176.19110\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 187.1178 - val_loss: 641.0516\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 176.19110\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 178.3413 - val_loss: 186.3748\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 176.19110\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 179.2109 - val_loss: 212.1546\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 176.19110\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 179.0034 - val_loss: 316.9269\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 176.19110\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 175.9261 - val_loss: 199.9344\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 176.19110\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 173.6916 - val_loss: 551.5713\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 176.19110\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 168.5613 - val_loss: 530.3331\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 176.19110\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 172.5864 - val_loss: 462.1501\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 176.19110\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 179.3390 - val_loss: 293.8746\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 176.19110\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 177.1179 - val_loss: 263.9347\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 176.19110\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 174.0326 - val_loss: 343.4665\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 176.19110\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 170.0177 - val_loss: 580.7696\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 176.19110\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 178.7523 - val_loss: 430.1728\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 176.19110\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 184.2451 - val_loss: 223.3582\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 176.19110\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 172.6638 - val_loss: 654.1223\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 176.19110\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 175.3888 - val_loss: 196.2353\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 176.19110\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 177.3178 - val_loss: 694.3406\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 176.19110\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 167.7675 - val_loss: 377.7775\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 176.19110\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 170.7125 - val_loss: 197.5273\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 176.19110\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 166.0524 - val_loss: 607.7708\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 176.19110\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 174.9312 - val_loss: 272.3351\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 176.19110\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 163.3490 - val_loss: 273.0892\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 176.19110\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 168.4279 - val_loss: 520.2976\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 176.19110\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 167.5231 - val_loss: 558.6044\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 176.19110\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 164.2718 - val_loss: 165.5722\n",
      "\n",
      "Epoch 00070: val_loss improved from 176.19110 to 165.57219, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 171.7599 - val_loss: 399.4700\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 165.57219\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 164.9743 - val_loss: 365.8941\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 165.57219\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 161.0689 - val_loss: 413.0620\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 165.57219\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 167.1882 - val_loss: 239.0216\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 165.57219\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 167.4211 - val_loss: 280.2712\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 165.57219\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 159.6681 - val_loss: 196.3200\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 165.57219\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.0345 - val_loss: 464.9571\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 165.57219\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 161.1929 - val_loss: 162.1519\n",
      "\n",
      "Epoch 00078: val_loss improved from 165.57219 to 162.15190, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 162.7296 - val_loss: 260.3980\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 162.15190\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 160.0090 - val_loss: 182.6296\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 162.15190\n",
      "Epoch 81/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 156.3425 - val_loss: 637.1592\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 162.15190\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 162.8907 - val_loss: 382.6299\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 162.15190\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.7424 - val_loss: 378.7292\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 162.15190\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 160.5598 - val_loss: 359.9194\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 162.15190\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 165.0182 - val_loss: 569.4964\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 162.15190\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 160.3785 - val_loss: 378.8959\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 162.15190\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 153.7713 - val_loss: 181.3084\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 162.15190\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 164.5957 - val_loss: 235.5871\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 162.15190\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 155.7815 - val_loss: 417.0312\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 162.15190\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 152.3960 - val_loss: 170.8134\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 162.15190\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 150.7729 - val_loss: 337.1586\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 162.15190\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 154.3471 - val_loss: 204.8635\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 162.15190\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 156.6302 - val_loss: 167.7977\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 162.15190\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 151.3986 - val_loss: 529.1818\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 162.15190\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.3050 - val_loss: 276.8195\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 162.15190\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.3116 - val_loss: 244.5089\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 162.15190\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 149.1222 - val_loss: 176.4986\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 162.15190\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.8068 - val_loss: 178.6476\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 162.15190\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.5549 - val_loss: 279.3437\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 162.15190\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 153.3784 - val_loss: 617.3473\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 162.15190\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.9280 - val_loss: 345.9384\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 162.15190\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 155.1700 - val_loss: 159.3117\n",
      "\n",
      "Epoch 00102: val_loss improved from 162.15190 to 159.31172, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.2882 - val_loss: 613.9119\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 159.31172\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.4640 - val_loss: 366.8142\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 159.31172\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.8523 - val_loss: 399.5384\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 159.31172\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 141.7494 - val_loss: 473.8026\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 159.31172\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.7085 - val_loss: 293.5027\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 159.31172\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.3930 - val_loss: 190.9540\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 159.31172\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.9906 - val_loss: 358.2803\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 159.31172\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 141.5204 - val_loss: 283.2218\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 159.31172\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.3382 - val_loss: 425.8889\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 159.31172\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.1897 - val_loss: 248.3240\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 159.31172\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.8717 - val_loss: 401.5757\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 159.31172\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 141.2391 - val_loss: 293.4084\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 159.31172\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.1100 - val_loss: 279.1821\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 159.31172\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.7807 - val_loss: 496.4763\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 159.31172\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.3759 - val_loss: 406.9962\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 159.31172\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.6094 - val_loss: 551.8187\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 159.31172\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 150.9509 - val_loss: 416.5452\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 159.31172\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.7147 - val_loss: 478.2778\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 159.31172\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 141.9025 - val_loss: 221.1493\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 159.31172\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 153.3247 - val_loss: 231.9310\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 159.31172\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.8185 - val_loss: 203.2515\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 159.31172\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 147.4748 - val_loss: 226.0102\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 159.31172\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.3207 - val_loss: 386.5243\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 159.31172\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.9099 - val_loss: 165.7420\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 159.31172\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.2908 - val_loss: 377.6520\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 159.31172\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.0646 - val_loss: 342.5084\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 159.31172\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.6353 - val_loss: 402.1130\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 159.31172\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.4410 - val_loss: 382.2544\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 159.31172\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.9929 - val_loss: 487.0034\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 159.31172\n",
      "Epoch 132/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 136.5477 - val_loss: 529.4574\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 159.31172\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 134.0551 - val_loss: 455.4867\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 159.31172\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.0767 - val_loss: 368.4741\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 159.31172\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.4977 - val_loss: 339.1215\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 159.31172\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.8734 - val_loss: 191.1429\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 159.31172\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 134.5596 - val_loss: 434.5853\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 159.31172\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 137.4094 - val_loss: 330.4478\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 159.31172\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.4953 - val_loss: 358.7063\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 159.31172\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.3699 - val_loss: 435.4078\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 159.31172\n",
      "Epoch 141/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 134.9737 - val_loss: 349.9937\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 159.31172\n",
      "Epoch 142/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.5327 - val_loss: 376.2423\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 159.31172\n",
      "Epoch 143/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 132.9767 - val_loss: 300.2448\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 159.31172\n",
      "Epoch 144/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 131.4620 - val_loss: 447.2911\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 159.31172\n",
      "Epoch 145/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 129.8899 - val_loss: 343.8283\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 159.31172\n",
      "Epoch 146/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.1001 - val_loss: 345.5774\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 159.31172\n",
      "Epoch 147/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.8503 - val_loss: 355.7158\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 159.31172\n",
      "Epoch 148/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.0138 - val_loss: 471.2646\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 159.31172\n",
      "Epoch 149/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 125.7545 - val_loss: 542.5474\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 159.31172\n",
      "Epoch 150/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 125.5371 - val_loss: 343.2952\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 159.31172\n",
      "Epoch 151/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 130.0298 - val_loss: 464.7740\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 159.31172\n",
      "Epoch 152/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 132.1854 - val_loss: 387.2647\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 159.31172\n",
      "Epoch 153/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 123.3610 - val_loss: 200.7166\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 159.31172\n",
      "Epoch 154/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 121.7629 - val_loss: 400.3953\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 159.31172\n",
      "Epoch 155/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 125.0067 - val_loss: 302.0402\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 159.31172\n",
      "Epoch 156/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.5838 - val_loss: 216.1938\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 159.31172\n",
      "Epoch 157/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 125.3465 - val_loss: 371.9286\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 159.31172\n",
      "Epoch 158/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 125.0601 - val_loss: 303.9607\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 159.31172\n",
      "Epoch 159/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.2461 - val_loss: 296.4897\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 159.31172\n",
      "Epoch 160/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.1963 - val_loss: 434.8749\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 159.31172\n",
      "Epoch 161/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 121.5893 - val_loss: 304.0679\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 159.31172\n",
      "Epoch 162/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 126.1896 - val_loss: 302.2253\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 159.31172\n",
      "Epoch 163/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 125.3330 - val_loss: 217.6993\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 159.31172\n",
      "Epoch 164/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 124.6967 - val_loss: 390.3160\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 159.31172\n",
      "Epoch 165/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 121.8316 - val_loss: 330.6839\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 159.31172\n",
      "Epoch 166/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.6533 - val_loss: 282.4799\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 159.31172\n",
      "Epoch 167/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.5224 - val_loss: 290.6642\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 159.31172\n",
      "Epoch 168/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.4866 - val_loss: 328.9455\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 159.31172\n",
      "Epoch 169/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 126.5420 - val_loss: 293.2841\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 159.31172\n",
      "Epoch 170/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.1522 - val_loss: 352.9328\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 159.31172\n",
      "Epoch 171/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.3866 - val_loss: 387.7042\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 159.31172\n",
      "Epoch 172/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 126.3419 - val_loss: 170.2376\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 159.31172\n",
      "Epoch 173/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 121.7341 - val_loss: 270.9175\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 159.31172\n",
      "Epoch 174/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 124.1536 - val_loss: 143.6955\n",
      "\n",
      "Epoch 00174: val_loss improved from 159.31172 to 143.69547, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 175/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 122.5091 - val_loss: 406.8517\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 143.69547\n",
      "Epoch 176/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.3737 - val_loss: 415.0087\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 143.69547\n",
      "Epoch 177/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.5116 - val_loss: 321.4774\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 143.69547\n",
      "Epoch 178/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.6208 - val_loss: 327.7897\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 143.69547\n",
      "Epoch 179/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 124.4551 - val_loss: 295.3079\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 143.69547\n",
      "Epoch 180/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 123.2140 - val_loss: 434.6995\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 143.69547\n",
      "Epoch 181/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 120.9935 - val_loss: 174.7160\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 143.69547\n",
      "Epoch 182/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.4596 - val_loss: 231.1258\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 143.69547\n",
      "Epoch 183/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 115.3430 - val_loss: 380.4938\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 143.69547\n",
      "Epoch 184/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 116.1694 - val_loss: 389.2668\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 143.69547\n",
      "Epoch 185/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 121.6789 - val_loss: 360.7984\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 143.69547\n",
      "Epoch 186/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 117.7656 - val_loss: 215.3223\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 143.69547\n",
      "Epoch 187/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 129.4366 - val_loss: 195.9172\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 143.69547\n",
      "Epoch 188/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 118.7835 - val_loss: 325.5308\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 143.69547\n",
      "Epoch 189/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.6235 - val_loss: 292.1709\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 143.69547\n",
      "Epoch 190/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 119.1759 - val_loss: 261.4377\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 143.69547\n",
      "Epoch 191/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 116.7737 - val_loss: 170.2632\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 143.69547\n",
      "Epoch 192/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 117.6135 - val_loss: 199.8697\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 143.69547\n",
      "Epoch 193/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 112.3433 - val_loss: 449.5157\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 143.69547\n",
      "Epoch 194/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 113.1975 - val_loss: 300.7419\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 143.69547\n",
      "Epoch 195/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 111.7165 - val_loss: 532.8300\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 143.69547\n",
      "Epoch 196/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 115.8523 - val_loss: 360.6843\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 143.69547\n",
      "Epoch 197/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 117.4710 - val_loss: 422.5375\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 143.69547\n",
      "Epoch 198/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 115.4008 - val_loss: 359.7155\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 143.69547\n",
      "Epoch 199/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.9357 - val_loss: 335.6489\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 143.69547\n",
      "Epoch 200/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 114.7959 - val_loss: 342.5445\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 143.69547\n",
      "Epoch 201/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 116.9717 - val_loss: 372.8199\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 143.69547\n",
      "Epoch 202/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 114.9713 - val_loss: 352.4450\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 143.69547\n",
      "Epoch 203/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 116.2212 - val_loss: 387.5621\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 143.69547\n",
      "Epoch 204/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 113.4594 - val_loss: 268.9886\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 143.69547\n",
      "Epoch 205/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 116.8653 - val_loss: 337.9740\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 143.69547\n",
      "Epoch 206/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 115.0077 - val_loss: 320.4124\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 143.69547\n",
      "Epoch 207/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.9781 - val_loss: 286.7346\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 143.69547\n",
      "Epoch 208/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 112.5365 - val_loss: 293.6420\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 143.69547\n",
      "Epoch 209/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 122.3830 - val_loss: 394.1518\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 143.69547\n",
      "Epoch 210/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.3514 - val_loss: 281.1611\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 143.69547\n",
      "Epoch 211/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 114.5234 - val_loss: 427.1628\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 143.69547\n",
      "Epoch 212/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.2563 - val_loss: 362.5188\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 143.69547\n",
      "Epoch 213/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 114.7232 - val_loss: 218.2140\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 143.69547\n",
      "Epoch 214/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.7816 - val_loss: 414.3253\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 143.69547\n",
      "Epoch 215/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 112.4153 - val_loss: 285.5069\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 143.69547\n",
      "Epoch 216/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 111.1029 - val_loss: 256.2899\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 143.69547\n",
      "Epoch 217/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 112.0421 - val_loss: 225.5525\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 143.69547\n",
      "Epoch 218/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 108.9819 - val_loss: 358.1574\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 143.69547\n",
      "Epoch 219/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.1293 - val_loss: 279.6069\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 143.69547\n",
      "Epoch 220/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 111.6478 - val_loss: 188.5557\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 143.69547\n",
      "Epoch 221/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 114.3488 - val_loss: 183.4187\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 143.69547\n",
      "Epoch 222/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 115.3237 - val_loss: 203.5584\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 143.69547\n",
      "Epoch 223/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 108.7973 - val_loss: 435.9102\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 143.69547\n",
      "Epoch 224/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 116.3954 - val_loss: 313.8473\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 143.69547\n",
      "Epoch 225/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.2742 - val_loss: 366.0585\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 143.69547\n",
      "Epoch 226/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.5331 - val_loss: 257.7810\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 143.69547\n",
      "Epoch 227/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.2941 - val_loss: 375.2059\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 143.69547\n",
      "Epoch 228/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 108.5863 - val_loss: 308.9842\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 143.69547\n",
      "Epoch 229/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.6717 - val_loss: 397.2821\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 143.69547\n",
      "Epoch 230/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.5522 - val_loss: 414.9290\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 143.69547\n",
      "Epoch 231/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.4029 - val_loss: 225.4378\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 143.69547\n",
      "Epoch 232/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.6255 - val_loss: 347.6023\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 143.69547\n",
      "Epoch 233/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.5516 - val_loss: 294.7626\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 143.69547\n",
      "Epoch 234/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 110.1757 - val_loss: 381.5104\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 143.69547\n",
      "Epoch 235/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 105.2589 - val_loss: 325.8001\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 143.69547\n",
      "Epoch 236/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.4267 - val_loss: 214.1985\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 143.69547\n",
      "Epoch 237/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 108.1930 - val_loss: 346.0771\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 143.69547\n",
      "Epoch 238/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 106.6261 - val_loss: 242.9667\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 143.69547\n",
      "Epoch 239/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 104.9047 - val_loss: 255.5378\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 143.69547\n",
      "Epoch 240/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 113.0109 - val_loss: 298.3117\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 143.69547\n",
      "Epoch 241/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.2704 - val_loss: 216.3966\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 143.69547\n",
      "Epoch 242/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 105.2696 - val_loss: 408.8202\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 143.69547\n",
      "Epoch 243/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.4961 - val_loss: 324.7536\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 143.69547\n",
      "Epoch 244/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 108.3369 - val_loss: 340.3487\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 143.69547\n",
      "Epoch 245/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.8372 - val_loss: 496.2088\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 143.69547\n",
      "Epoch 246/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.6339 - val_loss: 342.7743\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 143.69547\n",
      "Epoch 247/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.9300 - val_loss: 405.3184\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 143.69547\n",
      "Epoch 248/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.7329 - val_loss: 310.3501\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 143.69547\n",
      "Epoch 249/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 108.5390 - val_loss: 508.2368\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 143.69547\n",
      "Epoch 250/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.8567 - val_loss: 248.9493\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 143.69547\n",
      "Epoch 251/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 109.0665 - val_loss: 435.3724\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 143.69547\n",
      "Epoch 252/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.3449 - val_loss: 189.5695\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 143.69547\n",
      "Epoch 253/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 102.7372 - val_loss: 255.3384\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 143.69547\n",
      "Epoch 254/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.1057 - val_loss: 277.1963\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 143.69547\n",
      "Epoch 255/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.2367 - val_loss: 315.3048\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 143.69547\n",
      "Epoch 256/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.9359 - val_loss: 417.8887\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 143.69547\n",
      "Epoch 257/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 102.1208 - val_loss: 248.8050\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 143.69547\n",
      "Epoch 258/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 105.7159 - val_loss: 320.8152\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 143.69547\n",
      "Epoch 259/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 106.2322 - val_loss: 452.2336\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 143.69547\n",
      "Epoch 260/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 103.9496 - val_loss: 300.4140\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 143.69547\n",
      "Epoch 261/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.5356 - val_loss: 391.2515\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 143.69547\n",
      "Epoch 262/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 107.0598 - val_loss: 297.1659\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 143.69547\n",
      "Epoch 263/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.0363 - val_loss: 441.2219\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 143.69547\n",
      "Epoch 264/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 110.0907 - val_loss: 406.6106\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 143.69547\n",
      "Epoch 265/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 103.4264 - val_loss: 272.8528\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 143.69547\n",
      "Epoch 266/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 103.2635 - val_loss: 415.1056\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 143.69547\n",
      "Epoch 267/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.6531 - val_loss: 180.1382\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 143.69547\n",
      "Epoch 268/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.9849 - val_loss: 456.1982\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 143.69547\n",
      "Epoch 269/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 105.4278 - val_loss: 348.1605\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 143.69547\n",
      "Epoch 270/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.3375 - val_loss: 253.1129\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 143.69547\n",
      "Epoch 271/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 103.8554 - val_loss: 330.9922\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 143.69547\n",
      "Epoch 272/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 102.8909 - val_loss: 371.5654\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 143.69547\n",
      "Epoch 273/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 104.8147 - val_loss: 254.3598\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 143.69547\n",
      "Epoch 274/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.7668 - val_loss: 374.6325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████▏                                                  | 8/21 [16:19<27:59, 129.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00274: val_loss did not improve from 143.69547\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 4330.6880 - val_loss: 2624.1382\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2624.13818, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3635.0168 - val_loss: 1994.4442\n",
      "\n",
      "Epoch 00002: val_loss improved from 2624.13818 to 1994.44421, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3726.0325 - val_loss: 2050.6667\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1994.44421\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3819.0310 - val_loss: 2204.0444\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1994.44421\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3857.0239 - val_loss: 6247.6987\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1994.44421\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3878.9104 - val_loss: 2790.7463\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1994.44421\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3615.2083 - val_loss: 8923.1152\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1994.44421\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3607.5103 - val_loss: 5937.2461\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1994.44421\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3360.3496 - val_loss: 8057.1250\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1994.44421\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3290.7070 - val_loss: 9117.2266\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1994.44421\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 3385.4739 - val_loss: 3642.6877\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1994.44421\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 3074.2085 - val_loss: 8883.3604\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1994.44421\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3169.8428 - val_loss: 6302.1982\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1994.44421\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3034.0442 - val_loss: 5712.4590\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1994.44421\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2935.3872 - val_loss: 4345.4829\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1994.44421\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2697.1377 - val_loss: 7528.0820\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1994.44421\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2939.2205 - val_loss: 7806.1313\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1994.44421\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 2750.3032 - val_loss: 8443.5088\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1994.44421\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2776.3572 - val_loss: 7448.6836\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1994.44421\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2760.4722 - val_loss: 2244.8955\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1994.44421\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2779.0857 - val_loss: 2175.7515\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1994.44421\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2712.7825 - val_loss: 7956.3667\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1994.44421\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2557.5789 - val_loss: 8395.1279\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1994.44421\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2584.6921 - val_loss: 3818.8921\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1994.44421\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2788.3081 - val_loss: 8335.4854\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1994.44421\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2717.2314 - val_loss: 2113.0862\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1994.44421\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2504.9023 - val_loss: 2661.3850\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1994.44421\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2336.3687 - val_loss: 3848.8665\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1994.44421\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2433.1619 - val_loss: 3921.1731\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1994.44421\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2561.8691 - val_loss: 3476.9888\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1994.44421\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2761.3279 - val_loss: 3480.5684\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1994.44421\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2477.3171 - val_loss: 1921.5337\n",
      "\n",
      "Epoch 00032: val_loss improved from 1994.44421 to 1921.53369, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2504.1206 - val_loss: 7770.0483\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1921.53369\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 2652.6008 - val_loss: 5311.6274\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1921.53369\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2321.5833 - val_loss: 5804.6167\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1921.53369\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2489.3972 - val_loss: 4940.0967\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1921.53369\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2446.7498 - val_loss: 5382.9434\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1921.53369\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2221.8730 - val_loss: 4251.1333\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1921.53369\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2297.6296 - val_loss: 7340.2261\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1921.53369\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2360.3049 - val_loss: 5255.0542\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1921.53369\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2286.1506 - val_loss: 7166.1421\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1921.53369\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2267.5771 - val_loss: 4237.1475\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1921.53369\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 2029.3390 - val_loss: 2968.6421\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1921.53369\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 2147.6960 - val_loss: 6980.6108\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1921.53369\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2269.2949 - val_loss: 6375.8145\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1921.53369\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1359.4648 - val_loss: 4828.6113\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1921.53369\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1289.7228 - val_loss: 4733.9873\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1921.53369\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1292.2976 - val_loss: 4846.0566\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1921.53369\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1269.6459 - val_loss: 4940.4146\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1921.53369\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1271.6996 - val_loss: 4866.2314\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1921.53369\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1267.1147 - val_loss: 4783.7642\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1921.53369\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1306.8467 - val_loss: 4936.2573\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1921.53369\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1343.8363 - val_loss: 4831.7471\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1921.53369\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1263.4730 - val_loss: 4882.3989\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1921.53369\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1263.2225 - val_loss: 4920.4155\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1921.53369\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1288.9495 - val_loss: 4924.5562\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1921.53369\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1238.1545 - val_loss: 4784.3643\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1921.53369\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1269.9161 - val_loss: 4908.2207\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1921.53369\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1266.4370 - val_loss: 4896.9600\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1921.53369\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1251.5255 - val_loss: 4896.1440\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1921.53369\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1268.6063 - val_loss: 4899.1743\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1921.53369\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1250.9260 - val_loss: 4992.8286\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1921.53369\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1240.8036 - val_loss: 4905.0884\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1921.53369\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1275.3995 - val_loss: 4848.8042\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1921.53369\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1269.2081 - val_loss: 4905.3574\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1921.53369\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1246.9653 - val_loss: 4795.7119\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1921.53369\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1249.0754 - val_loss: 4724.6113\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1921.53369\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1264.0165 - val_loss: 4857.0532\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1921.53369\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1223.4354 - val_loss: 4834.1279\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1921.53369\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1241.1588 - val_loss: 5033.5649\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1921.53369\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1203.9054 - val_loss: 4988.2109\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1921.53369\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1260.6307 - val_loss: 4819.9727\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1921.53369\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1228.1837 - val_loss: 4985.5659\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1921.53369\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1232.2522 - val_loss: 4897.4492\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1921.53369\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1243.5612 - val_loss: 4966.2148\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1921.53369\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1249.3593 - val_loss: 4919.9844\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1921.53369\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1243.8307 - val_loss: 4912.2158\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1921.53369\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1244.0635 - val_loss: 4922.8232\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1921.53369\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1265.6682 - val_loss: 4722.4004\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1921.53369\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1216.6561 - val_loss: 4878.6836\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1921.53369\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1225.9446 - val_loss: 4765.5762\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1921.53369\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1225.7560 - val_loss: 4998.2139\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1921.53369\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1247.7957 - val_loss: 5002.6201\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1921.53369\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1213.2788 - val_loss: 5131.8682\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1921.53369\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1238.8312 - val_loss: 4817.7861\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1921.53369\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1215.5602 - val_loss: 5069.1719\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1921.53369\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1245.7825 - val_loss: 4887.3262\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1921.53369\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1233.5570 - val_loss: 4928.0259\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1921.53369\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1202.2013 - val_loss: 4951.6245\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1921.53369\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1205.8676 - val_loss: 4923.1387\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1921.53369\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1240.9871 - val_loss: 4929.4395\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1921.53369\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1195.2533 - val_loss: 4860.4014\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1921.53369\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1249.0272 - val_loss: 4933.0474\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1921.53369\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1228.5963 - val_loss: 5042.5493\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1921.53369\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1207.0793 - val_loss: 4855.7935\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1921.53369\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1237.3811 - val_loss: 4804.5845\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1921.53369\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1211.5640 - val_loss: 5026.4434\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1921.53369\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1229.7097 - val_loss: 4898.1675\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1921.53369\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1207.3636 - val_loss: 4914.2695\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1921.53369\n",
      "Epoch 100/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 1218.1919 - val_loss: 4948.7261\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1921.53369\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1229.1992 - val_loss: 4968.6499\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1921.53369\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1198.5538 - val_loss: 4786.7866\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1921.53369\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1236.7169 - val_loss: 5074.1880\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1921.53369\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1228.7410 - val_loss: 4923.3525\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1921.53369\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1205.0416 - val_loss: 4979.5928\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1921.53369\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1189.8763 - val_loss: 4922.5249\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1921.53369\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1182.4817 - val_loss: 4825.8677\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1921.53369\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1221.0686 - val_loss: 5015.5630\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1921.53369\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1232.7800 - val_loss: 4924.3794\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1921.53369\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1217.6444 - val_loss: 4967.7407\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1921.53369\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1222.1837 - val_loss: 4791.6587\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1921.53369\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1205.0062 - val_loss: 4741.9346\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1921.53369\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1233.0573 - val_loss: 4883.6245\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1921.53369\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1199.6824 - val_loss: 4839.2051\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1921.53369\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1202.3187 - val_loss: 4881.3921\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1921.53369\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1215.8235 - val_loss: 4960.9111\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1921.53369\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1219.5272 - val_loss: 5005.6729\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1921.53369\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1213.8486 - val_loss: 4954.7988\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1921.53369\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1199.8175 - val_loss: 4987.8135\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1921.53369\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1188.4415 - val_loss: 4884.3237\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1921.53369\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1195.9562 - val_loss: 4986.9189\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1921.53369\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1227.0958 - val_loss: 4770.3052\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1921.53369\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1220.1117 - val_loss: 5000.9614\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1921.53369\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1200.5077 - val_loss: 5072.3281\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1921.53369\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1198.6029 - val_loss: 4927.7129\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1921.53369\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1216.9047 - val_loss: 5023.9829\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1921.53369\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1189.7728 - val_loss: 4920.3472\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1921.53369\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1191.3033 - val_loss: 4911.2212\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1921.53369\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1205.6121 - val_loss: 4687.7026\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1921.53369\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1208.1038 - val_loss: 4815.9517\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1921.53369\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1232.5388 - val_loss: 4839.2432\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1921.53369\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1217.1550 - val_loss: 4963.7495\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1921.53369\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 3711.4512 - val_loss: 9224.2852\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 9224.28516, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3699.1597 - val_loss: 9212.7461\n",
      "\n",
      "Epoch 00002: val_loss improved from 9224.28516 to 9212.74609, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 4108.6255 - val_loss: 6918.3394\n",
      "\n",
      "Epoch 00003: val_loss improved from 9212.74609 to 6918.33936, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3486.3708 - val_loss: 9184.1504\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 6918.33936\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3895.2935 - val_loss: 8353.8320\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6918.33936\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3614.9302 - val_loss: 3972.9312\n",
      "\n",
      "Epoch 00006: val_loss improved from 6918.33936 to 3972.93115, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3323.1628 - val_loss: 6116.7700\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3972.93115\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3414.4851 - val_loss: 6315.0889\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3972.93115\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2898.6240 - val_loss: 6991.3779\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3972.93115\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3078.6052 - val_loss: 6679.6323\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3972.93115\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3305.6267 - val_loss: 3407.5420\n",
      "\n",
      "Epoch 00011: val_loss improved from 3972.93115 to 3407.54199, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2645.3401 - val_loss: 3716.1555\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3407.54199\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2902.1489 - val_loss: 3717.7849\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3407.54199\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3018.3315 - val_loss: 7639.0312\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3407.54199\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2892.9617 - val_loss: 1876.9789\n",
      "\n",
      "Epoch 00015: val_loss improved from 3407.54199 to 1876.97888, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 3400.9619 - val_loss: 2316.3735\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1876.97888\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3463.6455 - val_loss: 8896.1064\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1876.97888\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3573.8804 - val_loss: 6552.5688\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1876.97888\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3608.4060 - val_loss: 7862.8745\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1876.97888\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3313.6890 - val_loss: 8658.2715\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1876.97888\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3317.0837 - val_loss: 7348.9824\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1876.97888\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3162.2019 - val_loss: 4237.2705\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1876.97888\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3339.3601 - val_loss: 6582.7837\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1876.97888\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2956.6694 - val_loss: 4799.6997\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1876.97888\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3235.2300 - val_loss: 3245.7581\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1876.97888\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2797.8301 - val_loss: 8637.2568\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1876.97888\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2953.7612 - val_loss: 6949.2295\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1876.97888\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3026.9954 - val_loss: 4465.4346\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1876.97888\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2758.1790 - val_loss: 8574.4189\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1876.97888\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2651.7554 - val_loss: 1919.5325\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1876.97888\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2537.3862 - val_loss: 2641.9233\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1876.97888\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2653.5010 - val_loss: 3290.7024\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1876.97888\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2650.3433 - val_loss: 5606.5327\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1876.97888\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 2539.8638 - val_loss: 6278.3364\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1876.97888\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2710.8369 - val_loss: 2246.2012\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1876.97888\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2549.7554 - val_loss: 3161.0532\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1876.97888\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2942.4597 - val_loss: 8210.4414\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1876.97888\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 3085.5647 - val_loss: 2945.3311\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1876.97888\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2767.7646 - val_loss: 8223.6836\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1876.97888\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2266.0342 - val_loss: 4743.5371\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1876.97888\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1456.5624 - val_loss: 4663.2627\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1876.97888\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1433.1079 - val_loss: 4778.0781\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1876.97888\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1355.8662 - val_loss: 4736.8755\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1876.97888\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1438.1093 - val_loss: 4702.4863\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1876.97888\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1359.3900 - val_loss: 4825.5298\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1876.97888\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1350.0084 - val_loss: 5031.2544\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1876.97888\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1361.6879 - val_loss: 4789.9028\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1876.97888\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1405.6272 - val_loss: 4529.3999\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1876.97888\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1352.1344 - val_loss: 4817.7910\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1876.97888\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1368.9218 - val_loss: 4739.4814\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1876.97888\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1306.0247 - val_loss: 4843.7227\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1876.97888\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1342.0294 - val_loss: 4875.5825\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1876.97888\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1352.1078 - val_loss: 4655.0039\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1876.97888\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1307.3668 - val_loss: 4896.1343\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1876.97888\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1351.0444 - val_loss: 4968.9595\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1876.97888\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1394.1125 - val_loss: 4780.3179\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1876.97888\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1317.9596 - val_loss: 4862.8677\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1876.97888\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1313.6411 - val_loss: 4882.6626\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1876.97888\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1316.6097 - val_loss: 4940.0039\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1876.97888\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1321.5441 - val_loss: 4869.4346\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1876.97888\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1328.4229 - val_loss: 4889.6909\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1876.97888\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1336.1907 - val_loss: 4834.7441\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1876.97888\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1320.7505 - val_loss: 4855.9917\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1876.97888\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1348.0017 - val_loss: 4839.4766\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1876.97888\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1327.9047 - val_loss: 4775.2148\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1876.97888\n",
      "Epoch 66/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 1345.4442 - val_loss: 4800.2764\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1876.97888\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1359.2754 - val_loss: 4722.1436\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1876.97888\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1339.4308 - val_loss: 4840.3389\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1876.97888\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1326.0858 - val_loss: 4978.5762\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1876.97888\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1331.2225 - val_loss: 4663.8838\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1876.97888\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1378.2396 - val_loss: 4835.8252\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1876.97888\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1308.4701 - val_loss: 4800.5078\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1876.97888\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1306.6221 - val_loss: 4974.2651\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1876.97888\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1302.6510 - val_loss: 4756.4028\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1876.97888\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1323.6688 - val_loss: 4738.2476\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1876.97888\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1307.9791 - val_loss: 4935.3237\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1876.97888\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - ETA: 0s - loss: 1308.45 - 0s 1ms/step - loss: 1310.6221 - val_loss: 4897.3833\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1876.97888\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1324.5225 - val_loss: 4890.6533\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1876.97888\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1286.9650 - val_loss: 4762.8657\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1876.97888\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1315.5825 - val_loss: 4792.6704\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1876.97888\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1299.1801 - val_loss: 4986.0537\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1876.97888\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1288.7623 - val_loss: 4983.8105\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1876.97888\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1330.6899 - val_loss: 4858.3770\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1876.97888\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1272.7999 - val_loss: 4794.1577\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1876.97888\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1268.9500 - val_loss: 4879.3145\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1876.97888\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1289.3104 - val_loss: 4867.0986\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1876.97888\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1319.3020 - val_loss: 4794.8955\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1876.97888\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1320.2281 - val_loss: 4958.5835\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1876.97888\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1299.7355 - val_loss: 4659.3955\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1876.97888\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1323.6356 - val_loss: 4931.1992\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1876.97888\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1272.4316 - val_loss: 4822.5801\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1876.97888\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1270.1405 - val_loss: 4785.7026\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1876.97888\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1290.0736 - val_loss: 4770.0767\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1876.97888\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1296.9489 - val_loss: 4801.3477\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1876.97888\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1334.8462 - val_loss: 4697.6504\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1876.97888\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1267.5983 - val_loss: 4813.9634\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1876.97888\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1276.0249 - val_loss: 4771.5967\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1876.97888\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1301.5100 - val_loss: 4856.4678\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1876.97888\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1288.0640 - val_loss: 4824.6294\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1876.97888\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1264.8657 - val_loss: 4772.6323\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1876.97888\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1300.1729 - val_loss: 4926.8315\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1876.97888\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1272.6805 - val_loss: 4817.0161\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1876.97888\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1282.2572 - val_loss: 4840.1562\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1876.97888\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1300.9879 - val_loss: 4855.8730\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1876.97888\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1284.9771 - val_loss: 4882.6064\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1876.97888\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1289.1072 - val_loss: 4883.8086\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1876.97888\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1263.5608 - val_loss: 4894.3608\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1876.97888\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1257.0981 - val_loss: 4741.3745\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1876.97888\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1244.2454 - val_loss: 4772.2734\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1876.97888\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1304.9408 - val_loss: 4878.8809\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1876.97888\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1268.1437 - val_loss: 4935.6387\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1876.97888\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1283.0911 - val_loss: 4703.1519\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1876.97888\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1254.2590 - val_loss: 4787.7485\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1876.97888\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1287.4950 - val_loss: 4722.0879\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1876.97888\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1272.2897 - val_loss: 4990.9863\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1876.97888\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 4064.6785 - val_loss: 1660.8210\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1660.82104, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3534.0720 - val_loss: 9135.2979\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1660.82104\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3792.9883 - val_loss: 3004.9382\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1660.82104\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 898us/step - loss: 3631.6062 - val_loss: 9307.3936\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1660.82104\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3786.0923 - val_loss: 5438.3457\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1660.82104\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3722.2019 - val_loss: 7747.6367\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1660.82104\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3695.3035 - val_loss: 8175.3223\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1660.82104\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 962us/step - loss: 3785.1497 - val_loss: 8881.6260\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1660.82104\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3324.8884 - val_loss: 7863.8833\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1660.82104\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 990us/step - loss: 3628.1809 - val_loss: 6008.6377\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1660.82104\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3636.9224 - val_loss: 9143.3203\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1660.82104\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 3550.5471 - val_loss: 3276.7222\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1660.82104\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 925us/step - loss: 2981.2700 - val_loss: 3899.1621\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1660.82104\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 961us/step - loss: 2863.9182 - val_loss: 7597.2905\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1660.82104\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2571.2781 - val_loss: 2775.6282\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1660.82104\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2829.8027 - val_loss: 2172.0320\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1660.82104\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 910us/step - loss: 3006.5264 - val_loss: 8703.1172\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1660.82104\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2913.9509 - val_loss: 8568.3799\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1660.82104\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 974us/step - loss: 2992.8914 - val_loss: 8287.2832\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1660.82104\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2893.7109 - val_loss: 1907.3538\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1660.82104\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 905us/step - loss: 2800.7805 - val_loss: 8813.3916\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1660.82104\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2697.9790 - val_loss: 6294.6782\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1660.82104\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 945us/step - loss: 2609.2424 - val_loss: 8721.2490\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1660.82104\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2422.7896 - val_loss: 6915.4917\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1660.82104\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2441.5833 - val_loss: 7000.8354\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1660.82104\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 991us/step - loss: 2512.4956 - val_loss: 7971.8955\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1660.82104\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2552.3030 - val_loss: 7118.0195\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1660.82104\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2482.0444 - val_loss: 8866.0049\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1660.82104\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2400.8958 - val_loss: 3622.9211\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1660.82104\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 918us/step - loss: 2482.5137 - val_loss: 7958.2993\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1660.82104\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2443.2385 - val_loss: 3475.5349\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1660.82104\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2549.1411 - val_loss: 5204.0874\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1660.82104\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2687.7024 - val_loss: 7511.1763\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1660.82104\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 902us/step - loss: 2355.6096 - val_loss: 1993.0973\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1660.82104\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 915us/step - loss: 2379.3235 - val_loss: 3641.1514\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1660.82104\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2140.5227 - val_loss: 6036.0898\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1660.82104\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 938us/step - loss: 2308.4658 - val_loss: 1720.3761\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1660.82104\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 924us/step - loss: 2155.0864 - val_loss: 5431.9268\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1660.82104\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2294.0193 - val_loss: 6303.3633\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1660.82104\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 959us/step - loss: 2586.2886 - val_loss: 4088.3494\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1660.82104\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2313.8660 - val_loss: 5824.0620\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1660.82104\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 901us/step - loss: 2138.1621 - val_loss: 2696.5706\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1660.82104\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 981us/step - loss: 2265.3662 - val_loss: 4228.3882\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1660.82104\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2175.4294 - val_loss: 2979.6521\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1660.82104\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2335.3892 - val_loss: 7972.1392\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1660.82104\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2379.8232 - val_loss: 4856.3901\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1660.82104\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 909us/step - loss: 1441.1567 - val_loss: 4601.5952\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1660.82104\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 915us/step - loss: 1442.6935 - val_loss: 4688.6948\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1660.82104\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 909us/step - loss: 1442.3484 - val_loss: 4637.8599\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1660.82104\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 948us/step - loss: 1443.0635 - val_loss: 4654.2310\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1660.82104\n",
      "Epoch 51/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 1443.0251 - val_loss: 4625.2812\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1660.82104\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1440.4033 - val_loss: 4492.1895\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1660.82104\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 909us/step - loss: 1442.9457 - val_loss: 4580.4692\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1660.82104\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1441.7433 - val_loss: 4506.4146\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1660.82104\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1441.6492 - val_loss: 4634.7764\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1660.82104\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 927us/step - loss: 1443.1771 - val_loss: 4657.3989\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1660.82104\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.1233 - val_loss: 4582.2261\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1660.82104\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 998us/step - loss: 1440.2463 - val_loss: 4736.1123\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1660.82104\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 936us/step - loss: 1444.0162 - val_loss: 4582.1748\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1660.82104\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 987us/step - loss: 1442.5830 - val_loss: 4493.3628\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1660.82104\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 985us/step - loss: 1441.9780 - val_loss: 4760.9194\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1660.82104\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 907us/step - loss: 1441.0153 - val_loss: 4521.0098\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1660.82104\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1441.7037 - val_loss: 4527.7231\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1660.82104\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 965us/step - loss: 1442.2939 - val_loss: 4552.4326\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1660.82104\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 955us/step - loss: 1442.1354 - val_loss: 4617.4346\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1660.82104\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 921us/step - loss: 1442.7051 - val_loss: 4570.9185\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1660.82104\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.1936 - val_loss: 4635.3579\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1660.82104\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.8298 - val_loss: 4606.8721\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1660.82104\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 906us/step - loss: 1442.0785 - val_loss: 4591.2930\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1660.82104\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1439.5754 - val_loss: 4677.6543\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1660.82104\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 934us/step - loss: 1441.8408 - val_loss: 4626.6304\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1660.82104\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.4423 - val_loss: 4668.9893\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1660.82104\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1441.7856 - val_loss: 4771.0596\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1660.82104\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 907us/step - loss: 1441.5903 - val_loss: 4732.2451\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1660.82104\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 911us/step - loss: 1443.1318 - val_loss: 4667.4512\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1660.82104\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1441.0237 - val_loss: 4620.7983\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1660.82104\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.7977 - val_loss: 4676.8501\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1660.82104\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.2460 - val_loss: 4621.8926\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1660.82104\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1441.8560 - val_loss: 4652.2910\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1660.82104\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1441.5691 - val_loss: 4570.6494\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1660.82104\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.5029 - val_loss: 4608.4062\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1660.82104\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1440.9153 - val_loss: 4490.0532\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1660.82104\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1443.1177 - val_loss: 4546.4868\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1660.82104\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.3889 - val_loss: 4562.5776\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1660.82104\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1441.0436 - val_loss: 4807.7627\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1660.82104\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.0619 - val_loss: 4585.4985\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1660.82104\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.8690 - val_loss: 4561.6011\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1660.82104\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1441.5321 - val_loss: 4519.5107\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1660.82104\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.3105 - val_loss: 4758.7729\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1660.82104\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1444.0176 - val_loss: 4645.1792\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1660.82104\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1442.0724 - val_loss: 4545.1592\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1660.82104\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1438.1113 - val_loss: 4802.7476\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1660.82104\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1444.9587 - val_loss: 4670.1646\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1660.82104\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.2307 - val_loss: 4597.7129\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1660.82104\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.3140 - val_loss: 4599.9092\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1660.82104\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1441.4353 - val_loss: 4731.0898\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1660.82104\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1443.3602 - val_loss: 4635.7559\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1660.82104\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.6848 - val_loss: 4620.6436\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1660.82104\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.9716 - val_loss: 4658.5308\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1660.82104\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1443.3832 - val_loss: 4652.3521\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1660.82104\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1441.7080 - val_loss: 4636.7495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|███████████████████████████████████▏                                              | 9/21 [18:04<24:16, 121.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00101: val_loss did not improve from 1660.82104\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 1816.6272 - val_loss: 4315.4683\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4315.46826, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1252.9608 - val_loss: 839.0605\n",
      "\n",
      "Epoch 00002: val_loss improved from 4315.46826 to 839.06049, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1279.8698 - val_loss: 1051.7158\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 839.06049\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1326.2986 - val_loss: 747.4515\n",
      "\n",
      "Epoch 00004: val_loss improved from 839.06049 to 747.45154, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1386.4945 - val_loss: 5620.2773\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 747.45154\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1298.6337 - val_loss: 680.2076\n",
      "\n",
      "Epoch 00006: val_loss improved from 747.45154 to 680.20764, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1440.0033 - val_loss: 4836.8599\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 680.20764\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1421.5825 - val_loss: 3004.4656\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 680.20764\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1417.8420 - val_loss: 3623.8826\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 680.20764\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1471.9590 - val_loss: 3737.2949\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 680.20764\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1265.4109 - val_loss: 5929.5713\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 680.20764\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1380.9326 - val_loss: 5487.8296\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 680.20764\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1463.1464 - val_loss: 4241.1450\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 680.20764\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1345.7385 - val_loss: 3834.1748\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 680.20764\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1324.6055 - val_loss: 4532.5312\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 680.20764\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1448.8881 - val_loss: 4039.7766\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 680.20764\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1375.1675 - val_loss: 2010.9606\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 680.20764\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1314.2024 - val_loss: 1996.8774\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 680.20764\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1569.8596 - val_loss: 5589.2788\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 680.20764\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1420.6692 - val_loss: 4471.8784\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 680.20764\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1366.4276 - val_loss: 3514.6965\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 680.20764\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1381.4075 - val_loss: 5956.2905\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 680.20764\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1413.9633 - val_loss: 4565.0586\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 680.20764\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1376.3354 - val_loss: 3962.7581\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 680.20764\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1172.0765 - val_loss: 3530.0237\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 680.20764\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1331.9590 - val_loss: 2932.2354\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 680.20764\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1275.5438 - val_loss: 4295.3945\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 680.20764\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1166.1379 - val_loss: 3896.6709\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 680.20764\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1227.6743 - val_loss: 984.3961\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 680.20764\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1175.6227 - val_loss: 3586.5349\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 680.20764\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1054.1763 - val_loss: 3712.1562\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 680.20764\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1168.2310 - val_loss: 5034.7217\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 680.20764\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1045.2426 - val_loss: 5302.7788\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 680.20764\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1105.2986 - val_loss: 2743.8384\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 680.20764\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1077.7031 - val_loss: 743.3470\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 680.20764\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1159.5604 - val_loss: 4385.3633\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 680.20764\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1038.2366 - val_loss: 2581.4473\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 680.20764\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1035.4324 - val_loss: 1820.8683\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 680.20764\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1077.8456 - val_loss: 4295.3984\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 680.20764\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1094.7811 - val_loss: 2623.5476\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 680.20764\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1066.5028 - val_loss: 2722.0181\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 680.20764\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1037.1021 - val_loss: 686.2564\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 680.20764\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1005.9271 - val_loss: 3974.0740\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 680.20764\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1008.0261 - val_loss: 4125.4219\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 680.20764\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1059.4144 - val_loss: 708.7445\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 680.20764\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.5995 - val_loss: 746.8721\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 680.20764\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 984.9976 - val_loss: 1249.6254\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 680.20764\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 978.1175 - val_loss: 4734.2607\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 680.20764\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 939.2620 - val_loss: 3981.6611\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 680.20764\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 839.8927 - val_loss: 4284.4092\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 680.20764\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 979.5267 - val_loss: 4736.2764\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 680.20764\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 937.6819 - val_loss: 4727.9126\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 680.20764\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 992.8287 - val_loss: 4707.3457\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 680.20764\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1004.8074 - val_loss: 4757.0366\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 680.20764\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.8120 - val_loss: 4701.5698\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 680.20764\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.9137 - val_loss: 4708.6528\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 680.20764\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1002.1741 - val_loss: 4680.2446\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 680.20764\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1000.8118 - val_loss: 4753.1323\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 680.20764\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 994.4758 - val_loss: 4672.3423\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 680.20764\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 992.9732 - val_loss: 4632.6592\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 680.20764\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 998.5833 - val_loss: 4596.7422\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 680.20764\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 994.1548 - val_loss: 4669.0889\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 680.20764\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.2896 - val_loss: 4755.9111\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 680.20764\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1001.2651 - val_loss: 4659.6372\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 680.20764\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 999.9958 - val_loss: 4698.0342\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 680.20764\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1002.3520 - val_loss: 4660.4072\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 680.20764\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1002.9084 - val_loss: 4717.4424\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 680.20764\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.4844 - val_loss: 4654.9229\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 680.20764\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.7808 - val_loss: 4706.2583\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 680.20764\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.1265 - val_loss: 4698.6162\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 680.20764\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.2495 - val_loss: 4726.2285\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 680.20764\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.2756 - val_loss: 4721.4404\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 680.20764\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.5845 - val_loss: 4691.6943\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 680.20764\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1002.8472 - val_loss: 4622.5181\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 680.20764\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1003.8057 - val_loss: 4748.8730\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 680.20764\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.6509 - val_loss: 4714.6196\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 680.20764\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.2238 - val_loss: 4684.5127\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 680.20764\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1002.8046 - val_loss: 4676.6719\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 680.20764\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.2721 - val_loss: 4694.5098\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 680.20764\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.1164 - val_loss: 4716.1836\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 680.20764\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.1185 - val_loss: 4726.5498\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 680.20764\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.3315 - val_loss: 4700.0796\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 680.20764\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.2571 - val_loss: 4689.2588\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 680.20764\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1002.5833 - val_loss: 4677.6841\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 680.20764\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.5880 - val_loss: 4705.0635\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 680.20764\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1002.5537 - val_loss: 4646.4697\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 680.20764\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.3411 - val_loss: 4661.1924\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 680.20764\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.5312 - val_loss: 4676.3291\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 680.20764\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.1851 - val_loss: 4700.5684\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 680.20764\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.5254 - val_loss: 4710.3076\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 680.20764\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.1435 - val_loss: 4684.2808\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 680.20764\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1002.9030 - val_loss: 4654.8154\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 680.20764\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.4178 - val_loss: 4698.5918\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 680.20764\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1002.9219 - val_loss: 4773.2393\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 680.20764\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1002.7795 - val_loss: 4797.0615\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 680.20764\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.3857 - val_loss: 4648.8062\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 680.20764\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.5377 - val_loss: 4667.3545\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 680.20764\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.1343 - val_loss: 4706.7349\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 680.20764\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1002.4946 - val_loss: 4741.6045\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 680.20764\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.4252 - val_loss: 4729.5186\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 680.20764\n",
      "Epoch 101/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.4315 - val_loss: 4681.4639\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 680.20764\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.5602 - val_loss: 4713.6836\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 680.20764\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.5195 - val_loss: 4684.0371\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 680.20764\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1002.9418 - val_loss: 4762.2471\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 680.20764\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.5914 - val_loss: 4715.3281\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 680.20764\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1003.0884 - val_loss: 4704.0049\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 680.20764\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 1814.3240 - val_loss: 3892.9177\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3892.91772, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1305.8060 - val_loss: 4988.9141\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3892.91772\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 994us/step - loss: 1417.0555 - val_loss: 4176.0996\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3892.91772\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1386.6064 - val_loss: 4301.7529\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3892.91772\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1328.9985 - val_loss: 3845.0100\n",
      "\n",
      "Epoch 00005: val_loss improved from 3892.91772 to 3845.01001, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1478.8901 - val_loss: 5880.7583\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3845.01001\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1319.1686 - val_loss: 1983.4185\n",
      "\n",
      "Epoch 00007: val_loss improved from 3845.01001 to 1983.41846, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1280.3492 - val_loss: 1886.8806\n",
      "\n",
      "Epoch 00008: val_loss improved from 1983.41846 to 1886.88062, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1331.0160 - val_loss: 4461.4268\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1886.88062\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1348.0060 - val_loss: 5590.1782\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1886.88062\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1345.2496 - val_loss: 3552.7732\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1886.88062\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1242.2003 - val_loss: 5202.5044\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1886.88062\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1278.6658 - val_loss: 4982.4741\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1886.88062\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1189.5615 - val_loss: 2190.8484\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1886.88062\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1158.2025 - val_loss: 1257.2970\n",
      "\n",
      "Epoch 00015: val_loss improved from 1886.88062 to 1257.29700, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1190.8389 - val_loss: 5400.1792\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1257.29700\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1171.7283 - val_loss: 3346.2922\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1257.29700\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1108.3778 - val_loss: 3120.1599\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1257.29700\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1092.4659 - val_loss: 1281.3212\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1257.29700\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1173.7054 - val_loss: 5583.2954\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1257.29700\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1173.8254 - val_loss: 1385.0541\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1257.29700\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1043.3951 - val_loss: 666.9664\n",
      "\n",
      "Epoch 00022: val_loss improved from 1257.29700 to 666.96643, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1053.3882 - val_loss: 926.4869\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 666.96643\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1159.7245 - val_loss: 630.7420\n",
      "\n",
      "Epoch 00024: val_loss improved from 666.96643 to 630.74200, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1113.3026 - val_loss: 1790.7494\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 630.74200\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1025.3911 - val_loss: 1114.9944\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 630.74200\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1029.6980 - val_loss: 737.3273\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 630.74200\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1033.4475 - val_loss: 1535.6360\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 630.74200\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 988.9488 - val_loss: 1454.0188\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 630.74200\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1094.4038 - val_loss: 1569.5500\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 630.74200\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1001.3853 - val_loss: 2200.6624\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 630.74200\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 979.9474 - val_loss: 1914.9669\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 630.74200\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1066.9480 - val_loss: 976.9338\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 630.74200\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1024.5936 - val_loss: 1237.3545\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 630.74200\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1025.8269 - val_loss: 3976.8037\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 630.74200\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 948.9446 - val_loss: 4289.1299\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 630.74200\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1074.9086 - val_loss: 5898.0630\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 630.74200\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1011.9379 - val_loss: 1752.5928\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 630.74200\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1001.9399 - val_loss: 5058.8169\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 630.74200\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1305.5254 - val_loss: 3448.3660\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 630.74200\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1242.4619 - val_loss: 6240.9639\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 630.74200\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1295.1165 - val_loss: 5974.2749\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 630.74200\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1236.2769 - val_loss: 3802.4390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: val_loss did not improve from 630.74200\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1106.0957 - val_loss: 3821.9890\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 630.74200\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1060.4932 - val_loss: 893.8055\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 630.74200\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 981.0022 - val_loss: 3700.3328\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 630.74200\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 998.0668 - val_loss: 629.6835\n",
      "\n",
      "Epoch 00047: val_loss improved from 630.74200 to 629.68347, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1072.2699 - val_loss: 2930.4790\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 629.68347\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1034.7919 - val_loss: 5073.2012\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 629.68347\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1000.4352 - val_loss: 612.7280\n",
      "\n",
      "Epoch 00050: val_loss improved from 629.68347 to 612.72797, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1033.9430 - val_loss: 5400.3389\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 612.72797\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1035.9043 - val_loss: 757.0801\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 612.72797\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 975.7562 - val_loss: 605.8073\n",
      "\n",
      "Epoch 00053: val_loss improved from 612.72797 to 605.80725, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 971.8751 - val_loss: 5407.8242\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 605.80725\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1031.8423 - val_loss: 3574.9404\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 605.80725\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 977.6041 - val_loss: 1901.6196\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 605.80725\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1044.7028 - val_loss: 3588.2412\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 605.80725\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 902.1699 - val_loss: 2734.2266\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 605.80725\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 935.4152 - val_loss: 1007.5974\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 605.80725\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 887.0727 - val_loss: 750.0958\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 605.80725\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 767.3618 - val_loss: 4043.4507\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 605.80725\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 860.3572 - val_loss: 4401.9609\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 605.80725\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 884.7711 - val_loss: 4671.7642\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 605.80725\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 798.1437 - val_loss: 3295.6414\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 605.80725\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 865.0015 - val_loss: 3433.2905\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 605.80725\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 763.2886 - val_loss: 3215.8494\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 605.80725\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 817.0609 - val_loss: 4920.4155\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 605.80725\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 810.9584 - val_loss: 3746.2563\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 605.80725\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 835.1207 - val_loss: 2469.3230\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 605.80725\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 739.9555 - val_loss: 2163.4607\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 605.80725\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 719.8431 - val_loss: 4947.4658\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 605.80725\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1010.0797 - val_loss: 4738.7314\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 605.80725\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.6802 - val_loss: 4695.7441\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 605.80725\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.1177 - val_loss: 4692.0713\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 605.80725\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1007.5004 - val_loss: 4706.5308\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 605.80725\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.8251 - val_loss: 4718.9868\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 605.80725\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.7421 - val_loss: 4657.7383\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 605.80725\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.5144 - val_loss: 4661.9219\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 605.80725\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.8291 - val_loss: 4650.1348\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 605.80725\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1007.2152 - val_loss: 4694.1250\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 605.80725\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1007.5341 - val_loss: 4622.7188\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 605.80725\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.3774 - val_loss: 4770.1650\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 605.80725\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.4181 - val_loss: 4701.0762\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 605.80725\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1007.3384 - val_loss: 4739.8062\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 605.80725\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1007.2520 - val_loss: 4761.9834\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 605.80725\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.8697 - val_loss: 4735.7031\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 605.80725\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.1260 - val_loss: 4699.0449\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 605.80725\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.3458 - val_loss: 4721.3398\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 605.80725\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.0406 - val_loss: 4721.0073\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 605.80725\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.2880 - val_loss: 4720.2930\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 605.80725\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.0010 - val_loss: 4703.4717\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 605.80725\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.8984 - val_loss: 4693.0977\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 605.80725\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.7309 - val_loss: 4645.5371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00093: val_loss did not improve from 605.80725\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.0610 - val_loss: 4692.4102\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 605.80725\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.1205 - val_loss: 4790.7812\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 605.80725\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.1713 - val_loss: 4699.6094\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 605.80725\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.3246 - val_loss: 4828.0410\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 605.80725\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.4816 - val_loss: 4653.1143\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 605.80725\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.0240 - val_loss: 4682.0352\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 605.80725\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.4915 - val_loss: 4675.3672\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 605.80725\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.7628 - val_loss: 4769.0186\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 605.80725\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.7401 - val_loss: 4626.9697\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 605.80725\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.8644 - val_loss: 4639.6973\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 605.80725\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.7160 - val_loss: 4769.4600\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 605.80725\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.5685 - val_loss: 4801.2720\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 605.80725\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.7859 - val_loss: 4693.1636\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 605.80725\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.9079 - val_loss: 4699.0146\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 605.80725\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.9568 - val_loss: 4727.8750\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 605.80725\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1005.6164 - val_loss: 4807.2773\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 605.80725\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1008.7838 - val_loss: 4681.8018\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 605.80725\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1005.5580 - val_loss: 4640.7646\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 605.80725\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.6517 - val_loss: 4653.3574\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 605.80725\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.2978 - val_loss: 4706.4277\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 605.80725\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.5005 - val_loss: 4675.4561\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 605.80725\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.4506 - val_loss: 4671.6865\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 605.80725\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.1658 - val_loss: 4750.1289\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 605.80725\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.9229 - val_loss: 4696.4756\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 605.80725\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.1081 - val_loss: 4792.3496\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 605.80725\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1008.3270 - val_loss: 4712.0020\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 605.80725\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1007.0226 - val_loss: 4734.0518\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 605.80725\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1006.2214 - val_loss: 4674.1387\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 605.80725\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.1110 - val_loss: 4694.5518\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 605.80725\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.3604 - val_loss: 4690.8779\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 605.80725\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.0511 - val_loss: 4696.9717\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 605.80725\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.9758 - val_loss: 4693.2285\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 605.80725\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.3417 - val_loss: 4731.1768\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 605.80725\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.5931 - val_loss: 4679.1504\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 605.80725\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.0486 - val_loss: 4634.7109\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 605.80725\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.3122 - val_loss: 4711.8184\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 605.80725\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1007.4191 - val_loss: 4692.1621\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 605.80725\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.2799 - val_loss: 4728.4971\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 605.80725\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.0909 - val_loss: 4674.8086\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 605.80725\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.4545 - val_loss: 4784.4746\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 605.80725\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.4990 - val_loss: 4685.0615\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 605.80725\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.9379 - val_loss: 4699.4727\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 605.80725\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.7081 - val_loss: 4723.3096\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 605.80725\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.0234 - val_loss: 4674.6172\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 605.80725\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.2701 - val_loss: 4701.5840\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 605.80725\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.6879 - val_loss: 4707.6606\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 605.80725\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.5454 - val_loss: 4679.8262\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 605.80725\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.0436 - val_loss: 4782.7061\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 605.80725\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.2230 - val_loss: 4725.1572\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 605.80725\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.7341 - val_loss: 4723.1641\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 605.80725\n",
      "Epoch 144/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 2ms/step - loss: 1007.1204 - val_loss: 4680.9521\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 605.80725\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1007.2807 - val_loss: 4774.5874\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 605.80725\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.3591 - val_loss: 4667.2251\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 605.80725\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.9670 - val_loss: 4707.2559\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 605.80725\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1006.8313 - val_loss: 4671.2402\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 605.80725\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.4596 - val_loss: 4733.0352\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 605.80725\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1006.8923 - val_loss: 4732.4463\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 605.80725\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.7559 - val_loss: 4695.4414\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 605.80725\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.1996 - val_loss: 4717.2158\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 605.80725\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1007.6232 - val_loss: 4724.7954\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 605.80725\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 1783.1825 - val_loss: 3440.1772\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3440.17725, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1297.1316 - val_loss: 3460.0732\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3440.17725\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1309.7953 - val_loss: 5319.2559\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3440.17725\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1327.8285 - val_loss: 4443.9561\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3440.17725\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1274.4502 - val_loss: 5413.2388\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3440.17725\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1353.5012 - val_loss: 1429.5033\n",
      "\n",
      "Epoch 00006: val_loss improved from 3440.17725 to 1429.50330, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1310.0605 - val_loss: 6002.3623\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1429.50330\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1377.0232 - val_loss: 2525.0308\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1429.50330\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1345.6964 - val_loss: 1465.0875\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1429.50330\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1351.0105 - val_loss: 5192.9316\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1429.50330\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.1887 - val_loss: 4134.7905\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1429.50330\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1306.8319 - val_loss: 846.1264\n",
      "\n",
      "Epoch 00012: val_loss improved from 1429.50330 to 846.12640, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1348.0743 - val_loss: 3573.9561\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 846.12640\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1360.8849 - val_loss: 1575.0602\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 846.12640\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1305.3939 - val_loss: 6188.5767\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 846.12640\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1365.9902 - val_loss: 2638.2883\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 846.12640\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1273.6428 - val_loss: 2819.2019\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 846.12640\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1253.3088 - val_loss: 1373.2937\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 846.12640\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1285.3270 - val_loss: 2532.3481\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 846.12640\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1241.6411 - val_loss: 5424.8735\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 846.12640\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1227.1753 - val_loss: 609.2553\n",
      "\n",
      "Epoch 00021: val_loss improved from 846.12640 to 609.25531, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1231.6653 - val_loss: 5804.3354\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 609.25531\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1166.2052 - val_loss: 3008.5596\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 609.25531\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1259.2710 - val_loss: 4274.4980\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 609.25531\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1338.2068 - val_loss: 911.2952\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 609.25531\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1228.5112 - val_loss: 5198.7832\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 609.25531\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1161.9600 - val_loss: 1759.8707\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 609.25531\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1220.7467 - val_loss: 3356.8970\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 609.25531\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1223.9918 - val_loss: 4711.3760\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 609.25531\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1175.0602 - val_loss: 5551.1807\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 609.25531\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1224.1630 - val_loss: 4166.2285\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 609.25531\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1195.2524 - val_loss: 4026.9834\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 609.25531\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1149.8566 - val_loss: 2402.6655\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 609.25531\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1141.8768 - val_loss: 766.2887\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 609.25531\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1088.3264 - val_loss: 3764.1829\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 609.25531\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1060.0135 - val_loss: 998.6819\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 609.25531\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1074.1158 - val_loss: 1871.8527\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 609.25531\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1111.6414 - val_loss: 1826.5872\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 609.25531\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1064.4753 - val_loss: 647.5381\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 609.25531\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1110.1942 - val_loss: 3545.9463\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 609.25531\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1144.4834 - val_loss: 5416.4307\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 609.25531\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1039.5808 - val_loss: 2939.6008\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 609.25531\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - ETA: 0s - loss: 991.797 - 0s 1ms/step - loss: 995.6441 - val_loss: 3854.2593\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 609.25531\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 982.5135 - val_loss: 2277.6863\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 609.25531\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1002.8423 - val_loss: 1225.1479\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 609.25531\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 970.4496 - val_loss: 714.5798\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 609.25531\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1078.4089 - val_loss: 3092.6025\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 609.25531\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1028.0320 - val_loss: 765.1909\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 609.25531\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1086.4703 - val_loss: 3629.1606\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 609.25531\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1012.8978 - val_loss: 4437.3330\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 609.25531\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 978.6949 - val_loss: 3970.2568\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 609.25531\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1045.5386 - val_loss: 1041.7141\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 609.25531\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1026.5897 - val_loss: 1800.7792\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 609.25531\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 971.3072 - val_loss: 1711.3458\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 609.25531\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 904.3752 - val_loss: 4089.2373\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 609.25531\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 932.7635 - val_loss: 4473.1240\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 609.25531\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1064.1266 - val_loss: 1367.5707\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 609.25531\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.8742 - val_loss: 4720.3447\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 609.25531\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.0198 - val_loss: 4709.6592\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 609.25531\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1005.9335 - val_loss: 4717.9878\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 609.25531\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.4836 - val_loss: 4690.2231\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 609.25531\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.4830 - val_loss: 4704.2764\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 609.25531\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - ETA: 0s - loss: 1022.12 - 0s 1ms/step - loss: 1008.1351 - val_loss: 4662.1880\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 609.25531\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.0491 - val_loss: 4713.9282\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 609.25531\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1009.0382 - val_loss: 4684.7261\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 609.25531\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.4301 - val_loss: 4696.5605\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 609.25531\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.0209 - val_loss: 4635.4805\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 609.25531\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.4537 - val_loss: 4725.3813\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 609.25531\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.4359 - val_loss: 4722.0527\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 609.25531\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.1326 - val_loss: 4703.5547\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 609.25531\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.9842 - val_loss: 4702.2886\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 609.25531\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1001.4865 - val_loss: 4704.1387\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 609.25531\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1001.9854 - val_loss: 4684.1289\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 609.25531\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.5850 - val_loss: 4738.0259\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 609.25531\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.4948 - val_loss: 4717.7964\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 609.25531\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.5197 - val_loss: 4745.6006\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 609.25531\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.3201 - val_loss: 4657.9590\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 609.25531\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.0810 - val_loss: 4760.9487\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 609.25531\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.7552 - val_loss: 4685.9873\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 609.25531\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.5531 - val_loss: 4689.5430\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 609.25531\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.4777 - val_loss: 4748.3306\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 609.25531\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.7017 - val_loss: 4634.7607\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 609.25531\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.8379 - val_loss: 4710.9282\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 609.25531\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.0742 - val_loss: 4666.0386\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 609.25531\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.9830 - val_loss: 4703.7314\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 609.25531\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.0867 - val_loss: 4693.2700\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 609.25531\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.8211 - val_loss: 4686.9375\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 609.25531\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.2509 - val_loss: 4671.9292\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 609.25531\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.6877 - val_loss: 4731.5464\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 609.25531\n",
      "Epoch 90/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.7048 - val_loss: 4692.6479\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 609.25531\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.2498 - val_loss: 4706.7056\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 609.25531\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.1138 - val_loss: 4720.8311\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 609.25531\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.8889 - val_loss: 4716.0371\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 609.25531\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.6576 - val_loss: 4705.0815\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 609.25531\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.2442 - val_loss: 4743.3262\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 609.25531\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.1733 - val_loss: 4728.5098\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 609.25531\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.4570 - val_loss: 4675.7358\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 609.25531\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.7422 - val_loss: 4766.9111\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 609.25531\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.5947 - val_loss: 4701.0264\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 609.25531\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.5616 - val_loss: 4731.6992\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 609.25531\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.5081 - val_loss: 4706.3477\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 609.25531\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.2658 - val_loss: 4713.4683\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 609.25531\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.5129 - val_loss: 4754.5674\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 609.25531\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.4616 - val_loss: 4756.4971\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 609.25531\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.7112 - val_loss: 4673.1455\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 609.25531\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.3354 - val_loss: 4693.4238\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 609.25531\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.1342 - val_loss: 4683.0356\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 609.25531\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.6655 - val_loss: 4718.7124\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 609.25531\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.2280 - val_loss: 4728.7295\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 609.25531\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.6680 - val_loss: 4691.4219\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 609.25531\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.2520 - val_loss: 4725.6392\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 609.25531\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.1947 - val_loss: 4700.1421\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 609.25531\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.2968 - val_loss: 4676.2349\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 609.25531\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.7135 - val_loss: 4715.3408\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 609.25531\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.4553 - val_loss: 4659.3154\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 609.25531\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.9049 - val_loss: 4754.7671\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 609.25531\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.5686 - val_loss: 4757.5249\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 609.25531\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.8602 - val_loss: 4736.3662\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 609.25531\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.9401 - val_loss: 4746.4307\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 609.25531\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1007.4338 - val_loss: 4656.8564\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 609.25531\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1008.7361 - val_loss: 4714.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▌                                          | 10/21 [19:53<21:35, 117.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00121: val_loss did not improve from 609.25531\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 1643.5323 - val_loss: 3759.3049\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3759.30493, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1196.0193 - val_loss: 3032.2854\n",
      "\n",
      "Epoch 00002: val_loss improved from 3759.30493 to 3032.28540, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1223.5066 - val_loss: 1558.9719\n",
      "\n",
      "Epoch 00003: val_loss improved from 3032.28540 to 1558.97192, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1253.0480 - val_loss: 1536.1764\n",
      "\n",
      "Epoch 00004: val_loss improved from 1558.97192 to 1536.17639, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1114.8883 - val_loss: 3183.9072\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1536.17639\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1195.3678 - val_loss: 2518.5032\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1536.17639\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1185.8868 - val_loss: 3463.5125\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1536.17639\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1185.7545 - val_loss: 3412.0256\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1536.17639\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1114.4108 - val_loss: 1597.7010\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1536.17639\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1192.4629 - val_loss: 1876.5941\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1536.17639\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 1094.5337 - val_loss: 3124.2742\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1536.17639\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1130.3698 - val_loss: 1577.3274\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1536.17639\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1113.9697 - val_loss: 2982.8054\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1536.17639\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1115.0677 - val_loss: 2268.7139\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1536.17639\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1031.8173 - val_loss: 2330.3652\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1536.17639\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1066.3767 - val_loss: 1704.8762\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1536.17639\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 983.6897 - val_loss: 2710.6660\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1536.17639\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 952.6476 - val_loss: 1347.8949\n",
      "\n",
      "Epoch 00018: val_loss improved from 1536.17639 to 1347.89490, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 946.0151 - val_loss: 1623.9402\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1347.89490\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 922.1835 - val_loss: 2268.2034\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1347.89490\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 910.7469 - val_loss: 1294.2043\n",
      "\n",
      "Epoch 00021: val_loss improved from 1347.89490 to 1294.20435, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 950.2096 - val_loss: 1448.3699\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1294.20435\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 888.9581 - val_loss: 2648.4299\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1294.20435\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 910.8784 - val_loss: 1409.5225\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1294.20435\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 888.4224 - val_loss: 1402.1658\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1294.20435\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 902.5668 - val_loss: 2026.6339\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1294.20435\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.9005 - val_loss: 1384.2228\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1294.20435\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 904.2853 - val_loss: 3338.2480\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1294.20435\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 904.7538 - val_loss: 1380.0721\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1294.20435\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 866.4105 - val_loss: 1282.5581\n",
      "\n",
      "Epoch 00030: val_loss improved from 1294.20435 to 1282.55811, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 890.9237 - val_loss: 2696.8093\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1282.55811\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 865.0087 - val_loss: 2661.1125\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1282.55811\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 873.3580 - val_loss: 1164.6824\n",
      "\n",
      "Epoch 00033: val_loss improved from 1282.55811 to 1164.68237, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 846.4370 - val_loss: 1262.7136\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1164.68237\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 793.3987 - val_loss: 1165.3541\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1164.68237\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 855.8209 - val_loss: 1803.4711\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1164.68237\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 859.6694 - val_loss: 1685.6458\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1164.68237\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 812.2557 - val_loss: 1215.9420\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1164.68237\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 850.7429 - val_loss: 1019.9671\n",
      "\n",
      "Epoch 00039: val_loss improved from 1164.68237 to 1019.96710, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 781.8891 - val_loss: 2380.8694\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1019.96710\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 820.4399 - val_loss: 1320.2019\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1019.96710\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 824.3869 - val_loss: 1304.2690\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1019.96710\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 821.4424 - val_loss: 1858.4424\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1019.96710\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 855.1200 - val_loss: 2412.3010\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1019.96710\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 831.6912 - val_loss: 2641.9912\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1019.96710\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 867.2086 - val_loss: 997.5391\n",
      "\n",
      "Epoch 00046: val_loss improved from 1019.96710 to 997.53912, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 842.0341 - val_loss: 2007.7278\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 997.53912\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 812.0894 - val_loss: 1783.3115\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 997.53912\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 746.5458 - val_loss: 2466.3713\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 997.53912\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 782.5471 - val_loss: 1226.0994\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 997.53912\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 765.6410 - val_loss: 2408.8052\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 997.53912\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 832.1899 - val_loss: 1488.5173\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 997.53912\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 759.9513 - val_loss: 1266.5073\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 997.53912\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 812.3617 - val_loss: 1791.5096\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 997.53912\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 814.6708 - val_loss: 1102.7454\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 997.53912\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 754.5912 - val_loss: 1208.7184\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 997.53912\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 751.9110 - val_loss: 1761.7822\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 997.53912\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 819.9542 - val_loss: 2328.5493\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 997.53912\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 723.6371 - val_loss: 2795.1125\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 997.53912\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 789.0240 - val_loss: 1846.3141\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 997.53912\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 728.7887 - val_loss: 1127.3403\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 997.53912\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 779.1373 - val_loss: 1853.7997\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 997.53912\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 748.5793 - val_loss: 2436.8687\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 997.53912\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 724.8828 - val_loss: 2833.6973\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 997.53912\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 766.7862 - val_loss: 2252.0640\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 997.53912\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 761.9737 - val_loss: 1472.1334\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 997.53912\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 697.6757 - val_loss: 2234.3350\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 997.53912\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 764.2822 - val_loss: 2471.6228\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 997.53912\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 786.7591 - val_loss: 1263.9167\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 997.53912\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 774.6489 - val_loss: 1355.9231\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 997.53912\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 724.0571 - val_loss: 1128.8522\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 997.53912\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 722.2057 - val_loss: 2971.8218\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 997.53912\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 683.3680 - val_loss: 1812.3894\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 997.53912\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 669.9351 - val_loss: 1121.3905\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 997.53912\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 683.3033 - val_loss: 1384.8506\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 997.53912\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 709.5641 - val_loss: 1523.5513\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 997.53912\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 668.2744 - val_loss: 1245.4261\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 997.53912\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 691.7533 - val_loss: 1503.7230\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 997.53912\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 646.7247 - val_loss: 1989.7611\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 997.53912\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 666.0243 - val_loss: 1346.3704\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 997.53912\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 657.0170 - val_loss: 1958.4878\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 997.53912\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 646.1818 - val_loss: 1614.0068\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 997.53912\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 692.3517 - val_loss: 1753.8677\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 997.53912\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 643.5154 - val_loss: 1930.6589\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 997.53912\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 696.2732 - val_loss: 1347.9978\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 997.53912\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 639.0886 - val_loss: 1721.7178\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 997.53912\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 660.7667 - val_loss: 2690.9685\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 997.53912\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 672.2201 - val_loss: 1245.6066\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 997.53912\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 706.2900 - val_loss: 1579.6274\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 997.53912\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 646.2715 - val_loss: 1357.4282\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 997.53912\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 669.3223 - val_loss: 1514.9513\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 997.53912\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 622.4427 - val_loss: 1873.0542\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 997.53912\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 610.4407 - val_loss: 1652.2786\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 997.53912\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 650.7389 - val_loss: 1424.0715\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 997.53912\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 660.2771 - val_loss: 1408.0073\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 997.53912\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 632.1986 - val_loss: 1297.7651\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 997.53912\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 645.5627 - val_loss: 1964.3696\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 997.53912\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 631.3398 - val_loss: 1155.8193\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 997.53912\n",
      "Epoch 99/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 611.2938 - val_loss: 1504.8970\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 997.53912\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 647.7562 - val_loss: 1209.8165\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 997.53912\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 616.6881 - val_loss: 1296.7814\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 997.53912\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 575.4393 - val_loss: 1715.5969\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 997.53912\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 640.1682 - val_loss: 1892.5344\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 997.53912\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 652.7929 - val_loss: 1819.5665\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 997.53912\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 606.9474 - val_loss: 2115.7427\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 997.53912\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 581.6280 - val_loss: 1304.8972\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 997.53912\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 589.8554 - val_loss: 1580.7722\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 997.53912\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 583.1658 - val_loss: 1772.8071\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 997.53912\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 652.5468 - val_loss: 2364.1143\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 997.53912\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 622.0717 - val_loss: 1476.1886\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 997.53912\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 605.5762 - val_loss: 1290.9490\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 997.53912\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 616.3162 - val_loss: 1378.4438\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 997.53912\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 636.9708 - val_loss: 1760.7476\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 997.53912\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 612.0852 - val_loss: 1599.8214\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 997.53912\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 583.6474 - val_loss: 1232.1926\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 997.53912\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 600.7386 - val_loss: 1309.2878\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 997.53912\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 625.6380 - val_loss: 1924.3729\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 997.53912\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 634.8934 - val_loss: 1629.4867\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 997.53912\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 622.6023 - val_loss: 2169.2996\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 997.53912\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 643.4846 - val_loss: 1270.2692\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 997.53912\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 638.9604 - val_loss: 1170.2368\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 997.53912\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 596.7737 - val_loss: 1747.4794\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 997.53912\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 655.1633 - val_loss: 1881.0964\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 997.53912\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 594.2482 - val_loss: 2168.1191\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 997.53912\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 609.4559 - val_loss: 2572.9736\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 997.53912\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 594.4297 - val_loss: 2148.1426\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 997.53912\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 650.1702 - val_loss: 2402.9500\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 997.53912\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 617.4736 - val_loss: 1629.5675\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 997.53912\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 627.9443 - val_loss: 1509.2501\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 997.53912\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 653.1739 - val_loss: 1672.4392\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 997.53912\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 587.2995 - val_loss: 1230.2961\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 997.53912\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 652.0511 - val_loss: 1491.2710\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 997.53912\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 575.3079 - val_loss: 1967.6249\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 997.53912\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 604.0156 - val_loss: 1963.8171\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 997.53912\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 577.5716 - val_loss: 1530.3350\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 997.53912\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 582.6666 - val_loss: 1511.0681\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 997.53912\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 578.8295 - val_loss: 1751.6418\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 997.53912\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 543.5536 - val_loss: 1498.1118\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 997.53912\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 579.9552 - val_loss: 1358.4258\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 997.53912\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 649.6117 - val_loss: 1329.4496\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 997.53912\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 613.5527 - val_loss: 2184.3586\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 997.53912\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 590.4487 - val_loss: 1803.0361\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 997.53912\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 594.5505 - val_loss: 1665.9431\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 997.53912\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 583.0404 - val_loss: 1552.9050\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 997.53912\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 550.9687 - val_loss: 1385.6954\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 997.53912\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 630.4570 - val_loss: 1870.6536\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 997.53912\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 2031.4801 - val_loss: 2096.5623\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2096.56226, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1362.4431 - val_loss: 2918.2524\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2096.56226\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 915us/step - loss: 1151.0645 - val_loss: 2427.3503\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2096.56226\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1176.5410 - val_loss: 1483.9474\n",
      "\n",
      "Epoch 00004: val_loss improved from 2096.56226 to 1483.94739, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1153.3047 - val_loss: 1376.0621\n",
      "\n",
      "Epoch 00005: val_loss improved from 1483.94739 to 1376.06213, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1247.6626 - val_loss: 2903.1541\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1376.06213\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1145.9500 - val_loss: 1371.0378\n",
      "\n",
      "Epoch 00007: val_loss improved from 1376.06213 to 1371.03784, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1218.8318 - val_loss: 1201.6893\n",
      "\n",
      "Epoch 00008: val_loss improved from 1371.03784 to 1201.68933, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 909us/step - loss: 1133.5720 - val_loss: 1341.8827\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1201.68933\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 994us/step - loss: 1112.3038 - val_loss: 3448.9675\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1201.68933\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 922us/step - loss: 1085.9254 - val_loss: 2455.4514\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1201.68933\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1019.9395 - val_loss: 3763.5562\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1201.68933\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 908us/step - loss: 1070.3633 - val_loss: 3368.9075\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1201.68933\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1044.7363 - val_loss: 1810.5693\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1201.68933\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 943.5212 - val_loss: 3470.6440\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1201.68933\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1012.1022 - val_loss: 1841.1101\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1201.68933\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 975.9855 - val_loss: 2390.3997\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1201.68933\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 947.0259 - val_loss: 3341.4707\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1201.68933\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 982.3611 - val_loss: 2017.2489\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1201.68933\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 978us/step - loss: 1006.6557 - val_loss: 1097.8141\n",
      "\n",
      "Epoch 00020: val_loss improved from 1201.68933 to 1097.81409, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 836.2289 - val_loss: 1441.9141\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1097.81409\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 885.4554 - val_loss: 3933.5679\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1097.81409\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 918us/step - loss: 939.0049 - val_loss: 1798.8604\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1097.81409\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 901.4711 - val_loss: 2714.6506\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1097.81409\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 958.2682 - val_loss: 3411.0449\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1097.81409\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 924.8984 - val_loss: 3057.8943\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1097.81409\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 821.7745 - val_loss: 1489.3765\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1097.81409\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 902.4124 - val_loss: 1104.4067\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1097.81409\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 933us/step - loss: 874.6010 - val_loss: 1901.7545\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1097.81409\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 833.6223 - val_loss: 2102.1587\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1097.81409\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 863.5311 - val_loss: 1301.5120\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1097.81409\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 837.5327 - val_loss: 1293.3641\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1097.81409\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 811.0840 - val_loss: 2700.3892\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1097.81409\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 921.2008 - val_loss: 3066.2373\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1097.81409\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 934us/step - loss: 1003.6638 - val_loss: 1649.0739\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1097.81409\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 971us/step - loss: 1092.2949 - val_loss: 1018.3963\n",
      "\n",
      "Epoch 00036: val_loss improved from 1097.81409 to 1018.39630, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 982.4698 - val_loss: 2160.3069\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1018.39630\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1022.7680 - val_loss: 1534.4056\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1018.39630\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 898.0959 - val_loss: 2200.0156\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1018.39630\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 936.4276 - val_loss: 1234.7709\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1018.39630\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 859.2164 - val_loss: 2898.7642\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1018.39630\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 849.2722 - val_loss: 3157.7007\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1018.39630\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 933.7562 - val_loss: 2558.3032\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1018.39630\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 847.3807 - val_loss: 2627.5378\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1018.39630\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 814.1561 - val_loss: 3690.3848\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1018.39630\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 864.0127 - val_loss: 2065.6106\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1018.39630\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 841.8836 - val_loss: 2238.5996\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1018.39630\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 832.0582 - val_loss: 2755.8840\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1018.39630\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 872.6733 - val_loss: 1514.1523\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1018.39630\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 870.9630 - val_loss: 2214.2024\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1018.39630\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 795.1268 - val_loss: 1473.7177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: val_loss did not improve from 1018.39630\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 817.7251 - val_loss: 2401.2185\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1018.39630\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 806.3642 - val_loss: 1329.6132\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1018.39630\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 786.7416 - val_loss: 2490.4060\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1018.39630\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 849.2396 - val_loss: 1876.3696\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1018.39630\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 839.4835 - val_loss: 2850.4397\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1018.39630\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 757.4307 - val_loss: 1290.9204\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1018.39630\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 851.0746 - val_loss: 2691.7671\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1018.39630\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 830.1487 - val_loss: 1635.9982\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1018.39630\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 777.2653 - val_loss: 3572.7095\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1018.39630\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 810.9549 - val_loss: 2318.1299\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1018.39630\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 800.2802 - val_loss: 1983.9855\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1018.39630\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 811.1920 - val_loss: 2000.5424\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1018.39630\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 746.9229 - val_loss: 2712.1318\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1018.39630\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 756.6168 - val_loss: 1684.5475\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1018.39630\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 801.7240 - val_loss: 2998.9534\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1018.39630\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 751.1493 - val_loss: 2108.7280\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1018.39630\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 768.6558 - val_loss: 2391.7583\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1018.39630\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 787.4557 - val_loss: 2177.9512\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1018.39630\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 763.7090 - val_loss: 2975.0862\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1018.39630\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 719.8414 - val_loss: 1396.3104\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1018.39630\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 747.3806 - val_loss: 2803.5657\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1018.39630\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 750.4348 - val_loss: 1956.7535\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1018.39630\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 724.7319 - val_loss: 2204.6743\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1018.39630\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 735.7726 - val_loss: 2848.8435\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1018.39630\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 745.6411 - val_loss: 1854.2053\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1018.39630\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 733.6289 - val_loss: 2490.4304\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1018.39630\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 713.5841 - val_loss: 2687.4731\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1018.39630\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 724.3007 - val_loss: 3009.6953\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1018.39630\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 734.0289 - val_loss: 3264.7720\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1018.39630\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 830.8998 - val_loss: 2289.3645\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1018.39630\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 790.1401 - val_loss: 2937.8806\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1018.39630\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 824.9107 - val_loss: 2142.4661\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1018.39630\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 775.5416 - val_loss: 950.2226\n",
      "\n",
      "Epoch 00084: val_loss improved from 1018.39630 to 950.22260, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 757.7763 - val_loss: 1094.6141\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 950.22260\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 773.8531 - val_loss: 4393.5103\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 950.22260\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 784.1416 - val_loss: 3050.0562\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 950.22260\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 786.6352 - val_loss: 2147.0056\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 950.22260\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 796.7443 - val_loss: 1986.9087\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 950.22260\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 730.8904 - val_loss: 2353.9709\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 950.22260\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 753.9017 - val_loss: 3034.3428\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 950.22260\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 734.2833 - val_loss: 2430.9934\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 950.22260\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 723.5169 - val_loss: 2602.5471\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 950.22260\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 737.4977 - val_loss: 3137.1978\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 950.22260\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 696.4366 - val_loss: 2859.9329\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 950.22260\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 714.9905 - val_loss: 3125.8413\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 950.22260\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 751.9722 - val_loss: 1171.9360\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 950.22260\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 769.2693 - val_loss: 1337.4353\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 950.22260\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 735.9550 - val_loss: 3056.9832\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 950.22260\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 756.5203 - val_loss: 1994.9592\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 950.22260\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 720.1013 - val_loss: 3176.3445\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 950.22260\n",
      "Epoch 102/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 748.5354 - val_loss: 1264.3579\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 950.22260\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 730.7969 - val_loss: 2491.6130\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 950.22260\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 703.9286 - val_loss: 2192.5085\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 950.22260\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 728.0425 - val_loss: 3076.8408\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 950.22260\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 718.0280 - val_loss: 1190.7191\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 950.22260\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 684.9892 - val_loss: 3034.0093\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 950.22260\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 727.9186 - val_loss: 2777.7837\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 950.22260\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 719.3430 - val_loss: 2470.2480\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 950.22260\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 661.6634 - val_loss: 2591.1018\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 950.22260\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 692.5336 - val_loss: 3161.1353\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 950.22260\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 862.0644 - val_loss: 2976.4351\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 950.22260\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 818.3209 - val_loss: 1952.4478\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 950.22260\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 846.9314 - val_loss: 2564.4885\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 950.22260\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 898.0756 - val_loss: 2562.1982\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 950.22260\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 787.2365 - val_loss: 3023.0376\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 950.22260\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 820.8278 - val_loss: 2381.3071\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 950.22260\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 829.1270 - val_loss: 2354.4387\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 950.22260\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 801.3225 - val_loss: 1907.4285\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 950.22260\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 876.7092 - val_loss: 2754.2002\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 950.22260\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 772.3215 - val_loss: 1567.5621\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 950.22260\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 818.3241 - val_loss: 2654.7021\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 950.22260\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 781.1881 - val_loss: 1252.1742\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 950.22260\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 793.4987 - val_loss: 2908.5703\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 950.22260\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 810.3096 - val_loss: 2355.9272\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 950.22260\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 779.6771 - val_loss: 2527.1030\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 950.22260\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 732.7435 - val_loss: 2946.1775\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 950.22260\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 825.3385 - val_loss: 1707.3103\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 950.22260\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 779.5620 - val_loss: 2774.0437\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 950.22260\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 779.7076 - val_loss: 2247.9790\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 950.22260\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 801.3262 - val_loss: 1502.9843\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 950.22260\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 767.3152 - val_loss: 2426.5281\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 950.22260\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 786.7379 - val_loss: 1466.5250\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 950.22260\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 792.7722 - val_loss: 1500.6754\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 950.22260\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 800.3168 - val_loss: 2814.4087\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 950.22260\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 757.1223 - val_loss: 2819.8379\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 950.22260\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 759.7267 - val_loss: 2721.1995\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 950.22260\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 749.3001 - val_loss: 2939.3503\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 950.22260\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 801.5613 - val_loss: 2622.8105\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 950.22260\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 760.2296 - val_loss: 1628.3347\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 950.22260\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 800.5016 - val_loss: 1441.1672\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 950.22260\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 766.7229 - val_loss: 2485.1064\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 950.22260\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 723.1642 - val_loss: 2615.6777\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 950.22260\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 762.2460 - val_loss: 2563.2075\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 950.22260\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 777.2333 - val_loss: 3104.5527\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 950.22260\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 787.0850 - val_loss: 2533.5193\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 950.22260\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 772.4963 - val_loss: 2907.2678\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 950.22260\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 757.9439 - val_loss: 2326.7737\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 950.22260\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 783.2933 - val_loss: 1282.7032\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 950.22260\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 809.7022 - val_loss: 2282.5559\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 950.22260\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 743.5544 - val_loss: 2331.2207\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 950.22260\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 782.2499 - val_loss: 2065.7236\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 950.22260\n",
      "Epoch 153/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 746.8186 - val_loss: 1505.4517\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 950.22260\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 766.3626 - val_loss: 2624.0198\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 950.22260\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 789.6105 - val_loss: 1453.2546\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 950.22260\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 771.2996 - val_loss: 2893.4312\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 950.22260\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 771.4842 - val_loss: 1531.6458\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 950.22260\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 751.3406 - val_loss: 1681.5275\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 950.22260\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 730.8329 - val_loss: 3047.6299\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 950.22260\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 781.6334 - val_loss: 1292.9591\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 950.22260\n",
      "Epoch 161/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 782.3493 - val_loss: 1354.2241\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 950.22260\n",
      "Epoch 162/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 721.9704 - val_loss: 2286.2966\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 950.22260\n",
      "Epoch 163/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 775.0631 - val_loss: 6242.0142\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 950.22260\n",
      "Epoch 164/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 878.2509 - val_loss: 2665.7622\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 950.22260\n",
      "Epoch 165/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 762.1558 - val_loss: 2834.9722\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 950.22260\n",
      "Epoch 166/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 729.3188 - val_loss: 1511.9904\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 950.22260\n",
      "Epoch 167/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 758.0650 - val_loss: 3142.5793\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 950.22260\n",
      "Epoch 168/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 755.1086 - val_loss: 3196.0000\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 950.22260\n",
      "Epoch 169/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 851.2276 - val_loss: 1464.5524\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 950.22260\n",
      "Epoch 170/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 743.1041 - val_loss: 2737.6753\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 950.22260\n",
      "Epoch 171/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 782.0463 - val_loss: 1548.3064\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 950.22260\n",
      "Epoch 172/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 741.3909 - val_loss: 2635.1643\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 950.22260\n",
      "Epoch 173/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 726.9220 - val_loss: 2757.4521\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 950.22260\n",
      "Epoch 174/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 750.2559 - val_loss: 3288.7891\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 950.22260\n",
      "Epoch 175/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 801.6736 - val_loss: 2066.1206\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 950.22260\n",
      "Epoch 176/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 751.3204 - val_loss: 2803.2141\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 950.22260\n",
      "Epoch 177/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 812.3983 - val_loss: 2054.0410\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 950.22260\n",
      "Epoch 178/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 741.7196 - val_loss: 1347.6140\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 950.22260\n",
      "Epoch 179/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 752.0494 - val_loss: 2387.5515\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 950.22260\n",
      "Epoch 180/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 770.0678 - val_loss: 1858.6509\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 950.22260\n",
      "Epoch 181/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 718.5439 - val_loss: 1614.7482\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 950.22260\n",
      "Epoch 182/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 742.1198 - val_loss: 1416.3889\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 950.22260\n",
      "Epoch 183/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 765.2033 - val_loss: 3123.3928\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 950.22260\n",
      "Epoch 184/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 797.2265 - val_loss: 1516.7440\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 950.22260\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 1590.5619 - val_loss: 3208.7122\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3208.71216, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1205.2167 - val_loss: 2016.3074\n",
      "\n",
      "Epoch 00002: val_loss improved from 3208.71216 to 2016.30737, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1189.5277 - val_loss: 1895.0367\n",
      "\n",
      "Epoch 00003: val_loss improved from 2016.30737 to 1895.03674, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1186.4377 - val_loss: 3749.3606\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1895.03674\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1142.3668 - val_loss: 1988.3091\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1895.03674\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1088.2870 - val_loss: 2232.2800\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1895.03674\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1063.3296 - val_loss: 1804.0094\n",
      "\n",
      "Epoch 00007: val_loss improved from 1895.03674 to 1804.00940, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1068.7738 - val_loss: 2930.9189\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1804.00940\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1098.1718 - val_loss: 1105.9548\n",
      "\n",
      "Epoch 00009: val_loss improved from 1804.00940 to 1105.95483, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1042.6991 - val_loss: 2659.0579\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1105.95483\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 984.2520 - val_loss: 2085.3943\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1105.95483\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1036.4937 - val_loss: 2321.4629\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1105.95483\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1029.9448 - val_loss: 1617.5208\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1105.95483\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 927.1573 - val_loss: 2310.1543\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1105.95483\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 989.2507 - val_loss: 3120.8752\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1105.95483\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1009.0963 - val_loss: 2694.6897\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1105.95483\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 833.1971 - val_loss: 2022.2616\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1105.95483\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 891.4127 - val_loss: 2079.2839\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1105.95483\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 853.5491 - val_loss: 3523.1357\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1105.95483\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 915.3829 - val_loss: 2343.1477\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1105.95483\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 883.3896 - val_loss: 2608.7979\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1105.95483\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 904.9830 - val_loss: 2542.3564\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1105.95483\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 866.7583 - val_loss: 1985.4282\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1105.95483\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 888.7368 - val_loss: 3267.8743\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1105.95483\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 918.6127 - val_loss: 3112.6272\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1105.95483\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 953.9789 - val_loss: 2155.5947\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1105.95483\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 922.9698 - val_loss: 1514.9042\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1105.95483\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 883.7865 - val_loss: 3219.7197\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1105.95483\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 900.3835 - val_loss: 3317.7668\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1105.95483\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 927.2963 - val_loss: 3103.8508\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1105.95483\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 797.2062 - val_loss: 3141.3450\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1105.95483\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 876.8051 - val_loss: 1277.7767\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1105.95483\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 840.0743 - val_loss: 2687.2881\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1105.95483\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 830.1871 - val_loss: 2839.5320\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1105.95483\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 852.0331 - val_loss: 2304.7922\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1105.95483\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 770.8490 - val_loss: 3536.6357\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1105.95483\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 816.3069 - val_loss: 3354.1582\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1105.95483\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 798.7093 - val_loss: 1075.8761\n",
      "\n",
      "Epoch 00038: val_loss improved from 1105.95483 to 1075.87610, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 817.1779 - val_loss: 2779.0725\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1075.87610\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 790.1048 - val_loss: 2423.5979\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1075.87610\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 782.2224 - val_loss: 3619.2275\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1075.87610\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 846.9606 - val_loss: 1722.3999\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1075.87610\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 769.3622 - val_loss: 2104.0779\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1075.87610\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 783.0685 - val_loss: 3674.5459\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1075.87610\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 805.4368 - val_loss: 3455.6829\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1075.87610\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 786.5304 - val_loss: 2442.7246\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1075.87610\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 815.5425 - val_loss: 3168.5715\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1075.87610\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 822.2411 - val_loss: 3423.3552\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1075.87610\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 746.7244 - val_loss: 3113.6584\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1075.87610\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 788.8450 - val_loss: 2138.3057\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1075.87610\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 777.3400 - val_loss: 3173.7622\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1075.87610\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 757.2221 - val_loss: 2483.6348\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1075.87610\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 755.6877 - val_loss: 1805.3896\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1075.87610\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 749.3983 - val_loss: 2716.0986\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1075.87610\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 819.5311 - val_loss: 2807.2185\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1075.87610\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 759.4880 - val_loss: 3425.3213\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1075.87610\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 772.8677 - val_loss: 3114.3975\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1075.87610\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 776.3221 - val_loss: 3367.3694\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1075.87610\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 755.3406 - val_loss: 3179.9133\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1075.87610\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 765.4777 - val_loss: 3004.7107\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1075.87610\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 770.7000 - val_loss: 2452.2249\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1075.87610\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 752.5121 - val_loss: 2135.0706\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1075.87610\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 773.8531 - val_loss: 2761.5085\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1075.87610\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 711.2303 - val_loss: 2854.7769\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1075.87610\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 749.7443 - val_loss: 2513.5479\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1075.87610\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 741.8372 - val_loss: 3369.4272\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1075.87610\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 744.5521 - val_loss: 2746.9788\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1075.87610\n",
      "Epoch 68/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 755.9272 - val_loss: 3220.9609\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1075.87610\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 684.2384 - val_loss: 3230.7429\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1075.87610\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 718.9922 - val_loss: 2701.3740\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1075.87610\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 730.9252 - val_loss: 3109.6448\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1075.87610\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 744.6554 - val_loss: 2743.2654\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1075.87610\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 715.3165 - val_loss: 2156.5017\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1075.87610\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 706.8314 - val_loss: 2472.7222\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1075.87610\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 755.2104 - val_loss: 2554.8438\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1075.87610\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 700.6065 - val_loss: 2910.7622\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1075.87610\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 705.7784 - val_loss: 2139.8118\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1075.87610\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 726.1483 - val_loss: 2814.8552\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1075.87610\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 648.8939 - val_loss: 2174.2402\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1075.87610\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 678.2759 - val_loss: 2707.4126\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1075.87610\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 698.1637 - val_loss: 2488.3413\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1075.87610\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 669.4420 - val_loss: 2903.4937\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1075.87610\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 691.4424 - val_loss: 3039.5811\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1075.87610\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 691.6042 - val_loss: 2836.5830\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1075.87610\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 626.5756 - val_loss: 2678.4663\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1075.87610\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 670.9880 - val_loss: 2525.9824\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1075.87610\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 647.5200 - val_loss: 2348.1492\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1075.87610\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 665.8078 - val_loss: 2314.2854\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1075.87610\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 634.8114 - val_loss: 2587.1956\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1075.87610\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 657.3016 - val_loss: 2871.4053\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1075.87610\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 667.5114 - val_loss: 3078.8027\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1075.87610\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 615.7118 - val_loss: 3016.3965\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1075.87610\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 639.0349 - val_loss: 2595.2881\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1075.87610\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 624.6086 - val_loss: 2933.3962\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1075.87610\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 660.1671 - val_loss: 2919.7993\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1075.87610\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 683.9258 - val_loss: 2741.0583\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1075.87610\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 667.0856 - val_loss: 1636.3186\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1075.87610\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 664.2256 - val_loss: 1987.4576\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1075.87610\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 649.6516 - val_loss: 2414.3252\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1075.87610\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 674.3138 - val_loss: 2547.1855\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1075.87610\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 692.4644 - val_loss: 3163.1650\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1075.87610\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 653.3467 - val_loss: 2586.0525\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1075.87610\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 652.7892 - val_loss: 3157.8203\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1075.87610\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 668.1642 - val_loss: 2085.9895\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1075.87610\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 642.3925 - val_loss: 1836.6741\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1075.87610\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 694.2048 - val_loss: 1734.7516\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1075.87610\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 650.3206 - val_loss: 2971.9622\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1075.87610\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 654.0231 - val_loss: 2755.8118\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1075.87610\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 677.3222 - val_loss: 2601.5273\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1075.87610\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 628.0564 - val_loss: 2653.9587\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1075.87610\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 679.0233 - val_loss: 2881.5605\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1075.87610\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 687.6311 - val_loss: 2193.7798\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1075.87610\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 645.4654 - val_loss: 3162.1707\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1075.87610\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 644.1870 - val_loss: 1583.7253\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1075.87610\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 621.5294 - val_loss: 2758.1509\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1075.87610\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 639.2968 - val_loss: 2697.8872\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1075.87610\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 635.0730 - val_loss: 2496.1438\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1075.87610\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 647.7587 - val_loss: 1626.6390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00118: val_loss did not improve from 1075.87610\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 638.1159 - val_loss: 2136.8860\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1075.87610\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 638.2067 - val_loss: 3036.8306\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1075.87610\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 641.9133 - val_loss: 2510.0552\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1075.87610\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 654.9980 - val_loss: 2721.9390\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1075.87610\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 610.5696 - val_loss: 1773.9921\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1075.87610\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 635.8834 - val_loss: 2657.0125\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1075.87610\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 625.4445 - val_loss: 2875.8804\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1075.87610\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 612.1526 - val_loss: 2252.7361\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1075.87610\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 621.3713 - val_loss: 1646.8560\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1075.87610\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 640.7955 - val_loss: 1942.3650\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1075.87610\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 642.0109 - val_loss: 1851.3300\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1075.87610\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 641.9292 - val_loss: 1767.0275\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1075.87610\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 633.2880 - val_loss: 2699.8953\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1075.87610\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 622.6362 - val_loss: 3147.3401\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1075.87610\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 630.8234 - val_loss: 2792.9150\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1075.87610\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 622.5220 - val_loss: 2566.9587\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1075.87610\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 667.6038 - val_loss: 2450.8157\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1075.87610\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 639.4677 - val_loss: 2505.7554\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1075.87610\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 645.3784 - val_loss: 3045.2212\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1075.87610\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 612.1188 - val_loss: 1352.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▍                                      | 11/21 [21:46<19:23, 116.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00138: val_loss did not improve from 1075.87610\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 1061.8801 - val_loss: 1504.3572\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1504.35718, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 524.9359 - val_loss: 621.9421\n",
      "\n",
      "Epoch 00002: val_loss improved from 1504.35718 to 621.94214, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 251.3542 - val_loss: 184.6658\n",
      "\n",
      "Epoch 00003: val_loss improved from 621.94214 to 184.66582, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 274.1008 - val_loss: 512.8211\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 184.66582\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 255.3264 - val_loss: 395.2737\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 184.66582\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.3237 - val_loss: 229.4637\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 184.66582\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 248.5549 - val_loss: 195.6546\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 184.66582\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 274.8566 - val_loss: 454.0569\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 184.66582\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 285.6591 - val_loss: 169.1721\n",
      "\n",
      "Epoch 00009: val_loss improved from 184.66582 to 169.17215, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 256.9525 - val_loss: 183.3638\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 169.17215\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 261.8452 - val_loss: 340.6200\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 169.17215\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 260.6556 - val_loss: 396.2901\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 169.17215\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 263.8008 - val_loss: 519.1965\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 169.17215\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 263.9501 - val_loss: 197.9340\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 169.17215\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.3955 - val_loss: 461.0722\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 169.17215\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 254.5209 - val_loss: 391.4740\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 169.17215\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 265.0154 - val_loss: 341.7247\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 169.17215\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 275.7997 - val_loss: 338.4464\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 169.17215\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 263.0100 - val_loss: 400.7295\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 169.17215\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 262.3919 - val_loss: 752.5107\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 169.17215\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 259.7435 - val_loss: 341.0707\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 169.17215\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.6352 - val_loss: 635.6372\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 169.17215\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.5999 - val_loss: 279.1062\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 169.17215\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.2390 - val_loss: 209.5434\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 169.17215\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 240.3213 - val_loss: 496.9857\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 169.17215\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 249.1998 - val_loss: 768.4105\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 169.17215\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 251.9971 - val_loss: 393.1237\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 169.17215\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 243.3158 - val_loss: 191.9650\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 169.17215\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.5333 - val_loss: 434.4344\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 169.17215\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 243.4541 - val_loss: 170.1328\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 169.17215\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 247.4055 - val_loss: 438.9498\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 169.17215\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 231.7529 - val_loss: 749.3190\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 169.17215\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 245.5754 - val_loss: 478.0081\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 169.17215\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 246.4226 - val_loss: 514.4053\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 169.17215\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.5699 - val_loss: 186.9733\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 169.17215\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 244.8672 - val_loss: 382.3665\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 169.17215\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 250.9049 - val_loss: 175.3933\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 169.17215\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 997us/step - loss: 232.4983 - val_loss: 241.9180\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 169.17215\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.0928 - val_loss: 653.4073\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 169.17215\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 241.5991 - val_loss: 194.4411\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 169.17215\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 244.8788 - val_loss: 466.6605\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 169.17215\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.2283 - val_loss: 209.5092\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 169.17215\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 240.8284 - val_loss: 206.2746\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 169.17215\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 240.9832 - val_loss: 760.8947\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 169.17215\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 240.0256 - val_loss: 791.7461\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 169.17215\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.7221 - val_loss: 222.0255\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 169.17215\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 222.2362 - val_loss: 424.2257\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 169.17215\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.6673 - val_loss: 169.4390\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 169.17215\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.7012 - val_loss: 228.7214\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 169.17215\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 213.0952 - val_loss: 169.5513\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 169.17215\n",
      "Epoch 51/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 236.1239 - val_loss: 575.5221\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 169.17215\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 226.3258 - val_loss: 218.4091\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 169.17215\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 210.3470 - val_loss: 189.2714\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 169.17215\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 227.0383 - val_loss: 637.0951\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 169.17215\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 219.9338 - val_loss: 628.6094\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 169.17215\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 218.8933 - val_loss: 393.1368\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 169.17215\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 237.5502 - val_loss: 659.5696\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 169.17215\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.4105 - val_loss: 764.4684\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 169.17215\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.9307 - val_loss: 166.0318\n",
      "\n",
      "Epoch 00059: val_loss improved from 169.17215 to 166.03183, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 236.5066 - val_loss: 169.6922\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 166.03183\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 213.3220 - val_loss: 442.4325\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 166.03183\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 213.8105 - val_loss: 210.0157\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 166.03183\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 219.4278 - val_loss: 465.8458\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 166.03183\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 200.9921 - val_loss: 338.2487\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 166.03183\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 211.2080 - val_loss: 617.0903\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 166.03183\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 211.6475 - val_loss: 430.2168\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 166.03183\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 195.8468 - val_loss: 608.9893\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 166.03183\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 193.5690 - val_loss: 628.8489\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 166.03183\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 188.4324 - val_loss: 160.8841\n",
      "\n",
      "Epoch 00069: val_loss improved from 166.03183 to 160.88408, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 182.0294 - val_loss: 497.8874\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 160.88408\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 182.0022 - val_loss: 177.1001\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 160.88408\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 150.6125 - val_loss: 177.3304\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 160.88408\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 145.4976 - val_loss: 420.1967\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 160.88408\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 126.8291 - val_loss: 165.3909\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 160.88408\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.9482 - val_loss: 227.0328\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 160.88408\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.3152 - val_loss: 160.7141\n",
      "\n",
      "Epoch 00076: val_loss improved from 160.88408 to 160.71405, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.0370 - val_loss: 170.3868\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 160.71405\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.0620 - val_loss: 188.8253\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 160.71405\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 126.1201 - val_loss: 346.3139\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 160.71405\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 126.6615 - val_loss: 185.9091\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 160.71405\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.9697 - val_loss: 196.5076\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 160.71405\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 126.7186 - val_loss: 254.3366\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 160.71405\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.3750 - val_loss: 250.3489\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 160.71405\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.3505 - val_loss: 160.4246\n",
      "\n",
      "Epoch 00084: val_loss improved from 160.71405 to 160.42456, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.7499 - val_loss: 157.9175\n",
      "\n",
      "Epoch 00085: val_loss improved from 160.42456 to 157.91748, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 120.6740 - val_loss: 220.6156\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 157.91748\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.2247 - val_loss: 161.7582\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 157.91748\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.0673 - val_loss: 253.8284\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 157.91748\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 121.9214 - val_loss: 172.5395\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 157.91748\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.4686 - val_loss: 186.2832\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 157.91748\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 126.3430 - val_loss: 159.3835\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 157.91748\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.6941 - val_loss: 186.0963\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 157.91748\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 121.2120 - val_loss: 157.6461\n",
      "\n",
      "Epoch 00093: val_loss improved from 157.91748 to 157.64615, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.8039 - val_loss: 326.5911\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 157.64615\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.3288 - val_loss: 234.7201\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 157.64615\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 124.3526 - val_loss: 228.1932\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 157.64615\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.4566 - val_loss: 205.8484\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 157.64615\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.2068 - val_loss: 163.7626\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 157.64615\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.3153 - val_loss: 524.9379\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 157.64615\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.2225 - val_loss: 175.5990\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 157.64615\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.6688 - val_loss: 159.7657\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 157.64615\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.2135 - val_loss: 177.0905\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 157.64615\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 123.0789 - val_loss: 164.3694\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 157.64615\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.6731 - val_loss: 335.9550\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 157.64615\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.2883 - val_loss: 188.2286\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 157.64615\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.9176 - val_loss: 187.2823\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 157.64615\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.4958 - val_loss: 195.9192\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 157.64615\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.3735 - val_loss: 180.0263\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 157.64615\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.3609 - val_loss: 397.9673\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 157.64615\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.4927 - val_loss: 169.9096\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 157.64615\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.9077 - val_loss: 271.2530\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 157.64615\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 121.4299 - val_loss: 162.6625\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 157.64615\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 121.6453 - val_loss: 183.0139\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 157.64615\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.0400 - val_loss: 195.1930\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 157.64615\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.0089 - val_loss: 363.8690\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 157.64615\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.5092 - val_loss: 181.1351\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 157.64615\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.0640 - val_loss: 221.9348\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 157.64615\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.1557 - val_loss: 246.6003\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 157.64615\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 121.1916 - val_loss: 157.8856\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 157.64615\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.0593 - val_loss: 205.1098\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 157.64615\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.3149 - val_loss: 183.0505\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 157.64615\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.1594 - val_loss: 452.0959\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 157.64615\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.0506 - val_loss: 275.6879\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 157.64615\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 120.8613 - val_loss: 163.1343\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 157.64615\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 121.0024 - val_loss: 178.0988\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 157.64615\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.0036 - val_loss: 246.4619\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 157.64615\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.1068 - val_loss: 162.2125\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 157.64615\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.1549 - val_loss: 237.3537\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 157.64615\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.7158 - val_loss: 185.3092\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 157.64615\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 119.0298 - val_loss: 176.7045\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 157.64615\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.9882 - val_loss: 160.8407\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 157.64615\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 117.0850 - val_loss: 472.7344\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 157.64615\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 118.0647 - val_loss: 367.3317\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 157.64615\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.1146 - val_loss: 189.0480\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 157.64615\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 116.9281 - val_loss: 480.1211\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 157.64615\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.6018 - val_loss: 162.6977\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 157.64615\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.7720 - val_loss: 167.4233\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 157.64615\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.9715 - val_loss: 158.7686\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 157.64615\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.7404 - val_loss: 214.8425\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 157.64615\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 122.1653 - val_loss: 162.7843\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 157.64615\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.0152 - val_loss: 347.0183\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 157.64615\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 112.9696 - val_loss: 163.1754\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 157.64615\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.6469 - val_loss: 167.9992\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 157.64615\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.9328 - val_loss: 201.2943\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 157.64615\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.9715 - val_loss: 383.8129\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 157.64615\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.4565 - val_loss: 318.5798\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 157.64615\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 112.9695 - val_loss: 160.9830\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 157.64615\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.2764 - val_loss: 205.7267\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 157.64615\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.1574 - val_loss: 278.2740\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 157.64615\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.1720 - val_loss: 168.3118\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 157.64615\n",
      "Epoch 151/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 114.5794 - val_loss: 333.6296\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 157.64615\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.7666 - val_loss: 161.8635\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 157.64615\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.1712 - val_loss: 250.8218\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 157.64615\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.2243 - val_loss: 205.7758\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 157.64615\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.9352 - val_loss: 163.4873\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 157.64615\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 113.0354 - val_loss: 290.3224\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 157.64615\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.7576 - val_loss: 183.7586\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 157.64615\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.4216 - val_loss: 227.8315\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 157.64615\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 115.1098 - val_loss: 181.9496\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 157.64615\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.5088 - val_loss: 193.0741\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 157.64615\n",
      "Epoch 161/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.1312 - val_loss: 168.3130\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 157.64615\n",
      "Epoch 162/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 111.8904 - val_loss: 321.4423\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 157.64615\n",
      "Epoch 163/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.7643 - val_loss: 166.6834\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 157.64615\n",
      "Epoch 164/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.3348 - val_loss: 282.3651\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 157.64615\n",
      "Epoch 165/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.7750 - val_loss: 165.0252\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 157.64615\n",
      "Epoch 166/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.4786 - val_loss: 279.9096\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 157.64615\n",
      "Epoch 167/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.7204 - val_loss: 255.5082\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 157.64615\n",
      "Epoch 168/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.8497 - val_loss: 168.8326\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 157.64615\n",
      "Epoch 169/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 114.0051 - val_loss: 171.8618\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 157.64615\n",
      "Epoch 170/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.1865 - val_loss: 231.6647\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 157.64615\n",
      "Epoch 171/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.1762 - val_loss: 162.8647\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 157.64615\n",
      "Epoch 172/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.9182 - val_loss: 410.7333\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 157.64615\n",
      "Epoch 173/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.1821 - val_loss: 176.3791\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 157.64615\n",
      "Epoch 174/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.5158 - val_loss: 167.5869\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 157.64615\n",
      "Epoch 175/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.8559 - val_loss: 197.4355\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 157.64615\n",
      "Epoch 176/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.6530 - val_loss: 306.1561\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 157.64615\n",
      "Epoch 177/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.5353 - val_loss: 173.9686\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 157.64615\n",
      "Epoch 178/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.2651 - val_loss: 297.3455\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 157.64615\n",
      "Epoch 179/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.7223 - val_loss: 188.0197\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 157.64615\n",
      "Epoch 180/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 108.7551 - val_loss: 184.6756\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 157.64615\n",
      "Epoch 181/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 110.6963 - val_loss: 213.0624\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 157.64615\n",
      "Epoch 182/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.7835 - val_loss: 190.9057\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 157.64615\n",
      "Epoch 183/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.3357 - val_loss: 189.2400\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 157.64615\n",
      "Epoch 184/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.8511 - val_loss: 167.5200\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 157.64615\n",
      "Epoch 185/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.9105 - val_loss: 165.5527\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 157.64615\n",
      "Epoch 186/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 107.7463 - val_loss: 178.1951\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 157.64615\n",
      "Epoch 187/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.0336 - val_loss: 170.6426\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 157.64615\n",
      "Epoch 188/10000\n",
      "89/89 [==============================] - 0s 989us/step - loss: 106.6536 - val_loss: 176.7525\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 157.64615\n",
      "Epoch 189/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.4505 - val_loss: 195.6780\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 157.64615\n",
      "Epoch 190/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.3211 - val_loss: 191.0519\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 157.64615\n",
      "Epoch 191/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 106.3062 - val_loss: 173.5649\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 157.64615\n",
      "Epoch 192/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 109.1618 - val_loss: 255.2159\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 157.64615\n",
      "Epoch 193/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 105.7697 - val_loss: 181.1417\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 157.64615\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 1061.8671 - val_loss: 1490.4653\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1490.46533, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 779us/step - loss: 361.1690 - val_loss: 197.7905\n",
      "\n",
      "Epoch 00002: val_loss improved from 1490.46533 to 197.79054, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 940us/step - loss: 274.0923 - val_loss: 426.0796\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 197.79054\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 896us/step - loss: 252.8407 - val_loss: 419.8208\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 197.79054\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 737us/step - loss: 218.9719 - val_loss: 360.4448\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 197.79054\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 901us/step - loss: 254.3918 - val_loss: 319.0351\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 197.79054\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 848us/step - loss: 249.0710 - val_loss: 225.0894\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 197.79054\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 754us/step - loss: 263.7128 - val_loss: 331.5580\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 197.79054\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 720us/step - loss: 271.3243 - val_loss: 178.4456\n",
      "\n",
      "Epoch 00009: val_loss improved from 197.79054 to 178.44559, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 747us/step - loss: 251.9757 - val_loss: 182.7352\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 178.44559\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 888us/step - loss: 236.8795 - val_loss: 692.0722\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 178.44559\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 921us/step - loss: 264.8780 - val_loss: 598.6025\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 178.44559\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 753us/step - loss: 252.6541 - val_loss: 182.8056\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 178.44559\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 786us/step - loss: 238.8936 - val_loss: 573.6386\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 178.44559\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 760us/step - loss: 260.9217 - val_loss: 484.3625\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 178.44559\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 912us/step - loss: 254.9588 - val_loss: 177.2662\n",
      "\n",
      "Epoch 00016: val_loss improved from 178.44559 to 177.26620, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 911us/step - loss: 228.9518 - val_loss: 176.2207\n",
      "\n",
      "Epoch 00017: val_loss improved from 177.26620 to 176.22075, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 746us/step - loss: 270.7586 - val_loss: 546.3967\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 176.22075\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 749us/step - loss: 237.7267 - val_loss: 257.9151\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 176.22075\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 764us/step - loss: 247.9112 - val_loss: 265.7751\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 176.22075\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 829us/step - loss: 240.8956 - val_loss: 738.6274\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 176.22075\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 952us/step - loss: 255.3290 - val_loss: 602.0786\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 176.22075\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 721us/step - loss: 250.1365 - val_loss: 179.4567\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 176.22075\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 904us/step - loss: 245.5137 - val_loss: 450.9073\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 176.22075\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 897us/step - loss: 253.1268 - val_loss: 185.4561\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 176.22075\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 726us/step - loss: 250.5811 - val_loss: 233.3303\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 176.22075\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 255.2342 - val_loss: 190.3869\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 176.22075\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 252.0238 - val_loss: 245.6751\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 176.22075\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 859us/step - loss: 241.3753 - val_loss: 249.4292\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 176.22075\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 753us/step - loss: 239.3664 - val_loss: 241.3409\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 176.22075\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 933us/step - loss: 256.3383 - val_loss: 358.9363\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 176.22075\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 766us/step - loss: 245.9877 - val_loss: 723.8845\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 176.22075\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 898us/step - loss: 247.1078 - val_loss: 253.1640\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 176.22075\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 946us/step - loss: 247.9722 - val_loss: 222.4083\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 176.22075\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 717us/step - loss: 247.4753 - val_loss: 203.0576\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 176.22075\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 908us/step - loss: 233.9108 - val_loss: 575.0398\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 176.22075\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 723us/step - loss: 245.7064 - val_loss: 650.1442\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 176.22075\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 905us/step - loss: 244.6300 - val_loss: 442.8655\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 176.22075\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 780us/step - loss: 243.1051 - val_loss: 196.5650\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 176.22075\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 857us/step - loss: 223.2637 - val_loss: 716.6841\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 176.22075\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 755us/step - loss: 227.7776 - val_loss: 208.6303\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 176.22075\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 747us/step - loss: 236.5940 - val_loss: 266.3430\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 176.22075\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 917us/step - loss: 246.7573 - val_loss: 180.7773\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 176.22075\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 779us/step - loss: 239.0070 - val_loss: 390.9283\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 176.22075\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 865us/step - loss: 240.0721 - val_loss: 630.9821\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 176.22075\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 883us/step - loss: 247.1311 - val_loss: 205.2024\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 176.22075\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 755us/step - loss: 220.7474 - val_loss: 228.5392\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 176.22075\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 760us/step - loss: 239.5663 - val_loss: 292.9117\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 176.22075\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 732us/step - loss: 229.9472 - val_loss: 349.3607\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 176.22075\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 906us/step - loss: 235.0185 - val_loss: 197.1267\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 176.22075\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 855us/step - loss: 221.1785 - val_loss: 222.4510\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 176.22075\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 749us/step - loss: 228.6064 - val_loss: 289.4145\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 176.22075\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 883us/step - loss: 238.1257 - val_loss: 247.5597\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 176.22075\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 770us/step - loss: 222.9478 - val_loss: 224.5736\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 176.22075\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 871us/step - loss: 230.8302 - val_loss: 261.8716\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 176.22075\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 909us/step - loss: 210.0468 - val_loss: 527.6572\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 176.22075\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 742us/step - loss: 231.5786 - val_loss: 703.4863\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 176.22075\n",
      "Epoch 58/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 964us/step - loss: 220.5061 - val_loss: 274.9658\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 176.22075\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 827us/step - loss: 216.1637 - val_loss: 201.7437\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 176.22075\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 772us/step - loss: 219.9535 - val_loss: 638.4479\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 176.22075\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 903us/step - loss: 203.5505 - val_loss: 498.5211\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 176.22075\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 754us/step - loss: 216.0864 - val_loss: 629.6451\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 176.22075\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 883us/step - loss: 214.9445 - val_loss: 181.6465\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 176.22075\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 775us/step - loss: 208.9975 - val_loss: 186.6482\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 176.22075\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 911us/step - loss: 196.4800 - val_loss: 389.3468\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 176.22075\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 837us/step - loss: 190.7028 - val_loss: 211.9537\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 176.22075\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 799us/step - loss: 198.2702 - val_loss: 312.7131\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 176.22075\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 857us/step - loss: 195.7403 - val_loss: 185.8439\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 176.22075\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 855us/step - loss: 196.4914 - val_loss: 207.1533\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 176.22075\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 832us/step - loss: 189.9320 - val_loss: 180.2579\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 176.22075\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 867us/step - loss: 177.8161 - val_loss: 321.0524\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 176.22075\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 749us/step - loss: 158.9469 - val_loss: 215.1902\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 176.22075\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 931us/step - loss: 152.6982 - val_loss: 471.9787\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 176.22075\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 868us/step - loss: 135.5409 - val_loss: 206.6801\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 176.22075\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 750us/step - loss: 134.8774 - val_loss: 305.5273\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 176.22075\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 925us/step - loss: 133.5535 - val_loss: 179.6354\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 176.22075\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 776us/step - loss: 133.9210 - val_loss: 209.5945\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 176.22075\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 753us/step - loss: 127.5789 - val_loss: 246.0184\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 176.22075\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 936us/step - loss: 132.6024 - val_loss: 242.4166\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 176.22075\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 742us/step - loss: 131.0379 - val_loss: 354.3566\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 176.22075\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 887us/step - loss: 135.4934 - val_loss: 186.5896\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 176.22075\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 725us/step - loss: 131.3827 - val_loss: 215.5590\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 176.22075\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 885us/step - loss: 130.8417 - val_loss: 220.2790\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 176.22075\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 876us/step - loss: 134.6329 - val_loss: 185.5515\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 176.22075\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 755us/step - loss: 127.7784 - val_loss: 305.8871\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 176.22075\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 790us/step - loss: 130.3784 - val_loss: 196.9790\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 176.22075\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 809us/step - loss: 128.6109 - val_loss: 289.8641\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 176.22075\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 817us/step - loss: 132.8346 - val_loss: 210.2540\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 176.22075\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 889us/step - loss: 128.9236 - val_loss: 209.3248\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 176.22075\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 858us/step - loss: 127.5055 - val_loss: 320.6660\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 176.22075\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 740us/step - loss: 125.0502 - val_loss: 217.6218\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 176.22075\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 732us/step - loss: 127.7593 - val_loss: 211.6415\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 176.22075\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 730us/step - loss: 131.0641 - val_loss: 337.0412\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 176.22075\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 810us/step - loss: 127.9380 - val_loss: 308.8387\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 176.22075\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 743us/step - loss: 128.2078 - val_loss: 174.4299\n",
      "\n",
      "Epoch 00095: val_loss improved from 176.22075 to 174.42992, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 953us/step - loss: 130.8938 - val_loss: 304.3310\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 174.42992\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 774us/step - loss: 131.7407 - val_loss: 178.3610\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 174.42992\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 738us/step - loss: 126.4758 - val_loss: 192.0018\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 174.42992\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 897us/step - loss: 127.2601 - val_loss: 186.6111\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 174.42992\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 882us/step - loss: 129.0729 - val_loss: 190.4173\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 174.42992\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 783us/step - loss: 127.6453 - val_loss: 175.0463\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 174.42992\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 779us/step - loss: 128.5068 - val_loss: 196.0688\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 174.42992\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 875us/step - loss: 127.3930 - val_loss: 298.5077\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 174.42992\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 734us/step - loss: 127.4529 - val_loss: 173.3819\n",
      "\n",
      "Epoch 00104: val_loss improved from 174.42992 to 173.38193, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 728us/step - loss: 124.7556 - val_loss: 263.2646\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 173.38193\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 882us/step - loss: 126.7234 - val_loss: 193.6237\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 173.38193\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 839us/step - loss: 123.7695 - val_loss: 314.3127\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 173.38193\n",
      "Epoch 108/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 753us/step - loss: 128.2953 - val_loss: 181.5067\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 173.38193\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 761us/step - loss: 124.9518 - val_loss: 234.4544\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 173.38193\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 937us/step - loss: 122.9195 - val_loss: 232.6036\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 173.38193\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 758us/step - loss: 125.6018 - val_loss: 337.0289\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 173.38193\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 843us/step - loss: 125.9035 - val_loss: 215.2681\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 173.38193\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 777us/step - loss: 125.3505 - val_loss: 225.9713\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 173.38193\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 758us/step - loss: 125.5310 - val_loss: 228.0256\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 173.38193\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 822us/step - loss: 122.4009 - val_loss: 235.3439\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 173.38193\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 883us/step - loss: 124.3050 - val_loss: 248.0255\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 173.38193\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 736us/step - loss: 122.6929 - val_loss: 185.6241\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 173.38193\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 883us/step - loss: 123.1466 - val_loss: 201.2034\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 173.38193\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 881us/step - loss: 127.5418 - val_loss: 186.1472\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 173.38193\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 791us/step - loss: 121.8345 - val_loss: 182.4679\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 173.38193\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 808us/step - loss: 120.1705 - val_loss: 180.9149\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 173.38193\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 893us/step - loss: 126.6458 - val_loss: 232.2206\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 173.38193\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 757us/step - loss: 123.8041 - val_loss: 227.3947\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 173.38193\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 859us/step - loss: 122.0279 - val_loss: 173.0876\n",
      "\n",
      "Epoch 00124: val_loss improved from 173.38193 to 173.08760, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 899us/step - loss: 122.8255 - val_loss: 226.6646\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 173.08760\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 850us/step - loss: 121.0240 - val_loss: 270.4131\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 173.08760\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 809us/step - loss: 121.7430 - val_loss: 249.1718\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 173.08760\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 973us/step - loss: 121.8866 - val_loss: 243.6494\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 173.08760\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 871us/step - loss: 119.5783 - val_loss: 178.3015\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 173.08760\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 835us/step - loss: 117.8155 - val_loss: 212.4536\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 173.08760\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 770us/step - loss: 121.8189 - val_loss: 260.2075\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 173.08760\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 888us/step - loss: 121.8666 - val_loss: 259.8522\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 173.08760\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 746us/step - loss: 119.7101 - val_loss: 172.5126\n",
      "\n",
      "Epoch 00133: val_loss improved from 173.08760 to 172.51257, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - ETA: 0s - loss: 119.284 - 0s 766us/step - loss: 120.3250 - val_loss: 173.6201\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 172.51257\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 947us/step - loss: 123.3224 - val_loss: 210.8237\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 172.51257\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 742us/step - loss: 118.1653 - val_loss: 386.3942\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 172.51257\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 877us/step - loss: 119.4499 - val_loss: 225.5869\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 172.51257\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 907us/step - loss: 120.8753 - val_loss: 176.8228\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 172.51257\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 754us/step - loss: 118.8736 - val_loss: 177.9441\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 172.51257\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 916us/step - loss: 119.2303 - val_loss: 223.7137\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 172.51257\n",
      "Epoch 141/10000\n",
      "88/88 [==============================] - 0s 915us/step - loss: 123.2682 - val_loss: 250.0312\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 172.51257\n",
      "Epoch 142/10000\n",
      "88/88 [==============================] - 0s 811us/step - loss: 119.5139 - val_loss: 210.6080\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 172.51257\n",
      "Epoch 143/10000\n",
      "88/88 [==============================] - 0s 793us/step - loss: 123.0900 - val_loss: 196.7500\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 172.51257\n",
      "Epoch 144/10000\n",
      "88/88 [==============================] - 0s 867us/step - loss: 118.0575 - val_loss: 238.1233\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 172.51257\n",
      "Epoch 145/10000\n",
      "88/88 [==============================] - 0s 882us/step - loss: 122.3342 - val_loss: 208.5866\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 172.51257\n",
      "Epoch 146/10000\n",
      "88/88 [==============================] - 0s 745us/step - loss: 118.9014 - val_loss: 280.1956\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 172.51257\n",
      "Epoch 147/10000\n",
      "88/88 [==============================] - 0s 756us/step - loss: 119.4192 - val_loss: 294.5611\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 172.51257\n",
      "Epoch 148/10000\n",
      "88/88 [==============================] - 0s 738us/step - loss: 116.0608 - val_loss: 233.9633\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 172.51257\n",
      "Epoch 149/10000\n",
      "88/88 [==============================] - 0s 961us/step - loss: 118.7046 - val_loss: 172.3949\n",
      "\n",
      "Epoch 00149: val_loss improved from 172.51257 to 172.39488, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 150/10000\n",
      "88/88 [==============================] - 0s 775us/step - loss: 122.4541 - val_loss: 176.3145\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 172.39488\n",
      "Epoch 151/10000\n",
      "88/88 [==============================] - 0s 811us/step - loss: 119.4322 - val_loss: 239.9081\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 172.39488\n",
      "Epoch 152/10000\n",
      "88/88 [==============================] - 0s 875us/step - loss: 116.7686 - val_loss: 185.7400\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 172.39488\n",
      "Epoch 153/10000\n",
      "88/88 [==============================] - 0s 807us/step - loss: 116.4994 - val_loss: 271.8964\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 172.39488\n",
      "Epoch 154/10000\n",
      "88/88 [==============================] - 0s 747us/step - loss: 118.6922 - val_loss: 187.7945\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 172.39488\n",
      "Epoch 155/10000\n",
      "88/88 [==============================] - 0s 912us/step - loss: 115.8680 - val_loss: 173.9426\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 172.39488\n",
      "Epoch 156/10000\n",
      "88/88 [==============================] - 0s 799us/step - loss: 117.0746 - val_loss: 228.4388\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 172.39488\n",
      "Epoch 157/10000\n",
      "88/88 [==============================] - 0s 779us/step - loss: 116.7814 - val_loss: 294.4581\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 172.39488\n",
      "Epoch 158/10000\n",
      "88/88 [==============================] - 0s 858us/step - loss: 119.0925 - val_loss: 183.9601\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 172.39488\n",
      "Epoch 159/10000\n",
      "88/88 [==============================] - 0s 744us/step - loss: 116.9691 - val_loss: 258.0013\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 172.39488\n",
      "Epoch 160/10000\n",
      "88/88 [==============================] - 0s 744us/step - loss: 115.7085 - val_loss: 173.3564\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 172.39488\n",
      "Epoch 161/10000\n",
      "88/88 [==============================] - 0s 744us/step - loss: 116.6718 - val_loss: 192.6381\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 172.39488\n",
      "Epoch 162/10000\n",
      "88/88 [==============================] - 0s 961us/step - loss: 118.9231 - val_loss: 307.2066\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 172.39488\n",
      "Epoch 163/10000\n",
      "88/88 [==============================] - 0s 756us/step - loss: 118.0048 - val_loss: 209.9844\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 172.39488\n",
      "Epoch 164/10000\n",
      "88/88 [==============================] - 0s 895us/step - loss: 116.3985 - val_loss: 266.7133\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 172.39488\n",
      "Epoch 165/10000\n",
      "88/88 [==============================] - 0s 751us/step - loss: 114.8828 - val_loss: 257.0808\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 172.39488\n",
      "Epoch 166/10000\n",
      "88/88 [==============================] - 0s 747us/step - loss: 115.3340 - val_loss: 270.2408\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 172.39488\n",
      "Epoch 167/10000\n",
      "88/88 [==============================] - 0s 914us/step - loss: 115.3273 - val_loss: 215.3027\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 172.39488\n",
      "Epoch 168/10000\n",
      "88/88 [==============================] - 0s 978us/step - loss: 113.8286 - val_loss: 190.2016\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 172.39488\n",
      "Epoch 169/10000\n",
      "88/88 [==============================] - 0s 772us/step - loss: 118.3079 - val_loss: 192.2913\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 172.39488\n",
      "Epoch 170/10000\n",
      "88/88 [==============================] - 0s 824us/step - loss: 115.0688 - val_loss: 177.9102\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 172.39488\n",
      "Epoch 171/10000\n",
      "88/88 [==============================] - 0s 856us/step - loss: 114.3054 - val_loss: 205.6606\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 172.39488\n",
      "Epoch 172/10000\n",
      "88/88 [==============================] - 0s 729us/step - loss: 113.9411 - val_loss: 238.9776\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 172.39488\n",
      "Epoch 173/10000\n",
      "88/88 [==============================] - 0s 776us/step - loss: 114.8132 - val_loss: 183.4251\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 172.39488\n",
      "Epoch 174/10000\n",
      "88/88 [==============================] - 0s 839us/step - loss: 113.1884 - val_loss: 176.7986\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 172.39488\n",
      "Epoch 175/10000\n",
      "88/88 [==============================] - 0s 785us/step - loss: 113.7682 - val_loss: 183.4650\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 172.39488\n",
      "Epoch 176/10000\n",
      "88/88 [==============================] - 0s 885us/step - loss: 113.9689 - val_loss: 334.7213\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 172.39488\n",
      "Epoch 177/10000\n",
      "88/88 [==============================] - 0s 742us/step - loss: 113.2060 - val_loss: 188.1674\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 172.39488\n",
      "Epoch 178/10000\n",
      "88/88 [==============================] - 0s 781us/step - loss: 114.4579 - val_loss: 192.5025\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 172.39488\n",
      "Epoch 179/10000\n",
      "88/88 [==============================] - 0s 872us/step - loss: 116.2388 - val_loss: 171.5248\n",
      "\n",
      "Epoch 00179: val_loss improved from 172.39488 to 171.52481, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 180/10000\n",
      "88/88 [==============================] - 0s 806us/step - loss: 112.9436 - val_loss: 187.2088\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 171.52481\n",
      "Epoch 181/10000\n",
      "88/88 [==============================] - 0s 746us/step - loss: 112.0664 - val_loss: 173.8198\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 171.52481\n",
      "Epoch 182/10000\n",
      "88/88 [==============================] - 0s 753us/step - loss: 113.0069 - val_loss: 184.3876\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 171.52481\n",
      "Epoch 183/10000\n",
      "88/88 [==============================] - 0s 879us/step - loss: 109.8805 - val_loss: 176.7348\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 171.52481\n",
      "Epoch 184/10000\n",
      "88/88 [==============================] - 0s 742us/step - loss: 111.6132 - val_loss: 183.3291\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 171.52481\n",
      "Epoch 185/10000\n",
      "88/88 [==============================] - 0s 883us/step - loss: 112.0685 - val_loss: 181.5391\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 171.52481\n",
      "Epoch 186/10000\n",
      "88/88 [==============================] - 0s 748us/step - loss: 113.8517 - val_loss: 181.4422\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 171.52481\n",
      "Epoch 187/10000\n",
      "88/88 [==============================] - 0s 757us/step - loss: 111.8703 - val_loss: 194.3073\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 171.52481\n",
      "Epoch 188/10000\n",
      "88/88 [==============================] - 0s 897us/step - loss: 113.6776 - val_loss: 241.6465\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 171.52481\n",
      "Epoch 189/10000\n",
      "88/88 [==============================] - 0s 763us/step - loss: 111.9465 - val_loss: 214.3079\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 171.52481\n",
      "Epoch 190/10000\n",
      "88/88 [==============================] - 0s 851us/step - loss: 111.7118 - val_loss: 170.8048\n",
      "\n",
      "Epoch 00190: val_loss improved from 171.52481 to 170.80478, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 191/10000\n",
      "88/88 [==============================] - 0s 903us/step - loss: 112.4420 - val_loss: 237.9783\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 170.80478\n",
      "Epoch 192/10000\n",
      "88/88 [==============================] - 0s 743us/step - loss: 110.5996 - val_loss: 173.7673\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 170.80478\n",
      "Epoch 193/10000\n",
      "88/88 [==============================] - 0s 950us/step - loss: 112.5393 - val_loss: 179.7729\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 170.80478\n",
      "Epoch 194/10000\n",
      "88/88 [==============================] - 0s 797us/step - loss: 112.6567 - val_loss: 420.9992\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 170.80478\n",
      "Epoch 195/10000\n",
      "88/88 [==============================] - 0s 928us/step - loss: 110.8856 - val_loss: 177.0137\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 170.80478\n",
      "Epoch 196/10000\n",
      "88/88 [==============================] - 0s 901us/step - loss: 109.5562 - val_loss: 179.6734\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 170.80478\n",
      "Epoch 197/10000\n",
      "88/88 [==============================] - 0s 866us/step - loss: 110.6309 - val_loss: 188.6410\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 170.80478\n",
      "Epoch 198/10000\n",
      "88/88 [==============================] - 0s 756us/step - loss: 109.2502 - val_loss: 183.1663\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 170.80478\n",
      "Epoch 199/10000\n",
      "88/88 [==============================] - 0s 905us/step - loss: 111.3530 - val_loss: 235.6368\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 170.80478\n",
      "Epoch 200/10000\n",
      "88/88 [==============================] - 0s 745us/step - loss: 108.4688 - val_loss: 179.9751\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 170.80478\n",
      "Epoch 201/10000\n",
      "88/88 [==============================] - 0s 745us/step - loss: 111.0836 - val_loss: 187.0593\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 170.80478\n",
      "Epoch 202/10000\n",
      "88/88 [==============================] - 0s 750us/step - loss: 108.3642 - val_loss: 274.9377\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 170.80478\n",
      "Epoch 203/10000\n",
      "88/88 [==============================] - 0s 953us/step - loss: 110.0895 - val_loss: 195.6522\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 170.80478\n",
      "Epoch 204/10000\n",
      "88/88 [==============================] - 0s 819us/step - loss: 109.7172 - val_loss: 228.4785\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 170.80478\n",
      "Epoch 205/10000\n",
      "88/88 [==============================] - 0s 754us/step - loss: 109.3182 - val_loss: 189.2909\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 170.80478\n",
      "Epoch 206/10000\n",
      "88/88 [==============================] - 0s 890us/step - loss: 111.3114 - val_loss: 188.9987\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 170.80478\n",
      "Epoch 207/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 856us/step - loss: 111.6942 - val_loss: 237.3742\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 170.80478\n",
      "Epoch 208/10000\n",
      "88/88 [==============================] - 0s 761us/step - loss: 107.2703 - val_loss: 181.7831\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 170.80478\n",
      "Epoch 209/10000\n",
      "88/88 [==============================] - 0s 902us/step - loss: 109.0766 - val_loss: 210.2976\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 170.80478\n",
      "Epoch 210/10000\n",
      "88/88 [==============================] - 0s 858us/step - loss: 109.6132 - val_loss: 283.1753\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 170.80478\n",
      "Epoch 211/10000\n",
      "88/88 [==============================] - 0s 724us/step - loss: 108.8423 - val_loss: 254.0936\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 170.80478\n",
      "Epoch 212/10000\n",
      "88/88 [==============================] - 0s 875us/step - loss: 106.6567 - val_loss: 215.3371\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 170.80478\n",
      "Epoch 213/10000\n",
      "88/88 [==============================] - 0s 830us/step - loss: 107.8269 - val_loss: 175.0046\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 170.80478\n",
      "Epoch 214/10000\n",
      "88/88 [==============================] - 0s 759us/step - loss: 106.4593 - val_loss: 221.9447\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 170.80478\n",
      "Epoch 215/10000\n",
      "88/88 [==============================] - 0s 753us/step - loss: 107.9203 - val_loss: 181.7317\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 170.80478\n",
      "Epoch 216/10000\n",
      "88/88 [==============================] - 0s 740us/step - loss: 105.7179 - val_loss: 192.7222\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 170.80478\n",
      "Epoch 217/10000\n",
      "88/88 [==============================] - 0s 973us/step - loss: 107.4663 - val_loss: 235.4026\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 170.80478\n",
      "Epoch 218/10000\n",
      "88/88 [==============================] - 0s 770us/step - loss: 105.5041 - val_loss: 188.6570\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 170.80478\n",
      "Epoch 219/10000\n",
      "88/88 [==============================] - 0s 780us/step - loss: 108.6464 - val_loss: 208.7345\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 170.80478\n",
      "Epoch 220/10000\n",
      "88/88 [==============================] - 0s 887us/step - loss: 107.5241 - val_loss: 217.0342\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 170.80478\n",
      "Epoch 221/10000\n",
      "88/88 [==============================] - 0s 977us/step - loss: 108.5442 - val_loss: 219.9541\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 170.80478\n",
      "Epoch 222/10000\n",
      "88/88 [==============================] - 0s 756us/step - loss: 106.6633 - val_loss: 195.5653\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 170.80478\n",
      "Epoch 223/10000\n",
      "88/88 [==============================] - 0s 881us/step - loss: 107.7305 - val_loss: 237.8501\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 170.80478\n",
      "Epoch 224/10000\n",
      "88/88 [==============================] - 0s 858us/step - loss: 105.9179 - val_loss: 258.5986\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 170.80478\n",
      "Epoch 225/10000\n",
      "88/88 [==============================] - 0s 746us/step - loss: 104.1481 - val_loss: 251.3071\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 170.80478\n",
      "Epoch 226/10000\n",
      "88/88 [==============================] - 0s 905us/step - loss: 107.0465 - val_loss: 201.1294\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 170.80478\n",
      "Epoch 227/10000\n",
      "88/88 [==============================] - 0s 792us/step - loss: 107.8289 - val_loss: 203.3162\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 170.80478\n",
      "Epoch 228/10000\n",
      "88/88 [==============================] - 0s 762us/step - loss: 104.1326 - val_loss: 181.9717\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 170.80478\n",
      "Epoch 229/10000\n",
      "88/88 [==============================] - 0s 847us/step - loss: 105.6377 - val_loss: 246.7754\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 170.80478\n",
      "Epoch 230/10000\n",
      "88/88 [==============================] - 0s 755us/step - loss: 106.6431 - val_loss: 235.2336\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 170.80478\n",
      "Epoch 231/10000\n",
      "88/88 [==============================] - 0s 741us/step - loss: 108.9155 - val_loss: 252.3577\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 170.80478\n",
      "Epoch 232/10000\n",
      "88/88 [==============================] - 0s 995us/step - loss: 104.6544 - val_loss: 209.4828\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 170.80478\n",
      "Epoch 233/10000\n",
      "88/88 [==============================] - 0s 867us/step - loss: 105.3119 - val_loss: 202.6491\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 170.80478\n",
      "Epoch 234/10000\n",
      "88/88 [==============================] - 0s 770us/step - loss: 107.2312 - val_loss: 177.4234\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 170.80478\n",
      "Epoch 235/10000\n",
      "88/88 [==============================] - 0s 886us/step - loss: 104.5840 - val_loss: 189.8571\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 170.80478\n",
      "Epoch 236/10000\n",
      "88/88 [==============================] - 0s 886us/step - loss: 104.8473 - val_loss: 226.0704\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 170.80478\n",
      "Epoch 237/10000\n",
      "88/88 [==============================] - 0s 746us/step - loss: 103.9381 - val_loss: 260.9155\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 170.80478\n",
      "Epoch 238/10000\n",
      "88/88 [==============================] - 0s 873us/step - loss: 105.1474 - val_loss: 210.1952\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 170.80478\n",
      "Epoch 239/10000\n",
      "88/88 [==============================] - 0s 895us/step - loss: 105.3527 - val_loss: 179.7347\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 170.80478\n",
      "Epoch 240/10000\n",
      "88/88 [==============================] - 0s 758us/step - loss: 103.9803 - val_loss: 183.3934\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 170.80478\n",
      "Epoch 241/10000\n",
      "88/88 [==============================] - 0s 899us/step - loss: 105.7709 - val_loss: 173.5774\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 170.80478\n",
      "Epoch 242/10000\n",
      "88/88 [==============================] - 0s 896us/step - loss: 106.1141 - val_loss: 285.3089\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 170.80478\n",
      "Epoch 243/10000\n",
      "88/88 [==============================] - 0s 751us/step - loss: 102.9238 - val_loss: 183.1231\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 170.80478\n",
      "Epoch 244/10000\n",
      "88/88 [==============================] - 0s 896us/step - loss: 104.0797 - val_loss: 254.4765\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 170.80478\n",
      "Epoch 245/10000\n",
      "88/88 [==============================] - 0s 855us/step - loss: 101.2871 - val_loss: 199.3009\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 170.80478\n",
      "Epoch 246/10000\n",
      "88/88 [==============================] - 0s 766us/step - loss: 105.1311 - val_loss: 192.6311\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 170.80478\n",
      "Epoch 247/10000\n",
      "88/88 [==============================] - 0s 946us/step - loss: 105.0066 - val_loss: 233.6257\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 170.80478\n",
      "Epoch 248/10000\n",
      "88/88 [==============================] - 0s 850us/step - loss: 104.6936 - val_loss: 177.8434\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 170.80478\n",
      "Epoch 249/10000\n",
      "88/88 [==============================] - 0s 907us/step - loss: 104.7849 - val_loss: 176.8121\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 170.80478\n",
      "Epoch 250/10000\n",
      "88/88 [==============================] - 0s 855us/step - loss: 102.8744 - val_loss: 203.1519\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 170.80478\n",
      "Epoch 251/10000\n",
      "88/88 [==============================] - 0s 873us/step - loss: 102.8908 - val_loss: 177.4224\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 170.80478\n",
      "Epoch 252/10000\n",
      "88/88 [==============================] - 0s 885us/step - loss: 101.4149 - val_loss: 197.7417\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 170.80478\n",
      "Epoch 253/10000\n",
      "88/88 [==============================] - 0s 860us/step - loss: 102.0594 - val_loss: 194.7325\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 170.80478\n",
      "Epoch 254/10000\n",
      "88/88 [==============================] - 0s 765us/step - loss: 101.4668 - val_loss: 189.3515\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 170.80478\n",
      "Epoch 255/10000\n",
      "88/88 [==============================] - 0s 869us/step - loss: 103.3209 - val_loss: 181.0999\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 170.80478\n",
      "Epoch 256/10000\n",
      "88/88 [==============================] - 0s 743us/step - loss: 103.5271 - val_loss: 291.6385\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 170.80478\n",
      "Epoch 257/10000\n",
      "88/88 [==============================] - 0s 902us/step - loss: 102.7576 - val_loss: 186.2808\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 170.80478\n",
      "Epoch 258/10000\n",
      "88/88 [==============================] - 0s 748us/step - loss: 102.6505 - val_loss: 183.3048\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 170.80478\n",
      "Epoch 259/10000\n",
      "88/88 [==============================] - 0s 870us/step - loss: 101.4190 - val_loss: 211.1827\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 170.80478\n",
      "Epoch 260/10000\n",
      "88/88 [==============================] - 0s 975us/step - loss: 102.9271 - val_loss: 188.8837\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 170.80478\n",
      "Epoch 261/10000\n",
      "88/88 [==============================] - 0s 753us/step - loss: 101.2520 - val_loss: 181.7693\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 170.80478\n",
      "Epoch 262/10000\n",
      "88/88 [==============================] - 0s 902us/step - loss: 103.3933 - val_loss: 227.1309\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 170.80478\n",
      "Epoch 263/10000\n",
      "88/88 [==============================] - 0s 867us/step - loss: 103.5534 - val_loss: 208.5529\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 170.80478\n",
      "Epoch 264/10000\n",
      "88/88 [==============================] - 0s 733us/step - loss: 100.7130 - val_loss: 315.8072\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 170.80478\n",
      "Epoch 265/10000\n",
      "88/88 [==============================] - 0s 927us/step - loss: 104.8410 - val_loss: 204.7464\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 170.80478\n",
      "Epoch 266/10000\n",
      "88/88 [==============================] - 0s 750us/step - loss: 100.9715 - val_loss: 231.5550\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 170.80478\n",
      "Epoch 267/10000\n",
      "88/88 [==============================] - 0s 875us/step - loss: 101.0407 - val_loss: 209.0078\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 170.80478\n",
      "Epoch 268/10000\n",
      "88/88 [==============================] - 0s 883us/step - loss: 100.8648 - val_loss: 187.1059\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 170.80478\n",
      "Epoch 269/10000\n",
      "88/88 [==============================] - 0s 751us/step - loss: 102.0387 - val_loss: 230.7870\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 170.80478\n",
      "Epoch 270/10000\n",
      "88/88 [==============================] - 0s 878us/step - loss: 102.2276 - val_loss: 199.8536\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 170.80478\n",
      "Epoch 271/10000\n",
      "88/88 [==============================] - 0s 810us/step - loss: 99.7286 - val_loss: 184.2083\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 170.80478\n",
      "Epoch 272/10000\n",
      "88/88 [==============================] - 0s 855us/step - loss: 100.9646 - val_loss: 247.9512\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 170.80478\n",
      "Epoch 273/10000\n",
      "88/88 [==============================] - 0s 935us/step - loss: 102.7846 - val_loss: 261.4145\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 170.80478\n",
      "Epoch 274/10000\n",
      "88/88 [==============================] - 0s 791us/step - loss: 99.9317 - val_loss: 242.2930\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 170.80478\n",
      "Epoch 275/10000\n",
      "88/88 [==============================] - 0s 949us/step - loss: 102.7411 - val_loss: 184.5039\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 170.80478\n",
      "Epoch 276/10000\n",
      "88/88 [==============================] - 0s 936us/step - loss: 101.2365 - val_loss: 203.3374\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 170.80478\n",
      "Epoch 277/10000\n",
      "88/88 [==============================] - 0s 836us/step - loss: 97.5838 - val_loss: 218.1540\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 170.80478\n",
      "Epoch 278/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 103.3108 - val_loss: 290.7881\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 170.80478\n",
      "Epoch 279/10000\n",
      "88/88 [==============================] - 0s 987us/step - loss: 100.2338 - val_loss: 213.8796\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 170.80478\n",
      "Epoch 280/10000\n",
      "88/88 [==============================] - 0s 884us/step - loss: 99.5092 - val_loss: 192.3378\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 170.80478\n",
      "Epoch 281/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 99.1378 - val_loss: 198.0445\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 170.80478\n",
      "Epoch 282/10000\n",
      "88/88 [==============================] - 0s 984us/step - loss: 101.0955 - val_loss: 267.6835\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 170.80478\n",
      "Epoch 283/10000\n",
      "88/88 [==============================] - 0s 920us/step - loss: 98.7355 - val_loss: 191.1839\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 170.80478\n",
      "Epoch 284/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 100.9225 - val_loss: 191.6889\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 170.80478\n",
      "Epoch 285/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.7490 - val_loss: 244.9660\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 170.80478\n",
      "Epoch 286/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 98.5091 - val_loss: 217.8542\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 170.80478\n",
      "Epoch 287/10000\n",
      "88/88 [==============================] - 0s 987us/step - loss: 99.9837 - val_loss: 182.0755\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 170.80478\n",
      "Epoch 288/10000\n",
      "88/88 [==============================] - 0s 912us/step - loss: 98.4352 - val_loss: 191.1284\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 170.80478\n",
      "Epoch 289/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 101.2781 - val_loss: 192.9162\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 170.80478\n",
      "Epoch 290/10000\n",
      "88/88 [==============================] - 0s 961us/step - loss: 97.3664 - val_loss: 190.6269\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 170.80478\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 1064.0577 - val_loss: 1490.8750\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1490.87500, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 386.2060 - val_loss: 578.1204\n",
      "\n",
      "Epoch 00002: val_loss improved from 1490.87500 to 578.12042, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 996us/step - loss: 264.4364 - val_loss: 216.8411\n",
      "\n",
      "Epoch 00003: val_loss improved from 578.12042 to 216.84108, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 238.5739 - val_loss: 773.6520\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 216.84108\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 249.3712 - val_loss: 191.7397\n",
      "\n",
      "Epoch 00005: val_loss improved from 216.84108 to 191.73975, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 259.2895 - val_loss: 519.3575\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 191.73975\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.2646 - val_loss: 314.1719\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 191.73975\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 253.7589 - val_loss: 917.2502\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 191.73975\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 244.1077 - val_loss: 189.7827\n",
      "\n",
      "Epoch 00009: val_loss improved from 191.73975 to 189.78273, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 254.9695 - val_loss: 480.2865\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 189.78273\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 254.5905 - val_loss: 202.7366\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 189.78273\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 259.8476 - val_loss: 404.0370\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 189.78273\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 246.2666 - val_loss: 188.7565\n",
      "\n",
      "Epoch 00013: val_loss improved from 189.78273 to 188.75655, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 239.5810 - val_loss: 467.8866\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 188.75655\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 245.5830 - val_loss: 901.2994\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 188.75655\n",
      "Epoch 16/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 256.1941 - val_loss: 872.7754\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 188.75655\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 242.8013 - val_loss: 885.0988\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 188.75655\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 243.0428 - val_loss: 831.8521\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 188.75655\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 252.2842 - val_loss: 444.7392\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 188.75655\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 228.3852 - val_loss: 351.9084\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 188.75655\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 254.0278 - val_loss: 278.3362\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 188.75655\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 242.9288 - val_loss: 342.5223\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 188.75655\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 236.3345 - val_loss: 210.0089\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 188.75655\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 237.5137 - val_loss: 183.6664\n",
      "\n",
      "Epoch 00024: val_loss improved from 188.75655 to 183.66638, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 255.2821 - val_loss: 784.6792\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 183.66638\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 241.0706 - val_loss: 288.2252\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 183.66638\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 253.5394 - val_loss: 204.1272\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 183.66638\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 242.9455 - val_loss: 258.1330\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 183.66638\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 249.4736 - val_loss: 211.6243\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 183.66638\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 244.4347 - val_loss: 575.5026\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 183.66638\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 252.4524 - val_loss: 185.1432\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 183.66638\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 253.6054 - val_loss: 217.1530\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 183.66638\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 244.9576 - val_loss: 876.0276\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 183.66638\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 242.0599 - val_loss: 187.8391\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 183.66638\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 235.1298 - val_loss: 778.0253\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 183.66638\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 246.4508 - val_loss: 834.8217\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 183.66638\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 244.7309 - val_loss: 569.4024\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 183.66638\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 246.8941 - val_loss: 695.2358\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 183.66638\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 253.2947 - val_loss: 257.5188\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 183.66638\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 235.8459 - val_loss: 374.0743\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 183.66638\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 247.1983 - val_loss: 840.9453\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 183.66638\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 238.9188 - val_loss: 186.9017\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 183.66638\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 246.1413 - val_loss: 736.5103\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 183.66638\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 240.6344 - val_loss: 187.0912\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 183.66638\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 229.7756 - val_loss: 830.8070\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 183.66638\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 250.9524 - val_loss: 767.7957\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 183.66638\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 224.1893 - val_loss: 299.2377\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 183.66638\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 232.4985 - val_loss: 279.6106\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 183.66638\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 238.0367 - val_loss: 328.5343\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 183.66638\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 239.7660 - val_loss: 508.0781\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 183.66638\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 231.9522 - val_loss: 326.7748\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 183.66638\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 231.2622 - val_loss: 576.9091\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 183.66638\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 223.6086 - val_loss: 242.9012\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 183.66638\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 221.7095 - val_loss: 231.5075\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 183.66638\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 231.4002 - val_loss: 222.5339\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 183.66638\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 236.8192 - val_loss: 195.4261\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 183.66638\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 231.5787 - val_loss: 197.7566\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 183.66638\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 223.2171 - val_loss: 369.6121\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 183.66638\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 214.1922 - val_loss: 186.1890\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 183.66638\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 238.6450 - val_loss: 190.7235\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 183.66638\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 227.5023 - val_loss: 280.6648\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 183.66638\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 230.6622 - val_loss: 200.3508\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 183.66638\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 224.1604 - val_loss: 269.6643\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 183.66638\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 223.6424 - val_loss: 839.5878\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 183.66638\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 222.8449 - val_loss: 726.2363\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 183.66638\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 212.0173 - val_loss: 189.5571\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 183.66638\n",
      "Epoch 67/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 216.9521 - val_loss: 683.2458\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 183.66638\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 225.2774 - val_loss: 263.1483\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 183.66638\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 204.7385 - val_loss: 233.0864\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 183.66638\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 237.1382 - val_loss: 391.9691\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 183.66638\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 213.6671 - val_loss: 217.1716\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 183.66638\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 200.8618 - val_loss: 267.6674\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 183.66638\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 209.2542 - val_loss: 237.4727\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 183.66638\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 211.6045 - val_loss: 183.0668\n",
      "\n",
      "Epoch 00074: val_loss improved from 183.66638 to 183.06683, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 216.6232 - val_loss: 181.9224\n",
      "\n",
      "Epoch 00075: val_loss improved from 183.06683 to 181.92242, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 191.3675 - val_loss: 184.0263\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 181.92242\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 195.1222 - val_loss: 286.0703\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 181.92242\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 988us/step - loss: 215.7566 - val_loss: 200.9240\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 181.92242\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 938us/step - loss: 191.2712 - val_loss: 255.9396\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 181.92242\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 185.3792 - val_loss: 304.7690\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 181.92242\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 187.5419 - val_loss: 385.8310\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 181.92242\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 187.7214 - val_loss: 330.1578\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 181.92242\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 182.2275 - val_loss: 219.1303\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 181.92242\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 186.6361 - val_loss: 606.1662\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 181.92242\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 184.6511 - val_loss: 480.3136\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 181.92242\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 176.0052 - val_loss: 419.9161\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 181.92242\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 172.6799 - val_loss: 268.5965\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 181.92242\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 168.4791 - val_loss: 494.3987\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 181.92242\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 159.1800 - val_loss: 535.6424\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 181.92242\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 155.5096 - val_loss: 181.4545\n",
      "\n",
      "Epoch 00090: val_loss improved from 181.92242 to 181.45447, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 157.3484 - val_loss: 167.3725\n",
      "\n",
      "Epoch 00091: val_loss improved from 181.45447 to 167.37247, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 976us/step - loss: 155.6247 - val_loss: 283.0561\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 167.37247\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 152.6009 - val_loss: 409.7960\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 167.37247\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 154.5964 - val_loss: 242.6954\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 167.37247\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 151.7917 - val_loss: 257.4020\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 167.37247\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 151.5778 - val_loss: 166.2996\n",
      "\n",
      "Epoch 00096: val_loss improved from 167.37247 to 166.29962, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 152.7130 - val_loss: 289.1853\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 166.29962\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 150.8187 - val_loss: 289.1877\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 166.29962\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 149.8400 - val_loss: 171.1830\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 166.29962\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 150.4124 - val_loss: 390.9745\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 166.29962\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.3837 - val_loss: 535.2546\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 166.29962\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.4772 - val_loss: 426.1653\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 166.29962\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 147.7467 - val_loss: 240.6386\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 166.29962\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 150.2816 - val_loss: 331.7026\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 166.29962\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 147.9723 - val_loss: 180.6755\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 166.29962\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 148.6708 - val_loss: 231.6563\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 166.29962\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 150.4311 - val_loss: 223.6313\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 166.29962\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.7315 - val_loss: 177.4627\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 166.29962\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 149.4190 - val_loss: 306.4908\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 166.29962\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.0571 - val_loss: 184.2860\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 166.29962\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 147.8834 - val_loss: 200.2448\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 166.29962\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.7239 - val_loss: 182.4734\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 166.29962\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.7920 - val_loss: 504.9129\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 166.29962\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.5810 - val_loss: 184.9368\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 166.29962\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.6682 - val_loss: 187.4357\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 166.29962\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.1500 - val_loss: 188.3694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00116: val_loss did not improve from 166.29962\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 147.1501 - val_loss: 190.6673\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 166.29962\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.2410 - val_loss: 460.8407\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 166.29962\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.9307 - val_loss: 236.5426\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 166.29962\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 146.4610 - val_loss: 437.8805\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 166.29962\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.3978 - val_loss: 223.1475\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 166.29962\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.2777 - val_loss: 439.3120\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 166.29962\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 147.3524 - val_loss: 183.8798\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 166.29962\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.7411 - val_loss: 244.7187\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 166.29962\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 143.1984 - val_loss: 304.8224\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 166.29962\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.1432 - val_loss: 326.2185\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 166.29962\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 143.8037 - val_loss: 321.4379\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 166.29962\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.3510 - val_loss: 180.5100\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 166.29962\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.6644 - val_loss: 177.5915\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 166.29962\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 145.2941 - val_loss: 296.4742\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 166.29962\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 141.6919 - val_loss: 193.1366\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 166.29962\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 142.6294 - val_loss: 352.5829\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 166.29962\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.9103 - val_loss: 269.7151\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 166.29962\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.6542 - val_loss: 240.1476\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 166.29962\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.1687 - val_loss: 171.5358\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 166.29962\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 138.9242 - val_loss: 201.5257\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 166.29962\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.6156 - val_loss: 275.3444\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 166.29962\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 141.2362 - val_loss: 464.7878\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 166.29962\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.9178 - val_loss: 198.6953\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 166.29962\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 144.9886 - val_loss: 351.4836\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 166.29962\n",
      "Epoch 141/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.8299 - val_loss: 275.1251\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 166.29962\n",
      "Epoch 142/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.3001 - val_loss: 435.8707\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 166.29962\n",
      "Epoch 143/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.6553 - val_loss: 497.0836\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 166.29962\n",
      "Epoch 144/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 141.7829 - val_loss: 204.3455\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 166.29962\n",
      "Epoch 145/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 138.6689 - val_loss: 231.5914\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 166.29962\n",
      "Epoch 146/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 137.8291 - val_loss: 248.6197\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 166.29962\n",
      "Epoch 147/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 138.0357 - val_loss: 187.1192\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 166.29962\n",
      "Epoch 148/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 140.3402 - val_loss: 184.8887\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 166.29962\n",
      "Epoch 149/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 138.6480 - val_loss: 346.6934\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 166.29962\n",
      "Epoch 150/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.5219 - val_loss: 371.8383\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 166.29962\n",
      "Epoch 151/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 137.8194 - val_loss: 433.7941\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 166.29962\n",
      "Epoch 152/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.1609 - val_loss: 350.1071\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 166.29962\n",
      "Epoch 153/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 137.7869 - val_loss: 218.6348\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 166.29962\n",
      "Epoch 154/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 138.7234 - val_loss: 203.9379\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 166.29962\n",
      "Epoch 155/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 137.9889 - val_loss: 213.7155\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 166.29962\n",
      "Epoch 156/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.9221 - val_loss: 266.1374\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 166.29962\n",
      "Epoch 157/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 138.5971 - val_loss: 179.9708\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 166.29962\n",
      "Epoch 158/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 138.0087 - val_loss: 191.7789\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 166.29962\n",
      "Epoch 159/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 137.5300 - val_loss: 469.5446\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 166.29962\n",
      "Epoch 160/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 135.2283 - val_loss: 244.5541\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 166.29962\n",
      "Epoch 161/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 135.8749 - val_loss: 235.4347\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 166.29962\n",
      "Epoch 162/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.9860 - val_loss: 276.6704\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 166.29962\n",
      "Epoch 163/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 137.1270 - val_loss: 342.0973\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 166.29962\n",
      "Epoch 164/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 135.0033 - val_loss: 224.1039\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 166.29962\n",
      "Epoch 165/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.9050 - val_loss: 413.6413\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 166.29962\n",
      "Epoch 166/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 135.4589 - val_loss: 458.8306\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 166.29962\n",
      "Epoch 167/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.4151 - val_loss: 204.9732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00167: val_loss did not improve from 166.29962\n",
      "Epoch 168/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 138.0627 - val_loss: 268.9539\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 166.29962\n",
      "Epoch 169/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 135.1312 - val_loss: 432.7091\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 166.29962\n",
      "Epoch 170/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 139.8923 - val_loss: 174.9991\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 166.29962\n",
      "Epoch 171/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 138.0756 - val_loss: 192.1259\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 166.29962\n",
      "Epoch 172/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 135.2238 - val_loss: 287.5721\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 166.29962\n",
      "Epoch 173/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 133.3585 - val_loss: 210.2355\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 166.29962\n",
      "Epoch 174/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 133.8813 - val_loss: 261.6999\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 166.29962\n",
      "Epoch 175/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 134.1656 - val_loss: 194.4760\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 166.29962\n",
      "Epoch 176/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 134.1758 - val_loss: 198.3122\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 166.29962\n",
      "Epoch 177/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 132.4290 - val_loss: 385.6027\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 166.29962\n",
      "Epoch 178/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 136.2333 - val_loss: 289.5235\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 166.29962\n",
      "Epoch 179/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.9792 - val_loss: 243.3972\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 166.29962\n",
      "Epoch 180/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 133.5487 - val_loss: 454.9712\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 166.29962\n",
      "Epoch 181/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 134.3451 - val_loss: 239.4800\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 166.29962\n",
      "Epoch 182/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 132.2870 - val_loss: 391.2075\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 166.29962\n",
      "Epoch 183/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 131.4721 - val_loss: 298.3515\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 166.29962\n",
      "Epoch 184/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 131.0879 - val_loss: 229.1834\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 166.29962\n",
      "Epoch 185/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 130.4245 - val_loss: 204.4462\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 166.29962\n",
      "Epoch 186/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.1631 - val_loss: 267.8452\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 166.29962\n",
      "Epoch 187/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 129.3620 - val_loss: 195.4058\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 166.29962\n",
      "Epoch 188/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 131.6736 - val_loss: 320.5211\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 166.29962\n",
      "Epoch 189/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 133.5306 - val_loss: 214.7303\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 166.29962\n",
      "Epoch 190/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.4803 - val_loss: 265.9591\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 166.29962\n",
      "Epoch 191/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 132.3825 - val_loss: 291.4555\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 166.29962\n",
      "Epoch 192/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 127.7939 - val_loss: 331.2299\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 166.29962\n",
      "Epoch 193/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 134.2693 - val_loss: 206.5141\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 166.29962\n",
      "Epoch 194/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 130.9990 - val_loss: 264.7463\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 166.29962\n",
      "Epoch 195/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 128.6260 - val_loss: 212.5803\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 166.29962\n",
      "Epoch 196/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 131.0518 - val_loss: 199.0409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████▎                                  | 12/21 [23:32<16:57, 113.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00196: val_loss did not improve from 166.29962\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 2724.7859 - val_loss: 4478.4160\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4478.41602, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1919.1632 - val_loss: 4376.6543\n",
      "\n",
      "Epoch 00002: val_loss improved from 4478.41602 to 4376.65430, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1956.7791 - val_loss: 5124.4692\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4376.65430\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 2157.7935 - val_loss: 5143.1172\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4376.65430\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1934.3325 - val_loss: 3264.6313\n",
      "\n",
      "Epoch 00005: val_loss improved from 4376.65430 to 3264.63135, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 967us/step - loss: 1921.1412 - val_loss: 2766.6604\n",
      "\n",
      "Epoch 00006: val_loss improved from 3264.63135 to 2766.66040, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1799.7091 - val_loss: 5178.0776\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2766.66040\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1860.5828 - val_loss: 4848.4780\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2766.66040\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1915.5243 - val_loss: 5142.4155\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2766.66040\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1620.5874 - val_loss: 4703.4702\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2766.66040\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1633.8336 - val_loss: 2008.6847\n",
      "\n",
      "Epoch 00011: val_loss improved from 2766.66040 to 2008.68469, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1555.5342 - val_loss: 3245.5312\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2008.68469\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1627.5958 - val_loss: 3387.6772\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2008.68469\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1593.7689 - val_loss: 4746.5376\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2008.68469\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1505.1335 - val_loss: 2985.1030\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2008.68469\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1451.0791 - val_loss: 2457.9189\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2008.68469\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1418.0769 - val_loss: 1343.5601\n",
      "\n",
      "Epoch 00017: val_loss improved from 2008.68469 to 1343.56006, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1431.4688 - val_loss: 4078.4475\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1343.56006\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1551.8077 - val_loss: 2921.4382\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1343.56006\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1377.1343 - val_loss: 4707.4214\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1343.56006\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1420.8252 - val_loss: 1288.4629\n",
      "\n",
      "Epoch 00021: val_loss improved from 1343.56006 to 1288.46289, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1355.8167 - val_loss: 3238.9702\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1288.46289\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1354.3461 - val_loss: 4483.3301\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1288.46289\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1264.6168 - val_loss: 2986.4009\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1288.46289\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1388.3300 - val_loss: 3080.1008\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1288.46289\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1265.9840 - val_loss: 3199.2500\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1288.46289\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1258.5372 - val_loss: 1316.1187\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1288.46289\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1272.0184 - val_loss: 3280.9138\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1288.46289\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1472.1106 - val_loss: 1385.8672\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1288.46289\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1422.8619 - val_loss: 1940.9532\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1288.46289\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1428.2754 - val_loss: 2058.9307\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1288.46289\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1331.9492 - val_loss: 1581.3453\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1288.46289\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1286.6086 - val_loss: 2011.3601\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1288.46289\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1341.5670 - val_loss: 1146.0164\n",
      "\n",
      "Epoch 00034: val_loss improved from 1288.46289 to 1146.01636, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1179.5389 - val_loss: 5055.9004\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1146.01636\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1237.6949 - val_loss: 3602.7607\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1146.01636\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1284.6541 - val_loss: 1759.4153\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1146.01636\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1249.7446 - val_loss: 1542.2566\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1146.01636\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1183.3857 - val_loss: 2401.6606\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1146.01636\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1121.5831 - val_loss: 1679.0194\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1146.01636\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1170.9717 - val_loss: 2622.8601\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1146.01636\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1269.2126 - val_loss: 2962.3274\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1146.01636\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1152.4034 - val_loss: 3033.5125\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1146.01636\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1210.3312 - val_loss: 1569.3984\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1146.01636\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1207.7552 - val_loss: 3909.9624\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1146.01636\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1166.3828 - val_loss: 1335.7584\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1146.01636\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1120.5005 - val_loss: 1101.9185\n",
      "\n",
      "Epoch 00047: val_loss improved from 1146.01636 to 1101.91846, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1104.0007 - val_loss: 1899.7870\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1101.91846\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 967.4094 - val_loss: 1604.5646\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1101.91846\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 914.9557 - val_loss: 3183.7346\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1101.91846\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 860.8948 - val_loss: 1626.7048\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1101.91846\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 947.0690 - val_loss: 2007.6128\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1101.91846\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 885.9625 - val_loss: 3056.6575\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1101.91846\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 886.1009 - val_loss: 1753.8450\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1101.91846\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 857.2437 - val_loss: 1205.7029\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1101.91846\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 930.3010 - val_loss: 2931.0254\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1101.91846\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 877.1400 - val_loss: 2368.7444\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1101.91846\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 972.5776 - val_loss: 1148.2991\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1101.91846\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 889.1305 - val_loss: 2993.9189\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1101.91846\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 843.6115 - val_loss: 1808.1581\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1101.91846\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 849.0826 - val_loss: 3246.5093\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1101.91846\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 918.7643 - val_loss: 2369.6106\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1101.91846\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 966.8415 - val_loss: 2719.1228\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1101.91846\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 932.0867 - val_loss: 3008.6470\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1101.91846\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 926.6077 - val_loss: 3011.8274\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1101.91846\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 996.7380 - val_loss: 2252.8735\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1101.91846\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1016.4706 - val_loss: 2823.1833\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1101.91846\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 994.6068 - val_loss: 2661.8025\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1101.91846\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 880.4458 - val_loss: 5865.8530\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1101.91846\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1258.5300 - val_loss: 2038.6154\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1101.91846\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1117.9624 - val_loss: 1193.0691\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1101.91846\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 957.0173 - val_loss: 2749.0830\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1101.91846\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 954.9307 - val_loss: 1798.8085\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1101.91846\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 987.0810 - val_loss: 2279.9092\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1101.91846\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 996.3069 - val_loss: 2782.4534\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1101.91846\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 958.9373 - val_loss: 2234.8132\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1101.91846\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1001.6383 - val_loss: 2630.5457\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1101.91846\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1015.7082 - val_loss: 2472.3875\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1101.91846\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 992.1750 - val_loss: 2565.1416\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1101.91846\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 984.4360 - val_loss: 2749.9319\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1101.91846\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 928.7702 - val_loss: 2330.0564\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1101.91846\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 909.4941 - val_loss: 1346.7347\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1101.91846\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 979.7084 - val_loss: 1417.1055\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1101.91846\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 907.3287 - val_loss: 3597.8091\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1101.91846\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1067.5624 - val_loss: 2700.0144\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1101.91846\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 927.2244 - val_loss: 2779.7668\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1101.91846\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 876.0383 - val_loss: 1481.3271\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1101.91846\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 920.6013 - val_loss: 3033.0159\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1101.91846\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 932.7383 - val_loss: 3019.3748\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1101.91846\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 959.6834 - val_loss: 1279.2275\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1101.91846\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 923.1495 - val_loss: 2595.3123\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1101.91846\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 947.0483 - val_loss: 1338.6785\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1101.91846\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 910.5475 - val_loss: 1342.9008\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1101.91846\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 942.1400 - val_loss: 2820.0115\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1101.91846\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 846.2404 - val_loss: 2802.8474\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1101.91846\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 907.7482 - val_loss: 2895.8562\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1101.91846\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 936.4360 - val_loss: 1412.1842\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1101.91846\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 924.9230 - val_loss: 3119.4844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00098: val_loss did not improve from 1101.91846\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 890.0238 - val_loss: 2821.3132\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1101.91846\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 917.6480 - val_loss: 3091.5913\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1101.91846\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 948.3360 - val_loss: 2182.2876\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1101.91846\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 957.6311 - val_loss: 2969.4097\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1101.91846\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 909.8384 - val_loss: 1922.6138\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1101.91846\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 906.3222 - val_loss: 1274.6378\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1101.91846\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 928.1068 - val_loss: 2918.8396\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1101.91846\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 927.8456 - val_loss: 2564.3232\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1101.91846\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 947.1972 - val_loss: 2534.7029\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1101.91846\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 901.0030 - val_loss: 1980.3818\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1101.91846\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 938.8348 - val_loss: 2978.7246\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1101.91846\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 879.3391 - val_loss: 3052.9443\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1101.91846\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 840.9852 - val_loss: 1486.9825\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1101.91846\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 891.1301 - val_loss: 2653.3330\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1101.91846\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 911.3626 - val_loss: 2898.8574\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1101.91846\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 916.4269 - val_loss: 2332.1104\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1101.91846\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 868.6960 - val_loss: 1269.8170\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1101.91846\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 897.9360 - val_loss: 1802.1425\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1101.91846\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 847.7496 - val_loss: 1905.8549\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1101.91846\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 880.1858 - val_loss: 1211.5526\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1101.91846\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 893.8711 - val_loss: 1675.8018\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1101.91846\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 855.0473 - val_loss: 3184.5723\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1101.91846\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 982.6711 - val_loss: 1208.9614\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1101.91846\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 871.4631 - val_loss: 2031.8143\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1101.91846\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 894.5502 - val_loss: 1816.4269\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1101.91846\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 875.1078 - val_loss: 2887.4893\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1101.91846\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 881.8298 - val_loss: 1299.2388\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1101.91846\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 854.6568 - val_loss: 2950.9968\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1101.91846\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 832.7084 - val_loss: 2818.0066\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1101.91846\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 843.4944 - val_loss: 1199.7775\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1101.91846\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 834.9892 - val_loss: 3546.8467\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1101.91846\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 952.8679 - val_loss: 2650.5200\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1101.91846\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 897.1018 - val_loss: 2790.2173\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1101.91846\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 888.4351 - val_loss: 2445.6067\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1101.91846\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 894.1364 - val_loss: 3106.1309\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1101.91846\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 901.3462 - val_loss: 5336.1904\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1101.91846\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 991.4747 - val_loss: 3117.6384\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1101.91846\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 882.1842 - val_loss: 2917.9944\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1101.91846\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 898.9631 - val_loss: 1458.8879\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1101.91846\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 855.6381 - val_loss: 3249.6497\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1101.91846\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 887.0137 - val_loss: 2969.4873\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1101.91846\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 864.6207 - val_loss: 1213.7595\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1101.91846\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 876.3084 - val_loss: 1570.7014\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1101.91846\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 834.3497 - val_loss: 4131.5293\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1101.91846\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 894.4401 - val_loss: 1502.0216\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1101.91846\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 889.6793 - val_loss: 2394.9746\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1101.91846\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 862.9506 - val_loss: 2211.3696\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1101.91846\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 874.3235 - val_loss: 2310.2341\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1101.91846\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 857.6880 - val_loss: 2250.4722\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1101.91846\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 2626.5364 - val_loss: 1608.2905\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1608.29053, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 947us/step - loss: 1950.8370 - val_loss: 1504.8331\n",
      "\n",
      "Epoch 00002: val_loss improved from 1608.29053 to 1504.83313, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 902us/step - loss: 1972.8693 - val_loss: 4480.3975\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1504.83313\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2141.9307 - val_loss: 1350.0870\n",
      "\n",
      "Epoch 00004: val_loss improved from 1504.83313 to 1350.08704, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2026.6082 - val_loss: 1628.8588\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1350.08704\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 2007.2352 - val_loss: 1529.1049\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1350.08704\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 941us/step - loss: 2102.5483 - val_loss: 1318.0328\n",
      "\n",
      "Epoch 00007: val_loss improved from 1350.08704 to 1318.03284, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 987us/step - loss: 1887.8049 - val_loss: 4596.2905\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1318.03284\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1973.3693 - val_loss: 4450.5630\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1318.03284\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1682.7777 - val_loss: 5165.0229\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1318.03284\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1843.3696 - val_loss: 1473.5547\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1318.03284\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1590.4055 - val_loss: 3181.1660\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1318.03284\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1544.1427 - val_loss: 4786.1479\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1318.03284\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 993us/step - loss: 1642.1616 - val_loss: 1522.1516\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1318.03284\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1617.1641 - val_loss: 2684.3267\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1318.03284\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 977us/step - loss: 1455.2426 - val_loss: 3649.6790\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1318.03284\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1550.5166 - val_loss: 2211.9290\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1318.03284\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1516.0458 - val_loss: 1723.7278\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1318.03284\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1407.8914 - val_loss: 2969.3218\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1318.03284\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1410.2882 - val_loss: 3334.4197\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1318.03284\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1315.5846 - val_loss: 1414.0524\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1318.03284\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 925us/step - loss: 1410.0109 - val_loss: 2670.5715\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1318.03284\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1294.8136 - val_loss: 4780.7168\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1318.03284\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1427.6913 - val_loss: 2587.1287\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1318.03284\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 958us/step - loss: 1457.1510 - val_loss: 2609.1809\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1318.03284\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 945us/step - loss: 1275.9576 - val_loss: 4147.0171\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1318.03284\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1369.4674 - val_loss: 1527.3186\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1318.03284\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1322.4958 - val_loss: 3393.1506\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1318.03284\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1253.7668 - val_loss: 4246.7715\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1318.03284\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1302.6094 - val_loss: 1774.1372\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1318.03284\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1276.6620 - val_loss: 3784.6638\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1318.03284\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1224.8644 - val_loss: 3704.2480\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1318.03284\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 952us/step - loss: 1221.2896 - val_loss: 3880.4331\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1318.03284\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1278.0619 - val_loss: 3147.0537\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1318.03284\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1276.5034 - val_loss: 4194.1118\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1318.03284\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1172.9370 - val_loss: 1516.3977\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1318.03284\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1261.8157 - val_loss: 4325.4717\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1318.03284\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1184.2233 - val_loss: 3341.7556\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1318.03284\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1287.2246 - val_loss: 3553.6819\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1318.03284\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1188.3136 - val_loss: 4128.5586\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1318.03284\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1239.8551 - val_loss: 2150.8191\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1318.03284\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1214.8519 - val_loss: 3089.5137\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1318.03284\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1165.1033 - val_loss: 1947.9325\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1318.03284\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1098.9390 - val_loss: 1547.0088\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1318.03284\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 955us/step - loss: 1157.1506 - val_loss: 2134.0327\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1318.03284\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 965us/step - loss: 1170.8834 - val_loss: 2851.7546\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1318.03284\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1173.8922 - val_loss: 2669.4233\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1318.03284\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1227.6536 - val_loss: 1235.0601\n",
      "\n",
      "Epoch 00048: val_loss improved from 1318.03284 to 1235.06006, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1102.0140 - val_loss: 1536.4592\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1235.06006\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 986us/step - loss: 1118.5042 - val_loss: 3056.3936\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1235.06006\n",
      "Epoch 51/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 1031.1556 - val_loss: 1420.8651\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1235.06006\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1028.7032 - val_loss: 2906.7732\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1235.06006\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1085.7537 - val_loss: 2579.7810\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1235.06006\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 978.5099 - val_loss: 3496.2712\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1235.06006\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 940.9695 - val_loss: 2037.0238\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1235.06006\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 914.5721 - val_loss: 2011.9200\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1235.06006\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 902.7559 - val_loss: 2299.7812\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1235.06006\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 848.8423 - val_loss: 2408.3386\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1235.06006\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 850.6677 - val_loss: 2482.9548\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1235.06006\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 874.7311 - val_loss: 1733.4805\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1235.06006\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 939.7346 - val_loss: 2269.9248\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1235.06006\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 816.3392 - val_loss: 2645.5737\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1235.06006\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.7806 - val_loss: 2793.9297\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1235.06006\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 838.3969 - val_loss: 2916.8425\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1235.06006\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 888.5511 - val_loss: 3050.4756\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1235.06006\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 836.0609 - val_loss: 1794.3751\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1235.06006\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 852.9467 - val_loss: 2889.4934\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1235.06006\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 846.4427 - val_loss: 2086.1035\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1235.06006\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 828.7041 - val_loss: 3154.6987\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1235.06006\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 807.9050 - val_loss: 2419.6152\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1235.06006\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 835.2238 - val_loss: 2428.6213\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1235.06006\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 832.3430 - val_loss: 1548.1128\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1235.06006\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 816.8929 - val_loss: 1738.7802\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1235.06006\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 757.6932 - val_loss: 1791.5697\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1235.06006\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 828.9145 - val_loss: 2865.4707\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1235.06006\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 782.1856 - val_loss: 1734.7314\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1235.06006\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 824.9937 - val_loss: 2662.5862\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1235.06006\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 804.8815 - val_loss: 2329.9287\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1235.06006\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 841.1143 - val_loss: 2146.9993\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1235.06006\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 775.1932 - val_loss: 1861.8467\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1235.06006\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 773.2879 - val_loss: 1541.1188\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1235.06006\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 781.8616 - val_loss: 3171.6313\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1235.06006\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 794.4714 - val_loss: 3081.4617\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1235.06006\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 996us/step - loss: 781.5524 - val_loss: 3086.1516\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1235.06006\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 991us/step - loss: 796.7286 - val_loss: 2289.5962\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1235.06006\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 967us/step - loss: 766.3881 - val_loss: 2516.7705\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1235.06006\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 996us/step - loss: 816.5430 - val_loss: 2970.1533\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1235.06006\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 785.1862 - val_loss: 1751.8521\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1235.06006\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 964us/step - loss: 778.6483 - val_loss: 2688.0637\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1235.06006\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 812.2303 - val_loss: 2122.2664\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1235.06006\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 988us/step - loss: 761.2217 - val_loss: 2350.1453\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1235.06006\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 978us/step - loss: 798.7631 - val_loss: 2613.4775\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1235.06006\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 977us/step - loss: 762.8624 - val_loss: 1850.6150\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1235.06006\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 950us/step - loss: 785.0140 - val_loss: 2146.8218\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1235.06006\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 994us/step - loss: 767.3016 - val_loss: 2524.6831\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1235.06006\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 963us/step - loss: 748.7545 - val_loss: 2704.8325\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1235.06006\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 946us/step - loss: 799.2212 - val_loss: 1564.0491\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1235.06006\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 960us/step - loss: 751.3721 - val_loss: 2908.2825\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1235.06006\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 994us/step - loss: 765.7095 - val_loss: 2710.4241\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1235.06006\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 945us/step - loss: 772.5497 - val_loss: 1461.9147\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1235.06006\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 992us/step - loss: 766.5270 - val_loss: 1712.4100\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1235.06006\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 971us/step - loss: 797.0729 - val_loss: 2399.9397\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1235.06006\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 793.5861 - val_loss: 2597.9128\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1235.06006\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 950us/step - loss: 745.1176 - val_loss: 2796.6050\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1235.06006\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 954us/step - loss: 750.0391 - val_loss: 1901.5107\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1235.06006\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 992us/step - loss: 774.6302 - val_loss: 1372.7848\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1235.06006\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 954us/step - loss: 756.0644 - val_loss: 2070.7849\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1235.06006\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 945us/step - loss: 721.3790 - val_loss: 2743.5647\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1235.06006\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 945us/step - loss: 723.9229 - val_loss: 2532.2742\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1235.06006\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 959us/step - loss: 751.0851 - val_loss: 1748.5430\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1235.06006\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 960us/step - loss: 744.0683 - val_loss: 2705.1169\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1235.06006\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 949us/step - loss: 774.6754 - val_loss: 2463.5588\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1235.06006\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 951us/step - loss: 736.6742 - val_loss: 1499.4460\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1235.06006\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 930us/step - loss: 773.4211 - val_loss: 2524.1101\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1235.06006\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 966us/step - loss: 765.9916 - val_loss: 1774.4508\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1235.06006\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 939us/step - loss: 750.0358 - val_loss: 2683.3115\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1235.06006\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 945us/step - loss: 763.6588 - val_loss: 1930.7228\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1235.06006\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 969us/step - loss: 753.1788 - val_loss: 1479.7928\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1235.06006\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 979us/step - loss: 777.2800 - val_loss: 2096.3999\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1235.06006\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 953us/step - loss: 757.1379 - val_loss: 2017.7628\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1235.06006\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 967us/step - loss: 742.6986 - val_loss: 2385.2703\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1235.06006\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 979us/step - loss: 740.7700 - val_loss: 1965.0789\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1235.06006\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 935us/step - loss: 773.7611 - val_loss: 1699.9915\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1235.06006\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 961us/step - loss: 768.7195 - val_loss: 1596.8506\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1235.06006\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 747.2607 - val_loss: 2414.6692\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1235.06006\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 984us/step - loss: 770.4258 - val_loss: 2164.0193\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1235.06006\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 928us/step - loss: 764.9684 - val_loss: 2191.5054\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1235.06006\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 973us/step - loss: 781.7793 - val_loss: 2004.4301\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1235.06006\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 960us/step - loss: 766.0651 - val_loss: 2390.0923\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1235.06006\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 979us/step - loss: 757.8856 - val_loss: 1545.4878\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1235.06006\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 919us/step - loss: 774.9971 - val_loss: 2259.0562\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1235.06006\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 952us/step - loss: 739.6868 - val_loss: 1740.9855\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1235.06006\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 948us/step - loss: 712.7527 - val_loss: 1964.2959\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1235.06006\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 963us/step - loss: 731.7937 - val_loss: 1786.1915\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1235.06006\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 977us/step - loss: 713.8942 - val_loss: 2713.7961\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1235.06006\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 944us/step - loss: 735.5960 - val_loss: 1548.1462\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1235.06006\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 997us/step - loss: 734.0099 - val_loss: 1656.5105\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1235.06006\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 963us/step - loss: 719.3443 - val_loss: 1590.7495\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1235.06006\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 952us/step - loss: 727.5701 - val_loss: 1729.0887\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1235.06006\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 978us/step - loss: 716.6292 - val_loss: 1690.2946\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1235.06006\n",
      "Epoch 141/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 722.4344 - val_loss: 2289.2048\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1235.06006\n",
      "Epoch 142/10000\n",
      "88/88 [==============================] - 0s 949us/step - loss: 748.8116 - val_loss: 1688.2422\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1235.06006\n",
      "Epoch 143/10000\n",
      "88/88 [==============================] - 0s 970us/step - loss: 740.8573 - val_loss: 2343.2471\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1235.06006\n",
      "Epoch 144/10000\n",
      "88/88 [==============================] - 0s 950us/step - loss: 715.0771 - val_loss: 1314.6859\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1235.06006\n",
      "Epoch 145/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 760.0616 - val_loss: 2657.8848\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1235.06006\n",
      "Epoch 146/10000\n",
      "88/88 [==============================] - 0s 985us/step - loss: 752.6699 - val_loss: 2260.3857\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1235.06006\n",
      "Epoch 147/10000\n",
      "88/88 [==============================] - 0s 968us/step - loss: 743.5082 - val_loss: 2162.2844\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1235.06006\n",
      "Epoch 148/10000\n",
      "88/88 [==============================] - 0s 985us/step - loss: 731.9000 - val_loss: 2317.6350\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1235.06006\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 2406.5647 - val_loss: 2061.7063\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2061.70630, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 914us/step - loss: 1912.0480 - val_loss: 5286.8242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss did not improve from 2061.70630\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 917us/step - loss: 1839.5745 - val_loss: 5309.7002\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2061.70630\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 933us/step - loss: 1755.7065 - val_loss: 4876.7710\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2061.70630\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 966us/step - loss: 1968.2665 - val_loss: 4909.6167\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2061.70630\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 949us/step - loss: 1851.2793 - val_loss: 3276.3596\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2061.70630\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 979us/step - loss: 1912.5996 - val_loss: 3024.9272\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2061.70630\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 975us/step - loss: 1896.6177 - val_loss: 5238.1504\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2061.70630\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 987us/step - loss: 1843.3826 - val_loss: 4353.5210\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2061.70630\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1775.3802 - val_loss: 4748.3340\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2061.70630\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 953us/step - loss: 1767.0446 - val_loss: 10352.0615\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2061.70630\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1858.0984 - val_loss: 3643.0344\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2061.70630\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 959us/step - loss: 1520.9207 - val_loss: 4795.3564\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2061.70630\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 964us/step - loss: 1664.0717 - val_loss: 2117.8425\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2061.70630\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 972us/step - loss: 1536.1970 - val_loss: 1470.5043\n",
      "\n",
      "Epoch 00015: val_loss improved from 2061.70630 to 1470.50427, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 962us/step - loss: 1618.8444 - val_loss: 1936.5569\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1470.50427\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 979us/step - loss: 1551.7485 - val_loss: 2439.4468\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1470.50427\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 927us/step - loss: 1470.5936 - val_loss: 4556.2871\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1470.50427\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 962us/step - loss: 1473.9976 - val_loss: 5083.4702\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1470.50427\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 929us/step - loss: 1470.3654 - val_loss: 1601.7527\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1470.50427\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 937us/step - loss: 1430.0947 - val_loss: 7393.0737\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1470.50427\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 950us/step - loss: 1445.2069 - val_loss: 4451.7271\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1470.50427\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 953us/step - loss: 1326.0154 - val_loss: 1615.8417\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1470.50427\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 948us/step - loss: 1343.4238 - val_loss: 1367.8141\n",
      "\n",
      "Epoch 00024: val_loss improved from 1470.50427 to 1367.81409, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 971us/step - loss: 1346.9219 - val_loss: 2683.0337\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1367.81409\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 938us/step - loss: 1385.4846 - val_loss: 2913.6812\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1367.81409\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 981us/step - loss: 1308.9347 - val_loss: 3533.8083\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1367.81409\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 935us/step - loss: 1365.8102 - val_loss: 1427.7550\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1367.81409\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 931us/step - loss: 1282.5741 - val_loss: 4930.1348\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1367.81409\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 955us/step - loss: 1318.8049 - val_loss: 4901.0249\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1367.81409\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 964us/step - loss: 1273.8446 - val_loss: 5387.5879\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1367.81409\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 963us/step - loss: 1512.2129 - val_loss: 5195.2852\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1367.81409\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 928us/step - loss: 1603.4236 - val_loss: 2312.0154\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1367.81409\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1505.6814 - val_loss: 3384.1909\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1367.81409\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 978us/step - loss: 1721.3396 - val_loss: 2591.4265\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1367.81409\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 963us/step - loss: 1545.4650 - val_loss: 4218.8511\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1367.81409\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 946us/step - loss: 1643.1770 - val_loss: 3575.5657\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1367.81409\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 935us/step - loss: 1460.1648 - val_loss: 1584.9022\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1367.81409\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 946us/step - loss: 1568.0779 - val_loss: 1968.6879\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1367.81409\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 934us/step - loss: 1608.4003 - val_loss: 3610.1719\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1367.81409\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 974us/step - loss: 1383.0405 - val_loss: 1319.1300\n",
      "\n",
      "Epoch 00041: val_loss improved from 1367.81409 to 1319.13000, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 964us/step - loss: 1424.2584 - val_loss: 4027.8274\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1319.13000\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 970us/step - loss: 1512.6957 - val_loss: 3843.3877\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1319.13000\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 946us/step - loss: 1433.3251 - val_loss: 3490.7100\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1319.13000\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 995us/step - loss: 1474.3229 - val_loss: 1259.8157\n",
      "\n",
      "Epoch 00045: val_loss improved from 1319.13000 to 1259.81567, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 958us/step - loss: 1471.0364 - val_loss: 3930.1162\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1259.81567\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 985us/step - loss: 1048.3341 - val_loss: 3218.8843\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1259.81567\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 961us/step - loss: 943.8964 - val_loss: 2803.1130\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1259.81567\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 988us/step - loss: 969.6446 - val_loss: 2564.5220\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1259.81567\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 937us/step - loss: 944.8903 - val_loss: 2794.4722\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1259.81567\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 982us/step - loss: 910.0247 - val_loss: 2921.6497\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1259.81567\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 951us/step - loss: 1065.2675 - val_loss: 2582.6304\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1259.81567\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 962us/step - loss: 1118.5253 - val_loss: 2224.9644\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1259.81567\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 986us/step - loss: 1112.8085 - val_loss: 2287.5269\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1259.81567\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 922us/step - loss: 1112.0469 - val_loss: 2319.5837\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1259.81567\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 951us/step - loss: 1111.3185 - val_loss: 2468.6365\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1259.81567\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 928us/step - loss: 1113.9779 - val_loss: 2402.2014\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1259.81567\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 956us/step - loss: 1112.0120 - val_loss: 2413.4431\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1259.81567\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 945us/step - loss: 1113.6567 - val_loss: 2454.7688\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1259.81567\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 906us/step - loss: 1111.5009 - val_loss: 2318.6218\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1259.81567\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 936us/step - loss: 1111.9946 - val_loss: 2239.9280\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1259.81567\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 935us/step - loss: 1113.8302 - val_loss: 2362.3794\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1259.81567\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 908us/step - loss: 1112.9036 - val_loss: 2413.3201\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1259.81567\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 984us/step - loss: 1113.2665 - val_loss: 2425.0535\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1259.81567\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 988us/step - loss: 1113.1290 - val_loss: 2426.8289\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1259.81567\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 916us/step - loss: 1113.2506 - val_loss: 2408.9563\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1259.81567\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 969us/step - loss: 1112.5944 - val_loss: 2381.1594\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1259.81567\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 923us/step - loss: 1112.9496 - val_loss: 2480.6265\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1259.81567\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 930us/step - loss: 1111.7545 - val_loss: 2336.4458\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1259.81567\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 928us/step - loss: 1112.0763 - val_loss: 2197.8643\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1259.81567\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 949us/step - loss: 1113.2170 - val_loss: 2169.1411\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1259.81567\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 936us/step - loss: 1113.5876 - val_loss: 2410.7107\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1259.81567\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 923us/step - loss: 1110.0409 - val_loss: 2142.7410\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1259.81567\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 964us/step - loss: 1114.7156 - val_loss: 2365.7307\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1259.81567\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 933us/step - loss: 1111.7889 - val_loss: 2464.7659\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1259.81567\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 963us/step - loss: 1113.1771 - val_loss: 2289.8826\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1259.81567\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 940us/step - loss: 1112.4191 - val_loss: 2390.2793\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1259.81567\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 955us/step - loss: 1112.4512 - val_loss: 2469.7319\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1259.81567\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 982us/step - loss: 1113.2697 - val_loss: 2364.4900\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1259.81567\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 908us/step - loss: 1112.7755 - val_loss: 2366.3865\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1259.81567\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 953us/step - loss: 1113.5192 - val_loss: 2388.1609\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1259.81567\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 962us/step - loss: 1112.5662 - val_loss: 2281.3479\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1259.81567\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 969us/step - loss: 1113.0046 - val_loss: 2243.2964\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1259.81567\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 983us/step - loss: 1112.4196 - val_loss: 2304.9702\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1259.81567\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 961us/step - loss: 1113.6793 - val_loss: 2425.0383\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1259.81567\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 922us/step - loss: 1113.5543 - val_loss: 2426.9312\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1259.81567\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 920us/step - loss: 1112.7606 - val_loss: 2271.2761\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1259.81567\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 928us/step - loss: 1111.5475 - val_loss: 2478.7507\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1259.81567\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 927us/step - loss: 1113.7679 - val_loss: 2235.9465\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1259.81567\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 950us/step - loss: 1113.6066 - val_loss: 2357.0510\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1259.81567\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 968us/step - loss: 1112.8568 - val_loss: 2378.6626\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1259.81567\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 926us/step - loss: 1111.9093 - val_loss: 2252.4187\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1259.81567\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 926us/step - loss: 1112.9521 - val_loss: 2224.0930\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1259.81567\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 927us/step - loss: 1111.6101 - val_loss: 2185.4087\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1259.81567\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 927us/step - loss: 1113.7078 - val_loss: 2227.9233\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1259.81567\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 939us/step - loss: 1111.9131 - val_loss: 2159.3921\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1259.81567\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 934us/step - loss: 1113.6504 - val_loss: 2438.4990\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1259.81567\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 933us/step - loss: 1112.6249 - val_loss: 2333.2844\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1259.81567\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 994us/step - loss: 1112.0283 - val_loss: 2196.1318\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1259.81567\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 945us/step - loss: 1113.6882 - val_loss: 2258.2385\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1259.81567\n",
      "Epoch 101/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 933us/step - loss: 1112.3224 - val_loss: 2397.6108\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1259.81567\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 931us/step - loss: 1111.7330 - val_loss: 2141.4907\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1259.81567\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 941us/step - loss: 1114.3201 - val_loss: 2234.0435\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1259.81567\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 967us/step - loss: 1112.3553 - val_loss: 2126.1807\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1259.81567\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 928us/step - loss: 1113.7136 - val_loss: 2337.1890\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1259.81567\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 965us/step - loss: 1111.8976 - val_loss: 2179.7302\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1259.81567\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 928us/step - loss: 1113.2539 - val_loss: 2241.4385\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1259.81567\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 916us/step - loss: 1113.1368 - val_loss: 2468.0237\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1259.81567\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 953us/step - loss: 1113.9550 - val_loss: 2235.7607\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1259.81567\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 922us/step - loss: 1112.6260 - val_loss: 2404.3081\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1259.81567\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 963us/step - loss: 1112.3840 - val_loss: 2259.3518\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1259.81567\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 935us/step - loss: 1111.2738 - val_loss: 2160.6934\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1259.81567\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 962us/step - loss: 1113.6506 - val_loss: 2380.3206\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1259.81567\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 929us/step - loss: 1112.4979 - val_loss: 2333.7004\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1259.81567\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 946us/step - loss: 1112.9580 - val_loss: 2247.3484\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1259.81567\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 981us/step - loss: 1113.1780 - val_loss: 2199.8318\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1259.81567\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 983us/step - loss: 1112.9910 - val_loss: 2231.7229\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1259.81567\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 963us/step - loss: 1113.6603 - val_loss: 2400.4182\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1259.81567\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 937us/step - loss: 1111.9562 - val_loss: 2315.2168\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1259.81567\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 943us/step - loss: 1112.3722 - val_loss: 2307.5088\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1259.81567\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 914us/step - loss: 1113.1011 - val_loss: 2240.4731\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1259.81567\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 954us/step - loss: 1113.0879 - val_loss: 2331.2341\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1259.81567\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 961us/step - loss: 1112.3130 - val_loss: 2254.1289\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1259.81567\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 923us/step - loss: 1112.3947 - val_loss: 2402.3997\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1259.81567\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 970us/step - loss: 1112.7383 - val_loss: 2188.3694\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1259.81567\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 947us/step - loss: 1112.7109 - val_loss: 2434.7114\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1259.81567\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 933us/step - loss: 1113.3835 - val_loss: 2281.3938\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1259.81567\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 953us/step - loss: 1110.7759 - val_loss: 2466.6904\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1259.81567\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 952us/step - loss: 1111.6824 - val_loss: 2382.3547\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1259.81567\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 955us/step - loss: 1110.5083 - val_loss: 2167.4971\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1259.81567\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 924us/step - loss: 1113.4277 - val_loss: 2356.7048\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1259.81567\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 931us/step - loss: 1111.9595 - val_loss: 2348.7698\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1259.81567\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 931us/step - loss: 1112.3800 - val_loss: 2446.7400\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1259.81567\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 979us/step - loss: 1112.8340 - val_loss: 2204.7095\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1259.81567\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 954us/step - loss: 1113.3580 - val_loss: 2256.4172\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1259.81567\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 952us/step - loss: 1112.6251 - val_loss: 2277.8547\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1259.81567\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 926us/step - loss: 1112.6929 - val_loss: 2444.4282\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1259.81567\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 980us/step - loss: 1112.1447 - val_loss: 2321.5332\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1259.81567\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 935us/step - loss: 1112.3445 - val_loss: 2313.9736\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1259.81567\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 988us/step - loss: 1111.8843 - val_loss: 2431.0015\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1259.81567\n",
      "Epoch 141/10000\n",
      "88/88 [==============================] - 0s 930us/step - loss: 1112.8400 - val_loss: 2423.1584\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1259.81567\n",
      "Epoch 142/10000\n",
      "88/88 [==============================] - 0s 981us/step - loss: 1113.3569 - val_loss: 2396.3948\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1259.81567\n",
      "Epoch 143/10000\n",
      "88/88 [==============================] - 0s 928us/step - loss: 1112.8467 - val_loss: 2446.0522\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1259.81567\n",
      "Epoch 144/10000\n",
      "88/88 [==============================] - 0s 941us/step - loss: 1113.7268 - val_loss: 2485.9028\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1259.81567\n",
      "Epoch 145/10000\n",
      "88/88 [==============================] - 0s 933us/step - loss: 1113.0623 - val_loss: 2167.4641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████▏                              | 13/21 [25:16<14:43, 110.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00145: val_loss did not improve from 1259.81567\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 1702.2368 - val_loss: 930.0836\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 930.08362, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 929us/step - loss: 1304.1390 - val_loss: 414.6924\n",
      "\n",
      "Epoch 00002: val_loss improved from 930.08362 to 414.69238, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 929us/step - loss: 1366.9148 - val_loss: 1146.2327\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 414.69238\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 938us/step - loss: 1293.2261 - val_loss: 1556.9520\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 414.69238\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 993us/step - loss: 1376.4082 - val_loss: 1296.9629\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 414.69238\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1351.1398 - val_loss: 1788.8634\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 414.69238\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1362.1278 - val_loss: 2098.4028\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 414.69238\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1386.6588 - val_loss: 2073.1223\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 414.69238\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 927us/step - loss: 1289.3368 - val_loss: 1805.3492\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 414.69238\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 865us/step - loss: 1445.9545 - val_loss: 387.7322\n",
      "\n",
      "Epoch 00010: val_loss improved from 414.69238 to 387.73224, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 906us/step - loss: 1392.7040 - val_loss: 1465.3074\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 387.73224\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 866us/step - loss: 1320.3018 - val_loss: 1077.8315\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 387.73224\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 879us/step - loss: 1359.5309 - val_loss: 1270.5529\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 387.73224\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 884us/step - loss: 1329.5494 - val_loss: 313.7912\n",
      "\n",
      "Epoch 00014: val_loss improved from 387.73224 to 313.79120, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 909us/step - loss: 1334.2280 - val_loss: 1886.4751\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 313.79120\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 884us/step - loss: 1463.3162 - val_loss: 506.8960\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 313.79120\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 864us/step - loss: 1248.2213 - val_loss: 846.4319\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 313.79120\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 884us/step - loss: 1325.9127 - val_loss: 1547.8046\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 313.79120\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 869us/step - loss: 1301.0126 - val_loss: 261.8779\n",
      "\n",
      "Epoch 00019: val_loss improved from 313.79120 to 261.87787, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 883us/step - loss: 1156.7976 - val_loss: 1220.1787\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 261.87787\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 888us/step - loss: 1036.9581 - val_loss: 3554.7888\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 261.87787\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 880us/step - loss: 1060.4319 - val_loss: 757.1548\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 261.87787\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 881us/step - loss: 1053.7074 - val_loss: 1952.8014\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 261.87787\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 875us/step - loss: 1013.0316 - val_loss: 316.4617\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 261.87787\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 885us/step - loss: 971.7538 - val_loss: 601.3234\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 261.87787\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 854us/step - loss: 1119.2854 - val_loss: 1047.2886\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 261.87787\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 873us/step - loss: 1013.4357 - val_loss: 1372.6108\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 261.87787\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 873us/step - loss: 856.0139 - val_loss: 1127.8246\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 261.87787\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 871us/step - loss: 913.8264 - val_loss: 752.5222\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 261.87787\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 867us/step - loss: 802.4820 - val_loss: 1155.5068\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 261.87787\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 876us/step - loss: 840.2629 - val_loss: 1563.8417\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 261.87787\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 885us/step - loss: 927.3072 - val_loss: 1628.9508\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 261.87787\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 878us/step - loss: 777.1099 - val_loss: 436.5739\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 261.87787\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 868us/step - loss: 871.0478 - val_loss: 1254.5292\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 261.87787\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 875us/step - loss: 854.0618 - val_loss: 616.0463\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 261.87787\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 860us/step - loss: 824.1390 - val_loss: 1717.2159\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 261.87787\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 902us/step - loss: 769.1851 - val_loss: 547.6404\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 261.87787\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 883us/step - loss: 808.4322 - val_loss: 676.0715\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 261.87787\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 870us/step - loss: 799.6709 - val_loss: 889.7269\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 261.87787\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 930us/step - loss: 739.7456 - val_loss: 349.9581\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 261.87787\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 879us/step - loss: 739.7717 - val_loss: 1403.9574\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 261.87787\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 884us/step - loss: 743.9998 - val_loss: 505.5933\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 261.87787\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 888us/step - loss: 522.0932 - val_loss: 390.7054\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 261.87787\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 880us/step - loss: 274.8799 - val_loss: 331.6427\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 261.87787\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 878us/step - loss: 276.4653 - val_loss: 350.8549\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 261.87787\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 870us/step - loss: 269.3227 - val_loss: 346.5276\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 261.87787\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 873us/step - loss: 267.1035 - val_loss: 319.1430\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 261.87787\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 858us/step - loss: 262.2604 - val_loss: 352.4494\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 261.87787\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 862us/step - loss: 269.1666 - val_loss: 356.4416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00049: val_loss did not improve from 261.87787\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 883us/step - loss: 265.3900 - val_loss: 375.6126\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 261.87787\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 866us/step - loss: 261.0683 - val_loss: 336.2245\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 261.87787\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 887us/step - loss: 265.0386 - val_loss: 327.2507\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 261.87787\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 893us/step - loss: 259.3578 - val_loss: 348.5139\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 261.87787\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 874us/step - loss: 266.0936 - val_loss: 334.5793\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 261.87787\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 954us/step - loss: 261.1136 - val_loss: 332.8627\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 261.87787\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 875us/step - loss: 261.8736 - val_loss: 332.0281\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 261.87787\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 864us/step - loss: 262.8186 - val_loss: 341.5920\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 261.87787\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 880us/step - loss: 263.5732 - val_loss: 334.5267\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 261.87787\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - ETA: 0s - loss: 263.236 - 0s 866us/step - loss: 263.8093 - val_loss: 354.0427\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 261.87787\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 892us/step - loss: 263.6883 - val_loss: 335.9579\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 261.87787\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 875us/step - loss: 260.8071 - val_loss: 340.4696\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 261.87787\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 859us/step - loss: 260.4164 - val_loss: 334.6688\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 261.87787\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 878us/step - loss: 255.2804 - val_loss: 353.4207\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 261.87787\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 877us/step - loss: 263.2225 - val_loss: 337.7584\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 261.87787\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 875us/step - loss: 261.5948 - val_loss: 351.8324\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 261.87787\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 865us/step - loss: 256.0202 - val_loss: 342.7461\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 261.87787\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 878us/step - loss: 263.1406 - val_loss: 347.8799\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 261.87787\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 866us/step - loss: 261.7325 - val_loss: 338.5129\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 261.87787\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 869us/step - loss: 262.5434 - val_loss: 331.9996\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 261.87787\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 880us/step - loss: 258.2632 - val_loss: 344.9803\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 261.87787\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 865us/step - loss: 259.0728 - val_loss: 329.0202\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 261.87787\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 884us/step - loss: 264.3620 - val_loss: 331.7191\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 261.87787\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 870us/step - loss: 259.3649 - val_loss: 330.8738\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 261.87787\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 874us/step - loss: 256.5400 - val_loss: 331.5328\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 261.87787\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 878us/step - loss: 258.6962 - val_loss: 338.6593\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 261.87787\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 880us/step - loss: 260.2083 - val_loss: 340.9338\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 261.87787\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 881us/step - loss: 260.0522 - val_loss: 348.0821\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 261.87787\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 894us/step - loss: 257.6803 - val_loss: 345.7814\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 261.87787\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 864us/step - loss: 264.2363 - val_loss: 345.3289\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 261.87787\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 882us/step - loss: 258.4252 - val_loss: 340.5360\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 261.87787\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 877us/step - loss: 258.4259 - val_loss: 346.3709\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 261.87787\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 876us/step - loss: 258.6018 - val_loss: 345.7388\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 261.87787\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 886us/step - loss: 257.8704 - val_loss: 334.4434\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 261.87787\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 872us/step - loss: 254.9837 - val_loss: 324.9024\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 261.87787\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 873us/step - loss: 257.2862 - val_loss: 340.1184\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 261.87787\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 890us/step - loss: 258.1797 - val_loss: 344.6985\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 261.87787\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 876us/step - loss: 259.3860 - val_loss: 352.8836\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 261.87787\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 873us/step - loss: 257.8661 - val_loss: 346.2251\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 261.87787\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 882us/step - loss: 253.0479 - val_loss: 322.3876\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 261.87787\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 864us/step - loss: 259.0805 - val_loss: 339.2706\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 261.87787\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 881us/step - loss: 258.2430 - val_loss: 335.6520\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 261.87787\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 873us/step - loss: 259.2416 - val_loss: 330.4168\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 261.87787\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 893us/step - loss: 258.4009 - val_loss: 332.7500\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 261.87787\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 885us/step - loss: 260.1094 - val_loss: 320.4987\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 261.87787\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 871us/step - loss: 256.0200 - val_loss: 328.0588\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 261.87787\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 867us/step - loss: 256.4249 - val_loss: 321.3229\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 261.87787\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 906us/step - loss: 255.2892 - val_loss: 311.7928\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 261.87787\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 922us/step - loss: 265.7701 - val_loss: 315.7465\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 261.87787\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 905us/step - loss: 257.3140 - val_loss: 341.3895\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 261.87787\n",
      "Epoch 100/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 889us/step - loss: 258.3875 - val_loss: 324.9244\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 261.87787\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 916us/step - loss: 258.4476 - val_loss: 319.8814\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 261.87787\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 886us/step - loss: 255.2695 - val_loss: 371.7033\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 261.87787\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 922us/step - loss: 254.2633 - val_loss: 339.3555\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 261.87787\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 876us/step - loss: 256.0706 - val_loss: 373.9613\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 261.87787\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 925us/step - loss: 259.2086 - val_loss: 367.4165\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 261.87787\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 916us/step - loss: 257.3619 - val_loss: 352.4643\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 261.87787\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 915us/step - loss: 254.7124 - val_loss: 348.0315\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 261.87787\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 917us/step - loss: 259.3763 - val_loss: 344.2118\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 261.87787\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 935us/step - loss: 256.7841 - val_loss: 323.5783\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 261.87787\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 939us/step - loss: 261.0684 - val_loss: 341.6042\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 261.87787\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 978us/step - loss: 258.6980 - val_loss: 365.7087\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 261.87787\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 981us/step - loss: 262.0023 - val_loss: 317.0093\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 261.87787\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 968us/step - loss: 258.8148 - val_loss: 317.5442\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 261.87787\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 258.9993 - val_loss: 344.1335\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 261.87787\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 960us/step - loss: 256.0906 - val_loss: 323.3365\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 261.87787\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 989us/step - loss: 257.7845 - val_loss: 320.8659\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 261.87787\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 984us/step - loss: 257.1092 - val_loss: 332.7373\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 261.87787\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 988us/step - loss: 259.2652 - val_loss: 349.1273\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 261.87787\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 968us/step - loss: 253.5881 - val_loss: 362.2928\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 261.87787\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 1713.0710 - val_loss: 444.5826\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 444.58264, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 927us/step - loss: 1385.8542 - val_loss: 2062.4534\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 444.58264\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 914us/step - loss: 1308.4551 - val_loss: 1586.6328\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 444.58264\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 959us/step - loss: 1400.0516 - val_loss: 1165.4927\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 444.58264\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 943us/step - loss: 1420.1443 - val_loss: 335.6193\n",
      "\n",
      "Epoch 00005: val_loss improved from 444.58264 to 335.61929, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 944us/step - loss: 1420.4944 - val_loss: 375.2497\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 335.61929\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 962us/step - loss: 1234.1249 - val_loss: 2094.9434\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 335.61929\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 907us/step - loss: 1308.8489 - val_loss: 2102.7241\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 335.61929\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 906us/step - loss: 1391.9999 - val_loss: 1788.4647\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 335.61929\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 884us/step - loss: 1311.0120 - val_loss: 276.9462\n",
      "\n",
      "Epoch 00010: val_loss improved from 335.61929 to 276.94620, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 938us/step - loss: 1303.7152 - val_loss: 1058.1210\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 276.94620\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 928us/step - loss: 1364.4407 - val_loss: 1766.9020\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 276.94620\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 973us/step - loss: 1282.0758 - val_loss: 3457.7576\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 276.94620\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 964us/step - loss: 1383.8291 - val_loss: 1661.4197\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 276.94620\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 940us/step - loss: 1286.2820 - val_loss: 831.7780\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 276.94620\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 969us/step - loss: 1336.2408 - val_loss: 1734.6897\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 276.94620\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1306.1614 - val_loss: 592.7683\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 276.94620\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 975us/step - loss: 1360.5873 - val_loss: 2029.2755\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 276.94620\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 992us/step - loss: 1333.6134 - val_loss: 1407.0975\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 276.94620\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 958us/step - loss: 1233.3861 - val_loss: 1355.8561\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 276.94620\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 993us/step - loss: 1339.3053 - val_loss: 2038.4058\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 276.94620\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 963us/step - loss: 1316.1881 - val_loss: 1806.0245\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 276.94620\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1278.9341 - val_loss: 1992.0322\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 276.94620\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 987us/step - loss: 1257.5779 - val_loss: 746.1828\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 276.94620\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 963us/step - loss: 1157.4064 - val_loss: 1262.6372\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 276.94620\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 963us/step - loss: 1230.5610 - val_loss: 707.4382\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 276.94620\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 938us/step - loss: 1036.6204 - val_loss: 908.5726\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 276.94620\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1100.9054 - val_loss: 843.2667\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 276.94620\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 977us/step - loss: 996.6402 - val_loss: 1549.2529\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 276.94620\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 1036.3333 - val_loss: 1563.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: val_loss did not improve from 276.94620\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 979us/step - loss: 936.0621 - val_loss: 1932.1014\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 276.94620\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 991us/step - loss: 894.7913 - val_loss: 1750.3165\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 276.94620\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 901.4448 - val_loss: 357.5304\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 276.94620\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 848.4061 - val_loss: 368.0814\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 276.94620\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 833.1685 - val_loss: 570.0085\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 276.94620\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 884.4607 - val_loss: 443.8354\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 276.94620\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 821.5674 - val_loss: 836.0455\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 276.94620\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 845.8939 - val_loss: 637.2737\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 276.94620\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 867.6085 - val_loss: 1228.1403\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 276.94620\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 795.7635 - val_loss: 490.9455\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 276.94620\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 992us/step - loss: 617.9109 - val_loss: 352.8662\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 276.94620\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 964us/step - loss: 283.1192 - val_loss: 326.6212\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 276.94620\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 948us/step - loss: 276.8840 - val_loss: 333.5839\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 276.94620\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 278.3753 - val_loss: 333.0051\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 276.94620\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 936us/step - loss: 276.3630 - val_loss: 333.0675\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 276.94620\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 949us/step - loss: 272.3844 - val_loss: 324.6260\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 276.94620\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 987us/step - loss: 276.0943 - val_loss: 324.8940\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 276.94620\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 944us/step - loss: 269.1673 - val_loss: 327.4686\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 276.94620\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 941us/step - loss: 270.1512 - val_loss: 346.0229\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 276.94620\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 975us/step - loss: 264.8556 - val_loss: 362.0034\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 276.94620\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 292.6151 - val_loss: 315.8492\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 276.94620\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 977us/step - loss: 291.4844 - val_loss: 307.1800\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 276.94620\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 969us/step - loss: 290.6928 - val_loss: 308.5461\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 276.94620\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 291.4374 - val_loss: 311.2058\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 276.94620\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 996us/step - loss: 288.9007 - val_loss: 320.1081\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 276.94620\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 949us/step - loss: 290.4770 - val_loss: 312.7628\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 276.94620\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 982us/step - loss: 292.2683 - val_loss: 309.9749\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 276.94620\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 969us/step - loss: 291.6125 - val_loss: 323.7664\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 276.94620\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 973us/step - loss: 291.5389 - val_loss: 307.4905\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 276.94620\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 292.3280 - val_loss: 310.8587\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 276.94620\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 952us/step - loss: 291.1211 - val_loss: 307.7049\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 276.94620\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 291.7838 - val_loss: 307.2400\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 276.94620\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 291.3848 - val_loss: 313.5727\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 276.94620\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 950us/step - loss: 291.1377 - val_loss: 307.4538\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 276.94620\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 995us/step - loss: 291.5294 - val_loss: 319.7684\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 276.94620\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 987us/step - loss: 291.4779 - val_loss: 307.1801\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 276.94620\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 291.4925 - val_loss: 309.7560\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 276.94620\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 964us/step - loss: 291.7371 - val_loss: 325.5622\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 276.94620\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 960us/step - loss: 291.3452 - val_loss: 313.5938\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 276.94620\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 291.5339 - val_loss: 317.3685\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 276.94620\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 941us/step - loss: 290.2719 - val_loss: 315.5561\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 276.94620\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 954us/step - loss: 265.2505 - val_loss: 335.4900\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 276.94620\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 981us/step - loss: 268.6350 - val_loss: 327.5629\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 276.94620\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 925us/step - loss: 265.9653 - val_loss: 363.8198\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 276.94620\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 981us/step - loss: 265.8643 - val_loss: 345.1212\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 276.94620\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 977us/step - loss: 265.9791 - val_loss: 335.4630\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 276.94620\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 950us/step - loss: 261.2197 - val_loss: 329.5704\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 276.94620\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 962us/step - loss: 265.2850 - val_loss: 348.8602\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 276.94620\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 267.2719 - val_loss: 313.9151\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 276.94620\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 939us/step - loss: 266.6417 - val_loss: 325.1967\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 276.94620\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 259.5216 - val_loss: 342.2687\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 276.94620\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 955us/step - loss: 260.5714 - val_loss: 315.3157\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 276.94620\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 265.5551 - val_loss: 316.1659\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 276.94620\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 262.7937 - val_loss: 344.8193\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 276.94620\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 946us/step - loss: 267.6855 - val_loss: 343.8856\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 276.94620\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 257.7849 - val_loss: 369.1623\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 276.94620\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 992us/step - loss: 259.6211 - val_loss: 328.4229\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 276.94620\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 960us/step - loss: 263.5392 - val_loss: 362.2837\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 276.94620\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 964us/step - loss: 260.1497 - val_loss: 329.6544\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 276.94620\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 945us/step - loss: 266.9976 - val_loss: 328.3616\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 276.94620\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 983us/step - loss: 265.6693 - val_loss: 321.2645\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 276.94620\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 951us/step - loss: 258.0611 - val_loss: 319.8009\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 276.94620\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 951us/step - loss: 280.8981 - val_loss: 320.9935\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 276.94620\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 978us/step - loss: 273.3546 - val_loss: 359.3734\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 276.94620\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 259.7005 - val_loss: 342.0569\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 276.94620\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 927us/step - loss: 260.3705 - val_loss: 334.4170\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 276.94620\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 938us/step - loss: 263.6463 - val_loss: 340.9664\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 276.94620\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 947us/step - loss: 268.1875 - val_loss: 349.8573\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 276.94620\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 960us/step - loss: 259.3608 - val_loss: 357.2497\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 276.94620\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 942us/step - loss: 259.9542 - val_loss: 340.2692\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 276.94620\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 979us/step - loss: 261.7530 - val_loss: 335.3637\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 276.94620\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 992us/step - loss: 258.7083 - val_loss: 317.7569\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 276.94620\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 928us/step - loss: 263.3801 - val_loss: 363.4788\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 276.94620\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 968us/step - loss: 259.4098 - val_loss: 358.3988\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 276.94620\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 260.7480 - val_loss: 338.0840\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 276.94620\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 944us/step - loss: 257.7344 - val_loss: 345.9181\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 276.94620\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 262.0798 - val_loss: 336.8508\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 276.94620\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 956us/step - loss: 261.5942 - val_loss: 333.1434\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 276.94620\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 945us/step - loss: 257.9698 - val_loss: 348.2465\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 276.94620\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 940us/step - loss: 254.0210 - val_loss: 352.2039\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 276.94620\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 1727.6554 - val_loss: 597.1575\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 597.15753, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 938us/step - loss: 1293.3816 - val_loss: 1313.2010\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 597.15753\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 939us/step - loss: 1356.1055 - val_loss: 900.8195\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 597.15753\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 938us/step - loss: 1357.8732 - val_loss: 2150.2224\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 597.15753\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 939us/step - loss: 1373.2225 - val_loss: 2134.4529\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 597.15753\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 921us/step - loss: 1284.9465 - val_loss: 3127.1196\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 597.15753\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 926us/step - loss: 1416.5618 - val_loss: 926.9537\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 597.15753\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 925us/step - loss: 1244.6583 - val_loss: 2478.3127\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 597.15753\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 899us/step - loss: 1364.4948 - val_loss: 1166.1674\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 597.15753\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 871us/step - loss: 1231.4238 - val_loss: 289.2257\n",
      "\n",
      "Epoch 00010: val_loss improved from 597.15753 to 289.22574, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 931us/step - loss: 1289.0818 - val_loss: 457.3893\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 289.22574\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 923us/step - loss: 1253.0945 - val_loss: 897.2427\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 289.22574\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 960us/step - loss: 1364.7838 - val_loss: 2023.1149\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 289.22574\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 955us/step - loss: 1331.6606 - val_loss: 2662.5667\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 289.22574\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 930us/step - loss: 1320.5061 - val_loss: 1581.6779\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 289.22574\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 957us/step - loss: 1326.3162 - val_loss: 1231.0441\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 289.22574\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 974us/step - loss: 1283.7389 - val_loss: 1401.1616\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 289.22574\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 986us/step - loss: 1257.0649 - val_loss: 995.1090\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 289.22574\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 922us/step - loss: 1136.7067 - val_loss: 594.8343\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 289.22574\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 927us/step - loss: 1176.7356 - val_loss: 868.3077\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 289.22574\n",
      "Epoch 21/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 940us/step - loss: 1033.1099 - val_loss: 1335.9380\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 289.22574\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 918us/step - loss: 934.4437 - val_loss: 892.0151\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 289.22574\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 946us/step - loss: 1042.9124 - val_loss: 1972.0236\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 289.22574\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 969us/step - loss: 926.1051 - val_loss: 1975.8462\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 289.22574\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 986us/step - loss: 1002.8256 - val_loss: 922.6119\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 289.22574\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 949us/step - loss: 869.3986 - val_loss: 1563.5244\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 289.22574\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 927us/step - loss: 922.5945 - val_loss: 283.0005\n",
      "\n",
      "Epoch 00027: val_loss improved from 289.22574 to 283.00049, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 956us/step - loss: 895.1929 - val_loss: 352.5440\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 283.00049\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 957us/step - loss: 898.6337 - val_loss: 306.3295\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 283.00049\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 929us/step - loss: 932.8901 - val_loss: 467.2574\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 283.00049\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 962us/step - loss: 882.6398 - val_loss: 1393.5045\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 283.00049\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 984us/step - loss: 896.8826 - val_loss: 577.4628\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 283.00049\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 965us/step - loss: 868.5461 - val_loss: 849.6298\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 283.00049\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 947us/step - loss: 897.6508 - val_loss: 1017.0657\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 283.00049\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 922us/step - loss: 896.3980 - val_loss: 706.4617\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 283.00049\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 941us/step - loss: 855.4888 - val_loss: 1219.0587\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 283.00049\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 950us/step - loss: 834.8588 - val_loss: 1609.6879\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 283.00049\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 958us/step - loss: 836.2493 - val_loss: 828.8883\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 283.00049\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 751.1133 - val_loss: 1206.8472\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 283.00049\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 806.9225 - val_loss: 619.2527\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 283.00049\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 980us/step - loss: 783.5803 - val_loss: 486.7200\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 283.00049\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 930us/step - loss: 760.2205 - val_loss: 961.2549\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 283.00049\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 780.0544 - val_loss: 427.4348\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 283.00049\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 718.6669 - val_loss: 1547.2310\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 283.00049\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 704.9399 - val_loss: 683.7374\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 283.00049\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 961us/step - loss: 704.8788 - val_loss: 933.6086\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 283.00049\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 967us/step - loss: 340.9697 - val_loss: 360.0449\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 283.00049\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 281.4431 - val_loss: 326.8568\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 283.00049\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 279.8542 - val_loss: 330.0651\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 283.00049\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 276.5844 - val_loss: 329.1225\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 283.00049\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 271.5649 - val_loss: 314.2573\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 283.00049\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 270.7684 - val_loss: 342.0530\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 283.00049\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 269.5860 - val_loss: 331.0180\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 283.00049\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.4968 - val_loss: 431.6208\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 283.00049\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 265.2169 - val_loss: 337.7962\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 283.00049\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.3285 - val_loss: 349.2935\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 283.00049\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.1448 - val_loss: 332.9635\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 283.00049\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 261.5516 - val_loss: 355.0137\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 283.00049\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 265.2002 - val_loss: 342.6679\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 283.00049\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 988us/step - loss: 266.8603 - val_loss: 346.6439\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 283.00049\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 260.6289 - val_loss: 360.8206\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 283.00049\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 270.0818 - val_loss: 330.5097\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 283.00049\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 264.3030 - val_loss: 328.8455\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 283.00049\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 268.0254 - val_loss: 328.5873\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 283.00049\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 265.1738 - val_loss: 339.6000\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 283.00049\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.8677 - val_loss: 348.6609\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 283.00049\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 264.1763 - val_loss: 349.3716\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 283.00049\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 970us/step - loss: 261.0251 - val_loss: 345.8426\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 283.00049\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 757us/step - loss: 265.6064 - val_loss: 338.7935\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 283.00049\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 768us/step - loss: 267.6422 - val_loss: 348.9442\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 283.00049\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 963us/step - loss: 264.2614 - val_loss: 362.0333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00071: val_loss did not improve from 283.00049\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 824us/step - loss: 263.2179 - val_loss: 354.4989\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 283.00049\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 946us/step - loss: 261.9664 - val_loss: 340.5163\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 283.00049\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 796us/step - loss: 263.0777 - val_loss: 360.4043\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 283.00049\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 895us/step - loss: 263.1268 - val_loss: 334.1864\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 283.00049\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 868us/step - loss: 262.7774 - val_loss: 351.8942\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 283.00049\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 775us/step - loss: 257.6083 - val_loss: 369.2699\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 283.00049\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 950us/step - loss: 263.4497 - val_loss: 327.3212\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 283.00049\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 914us/step - loss: 267.3093 - val_loss: 356.8112\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 283.00049\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 905us/step - loss: 266.8074 - val_loss: 345.5860\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 283.00049\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 800us/step - loss: 261.0392 - val_loss: 359.8853\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 283.00049\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 940us/step - loss: 264.7500 - val_loss: 348.7854\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 283.00049\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 911us/step - loss: 273.7346 - val_loss: 317.9451\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 283.00049\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 926us/step - loss: 286.5306 - val_loss: 330.2367\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 283.00049\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 984us/step - loss: 265.6916 - val_loss: 351.9176\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 283.00049\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 934us/step - loss: 266.7460 - val_loss: 341.0210\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 283.00049\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 879us/step - loss: 265.9937 - val_loss: 340.4466\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 283.00049\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 929us/step - loss: 262.2658 - val_loss: 366.4315\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 283.00049\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 902us/step - loss: 260.9560 - val_loss: 348.8734\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 283.00049\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 921us/step - loss: 264.1299 - val_loss: 372.3053\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 283.00049\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 867us/step - loss: 266.3353 - val_loss: 365.0843\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 283.00049\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 961us/step - loss: 267.5753 - val_loss: 346.4970\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 283.00049\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 934us/step - loss: 259.8996 - val_loss: 354.0720\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 283.00049\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 804us/step - loss: 262.3188 - val_loss: 350.0873\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 283.00049\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 960us/step - loss: 260.5782 - val_loss: 347.0074\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 283.00049\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 898us/step - loss: 268.3727 - val_loss: 337.1119\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 283.00049\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 977us/step - loss: 260.1218 - val_loss: 357.1573\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 283.00049\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 944us/step - loss: 262.1808 - val_loss: 372.1320\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 283.00049\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 259.7142 - val_loss: 357.0592\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 283.00049\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 934us/step - loss: 261.6584 - val_loss: 328.8814\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 283.00049\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 927us/step - loss: 263.5422 - val_loss: 357.8425\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 283.00049\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 845us/step - loss: 270.8474 - val_loss: 376.1585\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 283.00049\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 946us/step - loss: 268.5883 - val_loss: 345.1285\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 283.00049\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 929us/step - loss: 265.5767 - val_loss: 347.3231\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 283.00049\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 933us/step - loss: 262.0291 - val_loss: 361.1931\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 283.00049\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.2992 - val_loss: 355.4957\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 283.00049\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 950us/step - loss: 263.7845 - val_loss: 400.6988\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 283.00049\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 934us/step - loss: 275.7212 - val_loss: 494.6194\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 283.00049\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 912us/step - loss: 283.4926 - val_loss: 333.5709\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 283.00049\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 875us/step - loss: 261.9519 - val_loss: 353.6748\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 283.00049\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 793us/step - loss: 272.1805 - val_loss: 334.6452\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 283.00049\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 938us/step - loss: 266.0208 - val_loss: 345.8918\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 283.00049\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 882us/step - loss: 267.1158 - val_loss: 325.7216\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 283.00049\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 261.2238 - val_loss: 328.4072\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 283.00049\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 938us/step - loss: 260.9100 - val_loss: 369.9901\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 283.00049\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 873us/step - loss: 265.8306 - val_loss: 342.8324\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 283.00049\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 787us/step - loss: 264.6365 - val_loss: 345.1030\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 283.00049\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 944us/step - loss: 270.4003 - val_loss: 345.1769\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 283.00049\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 277.4314 - val_loss: 345.8676\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 283.00049\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 958us/step - loss: 261.3484 - val_loss: 370.7470\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 283.00049\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 869us/step - loss: 258.2944 - val_loss: 394.6160\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 283.00049\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 995us/step - loss: 260.9976 - val_loss: 350.8783\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 283.00049\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.2030 - val_loss: 381.9884\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 283.00049\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 936us/step - loss: 265.1521 - val_loss: 327.6306\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 283.00049\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 935us/step - loss: 290.1640 - val_loss: 313.3546\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 283.00049\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 956us/step - loss: 270.6180 - val_loss: 356.4984\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 283.00049\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.8235 - val_loss: 435.1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████████                           | 14/21 [26:35<11:45, 100.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00127: val_loss did not improve from 283.00049\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 1281.8221 - val_loss: 1493.7664\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1493.76636, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 961us/step - loss: 871.0837 - val_loss: 1090.2372\n",
      "\n",
      "Epoch 00002: val_loss improved from 1493.76636 to 1090.23718, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 935us/step - loss: 860.7141 - val_loss: 1141.7306\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1090.23718\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 968us/step - loss: 812.4396 - val_loss: 1366.3402\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1090.23718\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 983us/step - loss: 882.2612 - val_loss: 2120.4004\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1090.23718\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 896.9125 - val_loss: 693.0261\n",
      "\n",
      "Epoch 00006: val_loss improved from 1090.23718 to 693.02612, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 964us/step - loss: 867.7391 - val_loss: 976.8557\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 693.02612\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 955us/step - loss: 844.2567 - val_loss: 1390.8259\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 693.02612\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 944us/step - loss: 758.4297 - val_loss: 1465.1161\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 693.02612\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 954us/step - loss: 858.0684 - val_loss: 422.7103\n",
      "\n",
      "Epoch 00010: val_loss improved from 693.02612 to 422.71027, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 934us/step - loss: 879.3593 - val_loss: 325.1914\n",
      "\n",
      "Epoch 00011: val_loss improved from 422.71027 to 325.19144, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 817.7844 - val_loss: 1534.7605\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 325.19144\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 795.0269 - val_loss: 559.3758\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 325.19144\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 962us/step - loss: 789.4865 - val_loss: 4267.4902\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 325.19144\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1000us/step - loss: 892.3307 - val_loss: 1844.9519\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 325.19144\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 939us/step - loss: 889.1880 - val_loss: 1105.6748\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 325.19144\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 963us/step - loss: 724.9602 - val_loss: 1433.6854\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 325.19144\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 954us/step - loss: 808.9203 - val_loss: 2090.8943\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 325.19144\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 795.9091 - val_loss: 353.1183\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 325.19144\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 966us/step - loss: 744.2214 - val_loss: 1190.7437\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 325.19144\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 747.8424 - val_loss: 1126.9108\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 325.19144\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 923us/step - loss: 725.1447 - val_loss: 340.7627\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 325.19144\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 996us/step - loss: 743.2068 - val_loss: 650.1726\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 325.19144\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 901us/step - loss: 735.8300 - val_loss: 1317.7181\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 325.19144\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 965us/step - loss: 712.3043 - val_loss: 625.2201\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 325.19144\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 698.7583 - val_loss: 941.1525\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 325.19144\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 987us/step - loss: 659.1018 - val_loss: 846.6858\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 325.19144\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 921us/step - loss: 664.4431 - val_loss: 1044.4530\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 325.19144\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 967us/step - loss: 678.0770 - val_loss: 1259.4714\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 325.19144\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 964us/step - loss: 631.7793 - val_loss: 991.8392\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 325.19144\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 626.4148 - val_loss: 704.4355\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 325.19144\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 924us/step - loss: 610.9307 - val_loss: 3859.7097\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 325.19144\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 963us/step - loss: 654.9927 - val_loss: 1243.4675\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 325.19144\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 610.2365 - val_loss: 1399.0459\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 325.19144\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 912us/step - loss: 598.8760 - val_loss: 895.0668\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 325.19144\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 597.5875 - val_loss: 297.2641\n",
      "\n",
      "Epoch 00036: val_loss improved from 325.19144 to 297.26407, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 947us/step - loss: 584.6334 - val_loss: 590.8444\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 297.26407\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 562.3312 - val_loss: 1157.8547\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 297.26407\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 589.9443 - val_loss: 310.2711\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 297.26407\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 926us/step - loss: 586.2566 - val_loss: 879.0726\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 297.26407\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 959us/step - loss: 511.3231 - val_loss: 777.0367\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 297.26407\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 966us/step - loss: 558.0472 - val_loss: 1110.9730\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 297.26407\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 554.8743 - val_loss: 306.4156\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 297.26407\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 924us/step - loss: 515.6250 - val_loss: 1096.4359\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 297.26407\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 964us/step - loss: 531.1981 - val_loss: 369.2321\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 297.26407\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 996us/step - loss: 543.2812 - val_loss: 293.9090\n",
      "\n",
      "Epoch 00046: val_loss improved from 297.26407 to 293.90903, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 932us/step - loss: 483.6608 - val_loss: 1035.3121\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 293.90903\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 974us/step - loss: 503.7591 - val_loss: 875.5994\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 293.90903\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 438.7974 - val_loss: 1906.1372\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 293.90903\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 993us/step - loss: 444.7294 - val_loss: 395.9452\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 293.90903\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 958us/step - loss: 371.4034 - val_loss: 482.6535\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 293.90903\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 931us/step - loss: 410.4819 - val_loss: 452.1522\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 293.90903\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 455.4014 - val_loss: 407.4566\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 293.90903\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 997us/step - loss: 455.6357 - val_loss: 448.1889\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 293.90903\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 932us/step - loss: 457.8190 - val_loss: 411.4516\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 293.90903\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 965us/step - loss: 438.7460 - val_loss: 327.2900\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 293.90903\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 956us/step - loss: 446.6372 - val_loss: 384.3586\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 293.90903\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 967us/step - loss: 456.9043 - val_loss: 429.8776\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 293.90903\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 958us/step - loss: 457.0092 - val_loss: 418.9155\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 293.90903\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 949us/step - loss: 457.2488 - val_loss: 420.9588\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 293.90903\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 958us/step - loss: 457.1404 - val_loss: 440.1936\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 293.90903\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.1035 - val_loss: 425.1052\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 293.90903\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.2122 - val_loss: 432.7227\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 293.90903\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9734 - val_loss: 406.2033\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 293.90903\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.1615 - val_loss: 422.8604\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 293.90903\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9611 - val_loss: 429.6547\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 293.90903\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.0395 - val_loss: 418.7725\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 293.90903\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.2056 - val_loss: 405.0133\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 293.90903\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 962us/step - loss: 457.4057 - val_loss: 439.2486\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 293.90903\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.1092 - val_loss: 407.2260\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 293.90903\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 999us/step - loss: 457.4837 - val_loss: 410.9814\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 293.90903\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.0113 - val_loss: 422.9684\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 293.90903\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.6411 - val_loss: 403.3222\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 293.90903\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.3067 - val_loss: 410.5185\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 293.90903\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.0278 - val_loss: 407.3436\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 293.90903\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9813 - val_loss: 415.2432\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 293.90903\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.8628 - val_loss: 409.1669\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 293.90903\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.8651 - val_loss: 431.9681\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 293.90903\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.2165 - val_loss: 413.8212\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 293.90903\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9946 - val_loss: 421.0917\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 293.90903\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.0579 - val_loss: 423.7383\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 293.90903\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9395 - val_loss: 411.7922\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 293.90903\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.2198 - val_loss: 434.9254\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 293.90903\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.3187 - val_loss: 412.9446\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 293.90903\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.7996 - val_loss: 399.3946\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 293.90903\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.3583 - val_loss: 409.4075\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 293.90903\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.3873 - val_loss: 425.4541\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 293.90903\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.1598 - val_loss: 417.4230\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 293.90903\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.5756 - val_loss: 394.3266\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 293.90903\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.3835 - val_loss: 435.0630\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 293.90903\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.7157 - val_loss: 431.3916\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 293.90903\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.8569 - val_loss: 412.2483\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 293.90903\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.0994 - val_loss: 423.6144\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 293.90903\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9367 - val_loss: 424.5364\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 293.90903\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.2462 - val_loss: 414.2634\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 293.90903\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.4282 - val_loss: 434.2344\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 293.90903\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9212 - val_loss: 415.9387\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 293.90903\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.4875 - val_loss: 446.2693\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 293.90903\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.2379 - val_loss: 422.2269\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 293.90903\n",
      "Epoch 100/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9806 - val_loss: 408.6204\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 293.90903\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.9189 - val_loss: 408.1488\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 293.90903\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.3400 - val_loss: 443.1572\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 293.90903\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.0934 - val_loss: 427.5054\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 293.90903\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.8034 - val_loss: 427.1303\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 293.90903\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9926 - val_loss: 409.7450\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 293.90903\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.2358 - val_loss: 417.5179\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 293.90903\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.4826 - val_loss: 425.9797\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 293.90903\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.8645 - val_loss: 439.5523\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 293.90903\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.5854 - val_loss: 417.7249\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 293.90903\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.3117 - val_loss: 423.2868\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 293.90903\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.7585 - val_loss: 448.6776\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 293.90903\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.8828 - val_loss: 428.9717\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 293.90903\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.1555 - val_loss: 440.5428\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 293.90903\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.0468 - val_loss: 402.5062\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 293.90903\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.5280 - val_loss: 409.5986\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 293.90903\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.4940 - val_loss: 440.7279\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 293.90903\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.4391 - val_loss: 407.8091\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 293.90903\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.5745 - val_loss: 432.6666\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 293.90903\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.4596 - val_loss: 418.5649\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 293.90903\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.2334 - val_loss: 417.1095\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 293.90903\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.7659 - val_loss: 426.3341\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 293.90903\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9790 - val_loss: 398.3055\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 293.90903\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.3165 - val_loss: 419.7129\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 293.90903\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.1960 - val_loss: 398.7802\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 293.90903\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.5034 - val_loss: 437.3502\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 293.90903\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.3114 - val_loss: 432.4569\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 293.90903\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.2434 - val_loss: 421.9694\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 293.90903\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.8108 - val_loss: 422.8744\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 293.90903\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.8698 - val_loss: 408.1914\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 293.90903\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.3585 - val_loss: 430.5597\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 293.90903\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9480 - val_loss: 411.1242\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 293.90903\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.1222 - val_loss: 412.5064\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 293.90903\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.7413 - val_loss: 421.4158\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 293.90903\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.9131 - val_loss: 406.7310\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 293.90903\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.5271 - val_loss: 424.7420\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 293.90903\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.8851 - val_loss: 434.2389\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 293.90903\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.3413 - val_loss: 409.2019\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 293.90903\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.1820 - val_loss: 436.1313\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 293.90903\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.3365 - val_loss: 413.6288\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 293.90903\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.3250 - val_loss: 421.3686\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 293.90903\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.6437 - val_loss: 422.2707\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 293.90903\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.7682 - val_loss: 424.9758\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 293.90903\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.1724 - val_loss: 425.2342\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 293.90903\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.1331 - val_loss: 420.8430\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 293.90903\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.8972 - val_loss: 418.7675\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 293.90903\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.0758 - val_loss: 421.3882\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 293.90903\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 990.2401 - val_loss: 3052.5100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3052.51001, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 807.3367 - val_loss: 812.3692\n",
      "\n",
      "Epoch 00002: val_loss improved from 3052.51001 to 812.36920, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 988us/step - loss: 807.1429 - val_loss: 1366.0632\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 812.36920\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 833.5683 - val_loss: 826.7971\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 812.36920\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 861.4944 - val_loss: 1391.2091\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 812.36920\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 833.9337 - val_loss: 732.9135\n",
      "\n",
      "Epoch 00006: val_loss improved from 812.36920 to 732.91345, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 999us/step - loss: 752.6271 - val_loss: 550.3475\n",
      "\n",
      "Epoch 00007: val_loss improved from 732.91345 to 550.34753, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 802.9442 - val_loss: 365.8410\n",
      "\n",
      "Epoch 00008: val_loss improved from 550.34753 to 365.84100, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 970us/step - loss: 836.5856 - val_loss: 756.2452\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 365.84100\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 880.3109 - val_loss: 466.4071\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 365.84100\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 837.6979 - val_loss: 756.7260\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 365.84100\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 794.9347 - val_loss: 1385.1417\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 365.84100\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 763.5682 - val_loss: 993.5669\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 365.84100\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 769.1274 - val_loss: 1040.0546\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 365.84100\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 807.7471 - val_loss: 418.4006\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 365.84100\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 780.2726 - val_loss: 815.8424\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 365.84100\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 770.4328 - val_loss: 1405.9113\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 365.84100\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 752.7294 - val_loss: 1173.3555\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 365.84100\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 746.9744 - val_loss: 1017.7957\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 365.84100\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 753.9664 - val_loss: 608.1631\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 365.84100\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 784.9407 - val_loss: 1339.6345\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 365.84100\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 767.4444 - val_loss: 1101.1885\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 365.84100\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 718.5432 - val_loss: 640.4454\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 365.84100\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 745.8420 - val_loss: 459.8127\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 365.84100\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 719.6288 - val_loss: 700.3144\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 365.84100\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 715.0398 - val_loss: 1147.0530\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 365.84100\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 642.1766 - val_loss: 559.3816\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 365.84100\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 613.8545 - val_loss: 1215.0771\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 365.84100\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 631.8859 - val_loss: 736.4715\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 365.84100\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 600.7577 - val_loss: 930.5881\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 365.84100\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 645.5979 - val_loss: 320.0294\n",
      "\n",
      "Epoch 00031: val_loss improved from 365.84100 to 320.02945, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 592.4648 - val_loss: 499.3214\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 320.02945\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 597.8134 - val_loss: 769.4615\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 320.02945\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 564.1878 - val_loss: 728.0764\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 320.02945\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 573.9413 - val_loss: 897.0371\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 320.02945\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 561.5088 - val_loss: 326.5753\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 320.02945\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 570.2916 - val_loss: 421.5949\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 320.02945\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 514.1459 - val_loss: 798.5731\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 320.02945\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 536.7078 - val_loss: 579.8920\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 320.02945\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 526.6839 - val_loss: 418.1772\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 320.02945\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 533.6667 - val_loss: 254.5578\n",
      "\n",
      "Epoch 00041: val_loss improved from 320.02945 to 254.55783, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 527.7427 - val_loss: 416.7661\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 254.55783\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 538.8482 - val_loss: 636.0433\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 254.55783\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 511.8864 - val_loss: 493.5721\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 254.55783\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 529.2252 - val_loss: 449.0834\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 254.55783\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 506.0717 - val_loss: 545.0271\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 254.55783\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 508.8856 - val_loss: 854.6688\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 254.55783\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 499.3481 - val_loss: 271.8690\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 254.55783\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 472.8373 - val_loss: 258.3161\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 254.55783\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 505.4524 - val_loss: 1094.2297\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 254.55783\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 479.8868 - val_loss: 295.3379\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 254.55783\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 477.7135 - val_loss: 243.4522\n",
      "\n",
      "Epoch 00052: val_loss improved from 254.55783 to 243.45224, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 53/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 467.3035 - val_loss: 289.8521\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 243.45224\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 452.0442 - val_loss: 293.8601\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 243.45224\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 455.4117 - val_loss: 478.6006\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 243.45224\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 462.7098 - val_loss: 528.6617\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 243.45224\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 418.5509 - val_loss: 578.7797\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 243.45224\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 399.6938 - val_loss: 852.0017\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 243.45224\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 406.0875 - val_loss: 369.8693\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 243.45224\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 385.6328 - val_loss: 379.9442\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 243.45224\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 378.5721 - val_loss: 471.6494\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 243.45224\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 389.8861 - val_loss: 469.1610\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 243.45224\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 357.1118 - val_loss: 433.8990\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 243.45224\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 357.2084 - val_loss: 342.3309\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 243.45224\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 361.7673 - val_loss: 459.3708\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 243.45224\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 371.6444 - val_loss: 452.5076\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 243.45224\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 354.5735 - val_loss: 343.1898\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 243.45224\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 330.1662 - val_loss: 534.1606\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 243.45224\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 334.2420 - val_loss: 317.3994\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 243.45224\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 353.7171 - val_loss: 561.9896\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 243.45224\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 329.5254 - val_loss: 250.9904\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 243.45224\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 352.8658 - val_loss: 284.4962\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 243.45224\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 341.1955 - val_loss: 476.4912\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 243.45224\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 328.3566 - val_loss: 316.4682\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 243.45224\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 329.8765 - val_loss: 484.9228\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 243.45224\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 334.1704 - val_loss: 384.9453\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 243.45224\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 334.2161 - val_loss: 375.5271\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 243.45224\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 329.5198 - val_loss: 359.0495\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 243.45224\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 986us/step - loss: 317.4109 - val_loss: 281.5804\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 243.45224\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 324.8629 - val_loss: 379.4548\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 243.45224\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 330.4893 - val_loss: 341.6768\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 243.45224\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 311.2798 - val_loss: 253.0138\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 243.45224\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 325.5275 - val_loss: 327.9954\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 243.45224\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 315.3982 - val_loss: 477.2008\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 243.45224\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 324.8974 - val_loss: 272.0514\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 243.45224\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 323.1617 - val_loss: 340.7217\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 243.45224\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 299.7034 - val_loss: 265.5029\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 243.45224\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 993us/step - loss: 305.8667 - val_loss: 230.1426\n",
      "\n",
      "Epoch 00088: val_loss improved from 243.45224 to 230.14258, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 973us/step - loss: 315.8042 - val_loss: 397.2444\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 230.14258\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 318.1120 - val_loss: 310.0713\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 230.14258\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 305.6729 - val_loss: 261.4171\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 230.14258\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 326.0878 - val_loss: 355.7398\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 230.14258\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 300.9428 - val_loss: 248.1733\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 230.14258\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 304.3428 - val_loss: 417.7299\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 230.14258\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 311.0031 - val_loss: 1405.0746\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 230.14258\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 311.7978 - val_loss: 322.6466\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 230.14258\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 307.4294 - val_loss: 291.0270\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 230.14258\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 298.6700 - val_loss: 316.8645\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 230.14258\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 303.9523 - val_loss: 346.0131\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 230.14258\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 310.8554 - val_loss: 284.9224\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 230.14258\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 317.1825 - val_loss: 261.3710\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 230.14258\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 310.9984 - val_loss: 330.6165\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 230.14258\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 303.5133 - val_loss: 497.9989\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 230.14258\n",
      "Epoch 104/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 301.3675 - val_loss: 240.3465\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 230.14258\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 303.3389 - val_loss: 358.6357\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 230.14258\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 293.7197 - val_loss: 367.5129\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 230.14258\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 313.9802 - val_loss: 327.7965\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 230.14258\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 308.2489 - val_loss: 324.9942\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 230.14258\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 310.0796 - val_loss: 486.6419\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 230.14258\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 296.3618 - val_loss: 363.5569\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 230.14258\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 300.1297 - val_loss: 234.8928\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 230.14258\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 292.0315 - val_loss: 360.0638\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 230.14258\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 299.6643 - val_loss: 231.4966\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 230.14258\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 977us/step - loss: 301.9028 - val_loss: 245.1556\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 230.14258\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 304.6467 - val_loss: 708.7145\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 230.14258\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 305.3114 - val_loss: 431.6432\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 230.14258\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 989us/step - loss: 284.1410 - val_loss: 268.7509\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 230.14258\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 294.9553 - val_loss: 302.3445\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 230.14258\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 294.9104 - val_loss: 240.2474\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 230.14258\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 302.0948 - val_loss: 238.8612\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 230.14258\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 308.0660 - val_loss: 446.2532\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 230.14258\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 305.9796 - val_loss: 412.2072\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 230.14258\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 289.2155 - val_loss: 244.9415\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 230.14258\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 291.7905 - val_loss: 409.8272\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 230.14258\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 297.3302 - val_loss: 319.0067\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 230.14258\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 299.9775 - val_loss: 272.8199\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 230.14258\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 289.5560 - val_loss: 256.3227\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 230.14258\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 300.8086 - val_loss: 448.5648\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 230.14258\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 301.6076 - val_loss: 248.2764\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 230.14258\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 286.6182 - val_loss: 326.1479\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 230.14258\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 289.1423 - val_loss: 285.8716\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 230.14258\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 301.4486 - val_loss: 407.4129\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 230.14258\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 993us/step - loss: 301.0289 - val_loss: 270.4192\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 230.14258\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 291.4233 - val_loss: 248.0189\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 230.14258\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 282.0678 - val_loss: 287.8773\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 230.14258\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 281.0425 - val_loss: 533.3736\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 230.14258\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 286.5936 - val_loss: 374.0394\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 230.14258\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 293.5215 - val_loss: 471.7487\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 230.14258\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 276.1857 - val_loss: 303.0088\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 230.14258\n",
      "Epoch 140/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 289.3889 - val_loss: 523.4062\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 230.14258\n",
      "Epoch 141/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 297.4274 - val_loss: 481.2234\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 230.14258\n",
      "Epoch 142/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 275.2753 - val_loss: 248.7906\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 230.14258\n",
      "Epoch 143/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 282.0351 - val_loss: 246.2137\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 230.14258\n",
      "Epoch 144/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 289.1641 - val_loss: 222.5949\n",
      "\n",
      "Epoch 00144: val_loss improved from 230.14258 to 222.59494, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 145/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 281.6070 - val_loss: 472.2486\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 222.59494\n",
      "Epoch 146/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 291.8897 - val_loss: 441.7775\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 222.59494\n",
      "Epoch 147/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 286.4417 - val_loss: 316.2291\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 222.59494\n",
      "Epoch 148/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 295.3455 - val_loss: 291.5860\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 222.59494\n",
      "Epoch 149/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 286.2939 - val_loss: 293.1963\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 222.59494\n",
      "Epoch 150/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 278.4025 - val_loss: 263.4906\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 222.59494\n",
      "Epoch 151/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 290.3800 - val_loss: 255.8643\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 222.59494\n",
      "Epoch 152/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 278.7739 - val_loss: 246.0620\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 222.59494\n",
      "Epoch 153/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 288.8820 - val_loss: 312.0410\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 222.59494\n",
      "Epoch 154/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 273.4507 - val_loss: 323.6465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00154: val_loss did not improve from 222.59494\n",
      "Epoch 155/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 270.1197 - val_loss: 253.5813\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 222.59494\n",
      "Epoch 156/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 275.2766 - val_loss: 244.5386\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 222.59494\n",
      "Epoch 157/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 274.3426 - val_loss: 245.5718\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 222.59494\n",
      "Epoch 158/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 274.3529 - val_loss: 501.9797\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 222.59494\n",
      "Epoch 159/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 276.4520 - val_loss: 239.8257\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 222.59494\n",
      "Epoch 160/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 281.0291 - val_loss: 287.9174\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 222.59494\n",
      "Epoch 161/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 279.6305 - val_loss: 420.5085\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 222.59494\n",
      "Epoch 162/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 283.4682 - val_loss: 325.4019\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 222.59494\n",
      "Epoch 163/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 277.1647 - val_loss: 305.6373\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 222.59494\n",
      "Epoch 164/10000\n",
      "88/88 [==============================] - 0s 985us/step - loss: 271.0855 - val_loss: 221.8986\n",
      "\n",
      "Epoch 00164: val_loss improved from 222.59494 to 221.89856, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 165/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.9503 - val_loss: 230.6251\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 221.89856\n",
      "Epoch 166/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 269.1009 - val_loss: 380.8102\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 221.89856\n",
      "Epoch 167/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 286.0344 - val_loss: 268.7162\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 221.89856\n",
      "Epoch 168/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 261.2393 - val_loss: 242.3981\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 221.89856\n",
      "Epoch 169/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 286.2282 - val_loss: 217.8917\n",
      "\n",
      "Epoch 00169: val_loss improved from 221.89856 to 217.89174, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 170/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 268.2593 - val_loss: 360.6340\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 217.89174\n",
      "Epoch 171/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 276.0978 - val_loss: 237.2782\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 217.89174\n",
      "Epoch 172/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 270.8311 - val_loss: 277.7726\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 217.89174\n",
      "Epoch 173/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 280.5910 - val_loss: 456.3001\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 217.89174\n",
      "Epoch 174/10000\n",
      "88/88 [==============================] - 0s 984us/step - loss: 272.6305 - val_loss: 408.1822\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 217.89174\n",
      "Epoch 175/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 264.9892 - val_loss: 268.1866\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 217.89174\n",
      "Epoch 176/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 276.4091 - val_loss: 425.5183\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 217.89174\n",
      "Epoch 177/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 276.7559 - val_loss: 299.0000\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 217.89174\n",
      "Epoch 178/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.1122 - val_loss: 230.0907\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 217.89174\n",
      "Epoch 179/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.7107 - val_loss: 288.3352\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 217.89174\n",
      "Epoch 180/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.7201 - val_loss: 294.5077\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 217.89174\n",
      "Epoch 181/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 270.8003 - val_loss: 372.1215\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 217.89174\n",
      "Epoch 182/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 272.0572 - val_loss: 253.8400\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 217.89174\n",
      "Epoch 183/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 271.1681 - val_loss: 238.9204\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 217.89174\n",
      "Epoch 184/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 281.0192 - val_loss: 239.9141\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 217.89174\n",
      "Epoch 185/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 284.7466 - val_loss: 283.4799\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 217.89174\n",
      "Epoch 186/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 271.0245 - val_loss: 388.2199\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 217.89174\n",
      "Epoch 187/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.3149 - val_loss: 215.2261\n",
      "\n",
      "Epoch 00187: val_loss improved from 217.89174 to 215.22614, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 188/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 269.6659 - val_loss: 275.1279\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 215.22614\n",
      "Epoch 189/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 293.2648 - val_loss: 264.3158\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 215.22614\n",
      "Epoch 190/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 269.3742 - val_loss: 262.5913\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 215.22614\n",
      "Epoch 191/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 277.7208 - val_loss: 369.7327\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 215.22614\n",
      "Epoch 192/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 272.9470 - val_loss: 232.2073\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 215.22614\n",
      "Epoch 193/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 272.4243 - val_loss: 434.5699\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 215.22614\n",
      "Epoch 194/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 268.3058 - val_loss: 370.6566\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 215.22614\n",
      "Epoch 195/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 263.3061 - val_loss: 474.4064\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 215.22614\n",
      "Epoch 196/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 269.1475 - val_loss: 509.8716\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 215.22614\n",
      "Epoch 197/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 278.1156 - val_loss: 195.7304\n",
      "\n",
      "Epoch 00197: val_loss improved from 215.22614 to 195.73039, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 198/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.3561 - val_loss: 307.9799\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 195.73039\n",
      "Epoch 199/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 257.9462 - val_loss: 288.0101\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 195.73039\n",
      "Epoch 200/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.6943 - val_loss: 261.4057\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 195.73039\n",
      "Epoch 201/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.5042 - val_loss: 402.8573\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 195.73039\n",
      "Epoch 202/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 274.2035 - val_loss: 409.4449\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 195.73039\n",
      "Epoch 203/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 261.6183 - val_loss: 310.4512\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 195.73039\n",
      "Epoch 204/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 255.7175 - val_loss: 483.5058\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 195.73039\n",
      "Epoch 205/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 267.2993 - val_loss: 354.3202\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 195.73039\n",
      "Epoch 206/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 269.5843 - val_loss: 339.8822\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 195.73039\n",
      "Epoch 207/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 265.8769 - val_loss: 418.0187\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 195.73039\n",
      "Epoch 208/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 263.5395 - val_loss: 204.6931\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 195.73039\n",
      "Epoch 209/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 267.5739 - val_loss: 323.0664\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 195.73039\n",
      "Epoch 210/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 271.7586 - val_loss: 316.9390\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 195.73039\n",
      "Epoch 211/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.6434 - val_loss: 243.2560\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 195.73039\n",
      "Epoch 212/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.0081 - val_loss: 278.4685\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 195.73039\n",
      "Epoch 213/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 259.5657 - val_loss: 421.6394\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 195.73039\n",
      "Epoch 214/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 256.4454 - val_loss: 360.4528\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 195.73039\n",
      "Epoch 215/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 270.7300 - val_loss: 228.2534\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 195.73039\n",
      "Epoch 216/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 267.8785 - val_loss: 293.3506\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 195.73039\n",
      "Epoch 217/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 256.4918 - val_loss: 240.0971\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 195.73039\n",
      "Epoch 218/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 280.2690 - val_loss: 396.7850\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 195.73039\n",
      "Epoch 219/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 256.4767 - val_loss: 252.4512\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 195.73039\n",
      "Epoch 220/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 265.9583 - val_loss: 304.0294\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 195.73039\n",
      "Epoch 221/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 265.4008 - val_loss: 222.6948\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 195.73039\n",
      "Epoch 222/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 268.2939 - val_loss: 255.3857\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 195.73039\n",
      "Epoch 223/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.0989 - val_loss: 405.0031\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 195.73039\n",
      "Epoch 224/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 261.2390 - val_loss: 363.4802\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 195.73039\n",
      "Epoch 225/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 263.2446 - val_loss: 237.7808\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 195.73039\n",
      "Epoch 226/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 253.7980 - val_loss: 206.4719\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 195.73039\n",
      "Epoch 227/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 263.5726 - val_loss: 447.2962\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 195.73039\n",
      "Epoch 228/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.5131 - val_loss: 265.4086\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 195.73039\n",
      "Epoch 229/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.5384 - val_loss: 231.8492\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 195.73039\n",
      "Epoch 230/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.7677 - val_loss: 233.0920\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 195.73039\n",
      "Epoch 231/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 260.8593 - val_loss: 259.1211\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 195.73039\n",
      "Epoch 232/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 265.4005 - val_loss: 205.3422\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 195.73039\n",
      "Epoch 233/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 269.1178 - val_loss: 330.3573\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 195.73039\n",
      "Epoch 234/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 270.4817 - val_loss: 507.6616\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 195.73039\n",
      "Epoch 235/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 267.1665 - val_loss: 205.7162\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 195.73039\n",
      "Epoch 236/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 273.5105 - val_loss: 468.9677\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 195.73039\n",
      "Epoch 237/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 268.0529 - val_loss: 232.1890\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 195.73039\n",
      "Epoch 238/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 265.1138 - val_loss: 329.2723\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 195.73039\n",
      "Epoch 239/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 265.1860 - val_loss: 319.5947\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 195.73039\n",
      "Epoch 240/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 285.8714 - val_loss: 363.5180\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 195.73039\n",
      "Epoch 241/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 277.4884 - val_loss: 406.0014\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 195.73039\n",
      "Epoch 242/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 271.0084 - val_loss: 228.9522\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 195.73039\n",
      "Epoch 243/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 263.8069 - val_loss: 324.5612\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 195.73039\n",
      "Epoch 244/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 267.3271 - val_loss: 485.3952\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 195.73039\n",
      "Epoch 245/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 256.3763 - val_loss: 222.9851\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 195.73039\n",
      "Epoch 246/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 257.3226 - val_loss: 463.1721\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 195.73039\n",
      "Epoch 247/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 259.5608 - val_loss: 210.6249\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 195.73039\n",
      "Epoch 248/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 268.7302 - val_loss: 455.6299\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 195.73039\n",
      "Epoch 249/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 257.8740 - val_loss: 251.7172\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 195.73039\n",
      "Epoch 250/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.7996 - val_loss: 427.4223\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 195.73039\n",
      "Epoch 251/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.9866 - val_loss: 320.3428\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 195.73039\n",
      "Epoch 252/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 270.1732 - val_loss: 291.9666\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 195.73039\n",
      "Epoch 253/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 274.9545 - val_loss: 325.3873\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 195.73039\n",
      "Epoch 254/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 267.8627 - val_loss: 217.0374\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 195.73039\n",
      "Epoch 255/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 266.0052 - val_loss: 286.1866\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 195.73039\n",
      "Epoch 256/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.2846 - val_loss: 212.2955\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 195.73039\n",
      "Epoch 257/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 250.8844 - val_loss: 275.6345\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 195.73039\n",
      "Epoch 258/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 257.7191 - val_loss: 212.1165\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 195.73039\n",
      "Epoch 259/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 275.7299 - val_loss: 307.5048\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 195.73039\n",
      "Epoch 260/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 256.5405 - val_loss: 390.0004\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 195.73039\n",
      "Epoch 261/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 262.2390 - val_loss: 260.4041\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 195.73039\n",
      "Epoch 262/10000\n",
      "88/88 [==============================] - 0s 970us/step - loss: 252.2345 - val_loss: 329.1789\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 195.73039\n",
      "Epoch 263/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 248.5055 - val_loss: 411.7791\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 195.73039\n",
      "Epoch 264/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 254.5472 - val_loss: 225.3138\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 195.73039\n",
      "Epoch 265/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 259.1345 - val_loss: 313.5833\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 195.73039\n",
      "Epoch 266/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 261.2407 - val_loss: 432.4229\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 195.73039\n",
      "Epoch 267/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 265.3916 - val_loss: 289.7569\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 195.73039\n",
      "Epoch 268/10000\n",
      "88/88 [==============================] - 0s 991us/step - loss: 257.2597 - val_loss: 329.7314\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 195.73039\n",
      "Epoch 269/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.7355 - val_loss: 234.1319\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 195.73039\n",
      "Epoch 270/10000\n",
      "88/88 [==============================] - 0s 991us/step - loss: 256.3664 - val_loss: 473.0766\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 195.73039\n",
      "Epoch 271/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 266.8160 - val_loss: 312.1723\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 195.73039\n",
      "Epoch 272/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 253.4978 - val_loss: 219.6917\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 195.73039\n",
      "Epoch 273/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 244.1708 - val_loss: 287.9548\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 195.73039\n",
      "Epoch 274/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.4631 - val_loss: 228.7266\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 195.73039\n",
      "Epoch 275/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 263.6717 - val_loss: 244.6509\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 195.73039\n",
      "Epoch 276/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 259.8223 - val_loss: 251.4347\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 195.73039\n",
      "Epoch 277/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 250.3530 - val_loss: 386.5714\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 195.73039\n",
      "Epoch 278/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 257.0155 - val_loss: 274.6138\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 195.73039\n",
      "Epoch 279/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 252.5559 - val_loss: 246.2398\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 195.73039\n",
      "Epoch 280/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 273.7482 - val_loss: 457.3958\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 195.73039\n",
      "Epoch 281/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 271.5529 - val_loss: 271.2972\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 195.73039\n",
      "Epoch 282/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 264.5515 - val_loss: 359.6808\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 195.73039\n",
      "Epoch 283/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 259.6432 - val_loss: 255.0849\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 195.73039\n",
      "Epoch 284/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 258.7883 - val_loss: 233.0575\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 195.73039\n",
      "Epoch 285/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 263.9191 - val_loss: 312.7040\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 195.73039\n",
      "Epoch 286/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 267.3098 - val_loss: 305.4262\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 195.73039\n",
      "Epoch 287/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 272.3427 - val_loss: 229.8885\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 195.73039\n",
      "Epoch 288/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 272.1743 - val_loss: 256.3862\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 195.73039\n",
      "Epoch 289/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 261.3439 - val_loss: 376.7219\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 195.73039\n",
      "Epoch 290/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 255.0612 - val_loss: 273.0615\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 195.73039\n",
      "Epoch 291/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 251.9087 - val_loss: 332.0839\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 195.73039\n",
      "Epoch 292/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 276.2787 - val_loss: 414.9477\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 195.73039\n",
      "Epoch 293/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 273.7359 - val_loss: 261.0787\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 195.73039\n",
      "Epoch 294/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 265.9534 - val_loss: 346.2310\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 195.73039\n",
      "Epoch 295/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 254.2744 - val_loss: 411.0320\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 195.73039\n",
      "Epoch 296/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 260.1827 - val_loss: 243.0395\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 195.73039\n",
      "Epoch 297/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 271.6131 - val_loss: 312.4970\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 195.73039\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 1096.7142 - val_loss: 1182.8656\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1182.86560, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 802.6550 - val_loss: 828.9236\n",
      "\n",
      "Epoch 00002: val_loss improved from 1182.86560 to 828.92365, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 889.2206 - val_loss: 2555.0266\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 828.92365\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 760.9074 - val_loss: 1224.7373\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 828.92365\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 808.4249 - val_loss: 1479.8475\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 828.92365\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 807.9084 - val_loss: 1453.1440\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 828.92365\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 792.1169 - val_loss: 1324.1786\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 828.92365\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 808.3046 - val_loss: 1351.6881\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 828.92365\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 833.4993 - val_loss: 1540.0919\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 828.92365\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 808.9515 - val_loss: 556.9503\n",
      "\n",
      "Epoch 00010: val_loss improved from 828.92365 to 556.95026, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 728.3683 - val_loss: 437.5686\n",
      "\n",
      "Epoch 00011: val_loss improved from 556.95026 to 437.56860, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 781.2410 - val_loss: 1339.7308\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 437.56860\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 777.1273 - val_loss: 1631.1049\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 437.56860\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 849.1051 - val_loss: 365.2205\n",
      "\n",
      "Epoch 00014: val_loss improved from 437.56860 to 365.22046, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 999us/step - loss: 809.0012 - val_loss: 1333.4929\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 365.22046\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 781.2186 - val_loss: 940.3725\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 365.22046\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 977us/step - loss: 779.2290 - val_loss: 1568.7388\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 365.22046\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 792.6925 - val_loss: 836.2333\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 365.22046\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 747.7762 - val_loss: 433.8970\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 365.22046\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 772.5107 - val_loss: 1277.0752\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 365.22046\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 725.1936 - val_loss: 1120.3019\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 365.22046\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 776.5128 - val_loss: 1598.7260\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 365.22046\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 821.5063 - val_loss: 1207.0618\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 365.22046\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 784.7767 - val_loss: 1265.6003\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 365.22046\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 796.0985 - val_loss: 464.4202\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 365.22046\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 768.9956 - val_loss: 484.1135\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 365.22046\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 796.2734 - val_loss: 1180.9965\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 365.22046\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 986us/step - loss: 777.9274 - val_loss: 950.6555\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 365.22046\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 757.2582 - val_loss: 2885.0894\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 365.22046\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 775.4193 - val_loss: 843.6744\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 365.22046\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 708.3999 - val_loss: 4539.0762\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 365.22046\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 800.6076 - val_loss: 1481.3491\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 365.22046\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 724.4889 - val_loss: 2042.7148\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 365.22046\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 760.4544 - val_loss: 1423.5479\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 365.22046\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 681.8739 - val_loss: 772.0128\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 365.22046\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 759.8038 - val_loss: 5183.3130\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 365.22046\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 734.0601 - val_loss: 2048.0649\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 365.22046\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 811.9872 - val_loss: 1441.0439\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 365.22046\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 707.3934 - val_loss: 2303.2869\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 365.22046\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 694.0182 - val_loss: 2852.9163\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 365.22046\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 708.7631 - val_loss: 478.1321\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 365.22046\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 706.3265 - val_loss: 1286.7446\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 365.22046\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 730.1973 - val_loss: 1236.7593\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 365.22046\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 647.4700 - val_loss: 1452.9723\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 365.22046\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 746.7418 - val_loss: 906.2639\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 365.22046\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 724.2272 - val_loss: 4586.8892\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 365.22046\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 685.8387 - val_loss: 554.8361\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 365.22046\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 730.8134 - val_loss: 2355.4287\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 365.22046\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 718.5140 - val_loss: 1210.2382\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 365.22046\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 647.6032 - val_loss: 1142.0619\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 365.22046\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 680.3162 - val_loss: 441.7651\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 365.22046\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 587.1526 - val_loss: 488.1795\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 365.22046\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 651.2930 - val_loss: 481.6620\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 365.22046\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 742.4850 - val_loss: 1184.7258\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 365.22046\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 743.5944 - val_loss: 396.4296\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 365.22046\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 631.5601 - val_loss: 837.7665\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 365.22046\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 650.6830 - val_loss: 438.4580\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 365.22046\n",
      "Epoch 58/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 664.6750 - val_loss: 1069.1372\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 365.22046\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 628.5748 - val_loss: 372.8731\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 365.22046\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 445.6522 - val_loss: 441.9398\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 365.22046\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.3002 - val_loss: 400.7167\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 365.22046\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.0284 - val_loss: 437.1194\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 365.22046\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.2161 - val_loss: 395.8149\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 365.22046\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.2783 - val_loss: 428.3795\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 365.22046\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.3680 - val_loss: 431.8740\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 365.22046\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.1613 - val_loss: 443.5818\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 365.22046\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.4209 - val_loss: 429.0329\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 365.22046\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.2112 - val_loss: 410.5816\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 365.22046\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.9178 - val_loss: 415.6193\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 365.22046\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.5725 - val_loss: 429.9991\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 365.22046\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.8895 - val_loss: 441.8035\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 365.22046\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 444.5489 - val_loss: 374.1361\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 365.22046\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 466.6470 - val_loss: 414.8613\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 365.22046\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.5783 - val_loss: 404.0543\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 365.22046\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.0343 - val_loss: 409.0089\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 365.22046\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.4845 - val_loss: 401.6274\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 365.22046\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.3094 - val_loss: 417.0951\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 365.22046\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.4656 - val_loss: 416.8481\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 365.22046\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.4380 - val_loss: 451.8578\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 365.22046\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.7259 - val_loss: 425.0770\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 365.22046\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.4027 - val_loss: 438.7332\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 365.22046\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.9294 - val_loss: 432.3243\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 365.22046\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.8435 - val_loss: 425.8485\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 365.22046\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.9319 - val_loss: 414.7788\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 365.22046\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.7230 - val_loss: 414.5479\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 365.22046\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.2379 - val_loss: 408.9919\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 365.22046\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.1797 - val_loss: 424.5180\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 365.22046\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.8897 - val_loss: 418.8650\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 365.22046\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.2502 - val_loss: 399.3375\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 365.22046\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.8711 - val_loss: 405.9029\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 365.22046\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.4342 - val_loss: 409.0701\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 365.22046\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.9699 - val_loss: 436.5954\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 365.22046\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.4124 - val_loss: 461.3309\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 365.22046\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 461.1342 - val_loss: 431.6528\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 365.22046\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.5775 - val_loss: 411.1029\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 365.22046\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.4270 - val_loss: 423.0901\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 365.22046\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.1073 - val_loss: 410.4647\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 365.22046\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.9159 - val_loss: 398.1424\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 365.22046\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 461.2980 - val_loss: 413.1555\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 365.22046\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.1012 - val_loss: 435.1682\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 365.22046\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.8436 - val_loss: 410.6714\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 365.22046\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.1517 - val_loss: 401.7032\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 365.22046\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.4598 - val_loss: 429.9813\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 365.22046\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.1412 - val_loss: 427.5938\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 365.22046\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.7868 - val_loss: 399.0415\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 365.22046\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.5680 - val_loss: 410.8365\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 365.22046\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.7074 - val_loss: 424.5540\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 365.22046\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.5271 - val_loss: 408.4948\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 365.22046\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.0612 - val_loss: 399.5787\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 365.22046\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.8047 - val_loss: 433.3265\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 365.22046\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 459.8969 - val_loss: 410.9603\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 365.22046\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.2457 - val_loss: 408.8590\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 365.22046\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.3187 - val_loss: 438.1210\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 365.22046\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.1894 - val_loss: 435.7311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|█████████████████████████████████████████████████████████▊                       | 15/21 [28:20<10:13, 102.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00114: val_loss did not improve from 365.22046\n",
      "good\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 2142.7820 - val_loss: 3272.8088\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3272.80884, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 924us/step - loss: 930.3447 - val_loss: 1731.0067\n",
      "\n",
      "Epoch 00002: val_loss improved from 3272.80884 to 1731.00671, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 914us/step - loss: 584.2261 - val_loss: 1339.9438\n",
      "\n",
      "Epoch 00003: val_loss improved from 1731.00671 to 1339.94385, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 950us/step - loss: 611.3754 - val_loss: 1203.4038\n",
      "\n",
      "Epoch 00004: val_loss improved from 1339.94385 to 1203.40381, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 917us/step - loss: 580.0557 - val_loss: 1243.6667\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1203.40381\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 570.5856 - val_loss: 1672.0847\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1203.40381\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 939us/step - loss: 586.7408 - val_loss: 1411.2629\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1203.40381\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 578.0441 - val_loss: 1171.0111\n",
      "\n",
      "Epoch 00008: val_loss improved from 1203.40381 to 1171.01111, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 923us/step - loss: 638.2534 - val_loss: 1135.1094\n",
      "\n",
      "Epoch 00009: val_loss improved from 1171.01111 to 1135.10938, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 934us/step - loss: 602.0594 - val_loss: 1151.9122\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1135.10938\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 932us/step - loss: 567.1594 - val_loss: 1132.6001\n",
      "\n",
      "Epoch 00011: val_loss improved from 1135.10938 to 1132.60010, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 971us/step - loss: 576.8292 - val_loss: 1188.3873\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1132.60010\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 942us/step - loss: 556.3292 - val_loss: 1144.1328\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1132.60010\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 946us/step - loss: 562.0740 - val_loss: 1565.1139\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1132.60010\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 969us/step - loss: 567.2540 - val_loss: 1192.5007\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1132.60010\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 935us/step - loss: 573.4081 - val_loss: 1132.7314\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1132.60010\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 945us/step - loss: 550.3716 - val_loss: 1594.6530\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1132.60010\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 936us/step - loss: 587.6706 - val_loss: 1213.2156\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1132.60010\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 978us/step - loss: 545.8579 - val_loss: 1130.3514\n",
      "\n",
      "Epoch 00019: val_loss improved from 1132.60010 to 1130.35144, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 902us/step - loss: 550.1155 - val_loss: 1198.2809\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1130.35144\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 926us/step - loss: 594.1277 - val_loss: 1115.4879\n",
      "\n",
      "Epoch 00021: val_loss improved from 1130.35144 to 1115.48792, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 959us/step - loss: 568.8608 - val_loss: 2119.7334\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1115.48792\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 938us/step - loss: 539.3524 - val_loss: 1184.8815\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1115.48792\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 925us/step - loss: 551.5128 - val_loss: 1471.6814\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1115.48792\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 958us/step - loss: 530.3430 - val_loss: 1116.8542\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1115.48792\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 937us/step - loss: 499.6639 - val_loss: 1747.6890\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1115.48792\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 990us/step - loss: 587.3039 - val_loss: 1794.4819\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1115.48792\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 998us/step - loss: 560.7558 - val_loss: 1473.5409\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1115.48792\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 550.9730 - val_loss: 1444.4747\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1115.48792\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 908us/step - loss: 568.8615 - val_loss: 1463.2192\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1115.48792\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 525.8307 - val_loss: 1191.6832\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1115.48792\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 946us/step - loss: 519.5505 - val_loss: 1523.8235\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1115.48792\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 992us/step - loss: 540.0801 - val_loss: 1250.8560\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1115.48792\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 905us/step - loss: 539.4376 - val_loss: 1100.6467\n",
      "\n",
      "Epoch 00034: val_loss improved from 1115.48792 to 1100.64673, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 954us/step - loss: 511.3359 - val_loss: 1189.7755\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1100.64673\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 533.0173 - val_loss: 1171.4548\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1100.64673\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 931us/step - loss: 513.4444 - val_loss: 1084.1930\n",
      "\n",
      "Epoch 00037: val_loss improved from 1100.64673 to 1084.19299, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 934us/step - loss: 497.3672 - val_loss: 1122.9630\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1084.19299\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 966us/step - loss: 496.2393 - val_loss: 1174.9497\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1084.19299\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 925us/step - loss: 526.1223 - val_loss: 1309.1689\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1084.19299\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 964us/step - loss: 507.8775 - val_loss: 2020.0884\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1084.19299\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 991us/step - loss: 513.7077 - val_loss: 1168.7939\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1084.19299\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 938us/step - loss: 535.3231 - val_loss: 1195.2764\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1084.19299\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 515.8552 - val_loss: 1181.3721\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1084.19299\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 934us/step - loss: 544.1885 - val_loss: 1102.9290\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1084.19299\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 954us/step - loss: 552.3342 - val_loss: 1632.4733\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1084.19299\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 508.0150 - val_loss: 1421.2733\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1084.19299\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 911us/step - loss: 526.7611 - val_loss: 1134.0121\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1084.19299\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 945us/step - loss: 498.4928 - val_loss: 1702.3243\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1084.19299\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 955us/step - loss: 495.6374 - val_loss: 1129.7312\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1084.19299\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 936us/step - loss: 493.3093 - val_loss: 1458.6167\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1084.19299\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 975us/step - loss: 522.1146 - val_loss: 1802.7247\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1084.19299\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 919us/step - loss: 477.7116 - val_loss: 1247.1235\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1084.19299\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 954us/step - loss: 491.6688 - val_loss: 1069.1641\n",
      "\n",
      "Epoch 00054: val_loss improved from 1084.19299 to 1069.16406, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 488.6541 - val_loss: 1087.3068\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1069.16406\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 472.3984 - val_loss: 1174.4270\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1069.16406\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 962us/step - loss: 495.6378 - val_loss: 1120.3590\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1069.16406\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 500.4740 - val_loss: 1149.9041\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1069.16406\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 944us/step - loss: 476.2428 - val_loss: 1122.1200\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1069.16406\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 952us/step - loss: 472.6132 - val_loss: 1347.0564\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1069.16406\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 945us/step - loss: 480.1154 - val_loss: 1220.4253\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1069.16406\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 959us/step - loss: 454.4604 - val_loss: 1082.0469\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1069.16406\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 452.7728 - val_loss: 1763.5531\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1069.16406\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 979us/step - loss: 470.0408 - val_loss: 1111.1549\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1069.16406\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 441.1373 - val_loss: 1152.3773\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1069.16406\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 441.9421 - val_loss: 1313.7930\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1069.16406\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 461.2612 - val_loss: 1101.6860\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1069.16406\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 451.2634 - val_loss: 1123.7839\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1069.16406\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 454.8285 - val_loss: 1111.9702\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1069.16406\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 451.7543 - val_loss: 1029.1389\n",
      "\n",
      "Epoch 00070: val_loss improved from 1069.16406 to 1029.13892, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 472.8911 - val_loss: 1612.6306\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1029.13892\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 447.2578 - val_loss: 1047.8052\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1029.13892\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 456.2912 - val_loss: 1049.5010\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1029.13892\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 433.8861 - val_loss: 1057.8330\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1029.13892\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 464.5732 - val_loss: 1026.0829\n",
      "\n",
      "Epoch 00075: val_loss improved from 1029.13892 to 1026.08289, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 434.9095 - val_loss: 1058.9161\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1026.08289\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 432.8252 - val_loss: 1044.7618\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1026.08289\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 447.0613 - val_loss: 1000.2472\n",
      "\n",
      "Epoch 00078: val_loss improved from 1026.08289 to 1000.24719, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 398.0150 - val_loss: 1113.9718\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1000.24719\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 421.0136 - val_loss: 1057.6637\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1000.24719\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 418.9408 - val_loss: 1085.1116\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1000.24719\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 431.2476 - val_loss: 1031.0601\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1000.24719\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 411.9525 - val_loss: 1213.0836\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1000.24719\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 421.9843 - val_loss: 1084.8846\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1000.24719\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 386.2284 - val_loss: 1078.6953\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1000.24719\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 412.6782 - val_loss: 1323.6155\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1000.24719\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 428.1626 - val_loss: 1143.6061\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1000.24719\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 417.0443 - val_loss: 1004.6676\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1000.24719\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 396.9600 - val_loss: 1133.6821\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1000.24719\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 420.3723 - val_loss: 1533.8080\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1000.24719\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 416.2843 - val_loss: 1050.0442\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1000.24719\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 375.5504 - val_loss: 1064.2095\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1000.24719\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 423.7778 - val_loss: 1241.9259\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1000.24719\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 408.2874 - val_loss: 1559.8536\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1000.24719\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 404.6447 - val_loss: 1140.3302\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1000.24719\n",
      "Epoch 96/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 373.8869 - val_loss: 1254.7898\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1000.24719\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 397.9701 - val_loss: 1221.7238\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1000.24719\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 996us/step - loss: 377.6352 - val_loss: 1111.9379\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1000.24719\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 384.3737 - val_loss: 1057.4254\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1000.24719\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 373.9840 - val_loss: 1072.1836\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1000.24719\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 390.1110 - val_loss: 1072.6230\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1000.24719\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 379.3582 - val_loss: 1116.9528\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1000.24719\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 383.2050 - val_loss: 1162.1584\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1000.24719\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 408.4324 - val_loss: 1324.1047\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1000.24719\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 379.8704 - val_loss: 1239.1550\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1000.24719\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 380.4001 - val_loss: 1016.9363\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1000.24719\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - ETA: 0s - loss: 367.824 - 0s 1ms/step - loss: 366.3586 - val_loss: 1179.5989\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1000.24719\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 371.8305 - val_loss: 1086.8545\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1000.24719\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 384.8491 - val_loss: 985.8992\n",
      "\n",
      "Epoch 00109: val_loss improved from 1000.24719 to 985.89917, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 403.2221 - val_loss: 1162.0920\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 985.89917\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 366.8236 - val_loss: 1105.7959\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 985.89917\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 376.4861 - val_loss: 1171.2423\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 985.89917\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 361.1700 - val_loss: 1036.2493\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 985.89917\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 369.6890 - val_loss: 1114.8508\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 985.89917\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 356.2594 - val_loss: 1189.4402\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 985.89917\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 374.6138 - val_loss: 1291.9792\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 985.89917\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 389.6885 - val_loss: 1048.8079\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 985.89917\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 359.6777 - val_loss: 993.5105\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 985.89917\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 362.5216 - val_loss: 1172.4268\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 985.89917\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 360.5567 - val_loss: 1127.5543\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 985.89917\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 358.2634 - val_loss: 1080.1455\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 985.89917\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 377.8568 - val_loss: 1193.5730\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 985.89917\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 358.8864 - val_loss: 1088.2950\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 985.89917\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 365.9714 - val_loss: 1536.3107\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 985.89917\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 349.4439 - val_loss: 1338.2356\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 985.89917\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 336.0459 - val_loss: 1236.1990\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 985.89917\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 365.7701 - val_loss: 1246.0894\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 985.89917\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 339.8395 - val_loss: 1006.1779\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 985.89917\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 356.0510 - val_loss: 994.4893\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 985.89917\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 361.3229 - val_loss: 1352.4175\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 985.89917\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 357.0549 - val_loss: 979.8429\n",
      "\n",
      "Epoch 00131: val_loss improved from 985.89917 to 979.84290, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 343.8795 - val_loss: 1277.5173\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 979.84290\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 345.1356 - val_loss: 1125.4088\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 979.84290\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 330.9265 - val_loss: 1008.4533\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 979.84290\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 342.0587 - val_loss: 1069.3513\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 979.84290\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 343.1714 - val_loss: 1074.2512\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 979.84290\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 329.8392 - val_loss: 1070.7194\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 979.84290\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 344.8965 - val_loss: 1079.8823\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 979.84290\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 325.5092 - val_loss: 1271.6466\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 979.84290\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 323.5728 - val_loss: 1273.0538\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 979.84290\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 344.0122 - val_loss: 1237.1382\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 979.84290\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 331.2011 - val_loss: 1171.3790\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 979.84290\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 343.7379 - val_loss: 967.6285\n",
      "\n",
      "Epoch 00143: val_loss improved from 979.84290 to 967.62854, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 339.3464 - val_loss: 1137.1187\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 967.62854\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 340.1511 - val_loss: 1196.6388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00145: val_loss did not improve from 967.62854\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 323.2974 - val_loss: 1023.6956\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 967.62854\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 326.2260 - val_loss: 1091.0056\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 967.62854\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 338.1768 - val_loss: 1147.3054\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 967.62854\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 320.2660 - val_loss: 1134.5461\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 967.62854\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 325.2234 - val_loss: 1196.4055\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 967.62854\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 332.4605 - val_loss: 1050.8875\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 967.62854\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 317.3794 - val_loss: 1077.3760\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 967.62854\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 329.6949 - val_loss: 1145.5574\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 967.62854\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 310.0932 - val_loss: 1113.5083\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 967.62854\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 323.8416 - val_loss: 1013.0080\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 967.62854\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 316.2973 - val_loss: 1223.0847\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 967.62854\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 318.0698 - val_loss: 1165.2230\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 967.62854\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 306.7448 - val_loss: 1199.2590\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 967.62854\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 301.3169 - val_loss: 1089.2086\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 967.62854\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 311.1763 - val_loss: 1266.4476\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 967.62854\n",
      "Epoch 161/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 304.0142 - val_loss: 1061.1661\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 967.62854\n",
      "Epoch 162/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 316.0106 - val_loss: 979.9123\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 967.62854\n",
      "Epoch 163/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 303.8332 - val_loss: 1069.5601\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 967.62854\n",
      "Epoch 164/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 307.9592 - val_loss: 1413.5835\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 967.62854\n",
      "Epoch 165/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 297.3242 - val_loss: 1043.5361\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 967.62854\n",
      "Epoch 166/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 304.2829 - val_loss: 1228.9905\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 967.62854\n",
      "Epoch 167/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 290.1815 - val_loss: 1013.7900\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 967.62854\n",
      "Epoch 168/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 310.2868 - val_loss: 985.0147\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 967.62854\n",
      "Epoch 169/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 288.8980 - val_loss: 1209.9745\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 967.62854\n",
      "Epoch 170/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 294.9476 - val_loss: 1004.5273\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 967.62854\n",
      "Epoch 171/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 299.9810 - val_loss: 1019.3702\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 967.62854\n",
      "Epoch 172/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 292.8929 - val_loss: 1044.5409\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 967.62854\n",
      "Epoch 173/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 295.3185 - val_loss: 1227.7736\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 967.62854\n",
      "Epoch 174/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 303.3688 - val_loss: 1030.0356\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 967.62854\n",
      "Epoch 175/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 286.7727 - val_loss: 1072.5055\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 967.62854\n",
      "Epoch 176/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 281.8389 - val_loss: 1026.6687\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 967.62854\n",
      "Epoch 177/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 307.2354 - val_loss: 1061.8707\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 967.62854\n",
      "Epoch 178/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 296.0835 - val_loss: 1422.0928\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 967.62854\n",
      "Epoch 179/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 296.1772 - val_loss: 1016.0031\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 967.62854\n",
      "Epoch 180/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 300.2906 - val_loss: 1056.1528\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 967.62854\n",
      "Epoch 181/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 287.0015 - val_loss: 1077.3165\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 967.62854\n",
      "Epoch 182/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 289.6320 - val_loss: 1289.6667\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 967.62854\n",
      "Epoch 183/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 285.6722 - val_loss: 1086.9595\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 967.62854\n",
      "Epoch 184/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 290.0803 - val_loss: 963.2495\n",
      "\n",
      "Epoch 00184: val_loss improved from 967.62854 to 963.24945, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 185/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 290.8528 - val_loss: 1122.5763\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 963.24945\n",
      "Epoch 186/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 296.0668 - val_loss: 1018.7618\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 963.24945\n",
      "Epoch 187/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 289.5057 - val_loss: 1127.7882\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 963.24945\n",
      "Epoch 188/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 283.7433 - val_loss: 922.8773\n",
      "\n",
      "Epoch 00188: val_loss improved from 963.24945 to 922.87726, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 189/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 290.3155 - val_loss: 1079.5820\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 922.87726\n",
      "Epoch 190/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 279.6341 - val_loss: 1011.3000\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 922.87726\n",
      "Epoch 191/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 290.0494 - val_loss: 989.7486\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 922.87726\n",
      "Epoch 192/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 288.4583 - val_loss: 1099.5608\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 922.87726\n",
      "Epoch 193/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 289.6989 - val_loss: 1092.6622\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 922.87726\n",
      "Epoch 194/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 278.5194 - val_loss: 992.8404\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 922.87726\n",
      "Epoch 195/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 280.4420 - val_loss: 1063.4694\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 922.87726\n",
      "Epoch 196/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 281.8296 - val_loss: 1124.8124\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 922.87726\n",
      "Epoch 197/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 299.0608 - val_loss: 1188.8352\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 922.87726\n",
      "Epoch 198/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 286.4671 - val_loss: 953.0865\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 922.87726\n",
      "Epoch 199/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 277.7052 - val_loss: 1204.3489\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 922.87726\n",
      "Epoch 200/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 286.3008 - val_loss: 910.1395\n",
      "\n",
      "Epoch 00200: val_loss improved from 922.87726 to 910.13947, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 201/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 291.3360 - val_loss: 987.7822\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 910.13947\n",
      "Epoch 202/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 276.9823 - val_loss: 1041.7021\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 910.13947\n",
      "Epoch 203/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 274.3559 - val_loss: 977.4575\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 910.13947\n",
      "Epoch 204/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 285.4491 - val_loss: 1017.0599\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 910.13947\n",
      "Epoch 205/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 277.7460 - val_loss: 1064.9268\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 910.13947\n",
      "Epoch 206/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 281.8238 - val_loss: 1271.7719\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 910.13947\n",
      "Epoch 207/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 280.7191 - val_loss: 1150.9191\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 910.13947\n",
      "Epoch 208/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 280.6126 - val_loss: 929.1230\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 910.13947\n",
      "Epoch 209/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 273.9861 - val_loss: 1014.5444\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 910.13947\n",
      "Epoch 210/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 275.7935 - val_loss: 1035.1118\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 910.13947\n",
      "Epoch 211/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 270.9729 - val_loss: 892.3554\n",
      "\n",
      "Epoch 00211: val_loss improved from 910.13947 to 892.35541, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 212/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 275.9708 - val_loss: 1061.1154\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 892.35541\n",
      "Epoch 213/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 279.4511 - val_loss: 940.1183\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 892.35541\n",
      "Epoch 214/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 268.2422 - val_loss: 937.1727\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 892.35541\n",
      "Epoch 215/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 263.4354 - val_loss: 987.1041\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 892.35541\n",
      "Epoch 216/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 271.5074 - val_loss: 1231.9213\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 892.35541\n",
      "Epoch 217/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 259.4939 - val_loss: 958.3081\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 892.35541\n",
      "Epoch 218/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 280.0899 - val_loss: 911.4497\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 892.35541\n",
      "Epoch 219/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 264.2982 - val_loss: 934.1152\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 892.35541\n",
      "Epoch 220/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 272.9909 - val_loss: 1113.5425\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 892.35541\n",
      "Epoch 221/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 259.1201 - val_loss: 1036.6343\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 892.35541\n",
      "Epoch 222/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 267.5942 - val_loss: 952.1941\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 892.35541\n",
      "Epoch 223/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 270.5588 - val_loss: 954.4968\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 892.35541\n",
      "Epoch 224/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 277.6411 - val_loss: 989.9697\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 892.35541\n",
      "Epoch 225/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 270.2012 - val_loss: 1005.1111\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 892.35541\n",
      "Epoch 226/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.9540 - val_loss: 1004.3323\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 892.35541\n",
      "Epoch 227/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 281.0849 - val_loss: 872.6170\n",
      "\n",
      "Epoch 00227: val_loss improved from 892.35541 to 872.61700, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 228/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 263.5448 - val_loss: 1032.9493\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 872.61700\n",
      "Epoch 229/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 282.3786 - val_loss: 1063.8008\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 872.61700\n",
      "Epoch 230/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 264.6786 - val_loss: 1059.3699\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 872.61700\n",
      "Epoch 231/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.5157 - val_loss: 1044.4432\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 872.61700\n",
      "Epoch 232/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 271.5036 - val_loss: 1001.7737\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 872.61700\n",
      "Epoch 233/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 267.1283 - val_loss: 951.4655\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 872.61700\n",
      "Epoch 234/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 263.8232 - val_loss: 930.6068\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 872.61700\n",
      "Epoch 235/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 259.0552 - val_loss: 1129.2867\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 872.61700\n",
      "Epoch 236/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 264.6491 - val_loss: 943.8894\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 872.61700\n",
      "Epoch 237/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 261.6860 - val_loss: 1016.4129\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 872.61700\n",
      "Epoch 238/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 253.7789 - val_loss: 854.9510\n",
      "\n",
      "Epoch 00238: val_loss improved from 872.61700 to 854.95099, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 239/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 259.8005 - val_loss: 1073.6141\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 854.95099\n",
      "Epoch 240/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 267.8849 - val_loss: 1124.9836\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 854.95099\n",
      "Epoch 241/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 274.8743 - val_loss: 930.5477\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 854.95099\n",
      "Epoch 242/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 256.5840 - val_loss: 904.7980\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 854.95099\n",
      "Epoch 243/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 252.1985 - val_loss: 948.6739\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 854.95099\n",
      "Epoch 244/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 263.7091 - val_loss: 971.2506\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 854.95099\n",
      "Epoch 245/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 257.9138 - val_loss: 883.2176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00245: val_loss did not improve from 854.95099\n",
      "Epoch 246/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 270.9289 - val_loss: 937.8683\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 854.95099\n",
      "Epoch 247/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 263.7802 - val_loss: 1057.9318\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 854.95099\n",
      "Epoch 248/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 265.3699 - val_loss: 1234.4934\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 854.95099\n",
      "Epoch 249/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.2401 - val_loss: 935.5123\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 854.95099\n",
      "Epoch 250/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 273.4821 - val_loss: 988.4319\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 854.95099\n",
      "Epoch 251/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 268.7002 - val_loss: 997.4621\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 854.95099\n",
      "Epoch 252/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 251.4959 - val_loss: 1019.2902\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 854.95099\n",
      "Epoch 253/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.4850 - val_loss: 1006.9112\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 854.95099\n",
      "Epoch 254/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 261.0946 - val_loss: 1053.0057\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 854.95099\n",
      "Epoch 255/10000\n",
      "89/89 [==============================] - 0s 995us/step - loss: 253.3099 - val_loss: 1089.0981\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 854.95099\n",
      "Epoch 256/10000\n",
      "89/89 [==============================] - 0s 954us/step - loss: 250.3678 - val_loss: 999.7332\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 854.95099\n",
      "Epoch 257/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 266.5032 - val_loss: 979.5014\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 854.95099\n",
      "Epoch 258/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 258.5698 - val_loss: 1082.8134\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 854.95099\n",
      "Epoch 259/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 248.6312 - val_loss: 890.0918\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 854.95099\n",
      "Epoch 260/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 253.4759 - val_loss: 1042.7632\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 854.95099\n",
      "Epoch 261/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 263.3823 - val_loss: 1230.2731\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 854.95099\n",
      "Epoch 262/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 258.9813 - val_loss: 1007.7860\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 854.95099\n",
      "Epoch 263/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 271.4379 - val_loss: 972.3113\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 854.95099\n",
      "Epoch 264/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 258.3505 - val_loss: 990.9786\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 854.95099\n",
      "Epoch 265/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 250.1542 - val_loss: 971.6408\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 854.95099\n",
      "Epoch 266/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 243.7102 - val_loss: 971.7629\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 854.95099\n",
      "Epoch 267/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 253.3839 - val_loss: 915.9799\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 854.95099\n",
      "Epoch 268/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 255.3131 - val_loss: 1091.8302\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 854.95099\n",
      "Epoch 269/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 247.8539 - val_loss: 1054.8135\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 854.95099\n",
      "Epoch 270/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 251.5972 - val_loss: 1163.2118\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 854.95099\n",
      "Epoch 271/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 243.3257 - val_loss: 1077.6970\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 854.95099\n",
      "Epoch 272/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 245.7630 - val_loss: 996.1824\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 854.95099\n",
      "Epoch 273/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 252.3060 - val_loss: 1007.4422\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 854.95099\n",
      "Epoch 274/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 248.6796 - val_loss: 955.7528\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 854.95099\n",
      "Epoch 275/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 242.0073 - val_loss: 1177.3149\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 854.95099\n",
      "Epoch 276/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 258.3499 - val_loss: 965.2681\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 854.95099\n",
      "Epoch 277/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 244.5358 - val_loss: 1173.9194\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 854.95099\n",
      "Epoch 278/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 259.0056 - val_loss: 1066.9471\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 854.95099\n",
      "Epoch 279/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 255.6231 - val_loss: 950.7417\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 854.95099\n",
      "Epoch 280/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 246.1974 - val_loss: 937.3862\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 854.95099\n",
      "Epoch 281/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 255.2922 - val_loss: 980.9601\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 854.95099\n",
      "Epoch 282/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 245.8439 - val_loss: 1361.6285\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 854.95099\n",
      "Epoch 283/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 247.3660 - val_loss: 962.5226\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 854.95099\n",
      "Epoch 284/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 259.2395 - val_loss: 945.6233\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 854.95099\n",
      "Epoch 285/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 243.7923 - val_loss: 919.9674\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 854.95099\n",
      "Epoch 286/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 246.2056 - val_loss: 939.4938\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 854.95099\n",
      "Epoch 287/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 251.1621 - val_loss: 1059.5164\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 854.95099\n",
      "Epoch 288/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 244.1424 - val_loss: 1047.3936\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 854.95099\n",
      "Epoch 289/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 245.8336 - val_loss: 995.3359\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 854.95099\n",
      "Epoch 290/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 244.7182 - val_loss: 1015.4049\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 854.95099\n",
      "Epoch 291/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.7888 - val_loss: 1089.3254\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 854.95099\n",
      "Epoch 292/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 240.7031 - val_loss: 978.8700\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 854.95099\n",
      "Epoch 293/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 249.8064 - val_loss: 1001.8580\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 854.95099\n",
      "Epoch 294/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 247.7192 - val_loss: 1045.0759\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 854.95099\n",
      "Epoch 295/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 237.8639 - val_loss: 976.7281\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 854.95099\n",
      "Epoch 296/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 252.0954 - val_loss: 960.6219\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 854.95099\n",
      "Epoch 297/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 242.5687 - val_loss: 955.8459\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 854.95099\n",
      "Epoch 298/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 240.9933 - val_loss: 1015.6596\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 854.95099\n",
      "Epoch 299/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 238.2072 - val_loss: 1108.3269\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 854.95099\n",
      "Epoch 300/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 257.4235 - val_loss: 1016.5951\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 854.95099\n",
      "Epoch 301/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 246.0631 - val_loss: 864.1044\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 854.95099\n",
      "Epoch 302/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.2036 - val_loss: 992.8531\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 854.95099\n",
      "Epoch 303/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 232.3522 - val_loss: 1010.4753\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 854.95099\n",
      "Epoch 304/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 231.8557 - val_loss: 851.7234\n",
      "\n",
      "Epoch 00304: val_loss improved from 854.95099 to 851.72339, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 305/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 232.6169 - val_loss: 1084.9893\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 851.72339\n",
      "Epoch 306/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 245.5159 - val_loss: 1119.8993\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 851.72339\n",
      "Epoch 307/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 248.2622 - val_loss: 946.1186\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 851.72339\n",
      "Epoch 308/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 237.9016 - val_loss: 1019.0356\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 851.72339\n",
      "Epoch 309/10000\n",
      "89/89 [==============================] - 0s 979us/step - loss: 235.3414 - val_loss: 978.7405\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 851.72339\n",
      "Epoch 310/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 236.3392 - val_loss: 980.4313\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 851.72339\n",
      "Epoch 311/10000\n",
      "89/89 [==============================] - 0s 974us/step - loss: 244.7820 - val_loss: 1113.7175\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 851.72339\n",
      "Epoch 312/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 232.1341 - val_loss: 920.2845\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 851.72339\n",
      "Epoch 313/10000\n",
      "89/89 [==============================] - 0s 994us/step - loss: 247.5652 - val_loss: 983.5326\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 851.72339\n",
      "Epoch 314/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.0188 - val_loss: 1060.0494\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 851.72339\n",
      "Epoch 315/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 238.0629 - val_loss: 1027.5627\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 851.72339\n",
      "Epoch 316/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 242.6761 - val_loss: 878.1318\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 851.72339\n",
      "Epoch 317/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 243.1080 - val_loss: 930.7463\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 851.72339\n",
      "Epoch 318/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.1771 - val_loss: 977.1715\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 851.72339\n",
      "Epoch 319/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 236.6702 - val_loss: 980.9350\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 851.72339\n",
      "Epoch 320/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 238.7098 - val_loss: 967.2684\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 851.72339\n",
      "Epoch 321/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 236.0439 - val_loss: 1007.6639\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 851.72339\n",
      "Epoch 322/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 223.9874 - val_loss: 1054.6215\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 851.72339\n",
      "Epoch 323/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 237.8740 - val_loss: 1004.4080\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 851.72339\n",
      "Epoch 324/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 237.0081 - val_loss: 1019.6975\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 851.72339\n",
      "Epoch 325/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.6544 - val_loss: 1043.7460\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 851.72339\n",
      "Epoch 326/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.5457 - val_loss: 942.3117\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 851.72339\n",
      "Epoch 327/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.1094 - val_loss: 1165.6722\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 851.72339\n",
      "Epoch 328/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 237.9325 - val_loss: 949.2601\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 851.72339\n",
      "Epoch 329/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.4860 - val_loss: 1217.4928\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 851.72339\n",
      "Epoch 330/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.7415 - val_loss: 926.4689\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 851.72339\n",
      "Epoch 331/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.9973 - val_loss: 1009.3981\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 851.72339\n",
      "Epoch 332/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 229.8606 - val_loss: 974.2614\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 851.72339\n",
      "Epoch 333/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 231.4757 - val_loss: 1118.6572\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 851.72339\n",
      "Epoch 334/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.7578 - val_loss: 1041.7876\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 851.72339\n",
      "Epoch 335/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.1598 - val_loss: 980.7273\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 851.72339\n",
      "Epoch 336/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.0401 - val_loss: 902.0588\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 851.72339\n",
      "Epoch 337/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.1695 - val_loss: 978.8914\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 851.72339\n",
      "Epoch 338/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.6683 - val_loss: 1048.6929\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 851.72339\n",
      "Epoch 339/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 248.0528 - val_loss: 1108.2393\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 851.72339\n",
      "Epoch 340/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 240.0843 - val_loss: 1001.9456\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 851.72339\n",
      "Epoch 341/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 238.0745 - val_loss: 888.8152\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 851.72339\n",
      "Epoch 342/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 229.4939 - val_loss: 1036.6395\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 851.72339\n",
      "Epoch 343/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 243.4361 - val_loss: 920.6843\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 851.72339\n",
      "Epoch 344/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.4951 - val_loss: 1082.5350\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 851.72339\n",
      "Epoch 345/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 242.7638 - val_loss: 953.8145\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 851.72339\n",
      "Epoch 346/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 975us/step - loss: 227.5840 - val_loss: 960.0259\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 851.72339\n",
      "Epoch 347/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.2518 - val_loss: 980.9222\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 851.72339\n",
      "Epoch 348/10000\n",
      "89/89 [==============================] - 0s 945us/step - loss: 224.6789 - val_loss: 989.0203\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 851.72339\n",
      "Epoch 349/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 231.4906 - val_loss: 906.8089\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 851.72339\n",
      "Epoch 350/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 238.4588 - val_loss: 1054.4749\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 851.72339\n",
      "Epoch 351/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.5818 - val_loss: 907.2608\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 851.72339\n",
      "Epoch 352/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 223.9376 - val_loss: 862.4617\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 851.72339\n",
      "Epoch 353/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 232.8122 - val_loss: 966.8527\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 851.72339\n",
      "Epoch 354/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.9992 - val_loss: 1038.6655\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 851.72339\n",
      "Epoch 355/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.6527 - val_loss: 922.6935\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 851.72339\n",
      "Epoch 356/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 235.5874 - val_loss: 1031.7117\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 851.72339\n",
      "Epoch 357/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 227.0543 - val_loss: 1035.0928\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 851.72339\n",
      "Epoch 358/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 235.4260 - val_loss: 1176.3495\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 851.72339\n",
      "Epoch 359/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 231.0676 - val_loss: 1196.8281\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 851.72339\n",
      "Epoch 360/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 229.9016 - val_loss: 994.5175\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 851.72339\n",
      "Epoch 361/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.3542 - val_loss: 924.5637\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 851.72339\n",
      "Epoch 362/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 239.7745 - val_loss: 1004.6959\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 851.72339\n",
      "Epoch 363/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 225.5236 - val_loss: 1002.3273\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 851.72339\n",
      "Epoch 364/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 235.4874 - val_loss: 981.2946\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 851.72339\n",
      "Epoch 365/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 227.5959 - val_loss: 999.4427\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 851.72339\n",
      "Epoch 366/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 238.3212 - val_loss: 1004.4944\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 851.72339\n",
      "Epoch 367/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 229.6734 - val_loss: 1005.4070\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 851.72339\n",
      "Epoch 368/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.2762 - val_loss: 959.7551\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 851.72339\n",
      "Epoch 369/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 233.5890 - val_loss: 966.4680\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 851.72339\n",
      "Epoch 370/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.5721 - val_loss: 991.1389\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 851.72339\n",
      "Epoch 371/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 234.0066 - val_loss: 906.2374\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 851.72339\n",
      "Epoch 372/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 225.8693 - val_loss: 863.6044\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 851.72339\n",
      "Epoch 373/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 225.3250 - val_loss: 1112.6552\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 851.72339\n",
      "Epoch 374/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 221.9064 - val_loss: 997.1864\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 851.72339\n",
      "Epoch 375/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 226.8701 - val_loss: 1006.9294\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 851.72339\n",
      "Epoch 376/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.2748 - val_loss: 987.5224\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 851.72339\n",
      "Epoch 377/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 231.1680 - val_loss: 982.7160\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 851.72339\n",
      "Epoch 378/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 232.7165 - val_loss: 1052.1011\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 851.72339\n",
      "Epoch 379/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 226.5136 - val_loss: 947.6129\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 851.72339\n",
      "Epoch 380/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.1402 - val_loss: 976.0019\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 851.72339\n",
      "Epoch 381/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 215.1132 - val_loss: 995.5693\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 851.72339\n",
      "Epoch 382/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.0513 - val_loss: 1070.3596\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 851.72339\n",
      "Epoch 383/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 231.2887 - val_loss: 972.8283\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 851.72339\n",
      "Epoch 384/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.5746 - val_loss: 1010.9791\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 851.72339\n",
      "Epoch 385/10000\n",
      "89/89 [==============================] - 0s 996us/step - loss: 224.7238 - val_loss: 926.9797\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 851.72339\n",
      "Epoch 386/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 229.4198 - val_loss: 1136.9176\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 851.72339\n",
      "Epoch 387/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 226.5656 - val_loss: 928.3033\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 851.72339\n",
      "Epoch 388/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 216.1455 - val_loss: 933.0242\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 851.72339\n",
      "Epoch 389/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 230.1800 - val_loss: 947.0745\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 851.72339\n",
      "Epoch 390/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 228.8224 - val_loss: 983.4931\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 851.72339\n",
      "Epoch 391/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 226.8997 - val_loss: 962.2674\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 851.72339\n",
      "Epoch 392/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 215.0726 - val_loss: 1219.8273\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 851.72339\n",
      "Epoch 393/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 221.1304 - val_loss: 990.5595\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 851.72339\n",
      "Epoch 394/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.7455 - val_loss: 1064.0043\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 851.72339\n",
      "Epoch 395/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 223.2866 - val_loss: 952.9563\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 851.72339\n",
      "Epoch 396/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 217.3697 - val_loss: 1016.8375\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 851.72339\n",
      "Epoch 397/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 221.8057 - val_loss: 907.4140\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 851.72339\n",
      "Epoch 398/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 221.6657 - val_loss: 977.1858\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 851.72339\n",
      "Epoch 399/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 227.7818 - val_loss: 952.3134\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 851.72339\n",
      "Epoch 400/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 224.6396 - val_loss: 1003.0758\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 851.72339\n",
      "Epoch 401/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 226.4219 - val_loss: 1029.3088\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 851.72339\n",
      "Epoch 402/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 237.8619 - val_loss: 993.4846\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 851.72339\n",
      "Epoch 403/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 221.2077 - val_loss: 1035.9229\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 851.72339\n",
      "Epoch 404/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 221.8101 - val_loss: 942.4874\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 851.72339\n",
      "good\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 2121.3857 - val_loss: 2325.6941\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2325.69409, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 993us/step - loss: 619.3816 - val_loss: 1343.6647\n",
      "\n",
      "Epoch 00002: val_loss improved from 2325.69409 to 1343.66467, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 597.9423 - val_loss: 1357.9301\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1343.66467\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 542.5892 - val_loss: 1317.2775\n",
      "\n",
      "Epoch 00004: val_loss improved from 1343.66467 to 1317.27747, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 599.9587 - val_loss: 2227.8513\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1317.27747\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 613.3857 - val_loss: 1772.8969\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1317.27747\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 595.7354 - val_loss: 1438.9219\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1317.27747\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 598.2232 - val_loss: 1326.1547\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1317.27747\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 621.9456 - val_loss: 1530.3461\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1317.27747\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 621.2313 - val_loss: 1325.2894\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1317.27747\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 981us/step - loss: 561.1793 - val_loss: 2189.7793\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1317.27747\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 595.4495 - val_loss: 1465.2727\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1317.27747\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 573.5331 - val_loss: 1358.7970\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1317.27747\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 575.9756 - val_loss: 2296.6780\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1317.27747\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 553.1227 - val_loss: 1372.0386\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1317.27747\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 612.6708 - val_loss: 1491.7820\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1317.27747\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 584.1376 - val_loss: 1336.5850\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1317.27747\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 595.3918 - val_loss: 1557.2205\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1317.27747\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 601.7659 - val_loss: 1453.2172\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1317.27747\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 571.9689 - val_loss: 1759.6840\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1317.27747\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 574.1768 - val_loss: 1357.9648\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1317.27747\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 587.5328 - val_loss: 2265.1401\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1317.27747\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 578.9113 - val_loss: 1419.5641\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1317.27747\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 580.4348 - val_loss: 1448.5809\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1317.27747\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 543.9135 - val_loss: 1392.8406\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1317.27747\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 574.7242 - val_loss: 1459.6461\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1317.27747\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 579.5062 - val_loss: 1491.8300\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1317.27747\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 568.4223 - val_loss: 1430.1892\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1317.27747\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 550.7977 - val_loss: 1386.7026\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1317.27747\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 557.4623 - val_loss: 1434.5887\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1317.27747\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 564.9272 - val_loss: 1722.6388\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1317.27747\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 537.2255 - val_loss: 2373.8447\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1317.27747\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 553.9150 - val_loss: 1420.0537\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1317.27747\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 531.7581 - val_loss: 1566.8871\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1317.27747\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 515.5071 - val_loss: 1388.3925\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1317.27747\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 543.5309 - val_loss: 1383.5453\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1317.27747\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 571.5199 - val_loss: 1651.3182\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1317.27747\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 535.2764 - val_loss: 1408.4242\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1317.27747\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 541.6837 - val_loss: 1437.6790\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1317.27747\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 534.1162 - val_loss: 1522.6718\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1317.27747\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 535.0837 - val_loss: 1453.6743\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1317.27747\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 529.3968 - val_loss: 1669.2426\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1317.27747\n",
      "Epoch 43/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 538.7092 - val_loss: 1554.5017\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1317.27747\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 523.9166 - val_loss: 1715.7837\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1317.27747\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 512.4540 - val_loss: 2021.7571\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1317.27747\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 514.3914 - val_loss: 1318.9845\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1317.27747\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 511.9956 - val_loss: 1399.2451\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1317.27747\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 535.5114 - val_loss: 1415.7192\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1317.27747\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 529.2635 - val_loss: 1431.0166\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1317.27747\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 515.3683 - val_loss: 1495.0865\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1317.27747\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 529.3371 - val_loss: 1404.4536\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1317.27747\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 518.4465 - val_loss: 1461.1193\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1317.27747\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 480.3259 - val_loss: 1795.9883\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1317.27747\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 489.3926 - val_loss: 1386.8174\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1317.27747\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 556.8967 - val_loss: 1523.2714\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1317.27747\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 528.4133 - val_loss: 1515.5409\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1317.27747\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 524.1578 - val_loss: 1307.4714\n",
      "\n",
      "Epoch 00057: val_loss improved from 1317.27747 to 1307.47144, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 478.0746 - val_loss: 1944.0435\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1307.47144\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 497.8435 - val_loss: 1363.9822\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1307.47144\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 507.9127 - val_loss: 2114.3643\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1307.47144\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 485.4453 - val_loss: 1567.5223\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1307.47144\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 487.5552 - val_loss: 2067.2158\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1307.47144\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 547.7867 - val_loss: 1484.3544\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1307.47144\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 490.5455 - val_loss: 1606.8019\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1307.47144\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 522.3166 - val_loss: 1445.4717\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1307.47144\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 997us/step - loss: 511.1485 - val_loss: 1395.5978\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1307.47144\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 495.3339 - val_loss: 1484.1600\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1307.47144\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 466.0849 - val_loss: 1427.8413\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1307.47144\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 489.5431 - val_loss: 1397.6854\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1307.47144\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 518.4637 - val_loss: 1493.8779\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1307.47144\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 489.0517 - val_loss: 1376.7915\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1307.47144\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 470.6069 - val_loss: 1391.2705\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1307.47144\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.1806 - val_loss: 1653.2031\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1307.47144\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 482.3394 - val_loss: 1386.9233\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1307.47144\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 494.1184 - val_loss: 1500.9897\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1307.47144\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 460.6538 - val_loss: 1465.8097\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1307.47144\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 476.7697 - val_loss: 1467.9122\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1307.47144\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 498.0923 - val_loss: 1393.2184\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1307.47144\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 471.0214 - val_loss: 1485.8252\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1307.47144\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 486.9385 - val_loss: 1466.4989\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1307.47144\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 462.5063 - val_loss: 1656.4348\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1307.47144\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 451.4802 - val_loss: 2029.5919\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1307.47144\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 459.3643 - val_loss: 2028.1425\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1307.47144\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 463.6678 - val_loss: 1539.0306\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1307.47144\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 485.3110 - val_loss: 1924.9481\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1307.47144\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 444.3134 - val_loss: 1544.4917\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1307.47144\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 445.3244 - val_loss: 1391.9828\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1307.47144\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 423.2068 - val_loss: 1532.0803\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1307.47144\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 465.2436 - val_loss: 1444.3564\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1307.47144\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 431.5916 - val_loss: 2035.2290\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1307.47144\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 453.9016 - val_loss: 1678.1121\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1307.47144\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 446.3923 - val_loss: 1433.8967\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1307.47144\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 421.9697 - val_loss: 1570.9794\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1307.47144\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 412.0475 - val_loss: 1435.9116\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1307.47144\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 443.6291 - val_loss: 1467.8550\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1307.47144\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 432.3109 - val_loss: 1814.2145\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1307.47144\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 436.9290 - val_loss: 1447.2523\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1307.47144\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 426.9990 - val_loss: 1429.1447\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1307.47144\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 411.2422 - val_loss: 1653.5837\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1307.47144\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 441.0253 - val_loss: 1414.6918\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1307.47144\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 412.1911 - val_loss: 1578.1294\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1307.47144\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 416.0842 - val_loss: 1363.8243\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1307.47144\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 419.1073 - val_loss: 1454.0144\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1307.47144\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 403.0817 - val_loss: 1443.5880\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1307.47144\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 403.9981 - val_loss: 1554.0659\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1307.47144\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 422.1668 - val_loss: 1530.9469\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1307.47144\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 427.6275 - val_loss: 1473.0669\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1307.47144\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 403.0806 - val_loss: 1608.2228\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1307.47144\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 408.1581 - val_loss: 1605.9302\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1307.47144\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 401.9982 - val_loss: 1522.8070\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1307.47144\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 410.9914 - val_loss: 1464.3677\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1307.47144\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 405.9422 - val_loss: 1505.4509\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1307.47144\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 399.6006 - val_loss: 1443.8925\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1307.47144\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 387.6452 - val_loss: 1503.7041\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1307.47144\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 404.7495 - val_loss: 1500.4750\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1307.47144\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 405.9930 - val_loss: 1520.2186\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1307.47144\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 392.5854 - val_loss: 1468.2205\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1307.47144\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 380.3409 - val_loss: 1726.5319\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1307.47144\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 393.2841 - val_loss: 1570.7878\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1307.47144\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 381.5793 - val_loss: 1485.9044\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1307.47144\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 377.0881 - val_loss: 1774.3689\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1307.47144\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 383.0145 - val_loss: 1723.7086\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1307.47144\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 390.0687 - val_loss: 1456.5017\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1307.47144\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 388.7048 - val_loss: 1598.3087\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1307.47144\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 376.3484 - val_loss: 1518.2723\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1307.47144\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 374.0733 - val_loss: 1550.6083\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1307.47144\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 387.0884 - val_loss: 1533.6880\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1307.47144\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 375.5916 - val_loss: 1595.6378\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1307.47144\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 370.3894 - val_loss: 1523.8013\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1307.47144\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 379.7360 - val_loss: 1608.1021\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1307.47144\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 389.1829 - val_loss: 1572.9580\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1307.47144\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 373.6016 - val_loss: 1528.2081\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1307.47144\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 367.0265 - val_loss: 1492.2428\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1307.47144\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 380.1432 - val_loss: 1510.4989\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1307.47144\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 382.0412 - val_loss: 1660.5458\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1307.47144\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 364.5983 - val_loss: 1547.2136\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1307.47144\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 376.0074 - val_loss: 1619.0966\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1307.47144\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 353.3266 - val_loss: 1458.9879\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1307.47144\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 998us/step - loss: 362.2082 - val_loss: 1469.2635\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1307.47144\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 361.9749 - val_loss: 1555.7610\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1307.47144\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 371.7080 - val_loss: 1460.2025\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1307.47144\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 369.2502 - val_loss: 1528.9387\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1307.47144\n",
      "Epoch 143/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 357.3727 - val_loss: 1545.1304\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1307.47144\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 364.6297 - val_loss: 1528.4436\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1307.47144\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 373.3395 - val_loss: 1617.8500\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1307.47144\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 371.0985 - val_loss: 1522.9144\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1307.47144\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 360.4461 - val_loss: 1486.2444\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1307.47144\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 375.2635 - val_loss: 1615.3789\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1307.47144\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 363.6776 - val_loss: 1567.1617\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1307.47144\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 366.6333 - val_loss: 1530.9788\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1307.47144\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 355.2484 - val_loss: 1471.6978\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1307.47144\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 345.0975 - val_loss: 1513.5863\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1307.47144\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 350.1479 - val_loss: 1514.2455\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1307.47144\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 365.8939 - val_loss: 1507.6490\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1307.47144\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 342.1908 - val_loss: 1636.7377\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1307.47144\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 354.9056 - val_loss: 1606.4498\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1307.47144\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 350.2052 - val_loss: 1524.3729\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1307.47144\n",
      "good\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 2136.1277 - val_loss: 3262.9609\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3262.96094, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 922.3135 - val_loss: 1219.2283\n",
      "\n",
      "Epoch 00002: val_loss improved from 3262.96094 to 1219.22827, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 995us/step - loss: 624.5587 - val_loss: 2032.3416\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1219.22827\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 605.5624 - val_loss: 1600.2292\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1219.22827\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 662.0805 - val_loss: 1448.9860\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1219.22827\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 592.6144 - val_loss: 1528.8696\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1219.22827\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 597.7167 - val_loss: 1840.1780\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1219.22827\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 564.9628 - val_loss: 1425.1469\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1219.22827\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 934us/step - loss: 622.4998 - val_loss: 1429.3864\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1219.22827\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 999us/step - loss: 558.9619 - val_loss: 1416.5034\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1219.22827\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 586.2652 - val_loss: 1519.6743\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1219.22827\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 596.1411 - val_loss: 2263.1641\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1219.22827\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 610.6595 - val_loss: 1421.2056\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1219.22827\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 553.6083 - val_loss: 1864.5396\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1219.22827\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 583.2543 - val_loss: 1652.5585\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1219.22827\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 550.0184 - val_loss: 1652.9723\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1219.22827\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 541.2775 - val_loss: 2230.5637\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1219.22827\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 607.0604 - val_loss: 1384.3940\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1219.22827\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 582.0436 - val_loss: 1465.1530\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1219.22827\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 600.4933 - val_loss: 1363.3666\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1219.22827\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 575.3485 - val_loss: 1369.7614\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1219.22827\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 547.1384 - val_loss: 1474.1201\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1219.22827\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 581.0427 - val_loss: 1360.2131\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1219.22827\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 551.6425 - val_loss: 1378.2195\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1219.22827\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 584.1620 - val_loss: 1409.6122\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1219.22827\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 569.8606 - val_loss: 1466.1288\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1219.22827\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 541.4520 - val_loss: 1505.6072\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1219.22827\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 575.5409 - val_loss: 1363.6105\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1219.22827\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 550.0565 - val_loss: 1604.2958\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1219.22827\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 567.8893 - val_loss: 1450.1936\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1219.22827\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 546.1153 - val_loss: 2055.0171\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1219.22827\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 571.7697 - val_loss: 1924.3835\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1219.22827\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 578.3950 - val_loss: 1674.9141\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1219.22827\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 549.4059 - val_loss: 1388.0029\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1219.22827\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 594.0872 - val_loss: 1492.0387\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1219.22827\n",
      "Epoch 36/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 560.9226 - val_loss: 1395.9741\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1219.22827\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 548.6013 - val_loss: 1829.6753\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1219.22827\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 534.3469 - val_loss: 2284.6038\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1219.22827\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 534.0338 - val_loss: 1509.5146\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1219.22827\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 556.4228 - val_loss: 2074.0342\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1219.22827\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 568.1355 - val_loss: 1334.0920\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1219.22827\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 559.0513 - val_loss: 1385.3662\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1219.22827\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 552.0162 - val_loss: 1933.1516\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1219.22827\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 534.6200 - val_loss: 1334.7788\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1219.22827\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 514.9637 - val_loss: 1388.0803\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1219.22827\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 570.1533 - val_loss: 1373.4851\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1219.22827\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 528.2992 - val_loss: 1429.1129\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1219.22827\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 569.3058 - val_loss: 1351.2202\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1219.22827\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 497.7825 - val_loss: 1539.7389\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1219.22827\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 523.2624 - val_loss: 1807.7562\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1219.22827\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 532.5109 - val_loss: 1400.6725\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1219.22827\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 550.2981 - val_loss: 1403.2744\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1219.22827\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 526.9998 - val_loss: 1432.0105\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1219.22827\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 532.4343 - val_loss: 1352.0367\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1219.22827\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 550.4283 - val_loss: 1350.1190\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1219.22827\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 556.0679 - val_loss: 1686.4200\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1219.22827\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 989us/step - loss: 523.7336 - val_loss: 2126.8796\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1219.22827\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 985us/step - loss: 524.2804 - val_loss: 1913.9944\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1219.22827\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 535.6801 - val_loss: 1868.2386\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1219.22827\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 944us/step - loss: 523.1050 - val_loss: 1475.6970\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1219.22827\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 529.0432 - val_loss: 1502.5305\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1219.22827\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 979us/step - loss: 487.9639 - val_loss: 1390.8632\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1219.22827\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 530.6185 - val_loss: 1452.0565\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1219.22827\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 465.8856 - val_loss: 1396.5291\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1219.22827\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 515.0286 - val_loss: 1396.3007\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1219.22827\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 510.8590 - val_loss: 1490.5897\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1219.22827\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 482.1039 - val_loss: 1407.5099\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1219.22827\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 494.6699 - val_loss: 1403.3246\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1219.22827\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 474.2623 - val_loss: 1756.8693\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1219.22827\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 509.6509 - val_loss: 1379.2014\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1219.22827\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 502.2399 - val_loss: 1904.7365\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1219.22827\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 498.9137 - val_loss: 1576.2124\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1219.22827\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 481.7102 - val_loss: 1532.8678\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1219.22827\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 478.6973 - val_loss: 1536.2432\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1219.22827\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 438.0910 - val_loss: 1593.1647\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1219.22827\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 473.9078 - val_loss: 1417.9478\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1219.22827\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 454.1315 - val_loss: 1440.0887\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1219.22827\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 468.9552 - val_loss: 1419.2551\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1219.22827\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 470.0612 - val_loss: 1405.0562\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1219.22827\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 470.5628 - val_loss: 1437.4087\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1219.22827\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 477.4583 - val_loss: 1595.0436\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1219.22827\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 970us/step - loss: 439.2509 - val_loss: 1514.4492\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1219.22827\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 446.6550 - val_loss: 1513.7281\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1219.22827\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 434.5276 - val_loss: 1449.6891\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1219.22827\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 454.8979 - val_loss: 1516.8481\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1219.22827\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 438.5939 - val_loss: 1636.4719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00086: val_loss did not improve from 1219.22827\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 999us/step - loss: 433.5087 - val_loss: 1825.8618\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1219.22827\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 439.3265 - val_loss: 1455.6215\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1219.22827\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 447.0633 - val_loss: 1477.7561\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1219.22827\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 419.1645 - val_loss: 1661.1797\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1219.22827\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 427.3588 - val_loss: 1485.8035\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1219.22827\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 392.4212 - val_loss: 1674.0045\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1219.22827\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 429.2583 - val_loss: 1704.3093\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1219.22827\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 418.9472 - val_loss: 1605.4016\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1219.22827\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 420.2946 - val_loss: 1542.7059\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1219.22827\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 426.8902 - val_loss: 1603.2111\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1219.22827\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 411.9693 - val_loss: 1624.6140\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1219.22827\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 408.5585 - val_loss: 1494.5242\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1219.22827\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 395.1265 - val_loss: 1455.7150\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1219.22827\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 408.9351 - val_loss: 1517.5441\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1219.22827\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 397.5005 - val_loss: 1504.1952\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1219.22827\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 394.2237 - val_loss: 1451.6117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████▍                   | 16/21 [29:43<08:01, 96.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00102: val_loss did not improve from 1219.22827\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 2365.4785 - val_loss: 2437.0581\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2437.05811, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 1668.0107 - val_loss: 3585.1775\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2437.05811\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 995us/step - loss: 1578.2041 - val_loss: 2523.6616\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2437.05811\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1597.1501 - val_loss: 2861.9365\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2437.05811\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1565.4366 - val_loss: 4820.3921\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2437.05811\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 917us/step - loss: 1568.9026 - val_loss: 2427.7397\n",
      "\n",
      "Epoch 00006: val_loss improved from 2437.05811 to 2427.73975, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 929us/step - loss: 1518.9753 - val_loss: 3773.0771\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2427.73975\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 953us/step - loss: 1719.3602 - val_loss: 2650.9331\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2427.73975\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1605.1130 - val_loss: 4708.4736\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2427.73975\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1510.8943 - val_loss: 2848.1904\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2427.73975\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 924us/step - loss: 1562.3558 - val_loss: 2928.1772\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2427.73975\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1780.8372 - val_loss: 5199.8877\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2427.73975\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1640.1322 - val_loss: 3277.7556\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2427.73975\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 938us/step - loss: 1581.1427 - val_loss: 4858.0684\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2427.73975\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1614.1006 - val_loss: 4485.1060\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2427.73975\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 973us/step - loss: 1505.9893 - val_loss: 4099.0601\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2427.73975\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 958us/step - loss: 1584.8440 - val_loss: 3897.8914\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2427.73975\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1727.5326 - val_loss: 2960.7742\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2427.73975\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 935us/step - loss: 1614.6150 - val_loss: 5507.2559\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2427.73975\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1542.9279 - val_loss: 2414.4985\n",
      "\n",
      "Epoch 00020: val_loss improved from 2427.73975 to 2414.49854, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 937us/step - loss: 1640.7773 - val_loss: 3616.6897\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2414.49854\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 962us/step - loss: 1618.2975 - val_loss: 2415.9722\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2414.49854\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1618.0820 - val_loss: 3772.8491\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2414.49854\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 917us/step - loss: 1521.4448 - val_loss: 2631.0103\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2414.49854\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 947us/step - loss: 1505.3945 - val_loss: 4837.5952\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2414.49854\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 975us/step - loss: 1594.7881 - val_loss: 2376.7397\n",
      "\n",
      "Epoch 00026: val_loss improved from 2414.49854 to 2376.73975, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 931us/step - loss: 1407.6471 - val_loss: 2689.2920\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2376.73975\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 960us/step - loss: 1482.7571 - val_loss: 2641.6831\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2376.73975\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 969us/step - loss: 1640.2203 - val_loss: 2356.5549\n",
      "\n",
      "Epoch 00029: val_loss improved from 2376.73975 to 2356.55493, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 1656.2333 - val_loss: 4933.7925\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2356.55493\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 986us/step - loss: 1672.5148 - val_loss: 4260.2109\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2356.55493\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 998us/step - loss: 1573.4077 - val_loss: 3959.8530\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2356.55493\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 920us/step - loss: 1608.9476 - val_loss: 3175.0093\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2356.55493\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 963us/step - loss: 1653.8411 - val_loss: 2402.0117\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2356.55493\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 952us/step - loss: 1605.3488 - val_loss: 2953.8743\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2356.55493\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1620.8527 - val_loss: 5111.3887\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2356.55493\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 904us/step - loss: 1514.2424 - val_loss: 4872.8438\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2356.55493\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 954us/step - loss: 1545.3834 - val_loss: 3239.2507\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2356.55493\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 941us/step - loss: 1524.3435 - val_loss: 2615.1333\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2356.55493\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1546.9807 - val_loss: 2401.1643\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2356.55493\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 907us/step - loss: 1512.6172 - val_loss: 4047.1194\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2356.55493\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 965us/step - loss: 1434.8151 - val_loss: 3293.8125\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2356.55493\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 987us/step - loss: 1516.5574 - val_loss: 4469.2192\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2356.55493\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1486.1108 - val_loss: 2775.5078\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2356.55493\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 971us/step - loss: 1425.7538 - val_loss: 3913.8569\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2356.55493\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 989us/step - loss: 1448.6035 - val_loss: 2370.4751\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2356.55493\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1362.6177 - val_loss: 2337.2095\n",
      "\n",
      "Epoch 00047: val_loss improved from 2356.55493 to 2337.20947, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 915us/step - loss: 1281.9248 - val_loss: 2474.3416\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2337.20947\n",
      "Epoch 49/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 1433.9465 - val_loss: 3126.0188\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2337.20947\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 983us/step - loss: 1543.8391 - val_loss: 5340.6270\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2337.20947\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 966us/step - loss: 1505.5554 - val_loss: 5291.4658\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2337.20947\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 964us/step - loss: 1395.0590 - val_loss: 2831.6765\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2337.20947\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1449.3151 - val_loss: 2496.4365\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2337.20947\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1379.0408 - val_loss: 2305.1140\n",
      "\n",
      "Epoch 00054: val_loss improved from 2337.20947 to 2305.11401, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 961us/step - loss: 1346.5825 - val_loss: 2446.1604\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2305.11401\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1354.2545 - val_loss: 2929.4980\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2305.11401\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 926us/step - loss: 1181.6547 - val_loss: 2610.8252\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2305.11401\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 975us/step - loss: 1186.0758 - val_loss: 4776.8096\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2305.11401\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 958us/step - loss: 1263.7358 - val_loss: 4646.7920\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2305.11401\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 982us/step - loss: 1370.2606 - val_loss: 4448.6011\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2305.11401\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 925us/step - loss: 1244.7269 - val_loss: 3888.7993\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2305.11401\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 960us/step - loss: 1272.0161 - val_loss: 3464.3748\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2305.11401\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 964us/step - loss: 1184.8179 - val_loss: 4566.2231\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2305.11401\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1099.8865 - val_loss: 4656.0713\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2305.11401\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1198.7162 - val_loss: 4694.7080\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2305.11401\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 981us/step - loss: 1361.5776 - val_loss: 4549.2876\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2305.11401\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1355.6880 - val_loss: 4485.0186\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2305.11401\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1351.3809 - val_loss: 4426.5845\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2305.11401\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 988us/step - loss: 1354.3148 - val_loss: 4507.3838\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2305.11401\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 924us/step - loss: 1348.8615 - val_loss: 4400.9019\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2305.11401\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 967us/step - loss: 1353.4191 - val_loss: 4425.0498\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2305.11401\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 955us/step - loss: 1351.5459 - val_loss: 4480.5444\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2305.11401\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 890us/step - loss: 1351.7426 - val_loss: 4418.4160\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2305.11401\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 955us/step - loss: 1354.6902 - val_loss: 4479.9883\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2305.11401\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 967us/step - loss: 1348.4183 - val_loss: 2673.0344\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2305.11401\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 1334.2455 - val_loss: 4430.0078\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2305.11401\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1347.7886 - val_loss: 4406.0610\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2305.11401\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 966us/step - loss: 1348.5319 - val_loss: 4423.7920\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2305.11401\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1350.3158 - val_loss: 4499.3628\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2305.11401\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1349.8115 - val_loss: 4420.4082\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2305.11401\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 937us/step - loss: 1344.4307 - val_loss: 4416.9248\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2305.11401\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1348.2222 - val_loss: 4482.2642\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2305.11401\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 984us/step - loss: 1341.7994 - val_loss: 4499.5659\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2305.11401\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1348.0970 - val_loss: 4447.4341\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2305.11401\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 999us/step - loss: 1345.4436 - val_loss: 4503.3589\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2305.11401\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1343.3090 - val_loss: 4488.5601\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2305.11401\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1348.0867 - val_loss: 4472.7461\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2305.11401\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 969us/step - loss: 1337.5900 - val_loss: 4498.2051\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2305.11401\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1351.2334 - val_loss: 4498.8398\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2305.11401\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1348.8212 - val_loss: 4458.8193\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2305.11401\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1348.4547 - val_loss: 4542.9414\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2305.11401\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1340.5259 - val_loss: 4458.7500\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2305.11401\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1343.3323 - val_loss: 4533.3760\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2305.11401\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1341.2734 - val_loss: 4421.2617\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2305.11401\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1342.4426 - val_loss: 4472.8438\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2305.11401\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1338.9607 - val_loss: 4480.0049\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2305.11401\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1339.7963 - val_loss: 4413.0820\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2305.11401\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1340.6865 - val_loss: 4481.9336\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2305.11401\n",
      "Epoch 99/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 1342.7920 - val_loss: 4400.6753\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2305.11401\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1334.3728 - val_loss: 4524.7227\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 2305.11401\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1343.0913 - val_loss: 4424.2793\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 2305.11401\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1340.6456 - val_loss: 4510.5986\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 2305.11401\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1332.3132 - val_loss: 4430.7031\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 2305.11401\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1339.6276 - val_loss: 4530.4404\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 2305.11401\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1329.5851 - val_loss: 4567.2432\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 2305.11401\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1337.0291 - val_loss: 4445.3379\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 2305.11401\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1343.5597 - val_loss: 4435.5801\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 2305.11401\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1339.8528 - val_loss: 4562.0625\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 2305.11401\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1330.9760 - val_loss: 4583.9043\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 2305.11401\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1332.0642 - val_loss: 4483.6636\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 2305.11401\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1329.6425 - val_loss: 4472.9038\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 2305.11401\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1335.4407 - val_loss: 4532.8115\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 2305.11401\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1334.6484 - val_loss: 4426.8193\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 2305.11401\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1334.4270 - val_loss: 4481.6602\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 2305.11401\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1337.8379 - val_loss: 4484.5234\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 2305.11401\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1334.2865 - val_loss: 4465.7998\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 2305.11401\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1330.9906 - val_loss: 4496.1162\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 2305.11401\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1336.0493 - val_loss: 4487.5381\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 2305.11401\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1332.3134 - val_loss: 4391.4102\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 2305.11401\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1337.6229 - val_loss: 4509.0615\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 2305.11401\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1334.1926 - val_loss: 4400.3271\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 2305.11401\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1331.7260 - val_loss: 4451.1123\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 2305.11401\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1324.2721 - val_loss: 4435.6533\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 2305.11401\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1328.7214 - val_loss: 4468.1973\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 2305.11401\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1332.2306 - val_loss: 4453.2432\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 2305.11401\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1332.7531 - val_loss: 4478.0039\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 2305.11401\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1335.7164 - val_loss: 4510.3252\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 2305.11401\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1330.2777 - val_loss: 4465.5918\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 2305.11401\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1335.4507 - val_loss: 4464.5586\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 2305.11401\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1361.4750 - val_loss: 4543.9883\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 2305.11401\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1331.6105 - val_loss: 4490.4512\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 2305.11401\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1331.4773 - val_loss: 4474.4688\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 2305.11401\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1323.3373 - val_loss: 4504.9307\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 2305.11401\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1333.4814 - val_loss: 4523.0332\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 2305.11401\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1329.3204 - val_loss: 4476.4668\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 2305.11401\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1328.3500 - val_loss: 4465.1523\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 2305.11401\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1325.6960 - val_loss: 4474.9785\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 2305.11401\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1321.2302 - val_loss: 4481.2520\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 2305.11401\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1330.2065 - val_loss: 4474.7637\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 2305.11401\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1324.7941 - val_loss: 4517.5137\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 2305.11401\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1320.2853 - val_loss: 4420.8320\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 2305.11401\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1324.6166 - val_loss: 4476.4971\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 2305.11401\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1326.6283 - val_loss: 4508.1465\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 2305.11401\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1323.1670 - val_loss: 4569.1094\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 2305.11401\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1322.3859 - val_loss: 4450.2217\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 2305.11401\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1323.2911 - val_loss: 4522.3613\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 2305.11401\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1320.8068 - val_loss: 4417.1523\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 2305.11401\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1327.7682 - val_loss: 4491.3623\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 2305.11401\n",
      "Epoch 149/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 1326.2743 - val_loss: 4433.7812\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 2305.11401\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1322.7567 - val_loss: 4423.4980\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 2305.11401\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1329.0513 - val_loss: 4466.8779\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 2305.11401\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1323.5480 - val_loss: 4456.1084\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 2305.11401\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1325.0886 - val_loss: 4448.7178\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 2305.11401\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1321.8442 - val_loss: 4342.0161\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 2305.11401\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 3ms/step - loss: 2003.6522 - val_loss: 2540.0908\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2540.09082, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 957us/step - loss: 1619.8464 - val_loss: 2669.0471\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2540.09082\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1621.0192 - val_loss: 4551.0317\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2540.09082\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 1633.5420 - val_loss: 6477.6650\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2540.09082\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1643.9683 - val_loss: 2516.0459\n",
      "\n",
      "Epoch 00005: val_loss improved from 2540.09082 to 2516.04590, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1557.5638 - val_loss: 6044.7393\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2516.04590\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1668.5955 - val_loss: 2966.6694\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2516.04590\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 991us/step - loss: 1737.3776 - val_loss: 2487.2649\n",
      "\n",
      "Epoch 00008: val_loss improved from 2516.04590 to 2487.26489, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1697.4146 - val_loss: 3425.7488\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2487.26489\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1648.7516 - val_loss: 2612.3691\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2487.26489\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1787.4847 - val_loss: 4792.0342\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2487.26489\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1658.2980 - val_loss: 2911.5134\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2487.26489\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1502.7534 - val_loss: 3257.6387\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2487.26489\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1626.4489 - val_loss: 2758.8494\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2487.26489\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1534.3148 - val_loss: 2646.2935\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2487.26489\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1463.5623 - val_loss: 2497.2563\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2487.26489\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1534.8700 - val_loss: 2631.4695\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2487.26489\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1703.0984 - val_loss: 3775.0149\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2487.26489\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 987us/step - loss: 1601.6490 - val_loss: 2611.4453\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2487.26489\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1610.2190 - val_loss: 2528.0894\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2487.26489\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1647.7332 - val_loss: 5377.6812\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2487.26489\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1647.0511 - val_loss: 2811.7039\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2487.26489\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1515.6302 - val_loss: 4513.6001\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2487.26489\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1545.7445 - val_loss: 3060.5122\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2487.26489\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1641.9572 - val_loss: 3498.6226\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2487.26489\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1692.7201 - val_loss: 4578.6724\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2487.26489\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1712.6049 - val_loss: 2988.8972\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2487.26489\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1420.7745 - val_loss: 2622.8623\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2487.26489\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1535.9121 - val_loss: 3639.9521\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2487.26489\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1540.0619 - val_loss: 3992.0322\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2487.26489\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1648.9961 - val_loss: 5354.2812\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2487.26489\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1513.6271 - val_loss: 2629.6375\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2487.26489\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1578.1754 - val_loss: 5066.7876\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2487.26489\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1516.3894 - val_loss: 6445.6963\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2487.26489\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1660.2909 - val_loss: 5514.0537\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2487.26489\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1592.8038 - val_loss: 3059.4189\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2487.26489\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1625.0195 - val_loss: 2678.9878\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2487.26489\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1534.6019 - val_loss: 2688.9663\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2487.26489\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1489.6559 - val_loss: 2671.2578\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2487.26489\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1552.7888 - val_loss: 3270.1663\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2487.26489\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1633.4066 - val_loss: 3612.3303\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2487.26489\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1546.0150 - val_loss: 3514.5654\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2487.26489\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1456.2485 - val_loss: 4722.8379\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2487.26489\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1585.6196 - val_loss: 2707.7988\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2487.26489\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1497.4214 - val_loss: 5056.3423\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2487.26489\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1528.5177 - val_loss: 3808.6074\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2487.26489\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1544.7036 - val_loss: 6409.7339\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2487.26489\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1464.4788 - val_loss: 2753.9580\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2487.26489\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1445.4401 - val_loss: 9771.7402\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2487.26489\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1588.4343 - val_loss: 2915.2998\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2487.26489\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1532.9617 - val_loss: 3431.9316\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2487.26489\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1528.6782 - val_loss: 5610.8677\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2487.26489\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1490.1520 - val_loss: 3757.3391\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2487.26489\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1413.3741 - val_loss: 4259.2422\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2487.26489\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1395.1139 - val_loss: 2798.1292\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2487.26489\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1457.4330 - val_loss: 3801.9368\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2487.26489\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1359.5120 - val_loss: 2772.0254\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2487.26489\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1443.4170 - val_loss: 2752.3167\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2487.26489\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1331.3757 - val_loss: 2728.0671\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2487.26489\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1310.3817 - val_loss: 3778.8184\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2487.26489\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1374.0640 - val_loss: 4078.1257\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2487.26489\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1327.5247 - val_loss: 4176.6304\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2487.26489\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1350.2263 - val_loss: 3990.9539\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2487.26489\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1350.0865 - val_loss: 4872.3330\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2487.26489\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1267.4271 - val_loss: 5503.9482\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2487.26489\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1442.9388 - val_loss: 3389.7056\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2487.26489\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1271.1213 - val_loss: 22284.6328\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2487.26489\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1684.4879 - val_loss: 4506.6611\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2487.26489\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1387.3718 - val_loss: 4438.1367\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2487.26489\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1351.8990 - val_loss: 4619.0684\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2487.26489\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.0546 - val_loss: 4449.9902\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2487.26489\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.9218 - val_loss: 4423.4707\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2487.26489\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.8475 - val_loss: 4483.5684\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2487.26489\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.1113 - val_loss: 4514.1895\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2487.26489\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.3098 - val_loss: 4421.9253\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2487.26489\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.2970 - val_loss: 4445.3652\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2487.26489\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.2802 - val_loss: 4428.2344\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2487.26489\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1357.6771 - val_loss: 3156.6240\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2487.26489\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1299.2491 - val_loss: 4537.0513\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2487.26489\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1371.0706 - val_loss: 4434.9941\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2487.26489\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.6328 - val_loss: 4335.0552\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2487.26489\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.4332 - val_loss: 4501.1465\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2487.26489\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1393.2301 - val_loss: 4420.0083\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2487.26489\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.1014 - val_loss: 4382.5864\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2487.26489\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.5481 - val_loss: 2802.1130\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2487.26489\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1384.6611 - val_loss: 4374.9238\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2487.26489\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1390.7263 - val_loss: 4454.8320\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2487.26489\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.7552 - val_loss: 4364.5664\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2487.26489\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1391.7468 - val_loss: 4457.0762\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2487.26489\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.5627 - val_loss: 4406.2881\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2487.26489\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.7605 - val_loss: 4404.7695\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2487.26489\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.2375 - val_loss: 4424.4346\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2487.26489\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.4408 - val_loss: 4339.3105\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2487.26489\n",
      "Epoch 94/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 1393.2053 - val_loss: 4349.1582\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2487.26489\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.2692 - val_loss: 4366.3535\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2487.26489\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.9966 - val_loss: 4489.8232\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2487.26489\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.1368 - val_loss: 4369.2988\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2487.26489\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.7706 - val_loss: 4428.4062\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2487.26489\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.4567 - val_loss: 4393.5347\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2487.26489\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.9460 - val_loss: 4472.7529\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 2487.26489\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.8704 - val_loss: 4367.4170\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 2487.26489\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.8186 - val_loss: 4431.5112\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 2487.26489\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1391.4197 - val_loss: 4507.2764\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 2487.26489\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.2992 - val_loss: 4377.0942\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 2487.26489\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.1936 - val_loss: 4469.2715\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 2487.26489\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.1503 - val_loss: 4387.6855\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 2487.26489\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.4587 - val_loss: 4441.1445\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 2487.26489\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 1392.2146 - val_loss: 4493.7979\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 2487.26489\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 2248.9675 - val_loss: 4985.2915\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4985.29150, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1676.3412 - val_loss: 4377.1660\n",
      "\n",
      "Epoch 00002: val_loss improved from 4985.29150 to 4377.16602, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1575.9110 - val_loss: 6170.3687\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4377.16602\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 962us/step - loss: 1628.1887 - val_loss: 2835.5713\n",
      "\n",
      "Epoch 00004: val_loss improved from 4377.16602 to 2835.57129, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1522.8979 - val_loss: 3303.3528\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2835.57129\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1667.1185 - val_loss: 2730.6772\n",
      "\n",
      "Epoch 00006: val_loss improved from 2835.57129 to 2730.67725, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1550.5305 - val_loss: 5502.3975\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2730.67725\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1626.4534 - val_loss: 3275.8518\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2730.67725\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1498.1649 - val_loss: 3947.4641\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2730.67725\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1676.2169 - val_loss: 5481.8535\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2730.67725\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1581.4777 - val_loss: 3728.1001\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2730.67725\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1542.2087 - val_loss: 2462.2153\n",
      "\n",
      "Epoch 00012: val_loss improved from 2730.67725 to 2462.21533, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 992us/step - loss: 1601.6147 - val_loss: 4737.4175\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2462.21533\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1549.9611 - val_loss: 2517.2568\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2462.21533\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1632.8447 - val_loss: 2796.0518\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2462.21533\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - ETA: 0s - loss: 1540.03 - 0s 1ms/step - loss: 1583.1785 - val_loss: 3794.4087\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2462.21533\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1583.1511 - val_loss: 5235.6597\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2462.21533\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1556.9545 - val_loss: 2505.2219\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2462.21533\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1512.9049 - val_loss: 4545.2881\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2462.21533\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1679.5692 - val_loss: 2533.9678\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2462.21533\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1622.2727 - val_loss: 2643.4885\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2462.21533\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1516.9099 - val_loss: 3084.0637\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2462.21533\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1584.6432 - val_loss: 2627.6760\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2462.21533\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1526.3463 - val_loss: 4207.8145\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2462.21533\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1604.4575 - val_loss: 3833.1514\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2462.21533\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1442.6810 - val_loss: 2871.5037\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2462.21533\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1446.0383 - val_loss: 5606.6387\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2462.21533\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1600.2008 - val_loss: 4484.8809\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2462.21533\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1621.9005 - val_loss: 3032.2688\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2462.21533\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1546.9991 - val_loss: 2844.0879\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2462.21533\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1533.5905 - val_loss: 6079.9033\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2462.21533\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1557.4518 - val_loss: 2481.4446\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2462.21533\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1489.9471 - val_loss: 5527.3799\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2462.21533\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1472.7882 - val_loss: 5400.3018\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2462.21533\n",
      "Epoch 35/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 1479.0776 - val_loss: 5454.6499\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2462.21533\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1601.0225 - val_loss: 4204.9873\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2462.21533\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1536.7924 - val_loss: 4519.1074\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2462.21533\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1465.8903 - val_loss: 5714.8857\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2462.21533\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1369.8660 - val_loss: 2442.3679\n",
      "\n",
      "Epoch 00039: val_loss improved from 2462.21533 to 2442.36792, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1473.8279 - val_loss: 5573.7124\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2442.36792\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1443.0261 - val_loss: 2980.5562\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2442.36792\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1479.9244 - val_loss: 3579.8616\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2442.36792\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1455.6963 - val_loss: 4115.9917\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2442.36792\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1510.7515 - val_loss: 2446.4932\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2442.36792\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1423.7504 - val_loss: 2657.1206\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2442.36792\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1402.3069 - val_loss: 5872.3325\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2442.36792\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1445.6189 - val_loss: 4702.6128\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2442.36792\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1419.2441 - val_loss: 2455.8982\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2442.36792\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1547.3044 - val_loss: 3977.7166\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2442.36792\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1405.2766 - val_loss: 5283.4785\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2442.36792\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1336.3235 - val_loss: 6325.9448\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2442.36792\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1458.1895 - val_loss: 3885.5081\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2442.36792\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1339.2318 - val_loss: 3302.3762\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2442.36792\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1374.1105 - val_loss: 3186.9773\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2442.36792\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1327.2715 - val_loss: 2738.2764\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2442.36792\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1423.3170 - val_loss: 5161.9414\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2442.36792\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1282.4473 - val_loss: 2835.6013\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2442.36792\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1410.0244 - val_loss: 3857.0940\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2442.36792\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1425.5814 - val_loss: 5858.4839\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2442.36792\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1420.7919 - val_loss: 4975.0029\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2442.36792\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1304.8439 - val_loss: 3947.5137\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2442.36792\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1424.6848 - val_loss: 5459.6934\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2442.36792\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1346.3829 - val_loss: 6104.0044\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2442.36792\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1360.1719 - val_loss: 4119.3921\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2442.36792\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1322.5441 - val_loss: 3849.5237\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2442.36792\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1295.6732 - val_loss: 3353.9094\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2442.36792\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1273.6895 - val_loss: 5722.2212\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2442.36792\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1306.6099 - val_loss: 2578.4854\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2442.36792\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1326.5448 - val_loss: 2552.4658\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2442.36792\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1319.3815 - val_loss: 3625.8401\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2442.36792\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1261.8420 - val_loss: 3981.5283\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2442.36792\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1207.6638 - val_loss: 2579.5527\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2442.36792\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1173.2476 - val_loss: 4077.2307\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2442.36792\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1156.5336 - val_loss: 4738.4673\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2442.36792\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1113.8217 - val_loss: 2848.5625\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2442.36792\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1234.0575 - val_loss: 4812.2139\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2442.36792\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1321.2462 - val_loss: 4405.5063\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2442.36792\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1225.6351 - val_loss: 3079.0459\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2442.36792\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1172.2970 - val_loss: 3855.1938\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2442.36792\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1134.4445 - val_loss: 4845.4648\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2442.36792\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1137.0995 - val_loss: 4965.6782\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2442.36792\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1172.5475 - val_loss: 4369.8403\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2442.36792\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1109.6725 - val_loss: 4981.4160\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2442.36792\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1117.7189 - val_loss: 4475.0718\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2442.36792\n",
      "Epoch 85/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 2ms/step - loss: 1152.4994 - val_loss: 4688.7935\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2442.36792\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1212.9662 - val_loss: 3377.4924\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2442.36792\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1127.1995 - val_loss: 4595.8745\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2442.36792\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1078.5122 - val_loss: 4726.0996\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2442.36792\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1085.6656 - val_loss: 4603.0273\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2442.36792\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1188.7781 - val_loss: 4512.7983\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2442.36792\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1095.7355 - val_loss: 4391.1992\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2442.36792\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1106.6625 - val_loss: 4637.6147\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2442.36792\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1120.8330 - val_loss: 4752.1099\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2442.36792\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1118.3945 - val_loss: 3081.0393\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2442.36792\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1088.7542 - val_loss: 4825.1016\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2442.36792\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1107.2305 - val_loss: 4572.2808\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2442.36792\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1112.5802 - val_loss: 4727.0767\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2442.36792\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1081.6270 - val_loss: 2583.9204\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2442.36792\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1103.3049 - val_loss: 4332.5210\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2442.36792\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - ETA: 0s - loss: 1096.34 - 0s 1ms/step - loss: 1093.4552 - val_loss: 2812.1194\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 2442.36792\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1077.1144 - val_loss: 4732.8276\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 2442.36792\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1090.7828 - val_loss: 2837.9656\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 2442.36792\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1101.9254 - val_loss: 4455.6309\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 2442.36792\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1100.4525 - val_loss: 4857.7915\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 2442.36792\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1086.2528 - val_loss: 3364.5100\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 2442.36792\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1077.1123 - val_loss: 4194.2812\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 2442.36792\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1069.8810 - val_loss: 5027.8267\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 2442.36792\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1116.4205 - val_loss: 4469.8574\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 2442.36792\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1097.7639 - val_loss: 4900.1929\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 2442.36792\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1091.2546 - val_loss: 4833.6201\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 2442.36792\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1045.7233 - val_loss: 3707.9746\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 2442.36792\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1046.8689 - val_loss: 2964.8384\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 2442.36792\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1045.8209 - val_loss: 2758.7346\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 2442.36792\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1066.4000 - val_loss: 3759.9070\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 2442.36792\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1032.4531 - val_loss: 3477.2324\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 2442.36792\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1054.9288 - val_loss: 3516.6765\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 2442.36792\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1041.6301 - val_loss: 4360.1221\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 2442.36792\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1082.8101 - val_loss: 5027.4526\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 2442.36792\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1061.2476 - val_loss: 3431.8245\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 2442.36792\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1060.3979 - val_loss: 3292.5210\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 2442.36792\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1064.6929 - val_loss: 3026.8196\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 2442.36792\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1029.7345 - val_loss: 4190.2861\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 2442.36792\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1079.4111 - val_loss: 3940.9438\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 2442.36792\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1069.3767 - val_loss: 5002.6826\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 2442.36792\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1048.7913 - val_loss: 3493.2871\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 2442.36792\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1006.6179 - val_loss: 2676.5872\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 2442.36792\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1083.5664 - val_loss: 3331.5684\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 2442.36792\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1067.4410 - val_loss: 3712.0588\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 2442.36792\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1033.0000 - val_loss: 3501.8977\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 2442.36792\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1094.2343 - val_loss: 4883.8184\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 2442.36792\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1129.4093 - val_loss: 2755.9561\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 2442.36792\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1060.8835 - val_loss: 4497.3926\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 2442.36792\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1026.5085 - val_loss: 2742.4915\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 2442.36792\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1085.9358 - val_loss: 4008.7351\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 2442.36792\n",
      "Epoch 135/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 1035.2662 - val_loss: 4483.9619\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 2442.36792\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1034.8538 - val_loss: 4728.1514\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 2442.36792\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1044.0118 - val_loss: 3843.6890\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 2442.36792\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1011.1002 - val_loss: 4805.1665\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 2442.36792\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1039.4778 - val_loss: 3005.2815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|██████████████████████████████████████████████████████████████████▍               | 17/21 [31:09<06:12, 93.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00139: val_loss did not improve from 2442.36792\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 1182.3904 - val_loss: 2100.8154\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2100.81543, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 844.0796 - val_loss: 1478.4325\n",
      "\n",
      "Epoch 00002: val_loss improved from 2100.81543 to 1478.43250, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 978us/step - loss: 886.6210 - val_loss: 2110.3313\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1478.43250\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 992us/step - loss: 882.0648 - val_loss: 479.6543\n",
      "\n",
      "Epoch 00004: val_loss improved from 1478.43250 to 479.65433, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 807.4789 - val_loss: 1874.5107\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 479.65433\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 836.0856 - val_loss: 1233.4165\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 479.65433\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 978us/step - loss: 807.4160 - val_loss: 2060.2117\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 479.65433\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 978us/step - loss: 952.9689 - val_loss: 678.4794\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 479.65433\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 957us/step - loss: 831.2197 - val_loss: 569.3619\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 479.65433\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 968us/step - loss: 910.0826 - val_loss: 498.7805\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 479.65433\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 865.8392 - val_loss: 471.5933\n",
      "\n",
      "Epoch 00011: val_loss improved from 479.65433 to 471.59329, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 917.5372 - val_loss: 2304.2219\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 471.59329\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 953us/step - loss: 897.6469 - val_loss: 512.3523\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 471.59329\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 961us/step - loss: 720.4511 - val_loss: 776.2639\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 471.59329\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 969us/step - loss: 713.7543 - val_loss: 710.2274\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 471.59329\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 682.4213 - val_loss: 2327.6882\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 471.59329\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 939us/step - loss: 643.0168 - val_loss: 544.8621\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 471.59329\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 957us/step - loss: 679.1484 - val_loss: 1689.6559\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 471.59329\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 720.8027 - val_loss: 2198.1282\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 471.59329\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 916us/step - loss: 663.3000 - val_loss: 559.0475\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 471.59329\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 969us/step - loss: 596.1364 - val_loss: 410.3049\n",
      "\n",
      "Epoch 00021: val_loss improved from 471.59329 to 410.30487, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 989us/step - loss: 638.4035 - val_loss: 1879.8409\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 410.30487\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 615.5330 - val_loss: 1779.4178\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 410.30487\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 607.6515 - val_loss: 1406.2080\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 410.30487\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 976us/step - loss: 605.0692 - val_loss: 499.0368\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 410.30487\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 637.7965 - val_loss: 1618.0969\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 410.30487\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 590.7946 - val_loss: 393.7341\n",
      "\n",
      "Epoch 00027: val_loss improved from 410.30487 to 393.73410, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 965us/step - loss: 592.2275 - val_loss: 945.9540\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 393.73410\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 955us/step - loss: 562.9958 - val_loss: 509.3336\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 393.73410\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 955us/step - loss: 644.3388 - val_loss: 1648.7915\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 393.73410\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 984us/step - loss: 601.7496 - val_loss: 630.6521\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 393.73410\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 606.1288 - val_loss: 1791.9056\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 393.73410\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 949us/step - loss: 609.2551 - val_loss: 919.7418\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 393.73410\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 598.7231 - val_loss: 921.3526\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 393.73410\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 925us/step - loss: 552.5051 - val_loss: 1830.6023\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 393.73410\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 567.9628 - val_loss: 1684.2500\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 393.73410\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 975us/step - loss: 535.3264 - val_loss: 591.0751\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 393.73410\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 568.5092 - val_loss: 783.7168\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 393.73410\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 956us/step - loss: 557.4200 - val_loss: 876.3171\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 393.73410\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 561.7273 - val_loss: 1066.5765\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 393.73410\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 567.8038 - val_loss: 522.7485\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 393.73410\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 530.1455 - val_loss: 522.8833\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 393.73410\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 521.0263 - val_loss: 1439.5730\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 393.73410\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 950us/step - loss: 502.6204 - val_loss: 1779.2655\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 393.73410\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 526.2830 - val_loss: 1105.9938\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 393.73410\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 934us/step - loss: 531.8905 - val_loss: 1549.7338\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 393.73410\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 975us/step - loss: 506.4629 - val_loss: 1828.2336\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 393.73410\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 523.8971 - val_loss: 1009.3515\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 393.73410\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 534.1411 - val_loss: 611.1046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00049: val_loss did not improve from 393.73410\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 507.5469 - val_loss: 1364.9922\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 393.73410\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 914us/step - loss: 528.9262 - val_loss: 442.3817\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 393.73410\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 971us/step - loss: 488.5488 - val_loss: 488.7473\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 393.73410\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 971us/step - loss: 484.8055 - val_loss: 1685.8236\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 393.73410\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 987us/step - loss: 483.4057 - val_loss: 514.4080\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 393.73410\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 950us/step - loss: 462.3640 - val_loss: 1130.6553\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 393.73410\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 988us/step - loss: 490.5747 - val_loss: 1372.4581\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 393.73410\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 460.6399 - val_loss: 371.0752\n",
      "\n",
      "Epoch 00057: val_loss improved from 393.73410 to 371.07516, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 941us/step - loss: 442.4843 - val_loss: 386.2627\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 371.07516\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 922us/step - loss: 419.1342 - val_loss: 1630.3705\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 371.07516\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 412.5024 - val_loss: 968.5958\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 371.07516\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 961us/step - loss: 415.9106 - val_loss: 1071.8916\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 371.07516\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 418.4269 - val_loss: 769.3946\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 371.07516\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 933us/step - loss: 400.5444 - val_loss: 1576.6837\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 371.07516\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 952us/step - loss: 384.1865 - val_loss: 1304.9977\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 371.07516\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 965us/step - loss: 384.4676 - val_loss: 475.3319\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 371.07516\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 390.0421 - val_loss: 417.6489\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 371.07516\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 930us/step - loss: 395.9355 - val_loss: 1314.6868\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 371.07516\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 990us/step - loss: 396.2828 - val_loss: 1234.9113\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 371.07516\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 998us/step - loss: 389.6569 - val_loss: 854.4853\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 371.07516\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 999us/step - loss: 384.7091 - val_loss: 491.7725\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 371.07516\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 387.5249 - val_loss: 1213.9934\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 371.07516\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 379.0250 - val_loss: 1421.0525\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 371.07516\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 933us/step - loss: 377.4474 - val_loss: 1377.1497\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 371.07516\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 977us/step - loss: 384.7004 - val_loss: 542.3146\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 371.07516\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 977us/step - loss: 365.5506 - val_loss: 1025.6425\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 371.07516\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 915us/step - loss: 367.3782 - val_loss: 1486.9429\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 371.07516\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 994us/step - loss: 370.2878 - val_loss: 591.2766\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 371.07516\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 963us/step - loss: 374.5506 - val_loss: 619.5428\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 371.07516\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 362.6333 - val_loss: 951.2147\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 371.07516\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 934us/step - loss: 377.7309 - val_loss: 1097.0028\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 371.07516\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 380.0243 - val_loss: 477.0356\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 371.07516\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 365.5367 - val_loss: 410.9832\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 371.07516\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 939us/step - loss: 379.8615 - val_loss: 1222.2472\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 371.07516\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 373.9653 - val_loss: 630.5244\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 371.07516\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 358.6938 - val_loss: 370.8137\n",
      "\n",
      "Epoch 00085: val_loss improved from 371.07516 to 370.81372, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 950us/step - loss: 365.4934 - val_loss: 1057.1990\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 370.81372\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 366.8835 - val_loss: 1358.3414\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 370.81372\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 364.3117 - val_loss: 1122.6953\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 370.81372\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 953us/step - loss: 365.7909 - val_loss: 1211.0972\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 370.81372\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 356.7106 - val_loss: 903.1994\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 370.81372\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 979us/step - loss: 361.7079 - val_loss: 1115.0337\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 370.81372\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 365.8379 - val_loss: 1235.9580\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 370.81372\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 946us/step - loss: 347.1971 - val_loss: 759.2452\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 370.81372\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 354.1468 - val_loss: 1136.0746\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 370.81372\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 996us/step - loss: 362.9046 - val_loss: 734.2553\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 370.81372\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 368.9102 - val_loss: 880.6562\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 370.81372\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 994us/step - loss: 351.0585 - val_loss: 390.5233\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 370.81372\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 999us/step - loss: 362.9533 - val_loss: 875.9286\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 370.81372\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 335.0691 - val_loss: 411.5523\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 370.81372\n",
      "Epoch 100/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 360.4279 - val_loss: 1851.6830\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 370.81372\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 359.6103 - val_loss: 648.0336\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 370.81372\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 348.1472 - val_loss: 912.7830\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 370.81372\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 327.1778 - val_loss: 428.4587\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 370.81372\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 344.8698 - val_loss: 671.4201\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 370.81372\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 345.7924 - val_loss: 598.4702\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 370.81372\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 341.6409 - val_loss: 658.3150\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 370.81372\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 352.5914 - val_loss: 423.3281\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 370.81372\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 351.7894 - val_loss: 1147.3523\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 370.81372\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 364.6384 - val_loss: 1303.8617\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 370.81372\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 345.2654 - val_loss: 799.8782\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 370.81372\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 371.9478 - val_loss: 1214.6794\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 370.81372\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 342.0015 - val_loss: 708.0377\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 370.81372\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 343.0544 - val_loss: 533.9334\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 370.81372\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 347.9684 - val_loss: 658.6683\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 370.81372\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 340.8234 - val_loss: 1387.2913\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 370.81372\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 357.4670 - val_loss: 686.8500\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 370.81372\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 341.9332 - val_loss: 1252.2604\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 370.81372\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 324.4185 - val_loss: 1130.7560\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 370.81372\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 337.0791 - val_loss: 611.2576\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 370.81372\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 356.4022 - val_loss: 740.0226\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 370.81372\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 324.6279 - val_loss: 540.8655\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 370.81372\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 338.4622 - val_loss: 1288.6425\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 370.81372\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 336.0559 - val_loss: 811.2042\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 370.81372\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 330.6471 - val_loss: 828.0751\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 370.81372\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 332.2280 - val_loss: 534.8796\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 370.81372\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 323.1170 - val_loss: 1323.6218\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 370.81372\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 336.5968 - val_loss: 1321.7560\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 370.81372\n",
      "Epoch 128/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 313.1249 - val_loss: 616.2957\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 370.81372\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 321.3262 - val_loss: 612.6683\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 370.81372\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 325.5080 - val_loss: 1296.0057\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 370.81372\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 311.0580 - val_loss: 892.1843\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 370.81372\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 328.6699 - val_loss: 648.7745\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 370.81372\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 324.3141 - val_loss: 591.2764\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 370.81372\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 314.6692 - val_loss: 799.6166\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 370.81372\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 314.5708 - val_loss: 1428.0385\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 370.81372\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 327.3591 - val_loss: 660.8998\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 370.81372\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 318.5335 - val_loss: 622.3675\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 370.81372\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 320.6314 - val_loss: 1063.0397\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 370.81372\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 322.4553 - val_loss: 847.7913\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 370.81372\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 332.4882 - val_loss: 1150.6133\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 370.81372\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 302.3316 - val_loss: 1160.0614\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 370.81372\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 323.1636 - val_loss: 1128.6476\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 370.81372\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 319.7097 - val_loss: 502.8615\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 370.81372\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 314.1095 - val_loss: 840.5302\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 370.81372\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 298.6587 - val_loss: 733.3914\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 370.81372\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 330.9941 - val_loss: 839.8984\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 370.81372\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 329.9955 - val_loss: 1196.3442\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 370.81372\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 314.9880 - val_loss: 468.2278\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 370.81372\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 306.0474 - val_loss: 1860.6561\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 370.81372\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 334.8204 - val_loss: 472.8594\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 370.81372\n",
      "Epoch 151/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 310.7302 - val_loss: 772.3546\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 370.81372\n",
      "Epoch 152/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 304.2682 - val_loss: 823.1181\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 370.81372\n",
      "Epoch 153/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 323.4235 - val_loss: 571.0410\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 370.81372\n",
      "Epoch 154/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 310.8309 - val_loss: 1054.6201\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 370.81372\n",
      "Epoch 155/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 297.5878 - val_loss: 1505.2863\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 370.81372\n",
      "Epoch 156/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 310.5748 - val_loss: 869.8148\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 370.81372\n",
      "Epoch 157/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 313.3275 - val_loss: 791.5701\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 370.81372\n",
      "Epoch 158/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 313.9098 - val_loss: 1087.6567\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 370.81372\n",
      "Epoch 159/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 310.1386 - val_loss: 918.5465\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 370.81372\n",
      "Epoch 160/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 318.2444 - val_loss: 565.6234\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 370.81372\n",
      "Epoch 161/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 296.4138 - val_loss: 446.9593\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 370.81372\n",
      "Epoch 162/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 331.7171 - val_loss: 854.1523\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 370.81372\n",
      "Epoch 163/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 327.5768 - val_loss: 944.9858\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 370.81372\n",
      "Epoch 164/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 320.0918 - val_loss: 721.5056\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 370.81372\n",
      "Epoch 165/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 317.0850 - val_loss: 684.3809\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 370.81372\n",
      "Epoch 166/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 294.0208 - val_loss: 742.2098\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 370.81372\n",
      "Epoch 167/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 319.4620 - val_loss: 812.4813\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 370.81372\n",
      "Epoch 168/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 315.7844 - val_loss: 590.3674\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 370.81372\n",
      "Epoch 169/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 313.8287 - val_loss: 581.6428\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 370.81372\n",
      "Epoch 170/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 317.4343 - val_loss: 875.1987\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 370.81372\n",
      "Epoch 171/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 318.6112 - val_loss: 1255.0009\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 370.81372\n",
      "Epoch 172/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 313.7132 - val_loss: 907.1119\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 370.81372\n",
      "Epoch 173/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 318.8325 - val_loss: 755.2505\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 370.81372\n",
      "Epoch 174/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 320.2313 - val_loss: 829.6602\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 370.81372\n",
      "Epoch 175/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 324.9232 - val_loss: 841.6415\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 370.81372\n",
      "Epoch 176/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 309.3745 - val_loss: 1051.2543\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 370.81372\n",
      "Epoch 177/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 319.1772 - val_loss: 704.7752\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 370.81372\n",
      "Epoch 178/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 306.9578 - val_loss: 1379.6038\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 370.81372\n",
      "Epoch 179/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 315.7205 - val_loss: 753.0043\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 370.81372\n",
      "Epoch 180/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 321.8863 - val_loss: 501.6469\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 370.81372\n",
      "Epoch 181/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 301.5267 - val_loss: 1221.8694\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 370.81372\n",
      "Epoch 182/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 306.8560 - val_loss: 416.0654\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 370.81372\n",
      "Epoch 183/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 310.0431 - val_loss: 858.9027\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 370.81372\n",
      "Epoch 184/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 306.2513 - val_loss: 1260.3525\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 370.81372\n",
      "Epoch 185/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 295.4727 - val_loss: 598.1509\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 370.81372\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 1218.7831 - val_loss: 1112.4803\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1112.48035, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 846.9465 - val_loss: 472.3192\n",
      "\n",
      "Epoch 00002: val_loss improved from 1112.48035 to 472.31915, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 964us/step - loss: 833.2816 - val_loss: 1404.4425\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 472.31915\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 970us/step - loss: 903.4857 - val_loss: 1798.1785\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 472.31915\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 842.1400 - val_loss: 448.7193\n",
      "\n",
      "Epoch 00005: val_loss improved from 472.31915 to 448.71930, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 993us/step - loss: 802.2282 - val_loss: 2013.4358\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 448.71930\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 835.5009 - val_loss: 430.5904\n",
      "\n",
      "Epoch 00007: val_loss improved from 448.71930 to 430.59036, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 972us/step - loss: 821.0232 - val_loss: 1467.6781\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 430.59036\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 816.0692 - val_loss: 935.6398\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 430.59036\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 787.8101 - val_loss: 1582.9375\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 430.59036\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 810.4033 - val_loss: 1537.7484\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 430.59036\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 766.9943 - val_loss: 1327.0608\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 430.59036\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 776.0663 - val_loss: 429.1209\n",
      "\n",
      "Epoch 00013: val_loss improved from 430.59036 to 429.12091, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 736.1132 - val_loss: 2084.4915\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 429.12091\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 755.7658 - val_loss: 1528.4436\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 429.12091\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 770.8334 - val_loss: 737.8748\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 429.12091\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 669.2613 - val_loss: 2090.2102\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 429.12091\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 774.1427 - val_loss: 728.5076\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 429.12091\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 678.9820 - val_loss: 1794.2788\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 429.12091\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 660.8121 - val_loss: 1755.8096\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 429.12091\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 643.5853 - val_loss: 1312.2365\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 429.12091\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 665.5582 - val_loss: 419.5879\n",
      "\n",
      "Epoch 00022: val_loss improved from 429.12091 to 419.58786, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 671.5567 - val_loss: 686.3223\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 419.58786\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 615.1866 - val_loss: 1881.7861\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 419.58786\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 591.4332 - val_loss: 460.5877\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 419.58786\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 586.5923 - val_loss: 1917.6658\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 419.58786\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 567.4057 - val_loss: 1516.0459\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 419.58786\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 622.3009 - val_loss: 1031.7698\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 419.58786\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 627.7795 - val_loss: 1745.1396\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 419.58786\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 606.9191 - val_loss: 1522.5439\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 419.58786\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 614.7913 - val_loss: 1239.8976\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 419.58786\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 602.4973 - val_loss: 1626.2092\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 419.58786\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 591.8013 - val_loss: 1269.8967\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 419.58786\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 559.4544 - val_loss: 608.4260\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 419.58786\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 575.2284 - val_loss: 1026.8022\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 419.58786\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 574.3869 - val_loss: 1863.5786\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 419.58786\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 543.9813 - val_loss: 755.1711\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 419.58786\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 580.2248 - val_loss: 1330.3176\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 419.58786\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 512.2263 - val_loss: 411.6081\n",
      "\n",
      "Epoch 00039: val_loss improved from 419.58786 to 411.60812, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 543.9958 - val_loss: 1868.5906\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 411.60812\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 578.9855 - val_loss: 668.9506\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 411.60812\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 525.9944 - val_loss: 1407.9861\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 411.60812\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 530.8717 - val_loss: 1931.1494\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 411.60812\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 570.5805 - val_loss: 868.5503\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 411.60812\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 509.9952 - val_loss: 1894.1154\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 411.60812\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 504.0775 - val_loss: 714.4969\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 411.60812\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 527.2565 - val_loss: 579.2093\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 411.60812\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 540.0088 - val_loss: 1826.1913\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 411.60812\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 541.0964 - val_loss: 1255.1158\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 411.60812\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 521.7397 - val_loss: 723.3513\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 411.60812\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 524.5099 - val_loss: 1292.2676\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 411.60812\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 505.7923 - val_loss: 1510.0546\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 411.60812\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 474.8994 - val_loss: 623.1165\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 411.60812\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 521.6935 - val_loss: 1271.5646\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 411.60812\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 460.5451 - val_loss: 801.9440\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 411.60812\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 452.7278 - val_loss: 1254.7251\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 411.60812\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 503.4499 - val_loss: 1806.0675\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 411.60812\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 482.3114 - val_loss: 833.0926\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 411.60812\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 469.7162 - val_loss: 447.5067\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 411.60812\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 479.4414 - val_loss: 1355.3376\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 411.60812\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 470.6911 - val_loss: 1137.3336\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 411.60812\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 432.6707 - val_loss: 514.0107\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 411.60812\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 454.2547 - val_loss: 1552.8483\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 411.60812\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 446.5586 - val_loss: 1460.6184\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 411.60812\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 426.8107 - val_loss: 1296.2373\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 411.60812\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 412.1427 - val_loss: 973.0496\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 411.60812\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 417.0291 - val_loss: 943.9741\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 411.60812\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 408.2516 - val_loss: 845.8145\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 411.60812\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 402.2359 - val_loss: 696.9470\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 411.60812\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 408.9348 - val_loss: 802.1412\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 411.60812\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 375.2138 - val_loss: 679.8442\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 411.60812\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 406.5108 - val_loss: 1059.4730\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 411.60812\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 405.3960 - val_loss: 1157.4180\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 411.60812\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 400.3298 - val_loss: 1280.9789\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 411.60812\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 401.1805 - val_loss: 1110.9268\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 411.60812\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 393.0715 - val_loss: 794.0510\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 411.60812\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 413.5174 - val_loss: 1571.6636\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 411.60812\n",
      "Epoch 78/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 395.9562 - val_loss: 1142.1364\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 411.60812\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 386.9145 - val_loss: 1603.0911\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 411.60812\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 384.0244 - val_loss: 752.9943\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 411.60812\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 380.0213 - val_loss: 1385.4631\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 411.60812\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 387.1170 - val_loss: 846.4554\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 411.60812\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 391.0496 - val_loss: 1025.9225\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 411.60812\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 386.2457 - val_loss: 981.2619\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 411.60812\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 394.9931 - val_loss: 1048.2759\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 411.60812\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 366.5361 - val_loss: 1175.4675\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 411.60812\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 399.3327 - val_loss: 780.8340\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 411.60812\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 393.7458 - val_loss: 1586.8121\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 411.60812\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 384.3327 - val_loss: 968.7672\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 411.60812\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 372.8745 - val_loss: 715.3982\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 411.60812\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 367.6380 - val_loss: 794.4139\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 411.60812\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 389.3967 - val_loss: 1140.7001\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 411.60812\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 384.0165 - val_loss: 1058.4254\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 411.60812\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 378.3015 - val_loss: 942.2123\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 411.60812\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 384.2658 - val_loss: 899.2227\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 411.60812\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 378.8293 - val_loss: 1078.3771\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 411.60812\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 370.3850 - val_loss: 872.5233\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 411.60812\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 362.6273 - val_loss: 1133.6617\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 411.60812\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 381.6093 - val_loss: 1266.2015\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 411.60812\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 369.5910 - val_loss: 954.3200\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 411.60812\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 362.3716 - val_loss: 1349.7384\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 411.60812\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 369.7072 - val_loss: 1545.0531\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 411.60812\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 381.9775 - val_loss: 1092.4515\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 411.60812\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 366.8266 - val_loss: 929.6094\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 411.60812\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 392.3407 - val_loss: 738.6708\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 411.60812\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 376.1533 - val_loss: 992.6646\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 411.60812\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 369.3661 - val_loss: 1021.3289\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 411.60812\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 373.0826 - val_loss: 953.1562\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 411.60812\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 371.2615 - val_loss: 1387.0472\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 411.60812\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 374.8497 - val_loss: 671.7660\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 411.60812\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 393.1531 - val_loss: 1179.8500\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 411.60812\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 365.0243 - val_loss: 1123.2443\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 411.60812\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 387.1985 - val_loss: 706.9996\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 411.60812\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 362.1003 - val_loss: 1078.2507\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 411.60812\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 379.5896 - val_loss: 744.1691\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 411.60812\n",
      "Epoch 116/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 363.6589 - val_loss: 1341.4269\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 411.60812\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 359.3080 - val_loss: 838.2189\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 411.60812\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 358.2207 - val_loss: 1137.3788\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 411.60812\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 374.9115 - val_loss: 959.0404\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 411.60812\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 369.4074 - val_loss: 1015.5765\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 411.60812\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 358.8895 - val_loss: 1121.1466\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 411.60812\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 372.4648 - val_loss: 1029.9471\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 411.60812\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 358.8286 - val_loss: 850.2763\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 411.60812\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 365.9745 - val_loss: 951.4291\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 411.60812\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 370.3116 - val_loss: 1335.9811\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 411.60812\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 351.9835 - val_loss: 1484.5765\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 411.60812\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 371.1015 - val_loss: 1282.0206\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 411.60812\n",
      "Epoch 128/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 373.5800 - val_loss: 876.7692\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 411.60812\n",
      "Epoch 129/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 360.3372 - val_loss: 789.0674\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 411.60812\n",
      "Epoch 130/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 366.7248 - val_loss: 948.9977\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 411.60812\n",
      "Epoch 131/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 363.9672 - val_loss: 1083.4796\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 411.60812\n",
      "Epoch 132/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 353.5068 - val_loss: 618.6241\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 411.60812\n",
      "Epoch 133/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 365.0365 - val_loss: 792.6669\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 411.60812\n",
      "Epoch 134/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 343.4633 - val_loss: 1038.2499\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 411.60812\n",
      "Epoch 135/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 358.5334 - val_loss: 1052.1277\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 411.60812\n",
      "Epoch 136/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 368.6382 - val_loss: 754.7958\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 411.60812\n",
      "Epoch 137/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 365.7207 - val_loss: 840.7075\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 411.60812\n",
      "Epoch 138/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 359.8415 - val_loss: 1041.0372\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 411.60812\n",
      "Epoch 139/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 347.8771 - val_loss: 847.6644\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 411.60812\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 1234.7324 - val_loss: 1236.8644\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1236.86438, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 799.8748 - val_loss: 462.1052\n",
      "\n",
      "Epoch 00002: val_loss improved from 1236.86438 to 462.10516, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 997us/step - loss: 769.9633 - val_loss: 595.0162\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 462.10516\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 878.4990 - val_loss: 1804.8723\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 462.10516\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 872.9904 - val_loss: 523.6851\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 462.10516\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 864.6426 - val_loss: 992.3582\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 462.10516\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 752.2019 - val_loss: 646.2794\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 462.10516\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 886.4896 - val_loss: 2086.7437\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 462.10516\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 823.7687 - val_loss: 1814.3640\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 462.10516\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 821.7023 - val_loss: 2040.8921\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 462.10516\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 804.1953 - val_loss: 1164.1101\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 462.10516\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 797.2648 - val_loss: 2526.8113\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 462.10516\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 872.9378 - val_loss: 1418.6278\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 462.10516\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 778.9468 - val_loss: 480.3840\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 462.10516\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 849.8641 - val_loss: 1108.3295\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 462.10516\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 784.3066 - val_loss: 2613.8352\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 462.10516\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 881.3544 - val_loss: 1476.9329\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 462.10516\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 811.0273 - val_loss: 2137.1240\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 462.10516\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 856.6581 - val_loss: 1183.9628\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 462.10516\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 738.2100 - val_loss: 550.3300\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 462.10516\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 809.0065 - val_loss: 2402.9839\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 462.10516\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 779.2087 - val_loss: 1667.4261\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 462.10516\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 741.9771 - val_loss: 464.1989\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 462.10516\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 714.2752 - val_loss: 2267.1514\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 462.10516\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 713.6083 - val_loss: 1533.0663\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 462.10516\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 679.7831 - val_loss: 1755.9164\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 462.10516\n",
      "Epoch 27/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 647.1052 - val_loss: 2284.1941\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 462.10516\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 666.3744 - val_loss: 498.3679\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 462.10516\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 624.0034 - val_loss: 483.6167\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 462.10516\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 634.5193 - val_loss: 671.0337\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 462.10516\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 617.8172 - val_loss: 2010.4111\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 462.10516\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 586.2032 - val_loss: 642.8845\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 462.10516\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 593.4821 - val_loss: 1264.4817\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 462.10516\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 635.7205 - val_loss: 2091.3318\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 462.10516\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 587.4091 - val_loss: 1093.4823\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 462.10516\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 605.9730 - val_loss: 1782.6785\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 462.10516\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 567.3854 - val_loss: 550.6094\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 462.10516\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 627.3743 - val_loss: 483.8786\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 462.10516\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 621.3029 - val_loss: 1530.5660\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 462.10516\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 599.5191 - val_loss: 882.7244\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 462.10516\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 530.0366 - val_loss: 511.2014\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 462.10516\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 564.9906 - val_loss: 1389.6040\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 462.10516\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 592.1250 - val_loss: 589.8231\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 462.10516\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 545.7687 - val_loss: 1107.8962\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 462.10516\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 544.8201 - val_loss: 648.8086\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 462.10516\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 542.1439 - val_loss: 1957.7694\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 462.10516\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 530.8298 - val_loss: 1902.8231\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 462.10516\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 534.8967 - val_loss: 2021.8230\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 462.10516\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 574.9378 - val_loss: 2449.9656\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 462.10516\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 566.9852 - val_loss: 805.8045\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 462.10516\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 550.1473 - val_loss: 1122.1692\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 462.10516\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 523.2002 - val_loss: 1066.7656\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 462.10516\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 550.1244 - val_loss: 2146.5940\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 462.10516\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 515.2552 - val_loss: 1149.8341\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 462.10516\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 523.0932 - val_loss: 803.4105\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 462.10516\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 539.9435 - val_loss: 760.6268\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 462.10516\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 568.8893 - val_loss: 625.3672\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 462.10516\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 523.8718 - val_loss: 2310.9062\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 462.10516\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 521.8977 - val_loss: 2213.3037\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 462.10516\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 502.4264 - val_loss: 1253.5464\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 462.10516\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 531.1864 - val_loss: 2278.7949\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 462.10516\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 582.4158 - val_loss: 1522.1501\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 462.10516\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 499.6484 - val_loss: 1053.8866\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 462.10516\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 484.7591 - val_loss: 1469.1062\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 462.10516\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 458.1661 - val_loss: 1554.3844\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 462.10516\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 465.9685 - val_loss: 500.8383\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 462.10516\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 478.7447 - val_loss: 1437.9120\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 462.10516\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 449.2448 - val_loss: 1347.4620\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 462.10516\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 441.5695 - val_loss: 1408.1899\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 462.10516\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 993us/step - loss: 437.6762 - val_loss: 887.6896\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 462.10516\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 454.1894 - val_loss: 1378.6460\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 462.10516\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 442.7038 - val_loss: 1381.7100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 462.10516\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 431.4513 - val_loss: 533.8318\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 462.10516\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 444.7999 - val_loss: 1379.2300\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 462.10516\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 437.8488 - val_loss: 1341.9137\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 462.10516\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 438.9695 - val_loss: 1353.0018\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 462.10516\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 432.3947 - val_loss: 1441.4526\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 462.10516\n",
      "Epoch 78/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 439.8316 - val_loss: 1411.6737\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 462.10516\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 441.6146 - val_loss: 1360.0068\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 462.10516\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 445.4324 - val_loss: 1080.4972\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 462.10516\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 433.3760 - val_loss: 1469.4087\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 462.10516\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 444.9135 - val_loss: 1389.8163\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 462.10516\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 441.6108 - val_loss: 1311.0537\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 462.10516\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 437.7482 - val_loss: 1405.8306\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 462.10516\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 440.1350 - val_loss: 1353.5054\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 462.10516\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 445.1698 - val_loss: 1456.3761\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 462.10516\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 452.9396 - val_loss: 1370.8597\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 462.10516\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 425.3498 - val_loss: 1294.7905\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 462.10516\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 430.4838 - val_loss: 1413.7861\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 462.10516\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 432.8638 - val_loss: 480.2084\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 462.10516\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 434.2952 - val_loss: 1185.9315\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 462.10516\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 431.3690 - val_loss: 1391.3794\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 462.10516\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 439.0743 - val_loss: 1367.2344\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 462.10516\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 437.5549 - val_loss: 1432.6729\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 462.10516\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 441.9714 - val_loss: 1260.5771\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 462.10516\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 435.6240 - val_loss: 1259.2954\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 462.10516\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 434.2890 - val_loss: 1389.8682\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 462.10516\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 428.6631 - val_loss: 1332.0192\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 462.10516\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 443.5320 - val_loss: 1323.1678\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 462.10516\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 435.3732 - val_loss: 1376.2496\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 462.10516\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 428.6939 - val_loss: 1285.2411\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 462.10516\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 456.6176 - val_loss: 887.5314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 18/21 [32:35<04:33, 91.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00102: val_loss did not improve from 462.10516\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 1341.2628 - val_loss: 1000.0770\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1000.07697, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 998us/step - loss: 865.2351 - val_loss: 2340.6318\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1000.07697\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 854.4952 - val_loss: 2692.8730\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1000.07697\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 846.1096 - val_loss: 921.3482\n",
      "\n",
      "Epoch 00004: val_loss improved from 1000.07697 to 921.34821, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 966us/step - loss: 835.8434 - val_loss: 975.5441\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 921.34821\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 968us/step - loss: 815.2310 - val_loss: 2180.4951\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 921.34821\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 979us/step - loss: 807.1462 - val_loss: 2915.3225\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 921.34821\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 889.9395 - val_loss: 2549.7444\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 921.34821\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 783.0359 - val_loss: 947.7556\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 921.34821\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 959us/step - loss: 792.0034 - val_loss: 1947.2878\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 921.34821\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 742.6799 - val_loss: 1564.5913\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 921.34821\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 767.0139 - val_loss: 2463.3350\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 921.34821\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 946us/step - loss: 770.7841 - val_loss: 1027.7924\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 921.34821\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 761.1780 - val_loss: 856.5528\n",
      "\n",
      "Epoch 00014: val_loss improved from 921.34821 to 856.55280, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 993us/step - loss: 773.2855 - val_loss: 2232.2275\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 856.55280\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 728.6255 - val_loss: 2614.9641\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 856.55280\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 944us/step - loss: 700.4464 - val_loss: 1851.3278\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 856.55280\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 683.6845 - val_loss: 2606.5615\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 856.55280\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 939us/step - loss: 659.2979 - val_loss: 1487.3992\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 856.55280\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 632.3821 - val_loss: 1951.5153\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 856.55280\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 953us/step - loss: 620.8200 - val_loss: 2177.4885\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 856.55280\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 993us/step - loss: 637.5259 - val_loss: 954.8323\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 856.55280\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 665.8069 - val_loss: 998.4849\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 856.55280\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 940us/step - loss: 700.8723 - val_loss: 776.4247\n",
      "\n",
      "Epoch 00024: val_loss improved from 856.55280 to 776.42474, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 662.8021 - val_loss: 2204.7644\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 776.42474\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 599.7919 - val_loss: 1835.0327\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 776.42474\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 933us/step - loss: 623.0606 - val_loss: 2403.1062\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 776.42474\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 966us/step - loss: 587.8765 - val_loss: 2460.1213\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 776.42474\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 957us/step - loss: 602.9412 - val_loss: 1363.4348\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 776.42474\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 974us/step - loss: 566.6434 - val_loss: 1371.7594\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 776.42474\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 977us/step - loss: 635.7144 - val_loss: 1207.9465\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 776.42474\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 977us/step - loss: 589.5193 - val_loss: 809.6935\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 776.42474\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 979us/step - loss: 558.6693 - val_loss: 1595.5719\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 776.42474\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 585.0587 - val_loss: 879.9685\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 776.42474\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 603.6083 - val_loss: 1463.6698\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 776.42474\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 518.7079 - val_loss: 2065.3704\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 776.42474\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 578.2613 - val_loss: 1599.0189\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 776.42474\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 916us/step - loss: 559.0248 - val_loss: 1516.8834\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 776.42474\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 983us/step - loss: 537.6618 - val_loss: 1203.7754\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 776.42474\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 515.9998 - val_loss: 1559.5837\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 776.42474\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 994us/step - loss: 554.9289 - val_loss: 1688.7349\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 776.42474\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 526.9895 - val_loss: 1403.2653\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 776.42474\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 924us/step - loss: 511.9562 - val_loss: 887.8876\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 776.42474\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 961us/step - loss: 526.2018 - val_loss: 2438.4893\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 776.42474\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 989us/step - loss: 514.9617 - val_loss: 2642.2627\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 776.42474\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 519.6309 - val_loss: 911.3819\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 776.42474\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 497.8584 - val_loss: 1438.8431\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 776.42474\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 968us/step - loss: 530.2121 - val_loss: 1163.3032\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 776.42474\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 507.4452 - val_loss: 1236.5433\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 776.42474\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 546.1029 - val_loss: 1133.7625\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 776.42474\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 983us/step - loss: 490.4400 - val_loss: 1529.0496\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 776.42474\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 483.4417 - val_loss: 1189.2343\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 776.42474\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 946us/step - loss: 494.7594 - val_loss: 1883.8325\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 776.42474\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 547.2888 - val_loss: 1635.6963\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 776.42474\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 994us/step - loss: 456.2349 - val_loss: 1529.4921\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 776.42474\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 475.7844 - val_loss: 805.7211\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 776.42474\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 924us/step - loss: 468.3511 - val_loss: 1083.9214\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 776.42474\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 992us/step - loss: 471.3023 - val_loss: 955.1663\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 776.42474\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 968us/step - loss: 432.2876 - val_loss: 2230.8948\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 776.42474\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 970us/step - loss: 423.4770 - val_loss: 1021.8873\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 776.42474\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 459.1931 - val_loss: 988.7106\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 776.42474\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 934us/step - loss: 422.7106 - val_loss: 1319.4027\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 776.42474\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 424.8790 - val_loss: 1451.2102\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 776.42474\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 411.7220 - val_loss: 1700.9800\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 776.42474\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 916us/step - loss: 406.4154 - val_loss: 1008.1677\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 776.42474\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 953us/step - loss: 397.2202 - val_loss: 1422.0500\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 776.42474\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 974us/step - loss: 418.8417 - val_loss: 2088.9487\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 776.42474\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 407.7027 - val_loss: 1690.7711\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 776.42474\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 982us/step - loss: 407.6791 - val_loss: 1914.9220\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 776.42474\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 422.7712 - val_loss: 1920.3666\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 776.42474\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 917us/step - loss: 417.4637 - val_loss: 1936.1971\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 776.42474\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 994us/step - loss: 392.0127 - val_loss: 1539.5671\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 776.42474\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 978us/step - loss: 381.3473 - val_loss: 1005.9570\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 776.42474\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 932us/step - loss: 407.8660 - val_loss: 905.9908\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 776.42474\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 966us/step - loss: 393.3283 - val_loss: 1210.5897\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 776.42474\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 986us/step - loss: 410.2754 - val_loss: 869.4106\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 776.42474\n",
      "Epoch 77/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 396.4676 - val_loss: 1194.1952\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 776.42474\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 384.8398 - val_loss: 1356.4081\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 776.42474\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 938us/step - loss: 372.3489 - val_loss: 927.8260\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 776.42474\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 975us/step - loss: 379.5953 - val_loss: 1301.8184\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 776.42474\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 973us/step - loss: 401.2117 - val_loss: 1492.7677\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 776.42474\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 976us/step - loss: 376.1090 - val_loss: 1565.3790\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 776.42474\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 382.0846 - val_loss: 1603.9397\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 776.42474\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 364.0712 - val_loss: 1005.2472\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 776.42474\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 972us/step - loss: 372.8464 - val_loss: 1394.9989\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 776.42474\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 373.3999 - val_loss: 1092.9897\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 776.42474\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 941us/step - loss: 393.5316 - val_loss: 917.9618\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 776.42474\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 994us/step - loss: 371.3736 - val_loss: 1357.3152\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 776.42474\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 995us/step - loss: 362.1526 - val_loss: 1773.1909\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 776.42474\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 980us/step - loss: 386.3012 - val_loss: 1246.3550\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 776.42474\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 381.7010 - val_loss: 850.4596\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 776.42474\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 372.9149 - val_loss: 1539.1117\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 776.42474\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 957us/step - loss: 364.4410 - val_loss: 1017.3480\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 776.42474\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 366.1842 - val_loss: 1347.7830\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 776.42474\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 359.2910 - val_loss: 1268.4133\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 776.42474\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 372.8448 - val_loss: 1091.4454\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 776.42474\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 377.0345 - val_loss: 1390.0980\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 776.42474\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 361.1865 - val_loss: 1017.0961\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 776.42474\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 359.8347 - val_loss: 1152.2881\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 776.42474\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 374.0584 - val_loss: 1634.7830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00100: val_loss did not improve from 776.42474\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 357.9536 - val_loss: 1912.9331\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 776.42474\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 372.9454 - val_loss: 1267.2955\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 776.42474\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 368.6391 - val_loss: 1545.9219\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 776.42474\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 360.4655 - val_loss: 1277.0281\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 776.42474\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 350.5508 - val_loss: 1220.8723\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 776.42474\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 360.1565 - val_loss: 1373.0861\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 776.42474\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 368.0466 - val_loss: 1531.8046\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 776.42474\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 355.9544 - val_loss: 1010.9818\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 776.42474\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 360.3242 - val_loss: 1358.9899\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 776.42474\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 346.4462 - val_loss: 1082.6898\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 776.42474\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 353.5123 - val_loss: 1905.7725\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 776.42474\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 370.4718 - val_loss: 1424.9961\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 776.42474\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 359.9403 - val_loss: 1705.4100\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 776.42474\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 356.9694 - val_loss: 1324.6914\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 776.42474\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 350.4074 - val_loss: 1137.4215\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 776.42474\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 331.3739 - val_loss: 1383.0381\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 776.42474\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 353.9268 - val_loss: 1554.9597\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 776.42474\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 354.9308 - val_loss: 1689.1182\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 776.42474\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 347.4106 - val_loss: 1509.1708\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 776.42474\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 351.6130 - val_loss: 1749.0955\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 776.42474\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 351.7918 - val_loss: 2195.6855\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 776.42474\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 356.5204 - val_loss: 1029.4443\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 776.42474\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 342.2865 - val_loss: 1269.4521\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 776.42474\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 351.2830 - val_loss: 1350.5894\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 776.42474\n",
      "Epoch 1/10000\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 1345.7479 - val_loss: 1412.7030\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1412.70300, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 830.5951 - val_loss: 2346.6421\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1412.70300\n",
      "Epoch 3/10000\n",
      "89/89 [==============================] - 0s 985us/step - loss: 799.2862 - val_loss: 2353.6240\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1412.70300\n",
      "Epoch 4/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 764.3450 - val_loss: 2327.7649\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1412.70300\n",
      "Epoch 5/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 784.9882 - val_loss: 1263.5491\n",
      "\n",
      "Epoch 00005: val_loss improved from 1412.70300 to 1263.54907, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 6/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 864.9802 - val_loss: 873.9683\n",
      "\n",
      "Epoch 00006: val_loss improved from 1263.54907 to 873.96826, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "89/89 [==============================] - 0s 994us/step - loss: 816.6104 - val_loss: 2255.5906\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 873.96826\n",
      "Epoch 8/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 836.5150 - val_loss: 1897.8806\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 873.96826\n",
      "Epoch 9/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 860.2884 - val_loss: 2309.0156\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 873.96826\n",
      "Epoch 10/10000\n",
      "89/89 [==============================] - 0s 982us/step - loss: 783.3893 - val_loss: 2894.6208\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 873.96826\n",
      "Epoch 11/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 784.1310 - val_loss: 892.8491\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 873.96826\n",
      "Epoch 12/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 751.8326 - val_loss: 1138.0416\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 873.96826\n",
      "Epoch 13/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 834.8884 - val_loss: 1411.5216\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 873.96826\n",
      "Epoch 14/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 874.7682 - val_loss: 2902.4807\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 873.96826\n",
      "Epoch 15/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 763.2580 - val_loss: 1966.3970\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 873.96826\n",
      "Epoch 16/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 715.8256 - val_loss: 1221.8597\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 873.96826\n",
      "Epoch 17/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 776.4144 - val_loss: 1963.9829\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 873.96826\n",
      "Epoch 18/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 718.8787 - val_loss: 2890.6172\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 873.96826\n",
      "Epoch 19/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 681.5922 - val_loss: 3002.8752\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 873.96826\n",
      "Epoch 20/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 661.8599 - val_loss: 2266.4653\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 873.96826\n",
      "Epoch 21/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 692.4075 - val_loss: 808.5209\n",
      "\n",
      "Epoch 00021: val_loss improved from 873.96826 to 808.52094, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 22/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 708.1781 - val_loss: 1163.7473\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 808.52094\n",
      "Epoch 23/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 679.5942 - val_loss: 1066.6241\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 808.52094\n",
      "Epoch 24/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 636.8730 - val_loss: 1255.1047\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 808.52094\n",
      "Epoch 25/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 571.4741 - val_loss: 2239.3279\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 808.52094\n",
      "Epoch 26/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 637.2156 - val_loss: 1260.1193\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 808.52094\n",
      "Epoch 27/10000\n",
      "89/89 [==============================] - 0s 998us/step - loss: 583.1310 - val_loss: 2592.7754\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 808.52094\n",
      "Epoch 28/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 640.3506 - val_loss: 2301.3020\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 808.52094\n",
      "Epoch 29/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 586.3506 - val_loss: 1464.5486\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 808.52094\n",
      "Epoch 30/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 603.9623 - val_loss: 2415.1204\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 808.52094\n",
      "Epoch 31/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 540.3328 - val_loss: 853.5581\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 808.52094\n",
      "Epoch 32/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 579.2252 - val_loss: 920.8552\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 808.52094\n",
      "Epoch 33/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 618.4081 - val_loss: 1916.0420\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 808.52094\n",
      "Epoch 34/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 594.4622 - val_loss: 1740.5676\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 808.52094\n",
      "Epoch 35/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 586.3596 - val_loss: 2167.5745\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 808.52094\n",
      "Epoch 36/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 523.0878 - val_loss: 1587.2979\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 808.52094\n",
      "Epoch 37/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 604.9202 - val_loss: 1333.4509\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 808.52094\n",
      "Epoch 38/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 581.8544 - val_loss: 1932.7124\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 808.52094\n",
      "Epoch 39/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 553.8412 - val_loss: 1289.1312\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 808.52094\n",
      "Epoch 40/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 578.8470 - val_loss: 2597.5293\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 808.52094\n",
      "Epoch 41/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 561.2556 - val_loss: 1778.6724\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 808.52094\n",
      "Epoch 42/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 537.4368 - val_loss: 2019.6385\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 808.52094\n",
      "Epoch 43/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 532.5244 - val_loss: 1767.8097\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 808.52094\n",
      "Epoch 44/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 525.2012 - val_loss: 1491.6449\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 808.52094\n",
      "Epoch 45/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 514.0230 - val_loss: 1399.9888\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 808.52094\n",
      "Epoch 46/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 532.8549 - val_loss: 2311.8884\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 808.52094\n",
      "Epoch 47/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 523.9306 - val_loss: 1794.2920\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 808.52094\n",
      "Epoch 48/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 533.4362 - val_loss: 1104.8165\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 808.52094\n",
      "Epoch 49/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 557.7889 - val_loss: 2583.1909\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 808.52094\n",
      "Epoch 50/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 521.1871 - val_loss: 2223.3171\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 808.52094\n",
      "Epoch 51/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 515.3571 - val_loss: 805.5457\n",
      "\n",
      "Epoch 00051: val_loss improved from 808.52094 to 805.54572, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 52/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 486.3963 - val_loss: 1715.0045\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 805.54572\n",
      "Epoch 53/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 496.4779 - val_loss: 1678.4056\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 805.54572\n",
      "Epoch 54/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 478.4138 - val_loss: 2186.0015\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 805.54572\n",
      "Epoch 55/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 476.4005 - val_loss: 1780.9966\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 805.54572\n",
      "Epoch 56/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 513.7590 - val_loss: 1345.2078\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 805.54572\n",
      "Epoch 57/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 504.3607 - val_loss: 2373.5996\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 805.54572\n",
      "Epoch 58/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 468.4821 - val_loss: 1020.2548\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 805.54572\n",
      "Epoch 59/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 467.1921 - val_loss: 2452.2637\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 805.54572\n",
      "Epoch 60/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 445.3573 - val_loss: 2073.1641\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 805.54572\n",
      "Epoch 61/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 452.9338 - val_loss: 1900.1205\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 805.54572\n",
      "Epoch 62/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 435.3370 - val_loss: 2142.4355\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 805.54572\n",
      "Epoch 63/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 432.2400 - val_loss: 2059.4373\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 805.54572\n",
      "Epoch 64/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 429.0253 - val_loss: 2045.1204\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 805.54572\n",
      "Epoch 65/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 426.2844 - val_loss: 1370.6860\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 805.54572\n",
      "Epoch 66/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 409.7918 - val_loss: 1162.4841\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 805.54572\n",
      "Epoch 67/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 425.9253 - val_loss: 1132.7329\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 805.54572\n",
      "Epoch 68/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 396.3394 - val_loss: 1680.7081\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 805.54572\n",
      "Epoch 69/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 428.6482 - val_loss: 1593.9937\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 805.54572\n",
      "Epoch 70/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 409.3084 - val_loss: 897.3427\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 805.54572\n",
      "Epoch 71/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 402.6484 - val_loss: 861.4995\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 805.54572\n",
      "Epoch 72/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 451.4973 - val_loss: 2031.1653\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 805.54572\n",
      "Epoch 73/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 457.2715 - val_loss: 1997.8345\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 805.54572\n",
      "Epoch 74/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 455.3375 - val_loss: 2029.8269\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 805.54572\n",
      "Epoch 75/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 435.9416 - val_loss: 2020.9492\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 805.54572\n",
      "Epoch 76/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 446.1947 - val_loss: 1962.8531\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 805.54572\n",
      "Epoch 77/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 437.8458 - val_loss: 2043.6539\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 805.54572\n",
      "Epoch 78/10000\n",
      "89/89 [==============================] - 0s 997us/step - loss: 439.7750 - val_loss: 1961.0167\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 805.54572\n",
      "Epoch 79/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 440.0208 - val_loss: 2026.5797\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 805.54572\n",
      "Epoch 80/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 432.5560 - val_loss: 2021.1211\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 805.54572\n",
      "Epoch 81/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 436.2066 - val_loss: 1990.7173\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 805.54572\n",
      "Epoch 82/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 419.3656 - val_loss: 2020.5525\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 805.54572\n",
      "Epoch 83/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 431.5381 - val_loss: 1998.1724\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 805.54572\n",
      "Epoch 84/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 434.3459 - val_loss: 1834.2159\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 805.54572\n",
      "Epoch 85/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 442.2935 - val_loss: 2035.4482\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 805.54572\n",
      "Epoch 86/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 429.4479 - val_loss: 2067.8806\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 805.54572\n",
      "Epoch 87/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 442.7100 - val_loss: 1994.3278\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 805.54572\n",
      "Epoch 88/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 422.4830 - val_loss: 2019.8896\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 805.54572\n",
      "Epoch 89/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 418.9908 - val_loss: 1995.0859\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 805.54572\n",
      "Epoch 90/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 422.4352 - val_loss: 2076.5823\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 805.54572\n",
      "Epoch 91/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 433.5124 - val_loss: 2078.0757\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 805.54572\n",
      "Epoch 92/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 438.7655 - val_loss: 1907.6395\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 805.54572\n",
      "Epoch 93/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 422.8414 - val_loss: 2025.4066\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 805.54572\n",
      "Epoch 94/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 431.1404 - val_loss: 1828.7716\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 805.54572\n",
      "Epoch 95/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 421.6877 - val_loss: 1969.8560\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 805.54572\n",
      "Epoch 96/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 422.7188 - val_loss: 1557.0565\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 805.54572\n",
      "Epoch 97/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 419.4699 - val_loss: 2019.1882\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 805.54572\n",
      "Epoch 98/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 432.5453 - val_loss: 1758.0687\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 805.54572\n",
      "Epoch 99/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 423.5667 - val_loss: 1992.7720\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 805.54572\n",
      "Epoch 100/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 427.3090 - val_loss: 1888.0531\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 805.54572\n",
      "Epoch 101/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 401.1552 - val_loss: 1903.2788\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 805.54572\n",
      "Epoch 102/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 408.9705 - val_loss: 1693.0547\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 805.54572\n",
      "Epoch 103/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 410.7897 - val_loss: 1256.3411\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 805.54572\n",
      "Epoch 104/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 417.8761 - val_loss: 1344.7161\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 805.54572\n",
      "Epoch 105/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 398.9070 - val_loss: 1493.2505\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 805.54572\n",
      "Epoch 106/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 394.4293 - val_loss: 1034.2426\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 805.54572\n",
      "Epoch 107/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 393.7304 - val_loss: 1594.0702\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 805.54572\n",
      "Epoch 108/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 420.6753 - val_loss: 1611.5201\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 805.54572\n",
      "Epoch 109/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 389.0368 - val_loss: 2171.3679\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 805.54572\n",
      "Epoch 110/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 406.6240 - val_loss: 1687.5397\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 805.54572\n",
      "Epoch 111/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 401.4109 - val_loss: 1945.1000\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 805.54572\n",
      "Epoch 112/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 387.5679 - val_loss: 1997.7053\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 805.54572\n",
      "Epoch 113/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 396.6908 - val_loss: 2063.2451\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 805.54572\n",
      "Epoch 114/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 400.2180 - val_loss: 1704.1406\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 805.54572\n",
      "Epoch 115/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 398.6849 - val_loss: 1419.6743\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 805.54572\n",
      "Epoch 116/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 401.0503 - val_loss: 1220.2399\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 805.54572\n",
      "Epoch 117/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 375.7422 - val_loss: 1639.1718\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 805.54572\n",
      "Epoch 118/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 375.8611 - val_loss: 2050.1091\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 805.54572\n",
      "Epoch 119/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 379.9252 - val_loss: 1719.5658\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 805.54572\n",
      "Epoch 120/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 386.5684 - val_loss: 1392.3573\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 805.54572\n",
      "Epoch 121/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 393.4097 - val_loss: 866.0352\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 805.54572\n",
      "Epoch 122/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 411.8664 - val_loss: 1499.7208\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 805.54572\n",
      "Epoch 123/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 402.5127 - val_loss: 2140.4441\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 805.54572\n",
      "Epoch 124/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 404.8825 - val_loss: 2042.5847\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 805.54572\n",
      "Epoch 125/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 398.5281 - val_loss: 1967.8636\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 805.54572\n",
      "Epoch 126/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 381.9172 - val_loss: 1469.2582\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 805.54572\n",
      "Epoch 127/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 402.9899 - val_loss: 1885.4393\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 805.54572\n",
      "Epoch 128/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 377.7461 - val_loss: 1856.4113\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 805.54572\n",
      "Epoch 129/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 393.0437 - val_loss: 1824.0127\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 805.54572\n",
      "Epoch 130/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 372.1624 - val_loss: 1215.4156\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 805.54572\n",
      "Epoch 131/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 384.8257 - val_loss: 1908.2072\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 805.54572\n",
      "Epoch 132/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 373.9243 - val_loss: 848.9380\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 805.54572\n",
      "Epoch 133/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 380.9992 - val_loss: 1535.5372\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 805.54572\n",
      "Epoch 134/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 375.3134 - val_loss: 1975.0039\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 805.54572\n",
      "Epoch 135/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 388.5550 - val_loss: 1851.1841\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 805.54572\n",
      "Epoch 136/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 387.1698 - val_loss: 1861.1273\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 805.54572\n",
      "Epoch 137/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 376.8316 - val_loss: 1915.7629\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 805.54572\n",
      "Epoch 138/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 380.3150 - val_loss: 1873.4709\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 805.54572\n",
      "Epoch 139/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 367.3049 - val_loss: 1129.3113\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 805.54572\n",
      "Epoch 140/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 376.5416 - val_loss: 2035.2551\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 805.54572\n",
      "Epoch 141/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 380.7762 - val_loss: 2055.8843\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 805.54572\n",
      "Epoch 142/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 370.0810 - val_loss: 1858.4976\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 805.54572\n",
      "Epoch 143/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 381.5451 - val_loss: 943.8163\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 805.54572\n",
      "Epoch 144/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 375.3438 - val_loss: 1371.3958\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 805.54572\n",
      "Epoch 145/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 376.4866 - val_loss: 1580.8682\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 805.54572\n",
      "Epoch 146/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 369.7251 - val_loss: 2077.6743\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 805.54572\n",
      "Epoch 147/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 368.7000 - val_loss: 981.0543\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 805.54572\n",
      "Epoch 148/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 371.1631 - val_loss: 1682.9900\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 805.54572\n",
      "Epoch 149/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 358.7069 - val_loss: 1978.5431\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 805.54572\n",
      "Epoch 150/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 380.3509 - val_loss: 1486.2625\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 805.54572\n",
      "Epoch 151/10000\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 364.2332 - val_loss: 1321.6022\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 805.54572\n",
      "Epoch 1/10000\n",
      "88/88 [==============================] - 1s 3ms/step - loss: 1233.8400 - val_loss: 3053.6748\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3053.67480, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 832.4075 - val_loss: 1343.5409\n",
      "\n",
      "Epoch 00002: val_loss improved from 3053.67480 to 1343.54089, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "88/88 [==============================] - 0s 994us/step - loss: 776.9396 - val_loss: 2407.3501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1343.54089\n",
      "Epoch 4/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 753.8816 - val_loss: 2550.4038\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1343.54089\n",
      "Epoch 5/10000\n",
      "88/88 [==============================] - 0s 980us/step - loss: 809.9150 - val_loss: 868.4217\n",
      "\n",
      "Epoch 00005: val_loss improved from 1343.54089 to 868.42169, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 6/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 803.0805 - val_loss: 824.4002\n",
      "\n",
      "Epoch 00006: val_loss improved from 868.42169 to 824.40021, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 7/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 859.8548 - val_loss: 1404.5884\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 824.40021\n",
      "Epoch 8/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 740.1107 - val_loss: 862.4911\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 824.40021\n",
      "Epoch 9/10000\n",
      "88/88 [==============================] - 0s 974us/step - loss: 835.6693 - val_loss: 1878.1740\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 824.40021\n",
      "Epoch 10/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 780.4776 - val_loss: 3028.6660\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 824.40021\n",
      "Epoch 11/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 828.8312 - val_loss: 2679.2554\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 824.40021\n",
      "Epoch 12/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 778.0029 - val_loss: 1424.5962\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 824.40021\n",
      "Epoch 13/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 761.4026 - val_loss: 1612.9302\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 824.40021\n",
      "Epoch 14/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 789.5109 - val_loss: 2256.7949\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 824.40021\n",
      "Epoch 15/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 765.8431 - val_loss: 2990.3066\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 824.40021\n",
      "Epoch 16/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 743.3747 - val_loss: 2486.2585\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 824.40021\n",
      "Epoch 17/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 706.4755 - val_loss: 1188.6750\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 824.40021\n",
      "Epoch 18/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 698.0845 - val_loss: 1206.6915\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 824.40021\n",
      "Epoch 19/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 676.5046 - val_loss: 1740.3689\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 824.40021\n",
      "Epoch 20/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 683.7968 - val_loss: 2243.5107\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 824.40021\n",
      "Epoch 21/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 654.9651 - val_loss: 1821.6729\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 824.40021\n",
      "Epoch 22/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 641.4789 - val_loss: 1088.8489\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 824.40021\n",
      "Epoch 23/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 648.3937 - val_loss: 1767.1698\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 824.40021\n",
      "Epoch 24/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 634.4409 - val_loss: 2076.6587\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 824.40021\n",
      "Epoch 25/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 567.8209 - val_loss: 2184.8225\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 824.40021\n",
      "Epoch 26/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 617.1869 - val_loss: 2111.9365\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 824.40021\n",
      "Epoch 27/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 583.5515 - val_loss: 762.1804\n",
      "\n",
      "Epoch 00027: val_loss improved from 824.40021 to 762.18042, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 28/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 566.6378 - val_loss: 2203.6169\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 762.18042\n",
      "Epoch 29/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 591.2155 - val_loss: 1502.3397\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 762.18042\n",
      "Epoch 30/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 560.6750 - val_loss: 1877.2161\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 762.18042\n",
      "Epoch 31/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 527.7057 - val_loss: 1730.8796\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 762.18042\n",
      "Epoch 32/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 549.1362 - val_loss: 2513.3252\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 762.18042\n",
      "Epoch 33/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 583.9117 - val_loss: 913.6044\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 762.18042\n",
      "Epoch 34/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 551.6896 - val_loss: 2382.2793\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 762.18042\n",
      "Epoch 35/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 548.3435 - val_loss: 993.0881\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 762.18042\n",
      "Epoch 36/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 580.7920 - val_loss: 2107.3491\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 762.18042\n",
      "Epoch 37/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 551.0280 - val_loss: 2294.1677\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 762.18042\n",
      "Epoch 38/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 555.6815 - val_loss: 2382.3389\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 762.18042\n",
      "Epoch 39/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 571.7833 - val_loss: 1459.6019\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 762.18042\n",
      "Epoch 40/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 557.6710 - val_loss: 1295.4644\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 762.18042\n",
      "Epoch 41/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 549.5361 - val_loss: 1718.5781\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 762.18042\n",
      "Epoch 42/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 516.3013 - val_loss: 2409.2214\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 762.18042\n",
      "Epoch 43/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 579.9792 - val_loss: 2373.3564\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 762.18042\n",
      "Epoch 44/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 560.7474 - val_loss: 1388.6509\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 762.18042\n",
      "Epoch 45/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 559.6553 - val_loss: 2621.8474\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 762.18042\n",
      "Epoch 46/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 566.5044 - val_loss: 1169.0654\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 762.18042\n",
      "Epoch 47/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 506.8841 - val_loss: 1613.0061\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 762.18042\n",
      "Epoch 48/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 512.2865 - val_loss: 1040.0078\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 762.18042\n",
      "Epoch 49/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 526.9868 - val_loss: 1611.0613\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 762.18042\n",
      "Epoch 50/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 535.2914 - val_loss: 1301.4929\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 762.18042\n",
      "Epoch 51/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 549.3754 - val_loss: 1464.9432\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 762.18042\n",
      "Epoch 52/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 524.3831 - val_loss: 1324.1031\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 762.18042\n",
      "Epoch 53/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 536.2488 - val_loss: 1409.9181\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 762.18042\n",
      "Epoch 54/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 542.0192 - val_loss: 1324.6385\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 762.18042\n",
      "Epoch 55/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 507.4985 - val_loss: 890.9692\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 762.18042\n",
      "Epoch 56/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 519.3854 - val_loss: 1773.0956\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 762.18042\n",
      "Epoch 57/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 523.3377 - val_loss: 1935.4042\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 762.18042\n",
      "Epoch 58/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 509.5159 - val_loss: 947.0801\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 762.18042\n",
      "Epoch 59/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 514.7087 - val_loss: 2002.9208\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 762.18042\n",
      "Epoch 60/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 513.7067 - val_loss: 1111.4579\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 762.18042\n",
      "Epoch 61/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 531.5948 - val_loss: 1110.1115\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 762.18042\n",
      "Epoch 62/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 518.9542 - val_loss: 1162.3629\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 762.18042\n",
      "Epoch 63/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 507.6890 - val_loss: 1641.3398\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 762.18042\n",
      "Epoch 64/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 501.5797 - val_loss: 1514.5420\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 762.18042\n",
      "Epoch 65/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 507.0294 - val_loss: 2115.1287\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 762.18042\n",
      "Epoch 66/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 483.8314 - val_loss: 895.0096\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 762.18042\n",
      "Epoch 67/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 477.9317 - val_loss: 2285.5005\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 762.18042\n",
      "Epoch 68/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 479.2838 - val_loss: 1557.7753\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 762.18042\n",
      "Epoch 69/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 497.4911 - val_loss: 1776.0184\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 762.18042\n",
      "Epoch 70/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 502.7651 - val_loss: 1469.2798\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 762.18042\n",
      "Epoch 71/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 486.2769 - val_loss: 1207.5128\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 762.18042\n",
      "Epoch 72/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 475.0945 - val_loss: 2156.7549\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 762.18042\n",
      "Epoch 73/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 484.5416 - val_loss: 1149.6204\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 762.18042\n",
      "Epoch 74/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 487.7611 - val_loss: 1352.3726\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 762.18042\n",
      "Epoch 75/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 475.0526 - val_loss: 1302.5983\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 762.18042\n",
      "Epoch 76/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 462.0357 - val_loss: 2126.2229\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 762.18042\n",
      "Epoch 77/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 455.0958 - val_loss: 1890.7406\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 762.18042\n",
      "Epoch 78/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 1ms/step - loss: 464.6902 - val_loss: 2154.7000\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 762.18042\n",
      "Epoch 79/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 491.6216 - val_loss: 2330.0271\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 762.18042\n",
      "Epoch 80/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 474.8473 - val_loss: 2194.8093\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 762.18042\n",
      "Epoch 81/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 447.0740 - val_loss: 900.3170\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 762.18042\n",
      "Epoch 82/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 446.2884 - val_loss: 1922.4335\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 762.18042\n",
      "Epoch 83/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 434.7570 - val_loss: 1862.4775\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 762.18042\n",
      "Epoch 84/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 438.8928 - val_loss: 1985.8497\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 762.18042\n",
      "Epoch 85/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 423.8505 - val_loss: 1660.4890\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 762.18042\n",
      "Epoch 86/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 431.1270 - val_loss: 1078.3014\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 762.18042\n",
      "Epoch 87/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 427.2080 - val_loss: 1325.7484\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 762.18042\n",
      "Epoch 88/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 437.6274 - val_loss: 1837.6410\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 762.18042\n",
      "Epoch 89/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 441.1690 - val_loss: 2071.3457\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 762.18042\n",
      "Epoch 90/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 431.8902 - val_loss: 1752.4962\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 762.18042\n",
      "Epoch 91/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 415.1651 - val_loss: 2125.8875\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 762.18042\n",
      "Epoch 92/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 425.8494 - val_loss: 1622.1882\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 762.18042\n",
      "Epoch 93/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 410.7570 - val_loss: 1822.9468\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 762.18042\n",
      "Epoch 94/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 413.8813 - val_loss: 1386.6631\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 762.18042\n",
      "Epoch 95/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 413.7980 - val_loss: 1738.3260\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 762.18042\n",
      "Epoch 96/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 429.1747 - val_loss: 1768.2947\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 762.18042\n",
      "Epoch 97/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 414.6845 - val_loss: 1570.0748\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 762.18042\n",
      "Epoch 98/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 402.4572 - val_loss: 2177.6426\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 762.18042\n",
      "Epoch 99/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 416.4046 - val_loss: 2174.1104\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 762.18042\n",
      "Epoch 100/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 437.2234 - val_loss: 2004.1108\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 762.18042\n",
      "Epoch 101/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 437.4843 - val_loss: 1977.4335\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 762.18042\n",
      "Epoch 102/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 425.4483 - val_loss: 1193.0015\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 762.18042\n",
      "Epoch 103/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 423.1494 - val_loss: 2062.0032\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 762.18042\n",
      "Epoch 104/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 407.6201 - val_loss: 1930.4117\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 762.18042\n",
      "Epoch 105/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 388.4991 - val_loss: 2063.2815\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 762.18042\n",
      "Epoch 106/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 403.7599 - val_loss: 1999.6542\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 762.18042\n",
      "Epoch 107/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 395.5087 - val_loss: 1883.1245\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 762.18042\n",
      "Epoch 108/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 403.5765 - val_loss: 1940.0815\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 762.18042\n",
      "Epoch 109/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 399.5377 - val_loss: 1966.8489\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 762.18042\n",
      "Epoch 110/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 403.8133 - val_loss: 978.4863\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 762.18042\n",
      "Epoch 111/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 400.1075 - val_loss: 851.7866\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 762.18042\n",
      "Epoch 112/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 382.5233 - val_loss: 1896.5809\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 762.18042\n",
      "Epoch 113/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 388.9508 - val_loss: 1956.8910\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 762.18042\n",
      "Epoch 114/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 398.3795 - val_loss: 1234.4847\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 762.18042\n",
      "Epoch 115/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 387.5807 - val_loss: 1405.3590\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 762.18042\n",
      "Epoch 116/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 395.0119 - val_loss: 1487.6189\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 762.18042\n",
      "Epoch 117/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 397.9474 - val_loss: 1914.5341\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 762.18042\n",
      "Epoch 118/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 397.5538 - val_loss: 1840.2935\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 762.18042\n",
      "Epoch 119/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 395.7668 - val_loss: 1928.0587\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 762.18042\n",
      "Epoch 120/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 394.6682 - val_loss: 1594.5592\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 762.18042\n",
      "Epoch 121/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 394.4404 - val_loss: 1501.8850\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 762.18042\n",
      "Epoch 122/10000\n",
      "88/88 [==============================] - ETA: 0s - loss: 398.504 - 0s 1ms/step - loss: 388.2731 - val_loss: 1687.5593\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 762.18042\n",
      "Epoch 123/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 396.6660 - val_loss: 1346.0035\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 762.18042\n",
      "Epoch 124/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 389.3825 - val_loss: 1851.0586\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 762.18042\n",
      "Epoch 125/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 394.3737 - val_loss: 1045.3654\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 762.18042\n",
      "Epoch 126/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 397.2580 - val_loss: 1480.0984\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 762.18042\n",
      "Epoch 127/10000\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 381.7471 - val_loss: 1835.1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▏       | 19/21 [34:00<02:58, 89.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00127: val_loss did not improve from 762.18042\n",
      "Epoch 1/10000\n",
      "86/86 [==============================] - 1s 2ms/step - loss: 3135.7917 - val_loss: 2341.7756\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2341.77563, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 2201.6030 - val_loss: 3698.1050\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2341.77563\n",
      "Epoch 3/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 2428.1523 - val_loss: 2046.2278\n",
      "\n",
      "Epoch 00003: val_loss improved from 2341.77563 to 2046.22778, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "86/86 [==============================] - 0s 980us/step - loss: 2200.9734 - val_loss: 3670.2971\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2046.22778\n",
      "Epoch 5/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 2355.6553 - val_loss: 3399.6963\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2046.22778\n",
      "Epoch 6/10000\n",
      "86/86 [==============================] - 0s 997us/step - loss: 2338.0193 - val_loss: 3576.2659\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2046.22778\n",
      "Epoch 7/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 2311.9646 - val_loss: 2704.9822\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2046.22778\n",
      "Epoch 8/10000\n",
      "86/86 [==============================] - 0s 975us/step - loss: 2219.6919 - val_loss: 2191.4172\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2046.22778\n",
      "Epoch 9/10000\n",
      "86/86 [==============================] - 0s 984us/step - loss: 2240.6970 - val_loss: 3672.2419\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2046.22778\n",
      "Epoch 10/10000\n",
      "86/86 [==============================] - 0s 976us/step - loss: 2399.3491 - val_loss: 2579.4529\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2046.22778\n",
      "Epoch 11/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 2407.8684 - val_loss: 2766.4858\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2046.22778\n",
      "Epoch 12/10000\n",
      "86/86 [==============================] - 0s 941us/step - loss: 2422.1709 - val_loss: 1158.3226\n",
      "\n",
      "Epoch 00012: val_loss improved from 2046.22778 to 1158.32263, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 13/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 2085.3052 - val_loss: 2837.7207\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1158.32263\n",
      "Epoch 14/10000\n",
      "86/86 [==============================] - 0s 966us/step - loss: 2061.8293 - val_loss: 507.8074\n",
      "\n",
      "Epoch 00014: val_loss improved from 1158.32263 to 507.80743, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 15/10000\n",
      "86/86 [==============================] - 0s 995us/step - loss: 2189.0935 - val_loss: 3689.5735\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 507.80743\n",
      "Epoch 16/10000\n",
      "86/86 [==============================] - 0s 992us/step - loss: 2073.4365 - val_loss: 2586.7180\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 507.80743\n",
      "Epoch 17/10000\n",
      "86/86 [==============================] - 0s 987us/step - loss: 1809.8051 - val_loss: 1030.5847\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 507.80743\n",
      "Epoch 18/10000\n",
      "86/86 [==============================] - 0s 987us/step - loss: 2143.4363 - val_loss: 2110.9517\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 507.80743\n",
      "Epoch 19/10000\n",
      "86/86 [==============================] - 0s 919us/step - loss: 2016.4218 - val_loss: 3386.3091\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 507.80743\n",
      "Epoch 20/10000\n",
      "86/86 [==============================] - 0s 954us/step - loss: 1946.8616 - val_loss: 2855.5356\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 507.80743\n",
      "Epoch 21/10000\n",
      "86/86 [==============================] - 0s 969us/step - loss: 2001.9553 - val_loss: 2869.5752\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 507.80743\n",
      "Epoch 22/10000\n",
      "86/86 [==============================] - 0s 965us/step - loss: 1818.1244 - val_loss: 1085.7280\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 507.80743\n",
      "Epoch 23/10000\n",
      "86/86 [==============================] - 0s 974us/step - loss: 1942.4347 - val_loss: 3075.1919\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 507.80743\n",
      "Epoch 24/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1947.4556 - val_loss: 1897.6104\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 507.80743\n",
      "Epoch 25/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1937.5455 - val_loss: 720.7659\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 507.80743\n",
      "Epoch 26/10000\n",
      "86/86 [==============================] - 0s 925us/step - loss: 1891.7947 - val_loss: 2689.2759\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 507.80743\n",
      "Epoch 27/10000\n",
      "86/86 [==============================] - 0s 978us/step - loss: 1946.2552 - val_loss: 585.1807\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 507.80743\n",
      "Epoch 28/10000\n",
      "86/86 [==============================] - 0s 992us/step - loss: 1808.7917 - val_loss: 2312.4434\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 507.80743\n",
      "Epoch 29/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1932.4147 - val_loss: 2181.6248\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 507.80743\n",
      "Epoch 30/10000\n",
      "86/86 [==============================] - 0s 930us/step - loss: 1665.0104 - val_loss: 2610.7051\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 507.80743\n",
      "Epoch 31/10000\n",
      "86/86 [==============================] - 0s 953us/step - loss: 1638.1669 - val_loss: 963.5673\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 507.80743\n",
      "Epoch 32/10000\n",
      "86/86 [==============================] - 0s 956us/step - loss: 1738.1029 - val_loss: 2409.1162\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 507.80743\n",
      "Epoch 33/10000\n",
      "86/86 [==============================] - 0s 958us/step - loss: 1714.2460 - val_loss: 1473.3525\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 507.80743\n",
      "Epoch 34/10000\n",
      "86/86 [==============================] - 0s 970us/step - loss: 1643.5322 - val_loss: 621.1439\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 507.80743\n",
      "Epoch 35/10000\n",
      "86/86 [==============================] - 0s 951us/step - loss: 1586.9253 - val_loss: 1574.0967\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 507.80743\n",
      "Epoch 36/10000\n",
      "86/86 [==============================] - 0s 969us/step - loss: 1612.0325 - val_loss: 3136.3171\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 507.80743\n",
      "Epoch 37/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1504.7094 - val_loss: 2040.8477\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 507.80743\n",
      "Epoch 38/10000\n",
      "86/86 [==============================] - 0s 921us/step - loss: 1657.7046 - val_loss: 2651.6465\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 507.80743\n",
      "Epoch 39/10000\n",
      "86/86 [==============================] - 0s 971us/step - loss: 1577.1683 - val_loss: 681.5969\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 507.80743\n",
      "Epoch 40/10000\n",
      "86/86 [==============================] - 0s 975us/step - loss: 1638.8457 - val_loss: 2086.8545\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 507.80743\n",
      "Epoch 41/10000\n",
      "86/86 [==============================] - 0s 963us/step - loss: 1537.9746 - val_loss: 949.2446\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 507.80743\n",
      "Epoch 42/10000\n",
      "86/86 [==============================] - 0s 981us/step - loss: 1507.3635 - val_loss: 2554.5266\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 507.80743\n",
      "Epoch 43/10000\n",
      "86/86 [==============================] - 0s 986us/step - loss: 1466.6385 - val_loss: 1725.3141\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 507.80743\n",
      "Epoch 44/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1381.8718 - val_loss: 1512.1221\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 507.80743\n",
      "Epoch 45/10000\n",
      "86/86 [==============================] - 0s 962us/step - loss: 1491.8589 - val_loss: 2156.1951\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 507.80743\n",
      "Epoch 46/10000\n",
      "86/86 [==============================] - 0s 989us/step - loss: 1423.6129 - val_loss: 933.0247\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 507.80743\n",
      "Epoch 47/10000\n",
      "86/86 [==============================] - 0s 972us/step - loss: 1356.9404 - val_loss: 1535.4418\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 507.80743\n",
      "Epoch 48/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1408.7532 - val_loss: 353.2888\n",
      "\n",
      "Epoch 00048: val_loss improved from 507.80743 to 353.28876, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 49/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1443.8518 - val_loss: 978.1094\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 353.28876\n",
      "Epoch 50/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1775.3862 - val_loss: 2484.9795\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 353.28876\n",
      "Epoch 51/10000\n",
      "86/86 [==============================] - 0s 924us/step - loss: 1494.2650 - val_loss: 686.7485\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 353.28876\n",
      "Epoch 52/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1274.9685 - val_loss: 212.9105\n",
      "\n",
      "Epoch 00052: val_loss improved from 353.28876 to 212.91046, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 53/10000\n",
      "86/86 [==============================] - 0s 991us/step - loss: 1231.7988 - val_loss: 271.5312\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 212.91046\n",
      "Epoch 54/10000\n",
      "86/86 [==============================] - 0s 955us/step - loss: 1232.6259 - val_loss: 247.8449\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 212.91046\n",
      "Epoch 55/10000\n",
      "86/86 [==============================] - 0s 964us/step - loss: 1232.1448 - val_loss: 230.0792\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 212.91046\n",
      "Epoch 56/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1225.9193 - val_loss: 220.7401\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 212.91046\n",
      "Epoch 57/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1225.3567 - val_loss: 226.8222\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 212.91046\n",
      "Epoch 58/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.8345 - val_loss: 294.5647\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 212.91046\n",
      "Epoch 59/10000\n",
      "86/86 [==============================] - 0s 977us/step - loss: 1231.7833 - val_loss: 279.8383\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 212.91046\n",
      "Epoch 60/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.4067 - val_loss: 196.8685\n",
      "\n",
      "Epoch 00060: val_loss improved from 212.91046 to 196.86850, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 61/10000\n",
      "86/86 [==============================] - 0s 958us/step - loss: 1232.2112 - val_loss: 206.1011\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 196.86850\n",
      "Epoch 62/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.5959 - val_loss: 272.4304\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 196.86850\n",
      "Epoch 63/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.9197 - val_loss: 207.0716\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 196.86850\n",
      "Epoch 64/10000\n",
      "86/86 [==============================] - 0s 936us/step - loss: 1232.9513 - val_loss: 267.6666\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 196.86850\n",
      "Epoch 65/10000\n",
      "86/86 [==============================] - 0s 984us/step - loss: 1231.2775 - val_loss: 337.7617\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 196.86850\n",
      "Epoch 66/10000\n",
      "86/86 [==============================] - 0s 978us/step - loss: 1233.4980 - val_loss: 265.8873\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 196.86850\n",
      "Epoch 67/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.4719 - val_loss: 220.1114\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 196.86850\n",
      "Epoch 68/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.0415 - val_loss: 195.4409\n",
      "\n",
      "Epoch 00068: val_loss improved from 196.86850 to 195.44086, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 69/10000\n",
      "86/86 [==============================] - 0s 992us/step - loss: 1231.0603 - val_loss: 251.0038\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 195.44086\n",
      "Epoch 70/10000\n",
      "86/86 [==============================] - 0s 993us/step - loss: 1232.0492 - val_loss: 286.7859\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 195.44086\n",
      "Epoch 71/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.4957 - val_loss: 259.9302\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 195.44086\n",
      "Epoch 72/10000\n",
      "86/86 [==============================] - 0s 983us/step - loss: 1232.7108 - val_loss: 224.3166\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 195.44086\n",
      "Epoch 73/10000\n",
      "86/86 [==============================] - 0s 957us/step - loss: 1231.5028 - val_loss: 254.1499\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 195.44086\n",
      "Epoch 74/10000\n",
      "86/86 [==============================] - 0s 963us/step - loss: 1232.4465 - val_loss: 243.1239\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 195.44086\n",
      "Epoch 75/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0913 - val_loss: 270.2755\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 195.44086\n",
      "Epoch 76/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.1497 - val_loss: 250.1322\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 195.44086\n",
      "Epoch 77/10000\n",
      "86/86 [==============================] - 0s 948us/step - loss: 1230.5795 - val_loss: 207.2206\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 195.44086\n",
      "Epoch 78/10000\n",
      "86/86 [==============================] - 0s 970us/step - loss: 1232.0856 - val_loss: 216.9759\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 195.44086\n",
      "Epoch 79/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.8456 - val_loss: 279.7486\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 195.44086\n",
      "Epoch 80/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.1816 - val_loss: 254.1577\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 195.44086\n",
      "Epoch 81/10000\n",
      "86/86 [==============================] - 0s 941us/step - loss: 1231.3109 - val_loss: 309.5053\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 195.44086\n",
      "Epoch 82/10000\n",
      "86/86 [==============================] - 0s 989us/step - loss: 1232.6304 - val_loss: 243.0566\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 195.44086\n",
      "Epoch 83/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.3027 - val_loss: 256.8584\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 195.44086\n",
      "Epoch 84/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.5521 - val_loss: 305.4645\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 195.44086\n",
      "Epoch 85/10000\n",
      "86/86 [==============================] - 0s 993us/step - loss: 1232.9576 - val_loss: 224.5918\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 195.44086\n",
      "Epoch 86/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.3917 - val_loss: 221.2528\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 195.44086\n",
      "Epoch 87/10000\n",
      "86/86 [==============================] - 0s 991us/step - loss: 1233.4508 - val_loss: 228.0059\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 195.44086\n",
      "Epoch 88/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.4697 - val_loss: 248.8633\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 195.44086\n",
      "Epoch 89/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.2565 - val_loss: 222.0329\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 195.44086\n",
      "Epoch 90/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.4401 - val_loss: 224.0421\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 195.44086\n",
      "Epoch 91/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0769 - val_loss: 274.3199\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 195.44086\n",
      "Epoch 92/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0211 - val_loss: 269.3824\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 195.44086\n",
      "Epoch 93/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0259 - val_loss: 249.9914\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 195.44086\n",
      "Epoch 94/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.8363 - val_loss: 243.1159\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 195.44086\n",
      "Epoch 95/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0038 - val_loss: 209.4202\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 195.44086\n",
      "Epoch 96/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.8733 - val_loss: 232.4316\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 195.44086\n",
      "Epoch 97/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.7776 - val_loss: 307.2506\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 195.44086\n",
      "Epoch 98/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.4202 - val_loss: 226.3111\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 195.44086\n",
      "Epoch 99/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.3014 - val_loss: 208.5317\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 195.44086\n",
      "Epoch 100/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.3071 - val_loss: 277.7247\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 195.44086\n",
      "Epoch 101/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.8777 - val_loss: 233.7640\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 195.44086\n",
      "Epoch 102/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.6522 - val_loss: 253.6618\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 195.44086\n",
      "Epoch 103/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.3202 - val_loss: 231.9460\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 195.44086\n",
      "Epoch 104/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.5575 - val_loss: 238.1827\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 195.44086\n",
      "Epoch 105/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.9235 - val_loss: 310.6481\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 195.44086\n",
      "Epoch 106/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0726 - val_loss: 201.1256\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 195.44086\n",
      "Epoch 107/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.5620 - val_loss: 224.7718\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 195.44086\n",
      "Epoch 108/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.9902 - val_loss: 256.1641\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 195.44086\n",
      "Epoch 109/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.9949 - val_loss: 226.4783\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 195.44086\n",
      "Epoch 110/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.5115 - val_loss: 247.1016\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 195.44086\n",
      "Epoch 111/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.6367 - val_loss: 230.0603\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 195.44086\n",
      "Epoch 112/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.5217 - val_loss: 203.5364\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 195.44086\n",
      "Epoch 113/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.1348 - val_loss: 196.3727\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 195.44086\n",
      "Epoch 114/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.3110 - val_loss: 251.7213\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 195.44086\n",
      "Epoch 115/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1233.4124 - val_loss: 251.2423\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 195.44086\n",
      "Epoch 116/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.7015 - val_loss: 236.7209\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 195.44086\n",
      "Epoch 117/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.0712 - val_loss: 246.3559\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 195.44086\n",
      "Epoch 118/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1233.0233 - val_loss: 253.2314\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 195.44086\n",
      "Epoch 119/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.5507 - val_loss: 202.2935\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 195.44086\n",
      "Epoch 120/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.1757 - val_loss: 232.2638\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 195.44086\n",
      "Epoch 121/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1233.1234 - val_loss: 205.5517\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 195.44086\n",
      "Epoch 122/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.6655 - val_loss: 235.0400\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 195.44086\n",
      "Epoch 123/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.4927 - val_loss: 219.3944\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 195.44086\n",
      "Epoch 124/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.2102 - val_loss: 277.5352\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 195.44086\n",
      "Epoch 125/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.4792 - val_loss: 229.8020\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 195.44086\n",
      "Epoch 126/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.7755 - val_loss: 221.8223\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 195.44086\n",
      "Epoch 127/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.8389 - val_loss: 226.5923\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 195.44086\n",
      "Epoch 128/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.5211 - val_loss: 270.0201\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 195.44086\n",
      "Epoch 129/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.1548 - val_loss: 295.3184\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 195.44086\n",
      "Epoch 130/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.9141 - val_loss: 284.7181\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 195.44086\n",
      "Epoch 131/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.9435 - val_loss: 232.1431\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 195.44086\n",
      "Epoch 132/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.0642 - val_loss: 234.2488\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 195.44086\n",
      "Epoch 133/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.5981 - val_loss: 194.4529\n",
      "\n",
      "Epoch 00133: val_loss improved from 195.44086 to 194.45287, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 134/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.3583 - val_loss: 235.2318\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 194.45287\n",
      "Epoch 135/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.2942 - val_loss: 214.9062\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 194.45287\n",
      "Epoch 136/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0228 - val_loss: 305.3305\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 194.45287\n",
      "Epoch 137/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1233.0258 - val_loss: 208.2115\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 194.45287\n",
      "Epoch 138/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.4055 - val_loss: 232.8790\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 194.45287\n",
      "Epoch 139/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.4944 - val_loss: 316.5475\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 194.45287\n",
      "Epoch 140/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1233.0966 - val_loss: 244.4771\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 194.45287\n",
      "Epoch 141/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.6638 - val_loss: 218.9515\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 194.45287\n",
      "Epoch 142/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.3074 - val_loss: 212.3145\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 194.45287\n",
      "Epoch 143/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.3458 - val_loss: 220.3813\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 194.45287\n",
      "Epoch 144/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.5010 - val_loss: 222.9407\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 194.45287\n",
      "Epoch 145/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.2837 - val_loss: 331.1170\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 194.45287\n",
      "Epoch 146/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.9836 - val_loss: 262.7414\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 194.45287\n",
      "Epoch 147/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.3080 - val_loss: 214.5839\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 194.45287\n",
      "Epoch 148/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.4174 - val_loss: 216.5132\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 194.45287\n",
      "Epoch 149/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.1609 - val_loss: 281.8256\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 194.45287\n",
      "Epoch 150/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.7892 - val_loss: 271.2328\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 194.45287\n",
      "Epoch 151/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.1465 - val_loss: 296.9223\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 194.45287\n",
      "Epoch 152/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.8483 - val_loss: 247.1811\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 194.45287\n",
      "Epoch 153/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.4678 - val_loss: 337.2385\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 194.45287\n",
      "Epoch 154/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1233.2451 - val_loss: 257.1851\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 194.45287\n",
      "Epoch 155/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.6598 - val_loss: 279.9943\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 194.45287\n",
      "Epoch 156/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.7361 - val_loss: 226.3075\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 194.45287\n",
      "Epoch 157/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.2802 - val_loss: 257.2637\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 194.45287\n",
      "Epoch 158/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.6533 - val_loss: 242.0329\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 194.45287\n",
      "Epoch 159/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.6438 - val_loss: 235.1838\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 194.45287\n",
      "Epoch 160/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.6552 - val_loss: 216.7360\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 194.45287\n",
      "Epoch 161/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.7213 - val_loss: 218.4003\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 194.45287\n",
      "Epoch 162/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.8732 - val_loss: 252.7308\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 194.45287\n",
      "Epoch 163/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0476 - val_loss: 209.3595\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 194.45287\n",
      "Epoch 164/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.2239 - val_loss: 262.1490\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 194.45287\n",
      "Epoch 165/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.7601 - val_loss: 257.4927\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 194.45287\n",
      "Epoch 166/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.2076 - val_loss: 314.3000\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 194.45287\n",
      "Epoch 167/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.9064 - val_loss: 246.3234\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 194.45287\n",
      "Epoch 168/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.6251 - val_loss: 280.0648\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 194.45287\n",
      "Epoch 169/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0287 - val_loss: 306.3274\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 194.45287\n",
      "Epoch 170/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.4854 - val_loss: 224.1241\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 194.45287\n",
      "Epoch 171/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1233.0197 - val_loss: 237.6003\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 194.45287\n",
      "Epoch 172/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.7399 - val_loss: 246.3764\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 194.45287\n",
      "Epoch 173/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.5311 - val_loss: 230.1102\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 194.45287\n",
      "Epoch 174/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.4349 - val_loss: 211.5777\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 194.45287\n",
      "Epoch 175/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.5978 - val_loss: 325.5256\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 194.45287\n",
      "Epoch 176/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1233.1465 - val_loss: 213.0669\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 194.45287\n",
      "Epoch 177/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1233.1254 - val_loss: 224.2272\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 194.45287\n",
      "Epoch 178/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.6835 - val_loss: 217.1870\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 194.45287\n",
      "Epoch 179/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.1484 - val_loss: 268.8591\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 194.45287\n",
      "Epoch 180/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.1908 - val_loss: 267.9734\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 194.45287\n",
      "Epoch 181/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.6764 - val_loss: 199.8787\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 194.45287\n",
      "Epoch 182/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.6909 - val_loss: 258.8900\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 194.45287\n",
      "Epoch 183/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0795 - val_loss: 197.0333\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 194.45287\n",
      "Epoch 184/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.1438 - val_loss: 238.7148\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 194.45287\n",
      "Epoch 185/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.2992 - val_loss: 244.7365\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 194.45287\n",
      "Epoch 186/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.6814 - val_loss: 213.4344\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 194.45287\n",
      "Epoch 187/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.2660 - val_loss: 209.6622\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 194.45287\n",
      "Epoch 188/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.9242 - val_loss: 279.0549\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 194.45287\n",
      "Epoch 189/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.0815 - val_loss: 290.6766\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 194.45287\n",
      "Epoch 190/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0596 - val_loss: 267.1979\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 194.45287\n",
      "Epoch 191/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.4534 - val_loss: 257.8325\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 194.45287\n",
      "Epoch 192/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.1639 - val_loss: 226.3326\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 194.45287\n",
      "Epoch 193/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.0436 - val_loss: 236.0685\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 194.45287\n",
      "Epoch 194/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.3940 - val_loss: 280.3429\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 194.45287\n",
      "Epoch 195/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.2115 - val_loss: 210.0845\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 194.45287\n",
      "Epoch 196/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.5369 - val_loss: 210.0705\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 194.45287\n",
      "Epoch 197/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.8290 - val_loss: 222.5791\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 194.45287\n",
      "Epoch 198/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.2296 - val_loss: 207.4413\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 194.45287\n",
      "Epoch 199/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.5601 - val_loss: 261.2412\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 194.45287\n",
      "Epoch 200/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.6522 - val_loss: 230.7659\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 194.45287\n",
      "Epoch 201/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0760 - val_loss: 198.9411\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 194.45287\n",
      "Epoch 202/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.9185 - val_loss: 294.9768\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 194.45287\n",
      "Epoch 203/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.6697 - val_loss: 216.4851\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 194.45287\n",
      "Epoch 204/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.8162 - val_loss: 270.7907\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 194.45287\n",
      "Epoch 205/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.1821 - val_loss: 220.1144\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 194.45287\n",
      "Epoch 206/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.7760 - val_loss: 261.8106\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 194.45287\n",
      "Epoch 207/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.6135 - val_loss: 253.8411\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 194.45287\n",
      "Epoch 208/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.0870 - val_loss: 218.9500\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 194.45287\n",
      "Epoch 209/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1229.9821 - val_loss: 330.1959\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 194.45287\n",
      "Epoch 210/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.1677 - val_loss: 215.8667\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 194.45287\n",
      "Epoch 211/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.6382 - val_loss: 227.0130\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 194.45287\n",
      "Epoch 212/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.4089 - val_loss: 211.0382\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 194.45287\n",
      "Epoch 213/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.3824 - val_loss: 240.2780\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 194.45287\n",
      "Epoch 214/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.5013 - val_loss: 302.2157\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 194.45287\n",
      "Epoch 215/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.9772 - val_loss: 263.5268\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 194.45287\n",
      "Epoch 216/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.9514 - val_loss: 239.2570\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 194.45287\n",
      "Epoch 217/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.9988 - val_loss: 230.4357\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 194.45287\n",
      "Epoch 218/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1233.2521 - val_loss: 235.0765\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 194.45287\n",
      "Epoch 219/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.5121 - val_loss: 246.9099\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 194.45287\n",
      "Epoch 220/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.8040 - val_loss: 245.4548\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 194.45287\n",
      "Epoch 221/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.4775 - val_loss: 241.0747\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 194.45287\n",
      "Epoch 222/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.2534 - val_loss: 351.4154\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 194.45287\n",
      "Epoch 223/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.4962 - val_loss: 214.9052\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 194.45287\n",
      "Epoch 224/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.7292 - val_loss: 219.0213\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 194.45287\n",
      "Epoch 225/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.2491 - val_loss: 253.5000\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 194.45287\n",
      "Epoch 226/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.2721 - val_loss: 227.9794\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 194.45287\n",
      "Epoch 227/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.8076 - val_loss: 225.3350\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 194.45287\n",
      "Epoch 228/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.4570 - val_loss: 259.0876\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 194.45287\n",
      "Epoch 229/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1233.0770 - val_loss: 270.2588\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 194.45287\n",
      "Epoch 230/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.6085 - val_loss: 282.8383\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 194.45287\n",
      "Epoch 231/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1230.1235 - val_loss: 196.7771\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 194.45287\n",
      "Epoch 232/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1232.8848 - val_loss: 231.2368\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 194.45287\n",
      "Epoch 233/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1231.9718 - val_loss: 242.8802\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 194.45287\n",
      "Epoch 1/10000\n",
      "86/86 [==============================] - 1s 2ms/step - loss: 2794.0217 - val_loss: 1620.1598\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1620.15979, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "86/86 [==============================] - 0s 959us/step - loss: 2183.8320 - val_loss: 386.7034\n",
      "\n",
      "Epoch 00002: val_loss improved from 1620.15979 to 386.70337, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 2185.2874 - val_loss: 1690.5311\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 386.70337\n",
      "Epoch 4/10000\n",
      "86/86 [==============================] - 0s 968us/step - loss: 2242.3105 - val_loss: 2835.5166\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 386.70337\n",
      "Epoch 5/10000\n",
      "86/86 [==============================] - 0s 963us/step - loss: 2120.2180 - val_loss: 694.3287\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 386.70337\n",
      "Epoch 6/10000\n",
      "86/86 [==============================] - 0s 970us/step - loss: 2145.2090 - val_loss: 2937.9404\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 386.70337\n",
      "Epoch 7/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 2161.9622 - val_loss: 2605.6189\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 386.70337\n",
      "Epoch 8/10000\n",
      "86/86 [==============================] - 0s 957us/step - loss: 2289.6550 - val_loss: 4045.3545\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 386.70337\n",
      "Epoch 9/10000\n",
      "86/86 [==============================] - 0s 956us/step - loss: 2026.7822 - val_loss: 2350.0544\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 386.70337\n",
      "Epoch 10/10000\n",
      "86/86 [==============================] - 0s 985us/step - loss: 2199.8911 - val_loss: 349.5149\n",
      "\n",
      "Epoch 00010: val_loss improved from 386.70337 to 349.51489, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 11/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 2079.9854 - val_loss: 1993.2516\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 349.51489\n",
      "Epoch 12/10000\n",
      "86/86 [==============================] - 0s 967us/step - loss: 1985.9382 - val_loss: 1976.3521\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 349.51489\n",
      "Epoch 13/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 2138.3567 - val_loss: 324.5475\n",
      "\n",
      "Epoch 00013: val_loss improved from 349.51489 to 324.54745, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 14/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1945.3861 - val_loss: 651.0355\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 324.54745\n",
      "Epoch 15/10000\n",
      "86/86 [==============================] - 0s 973us/step - loss: 2017.6912 - val_loss: 7864.6807\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 324.54745\n",
      "Epoch 16/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1874.5073 - val_loss: 751.8553\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 324.54745\n",
      "Epoch 17/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1992.0337 - val_loss: 2024.6139\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 324.54745\n",
      "Epoch 18/10000\n",
      "86/86 [==============================] - 0s 941us/step - loss: 1865.2483 - val_loss: 1379.0718\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 324.54745\n",
      "Epoch 19/10000\n",
      "86/86 [==============================] - 0s 957us/step - loss: 1769.1465 - val_loss: 3526.6516\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 324.54745\n",
      "Epoch 20/10000\n",
      "86/86 [==============================] - 0s 962us/step - loss: 1941.7843 - val_loss: 3460.2937\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 324.54745\n",
      "Epoch 21/10000\n",
      "86/86 [==============================] - 0s 956us/step - loss: 2064.5061 - val_loss: 2484.1130\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 324.54745\n",
      "Epoch 22/10000\n",
      "86/86 [==============================] - 0s 989us/step - loss: 1859.4817 - val_loss: 2757.1968\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 324.54745\n",
      "Epoch 23/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1799.5028 - val_loss: 856.6905\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 324.54745\n",
      "Epoch 24/10000\n",
      "86/86 [==============================] - 0s 981us/step - loss: 1918.5709 - val_loss: 1862.7312\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 324.54745\n",
      "Epoch 25/10000\n",
      "86/86 [==============================] - 0s 969us/step - loss: 1893.2993 - val_loss: 836.8553\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 324.54745\n",
      "Epoch 26/10000\n",
      "86/86 [==============================] - 0s 986us/step - loss: 1824.5328 - val_loss: 2309.8525\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 324.54745\n",
      "Epoch 27/10000\n",
      "86/86 [==============================] - 0s 990us/step - loss: 1754.6222 - val_loss: 3588.9944\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 324.54745\n",
      "Epoch 28/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1888.6431 - val_loss: 1334.1195\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 324.54745\n",
      "Epoch 29/10000\n",
      "86/86 [==============================] - 0s 904us/step - loss: 1728.3682 - val_loss: 1691.9125\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 324.54745\n",
      "Epoch 30/10000\n",
      "86/86 [==============================] - 0s 960us/step - loss: 1819.0198 - val_loss: 3356.8325\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 324.54745\n",
      "Epoch 31/10000\n",
      "86/86 [==============================] - 0s 957us/step - loss: 1958.6313 - val_loss: 2345.1921\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 324.54745\n",
      "Epoch 32/10000\n",
      "86/86 [==============================] - 0s 953us/step - loss: 1818.9781 - val_loss: 2833.8508\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 324.54745\n",
      "Epoch 33/10000\n",
      "86/86 [==============================] - 0s 956us/step - loss: 1684.1718 - val_loss: 1454.8192\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 324.54745\n",
      "Epoch 34/10000\n",
      "86/86 [==============================] - 0s 981us/step - loss: 1753.1512 - val_loss: 467.6300\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 324.54745\n",
      "Epoch 35/10000\n",
      "86/86 [==============================] - 0s 967us/step - loss: 1590.2650 - val_loss: 3250.4717\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 324.54745\n",
      "Epoch 36/10000\n",
      "86/86 [==============================] - 0s 970us/step - loss: 1793.7029 - val_loss: 1950.0245\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 324.54745\n",
      "Epoch 37/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1683.8115 - val_loss: 1946.2069\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 324.54745\n",
      "Epoch 38/10000\n",
      "86/86 [==============================] - 0s 913us/step - loss: 1729.0013 - val_loss: 1028.3306\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 324.54745\n",
      "Epoch 39/10000\n",
      "86/86 [==============================] - 0s 958us/step - loss: 1649.8495 - val_loss: 2382.6865\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 324.54745\n",
      "Epoch 40/10000\n",
      "86/86 [==============================] - 0s 968us/step - loss: 1555.5383 - val_loss: 2509.5369\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 324.54745\n",
      "Epoch 41/10000\n",
      "86/86 [==============================] - 0s 970us/step - loss: 1647.8416 - val_loss: 2519.2346\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 324.54745\n",
      "Epoch 42/10000\n",
      "86/86 [==============================] - 0s 979us/step - loss: 1516.0544 - val_loss: 978.9478\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 324.54745\n",
      "Epoch 43/10000\n",
      "86/86 [==============================] - 0s 983us/step - loss: 1615.9700 - val_loss: 1272.3619\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 324.54745\n",
      "Epoch 44/10000\n",
      "86/86 [==============================] - 0s 977us/step - loss: 1493.0487 - val_loss: 2810.1125\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 324.54745\n",
      "Epoch 45/10000\n",
      "86/86 [==============================] - 0s 968us/step - loss: 1643.0128 - val_loss: 2591.7947\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 324.54745\n",
      "Epoch 46/10000\n",
      "86/86 [==============================] - 0s 971us/step - loss: 1721.2762 - val_loss: 557.6738\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 324.54745\n",
      "Epoch 47/10000\n",
      "86/86 [==============================] - 0s 960us/step - loss: 1584.0695 - val_loss: 1449.7382\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 324.54745\n",
      "Epoch 48/10000\n",
      "86/86 [==============================] - 0s 977us/step - loss: 1466.6166 - val_loss: 2479.7690\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 324.54745\n",
      "Epoch 49/10000\n",
      "86/86 [==============================] - 0s 979us/step - loss: 1411.6653 - val_loss: 3022.5327\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 324.54745\n",
      "Epoch 50/10000\n",
      "86/86 [==============================] - 0s 983us/step - loss: 1498.7838 - val_loss: 1505.5300\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 324.54745\n",
      "Epoch 51/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1483.3877 - val_loss: 2270.1440\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 324.54745\n",
      "Epoch 52/10000\n",
      "86/86 [==============================] - 0s 983us/step - loss: 1430.6276 - val_loss: 2109.9834\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 324.54745\n",
      "Epoch 53/10000\n",
      "86/86 [==============================] - 0s 967us/step - loss: 1360.0558 - val_loss: 1920.5955\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 324.54745\n",
      "Epoch 54/10000\n",
      "86/86 [==============================] - 0s 975us/step - loss: 1477.2031 - val_loss: 1225.1980\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 324.54745\n",
      "Epoch 55/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1262.0535 - val_loss: 1039.4363\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 324.54745\n",
      "Epoch 56/10000\n",
      "86/86 [==============================] - 0s 937us/step - loss: 1321.2979 - val_loss: 1802.5532\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 324.54745\n",
      "Epoch 57/10000\n",
      "86/86 [==============================] - 0s 979us/step - loss: 1341.0581 - val_loss: 424.4291\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 324.54745\n",
      "Epoch 58/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1321.9031 - val_loss: 1688.8052\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 324.54745\n",
      "Epoch 59/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1199.3372 - val_loss: 1146.7848\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 324.54745\n",
      "Epoch 60/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1106.1484 - val_loss: 1265.0114\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 324.54745\n",
      "Epoch 61/10000\n",
      "86/86 [==============================] - 0s 967us/step - loss: 1075.1849 - val_loss: 1140.4126\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 324.54745\n",
      "Epoch 62/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1126.8118 - val_loss: 1163.7477\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 324.54745\n",
      "Epoch 63/10000\n",
      "86/86 [==============================] - 0s 950us/step - loss: 1151.9879 - val_loss: 787.4879\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 324.54745\n",
      "Epoch 64/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1120.5129 - val_loss: 781.5198\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 324.54745\n",
      "Epoch 65/10000\n",
      "86/86 [==============================] - 0s 940us/step - loss: 1069.6335 - val_loss: 1166.8734\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 324.54745\n",
      "Epoch 66/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 970us/step - loss: 1057.5453 - val_loss: 1182.6656\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 324.54745\n",
      "Epoch 67/10000\n",
      "86/86 [==============================] - 0s 968us/step - loss: 1067.5626 - val_loss: 1170.9658\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 324.54745\n",
      "Epoch 68/10000\n",
      "86/86 [==============================] - 0s 979us/step - loss: 1079.7876 - val_loss: 1226.5323\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 324.54745\n",
      "Epoch 69/10000\n",
      "86/86 [==============================] - 0s 995us/step - loss: 1180.7708 - val_loss: 870.4686\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 324.54745\n",
      "Epoch 70/10000\n",
      "86/86 [==============================] - 0s 965us/step - loss: 1116.8564 - val_loss: 914.5828\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 324.54745\n",
      "Epoch 71/10000\n",
      "86/86 [==============================] - 0s 968us/step - loss: 1075.2797 - val_loss: 991.0215\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 324.54745\n",
      "Epoch 72/10000\n",
      "86/86 [==============================] - 0s 961us/step - loss: 1075.5411 - val_loss: 865.3441\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 324.54745\n",
      "Epoch 73/10000\n",
      "86/86 [==============================] - 0s 983us/step - loss: 1074.6201 - val_loss: 856.3981\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 324.54745\n",
      "Epoch 74/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1026.8417 - val_loss: 719.4752\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 324.54745\n",
      "Epoch 75/10000\n",
      "86/86 [==============================] - 0s 935us/step - loss: 1058.3422 - val_loss: 1137.8656\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 324.54745\n",
      "Epoch 76/10000\n",
      "86/86 [==============================] - 0s 963us/step - loss: 1139.2811 - val_loss: 524.0639\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 324.54745\n",
      "Epoch 77/10000\n",
      "86/86 [==============================] - 0s 972us/step - loss: 1066.9614 - val_loss: 1120.9133\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 324.54745\n",
      "Epoch 78/10000\n",
      "86/86 [==============================] - 0s 939us/step - loss: 1089.8108 - val_loss: 700.3542\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 324.54745\n",
      "Epoch 79/10000\n",
      "86/86 [==============================] - 0s 965us/step - loss: 1052.5640 - val_loss: 1364.8054\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 324.54745\n",
      "Epoch 80/10000\n",
      "86/86 [==============================] - 0s 965us/step - loss: 1041.3992 - val_loss: 644.9469\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 324.54745\n",
      "Epoch 81/10000\n",
      "86/86 [==============================] - 0s 975us/step - loss: 1065.0687 - val_loss: 1458.1129\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 324.54745\n",
      "Epoch 82/10000\n",
      "86/86 [==============================] - 0s 959us/step - loss: 1201.3535 - val_loss: 1043.5814\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 324.54745\n",
      "Epoch 83/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1089.7253 - val_loss: 734.3840\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 324.54745\n",
      "Epoch 84/10000\n",
      "86/86 [==============================] - 0s 958us/step - loss: 1062.5551 - val_loss: 1065.8405\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 324.54745\n",
      "Epoch 85/10000\n",
      "86/86 [==============================] - 0s 993us/step - loss: 993.4789 - val_loss: 1233.1731\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 324.54745\n",
      "Epoch 86/10000\n",
      "86/86 [==============================] - 0s 985us/step - loss: 954.8323 - val_loss: 1095.5951\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 324.54745\n",
      "Epoch 87/10000\n",
      "86/86 [==============================] - 0s 978us/step - loss: 965.9427 - val_loss: 1189.4280\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 324.54745\n",
      "Epoch 88/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1017.4332 - val_loss: 1134.6038\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 324.54745\n",
      "Epoch 89/10000\n",
      "86/86 [==============================] - 0s 922us/step - loss: 1013.0022 - val_loss: 745.6279\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 324.54745\n",
      "Epoch 90/10000\n",
      "86/86 [==============================] - 0s 948us/step - loss: 993.5081 - val_loss: 1109.1768\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 324.54745\n",
      "Epoch 91/10000\n",
      "86/86 [==============================] - 0s 945us/step - loss: 1014.4141 - val_loss: 1344.8544\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 324.54745\n",
      "Epoch 92/10000\n",
      "86/86 [==============================] - 0s 956us/step - loss: 1022.6807 - val_loss: 1106.7867\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 324.54745\n",
      "Epoch 93/10000\n",
      "86/86 [==============================] - 0s 975us/step - loss: 1022.0457 - val_loss: 1262.9346\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 324.54745\n",
      "Epoch 94/10000\n",
      "86/86 [==============================] - 0s 958us/step - loss: 1015.8031 - val_loss: 1188.6110\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 324.54745\n",
      "Epoch 95/10000\n",
      "86/86 [==============================] - 0s 977us/step - loss: 1039.2322 - val_loss: 395.8228\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 324.54745\n",
      "Epoch 96/10000\n",
      "86/86 [==============================] - 0s 964us/step - loss: 996.4214 - val_loss: 1467.5525\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 324.54745\n",
      "Epoch 97/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1009.4160 - val_loss: 662.3027\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 324.54745\n",
      "Epoch 98/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1039.8572 - val_loss: 935.6560\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 324.54745\n",
      "Epoch 99/10000\n",
      "86/86 [==============================] - 0s 919us/step - loss: 998.9738 - val_loss: 1285.4896\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 324.54745\n",
      "Epoch 100/10000\n",
      "86/86 [==============================] - 0s 970us/step - loss: 993.6729 - val_loss: 790.0991\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 324.54745\n",
      "Epoch 101/10000\n",
      "86/86 [==============================] - 0s 971us/step - loss: 1004.3408 - val_loss: 1386.4900\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 324.54745\n",
      "Epoch 102/10000\n",
      "86/86 [==============================] - 0s 991us/step - loss: 1038.0867 - val_loss: 1285.3973\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 324.54745\n",
      "Epoch 103/10000\n",
      "86/86 [==============================] - 0s 978us/step - loss: 1033.1687 - val_loss: 1172.0217\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 324.54745\n",
      "Epoch 104/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 1004.0322 - val_loss: 1064.8805\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 324.54745\n",
      "Epoch 105/10000\n",
      "86/86 [==============================] - 0s 936us/step - loss: 986.1618 - val_loss: 1468.4595\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 324.54745\n",
      "Epoch 106/10000\n",
      "86/86 [==============================] - 0s 969us/step - loss: 1039.2479 - val_loss: 1258.7983\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 324.54745\n",
      "Epoch 107/10000\n",
      "86/86 [==============================] - 0s 959us/step - loss: 989.5447 - val_loss: 1204.6461\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 324.54745\n",
      "Epoch 108/10000\n",
      "86/86 [==============================] - 0s 968us/step - loss: 1067.4519 - val_loss: 230.6700\n",
      "\n",
      "Epoch 00108: val_loss improved from 324.54745 to 230.67004, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 109/10000\n",
      "86/86 [==============================] - 0s 935us/step - loss: 1096.1163 - val_loss: 538.2963\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 230.67004\n",
      "Epoch 110/10000\n",
      "86/86 [==============================] - 0s 963us/step - loss: 971.3727 - val_loss: 757.6263\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 230.67004\n",
      "Epoch 111/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 975.5189 - val_loss: 978.4659\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 230.67004\n",
      "Epoch 112/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 969.9629 - val_loss: 1301.4575\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 230.67004\n",
      "Epoch 113/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 925.1142 - val_loss: 1006.8069\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 230.67004\n",
      "Epoch 114/10000\n",
      "86/86 [==============================] - 0s 920us/step - loss: 946.1376 - val_loss: 1405.3539\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 230.67004\n",
      "Epoch 115/10000\n",
      "86/86 [==============================] - 0s 971us/step - loss: 973.1620 - val_loss: 1133.6240\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 230.67004\n",
      "Epoch 116/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 960us/step - loss: 945.1812 - val_loss: 941.1752\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 230.67004\n",
      "Epoch 117/10000\n",
      "86/86 [==============================] - 0s 961us/step - loss: 953.7840 - val_loss: 1175.5359\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 230.67004\n",
      "Epoch 118/10000\n",
      "86/86 [==============================] - 0s 973us/step - loss: 934.3813 - val_loss: 1128.8207\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 230.67004\n",
      "Epoch 119/10000\n",
      "86/86 [==============================] - 0s 973us/step - loss: 941.3635 - val_loss: 902.1556\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 230.67004\n",
      "Epoch 120/10000\n",
      "86/86 [==============================] - 0s 989us/step - loss: 991.9166 - val_loss: 1164.7269\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 230.67004\n",
      "Epoch 121/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 988.4308 - val_loss: 865.4872\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 230.67004\n",
      "Epoch 122/10000\n",
      "86/86 [==============================] - 0s 975us/step - loss: 1211.1504 - val_loss: 337.0418\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 230.67004\n",
      "Epoch 123/10000\n",
      "86/86 [==============================] - 0s 970us/step - loss: 971.2538 - val_loss: 609.9547\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 230.67004\n",
      "Epoch 124/10000\n",
      "86/86 [==============================] - 0s 971us/step - loss: 964.5203 - val_loss: 1085.3015\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 230.67004\n",
      "Epoch 125/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 955.1967 - val_loss: 807.1815\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 230.67004\n",
      "Epoch 126/10000\n",
      "86/86 [==============================] - 0s 920us/step - loss: 973.3171 - val_loss: 1161.6053\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 230.67004\n",
      "Epoch 127/10000\n",
      "86/86 [==============================] - 0s 960us/step - loss: 964.5302 - val_loss: 1153.7129\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 230.67004\n",
      "Epoch 128/10000\n",
      "86/86 [==============================] - 0s 965us/step - loss: 906.2656 - val_loss: 951.0842\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 230.67004\n",
      "Epoch 129/10000\n",
      "86/86 [==============================] - 0s 956us/step - loss: 1022.8531 - val_loss: 703.1002\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 230.67004\n",
      "Epoch 130/10000\n",
      "86/86 [==============================] - 0s 984us/step - loss: 958.7683 - val_loss: 1052.0698\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 230.67004\n",
      "Epoch 131/10000\n",
      "86/86 [==============================] - 0s 968us/step - loss: 958.1071 - val_loss: 1172.6023\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 230.67004\n",
      "Epoch 132/10000\n",
      "86/86 [==============================] - 0s 970us/step - loss: 933.3447 - val_loss: 868.9258\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 230.67004\n",
      "Epoch 133/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 943.1715 - val_loss: 1394.3970\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 230.67004\n",
      "Epoch 134/10000\n",
      "86/86 [==============================] - 0s 957us/step - loss: 918.3145 - val_loss: 1097.7965\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 230.67004\n",
      "Epoch 135/10000\n",
      "86/86 [==============================] - 0s 969us/step - loss: 946.7926 - val_loss: 1246.9711\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 230.67004\n",
      "Epoch 136/10000\n",
      "86/86 [==============================] - 0s 968us/step - loss: 952.0502 - val_loss: 1202.4276\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 230.67004\n",
      "Epoch 137/10000\n",
      "86/86 [==============================] - 0s 979us/step - loss: 928.1676 - val_loss: 1093.7761\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 230.67004\n",
      "Epoch 138/10000\n",
      "86/86 [==============================] - 0s 982us/step - loss: 899.4404 - val_loss: 1844.7781\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 230.67004\n",
      "Epoch 139/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 983.8401 - val_loss: 1420.1851\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 230.67004\n",
      "Epoch 140/10000\n",
      "86/86 [==============================] - 0s 928us/step - loss: 879.0873 - val_loss: 762.6889\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 230.67004\n",
      "Epoch 141/10000\n",
      "86/86 [==============================] - 0s 960us/step - loss: 989.9753 - val_loss: 1478.0658\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 230.67004\n",
      "Epoch 142/10000\n",
      "86/86 [==============================] - 0s 977us/step - loss: 910.9178 - val_loss: 1307.6422\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 230.67004\n",
      "Epoch 143/10000\n",
      "86/86 [==============================] - 0s 983us/step - loss: 897.4144 - val_loss: 794.2991\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 230.67004\n",
      "Epoch 144/10000\n",
      "86/86 [==============================] - 0s 966us/step - loss: 903.2068 - val_loss: 1307.1840\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 230.67004\n",
      "Epoch 145/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 944.0267 - val_loss: 1241.1182\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 230.67004\n",
      "Epoch 146/10000\n",
      "86/86 [==============================] - 0s 945us/step - loss: 935.7103 - val_loss: 949.7269\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 230.67004\n",
      "Epoch 147/10000\n",
      "86/86 [==============================] - 0s 968us/step - loss: 948.2604 - val_loss: 1016.9916\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 230.67004\n",
      "Epoch 148/10000\n",
      "86/86 [==============================] - 0s 958us/step - loss: 962.9966 - val_loss: 912.5300\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 230.67004\n",
      "Epoch 149/10000\n",
      "86/86 [==============================] - 0s 953us/step - loss: 944.7877 - val_loss: 1301.4115\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 230.67004\n",
      "Epoch 150/10000\n",
      "86/86 [==============================] - 0s 976us/step - loss: 906.7802 - val_loss: 887.3859\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 230.67004\n",
      "Epoch 151/10000\n",
      "86/86 [==============================] - 0s 977us/step - loss: 881.0546 - val_loss: 608.7495\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 230.67004\n",
      "Epoch 152/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 907.8304 - val_loss: 1068.2438\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 230.67004\n",
      "Epoch 153/10000\n",
      "86/86 [==============================] - 0s 934us/step - loss: 864.7888 - val_loss: 1194.8446\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 230.67004\n",
      "Epoch 154/10000\n",
      "86/86 [==============================] - 0s 977us/step - loss: 939.2945 - val_loss: 1314.1622\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 230.67004\n",
      "Epoch 155/10000\n",
      "86/86 [==============================] - 0s 958us/step - loss: 970.9172 - val_loss: 1144.1335\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 230.67004\n",
      "Epoch 156/10000\n",
      "86/86 [==============================] - 0s 989us/step - loss: 943.7475 - val_loss: 1097.7513\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 230.67004\n",
      "Epoch 157/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 920.3669 - val_loss: 1075.4556\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 230.67004\n",
      "Epoch 158/10000\n",
      "86/86 [==============================] - 0s 921us/step - loss: 887.8318 - val_loss: 1320.3533\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 230.67004\n",
      "Epoch 159/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 901.5249 - val_loss: 1147.5956\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 230.67004\n",
      "Epoch 160/10000\n",
      "86/86 [==============================] - 0s 943us/step - loss: 887.7441 - val_loss: 724.5262\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 230.67004\n",
      "Epoch 161/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 916.3795 - val_loss: 1125.7731\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 230.67004\n",
      "Epoch 162/10000\n",
      "86/86 [==============================] - 0s 981us/step - loss: 891.3519 - val_loss: 778.8862\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 230.67004\n",
      "Epoch 163/10000\n",
      "86/86 [==============================] - 0s 963us/step - loss: 967.6173 - val_loss: 1146.5472\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 230.67004\n",
      "Epoch 164/10000\n",
      "86/86 [==============================] - 0s 977us/step - loss: 931.1567 - val_loss: 1206.7950\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 230.67004\n",
      "Epoch 165/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 917.6716 - val_loss: 1452.4814\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 230.67004\n",
      "Epoch 166/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 946.8823 - val_loss: 713.5229\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 230.67004\n",
      "Epoch 167/10000\n",
      "86/86 [==============================] - 0s 951us/step - loss: 893.6785 - val_loss: 1060.8030\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 230.67004\n",
      "Epoch 168/10000\n",
      "86/86 [==============================] - 0s 962us/step - loss: 886.9589 - val_loss: 1386.0422\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 230.67004\n",
      "Epoch 169/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 874.5055 - val_loss: 1422.9125\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 230.67004\n",
      "Epoch 170/10000\n",
      "86/86 [==============================] - 0s 924us/step - loss: 894.4123 - val_loss: 1243.5981\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 230.67004\n",
      "Epoch 171/10000\n",
      "86/86 [==============================] - 0s 959us/step - loss: 824.7950 - val_loss: 1000.8492\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 230.67004\n",
      "Epoch 172/10000\n",
      "86/86 [==============================] - 0s 948us/step - loss: 878.7489 - val_loss: 1162.6177\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 230.67004\n",
      "Epoch 173/10000\n",
      "86/86 [==============================] - 0s 969us/step - loss: 890.7370 - val_loss: 1159.4646\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 230.67004\n",
      "Epoch 174/10000\n",
      "86/86 [==============================] - 0s 970us/step - loss: 900.6791 - val_loss: 1137.6665\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 230.67004\n",
      "Epoch 175/10000\n",
      "86/86 [==============================] - 0s 959us/step - loss: 935.4891 - val_loss: 1066.8867\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 230.67004\n",
      "Epoch 176/10000\n",
      "86/86 [==============================] - 0s 976us/step - loss: 864.9325 - val_loss: 1187.0948\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 230.67004\n",
      "Epoch 177/10000\n",
      "86/86 [==============================] - 0s 983us/step - loss: 894.2123 - val_loss: 908.6825\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 230.67004\n",
      "Epoch 178/10000\n",
      "86/86 [==============================] - 0s 988us/step - loss: 846.5648 - val_loss: 1008.2015\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 230.67004\n",
      "Epoch 179/10000\n",
      "86/86 [==============================] - 0s 950us/step - loss: 915.3160 - val_loss: 1277.9811\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 230.67004\n",
      "Epoch 180/10000\n",
      "86/86 [==============================] - 0s 958us/step - loss: 878.0961 - val_loss: 892.4624\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 230.67004\n",
      "Epoch 181/10000\n",
      "86/86 [==============================] - 0s 958us/step - loss: 918.2337 - val_loss: 993.3934\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 230.67004\n",
      "Epoch 182/10000\n",
      "86/86 [==============================] - 0s 951us/step - loss: 879.0732 - val_loss: 1110.4044\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 230.67004\n",
      "Epoch 183/10000\n",
      "86/86 [==============================] - 0s 961us/step - loss: 949.8619 - val_loss: 852.3427\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 230.67004\n",
      "Epoch 184/10000\n",
      "86/86 [==============================] - 0s 990us/step - loss: 909.1036 - val_loss: 1157.5553\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 230.67004\n",
      "Epoch 185/10000\n",
      "86/86 [==============================] - 0s 981us/step - loss: 859.7178 - val_loss: 879.1038\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 230.67004\n",
      "Epoch 186/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 926.0757 - val_loss: 1270.0021\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 230.67004\n",
      "Epoch 187/10000\n",
      "86/86 [==============================] - 0s 941us/step - loss: 927.5051 - val_loss: 1350.5024\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 230.67004\n",
      "Epoch 188/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 887.4050 - val_loss: 941.4549\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 230.67004\n",
      "Epoch 189/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 860.9976 - val_loss: 1306.1045\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 230.67004\n",
      "Epoch 190/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 892.9269 - val_loss: 1195.3678\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 230.67004\n",
      "Epoch 191/10000\n",
      "86/86 [==============================] - 0s 997us/step - loss: 895.2754 - val_loss: 937.9640\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 230.67004\n",
      "Epoch 192/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 886.2507 - val_loss: 1143.4214\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 230.67004\n",
      "Epoch 193/10000\n",
      "86/86 [==============================] - 0s 913us/step - loss: 921.3819 - val_loss: 1093.3788\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 230.67004\n",
      "Epoch 194/10000\n",
      "86/86 [==============================] - 0s 956us/step - loss: 835.6667 - val_loss: 1297.4247\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 230.67004\n",
      "Epoch 195/10000\n",
      "86/86 [==============================] - 0s 973us/step - loss: 906.8490 - val_loss: 1087.5067\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 230.67004\n",
      "Epoch 196/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 902.3334 - val_loss: 885.9894\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 230.67004\n",
      "Epoch 197/10000\n",
      "86/86 [==============================] - 0s 979us/step - loss: 890.5189 - val_loss: 1368.2833\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 230.67004\n",
      "Epoch 198/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 920.2290 - val_loss: 1158.9147\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 230.67004\n",
      "Epoch 199/10000\n",
      "86/86 [==============================] - 0s 964us/step - loss: 908.7147 - val_loss: 743.7823\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 230.67004\n",
      "Epoch 200/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 900.8837 - val_loss: 1120.2667\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 230.67004\n",
      "Epoch 201/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 939.8345 - val_loss: 647.3783\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 230.67004\n",
      "Epoch 202/10000\n",
      "86/86 [==============================] - 0s 963us/step - loss: 876.5391 - val_loss: 782.9927\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 230.67004\n",
      "Epoch 203/10000\n",
      "86/86 [==============================] - 0s 962us/step - loss: 924.8745 - val_loss: 1206.0024\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 230.67004\n",
      "Epoch 204/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 808.0994 - val_loss: 1076.0994\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 230.67004\n",
      "Epoch 205/10000\n",
      "86/86 [==============================] - 0s 960us/step - loss: 848.0558 - val_loss: 1262.2744\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 230.67004\n",
      "Epoch 206/10000\n",
      "86/86 [==============================] - 0s 948us/step - loss: 861.7317 - val_loss: 955.5480\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 230.67004\n",
      "Epoch 207/10000\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 860.4226 - val_loss: 1312.4906\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 230.67004\n",
      "Epoch 208/10000\n",
      "86/86 [==============================] - 0s 980us/step - loss: 853.8827 - val_loss: 1273.5554\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 230.67004\n",
      "Epoch 1/10000\n",
      "85/85 [==============================] - ETA: 0s - loss: 3913.554 - 1s 2ms/step - loss: 3559.0073 - val_loss: 2546.7158\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2546.71582, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "85/85 [==============================] - 0s 991us/step - loss: 2032.2151 - val_loss: 399.2408\n",
      "\n",
      "Epoch 00002: val_loss improved from 2546.71582 to 399.24078, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 3/10000\n",
      "85/85 [==============================] - 0s 956us/step - loss: 2055.6350 - val_loss: 934.5062\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 399.24078\n",
      "Epoch 4/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2066.7903 - val_loss: 2182.9724\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 399.24078\n",
      "Epoch 5/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1896.1168 - val_loss: 5212.8262\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 399.24078\n",
      "Epoch 6/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2189.2322 - val_loss: 2542.6453\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 399.24078\n",
      "Epoch 7/10000\n",
      "85/85 [==============================] - 0s 969us/step - loss: 2085.3933 - val_loss: 1214.7482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss did not improve from 399.24078\n",
      "Epoch 8/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2072.9546 - val_loss: 3112.9878\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 399.24078\n",
      "Epoch 9/10000\n",
      "85/85 [==============================] - 0s 964us/step - loss: 2113.5164 - val_loss: 2045.7688\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 399.24078\n",
      "Epoch 10/10000\n",
      "85/85 [==============================] - 0s 977us/step - loss: 2133.0986 - val_loss: 3475.6951\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 399.24078\n",
      "Epoch 11/10000\n",
      "85/85 [==============================] - 0s 976us/step - loss: 2078.2866 - val_loss: 3487.2329\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 399.24078\n",
      "Epoch 12/10000\n",
      "85/85 [==============================] - 0s 977us/step - loss: 2065.8193 - val_loss: 625.7039\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 399.24078\n",
      "Epoch 13/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 2095.7219 - val_loss: 426.3596\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 399.24078\n",
      "Epoch 14/10000\n",
      "85/85 [==============================] - 0s 937us/step - loss: 2223.4871 - val_loss: 685.9137\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 399.24078\n",
      "Epoch 15/10000\n",
      "85/85 [==============================] - 0s 969us/step - loss: 2044.6022 - val_loss: 1400.8315\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 399.24078\n",
      "Epoch 16/10000\n",
      "85/85 [==============================] - 0s 977us/step - loss: 2168.1533 - val_loss: 2972.7705\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 399.24078\n",
      "Epoch 17/10000\n",
      "85/85 [==============================] - 0s 973us/step - loss: 1965.6769 - val_loss: 2986.1187\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 399.24078\n",
      "Epoch 18/10000\n",
      "85/85 [==============================] - 0s 966us/step - loss: 2020.0366 - val_loss: 2243.2129\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 399.24078\n",
      "Epoch 19/10000\n",
      "85/85 [==============================] - 0s 974us/step - loss: 1810.6260 - val_loss: 369.0588\n",
      "\n",
      "Epoch 00019: val_loss improved from 399.24078 to 369.05878, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 20/10000\n",
      "85/85 [==============================] - 0s 939us/step - loss: 1985.0425 - val_loss: 964.6822\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 369.05878\n",
      "Epoch 21/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1941.4554 - val_loss: 3026.9668\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 369.05878\n",
      "Epoch 22/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1906.2982 - val_loss: 2466.8625\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 369.05878\n",
      "Epoch 23/10000\n",
      "85/85 [==============================] - 0s 905us/step - loss: 1820.5002 - val_loss: 2925.4653\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 369.05878\n",
      "Epoch 24/10000\n",
      "85/85 [==============================] - 0s 978us/step - loss: 1879.3605 - val_loss: 2932.4014\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 369.05878\n",
      "Epoch 25/10000\n",
      "85/85 [==============================] - 0s 972us/step - loss: 2003.8375 - val_loss: 1109.9663\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 369.05878\n",
      "Epoch 26/10000\n",
      "85/85 [==============================] - 0s 964us/step - loss: 1894.4769 - val_loss: 1241.7557\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 369.05878\n",
      "Epoch 27/10000\n",
      "85/85 [==============================] - 0s 955us/step - loss: 1757.7964 - val_loss: 3493.4229\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 369.05878\n",
      "Epoch 28/10000\n",
      "85/85 [==============================] - 0s 968us/step - loss: 1962.4152 - val_loss: 3082.0596\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 369.05878\n",
      "Epoch 29/10000\n",
      "85/85 [==============================] - 0s 981us/step - loss: 1851.9453 - val_loss: 3217.4255\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 369.05878\n",
      "Epoch 30/10000\n",
      "85/85 [==============================] - 0s 999us/step - loss: 1789.5560 - val_loss: 2380.3530\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 369.05878\n",
      "Epoch 31/10000\n",
      "85/85 [==============================] - 0s 964us/step - loss: 1748.3058 - val_loss: 2662.1663\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 369.05878\n",
      "Epoch 32/10000\n",
      "85/85 [==============================] - 0s 967us/step - loss: 1874.3191 - val_loss: 1051.6418\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 369.05878\n",
      "Epoch 33/10000\n",
      "85/85 [==============================] - 0s 969us/step - loss: 1714.3235 - val_loss: 2680.6550\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 369.05878\n",
      "Epoch 34/10000\n",
      "85/85 [==============================] - 0s 955us/step - loss: 1707.3110 - val_loss: 410.5658\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 369.05878\n",
      "Epoch 35/10000\n",
      "85/85 [==============================] - 0s 954us/step - loss: 1734.0104 - val_loss: 3320.5220\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 369.05878\n",
      "Epoch 36/10000\n",
      "85/85 [==============================] - 0s 968us/step - loss: 1788.7860 - val_loss: 809.3290\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 369.05878\n",
      "Epoch 37/10000\n",
      "85/85 [==============================] - 0s 974us/step - loss: 1693.1350 - val_loss: 1865.7762\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 369.05878\n",
      "Epoch 38/10000\n",
      "85/85 [==============================] - 0s 996us/step - loss: 1751.6206 - val_loss: 2313.1750\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 369.05878\n",
      "Epoch 39/10000\n",
      "85/85 [==============================] - 0s 986us/step - loss: 1652.3540 - val_loss: 2359.9768\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 369.05878\n",
      "Epoch 40/10000\n",
      "85/85 [==============================] - 0s 987us/step - loss: 1695.6097 - val_loss: 1084.9211\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 369.05878\n",
      "Epoch 41/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1682.6342 - val_loss: 1755.0653\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 369.05878\n",
      "Epoch 42/10000\n",
      "85/85 [==============================] - 0s 921us/step - loss: 1719.9003 - val_loss: 2347.7585\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 369.05878\n",
      "Epoch 43/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1642.5583 - val_loss: 1573.3109\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 369.05878\n",
      "Epoch 44/10000\n",
      "85/85 [==============================] - 0s 964us/step - loss: 1606.0219 - val_loss: 1647.7667\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 369.05878\n",
      "Epoch 45/10000\n",
      "85/85 [==============================] - 0s 963us/step - loss: 1637.3413 - val_loss: 1806.3076\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 369.05878\n",
      "Epoch 46/10000\n",
      "85/85 [==============================] - 0s 992us/step - loss: 1587.9004 - val_loss: 2608.3135\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 369.05878\n",
      "Epoch 47/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1547.2700 - val_loss: 542.2649\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 369.05878\n",
      "Epoch 48/10000\n",
      "85/85 [==============================] - 0s 917us/step - loss: 1698.8562 - val_loss: 679.8262\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 369.05878\n",
      "Epoch 49/10000\n",
      "85/85 [==============================] - 0s 920us/step - loss: 1614.4792 - val_loss: 758.7735\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 369.05878\n",
      "Epoch 50/10000\n",
      "85/85 [==============================] - 0s 931us/step - loss: 1580.7198 - val_loss: 2612.3279\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 369.05878\n",
      "Epoch 51/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1496.1650 - val_loss: 1392.5337\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 369.05878\n",
      "Epoch 52/10000\n",
      "85/85 [==============================] - 0s 960us/step - loss: 1402.2141 - val_loss: 338.0269\n",
      "\n",
      "Epoch 00052: val_loss improved from 369.05878 to 338.02692, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 53/10000\n",
      "85/85 [==============================] - 0s 956us/step - loss: 1198.7057 - val_loss: 912.6868\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 338.02692\n",
      "Epoch 54/10000\n",
      "85/85 [==============================] - 0s 987us/step - loss: 1244.9236 - val_loss: 261.8857\n",
      "\n",
      "Epoch 00054: val_loss improved from 338.02692 to 261.88565, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 55/10000\n",
      "85/85 [==============================] - 0s 971us/step - loss: 1224.7115 - val_loss: 266.7548\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 261.88565\n",
      "Epoch 56/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1216.7124 - val_loss: 561.4462\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 261.88565\n",
      "Epoch 57/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 932us/step - loss: 1238.9869 - val_loss: 315.2453\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 261.88565\n",
      "Epoch 58/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1189.2695 - val_loss: 705.0402\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 261.88565\n",
      "Epoch 59/10000\n",
      "85/85 [==============================] - 0s 978us/step - loss: 1242.5078 - val_loss: 278.2971\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 261.88565\n",
      "Epoch 60/10000\n",
      "85/85 [==============================] - 0s 985us/step - loss: 1232.1176 - val_loss: 327.1543\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 261.88565\n",
      "Epoch 61/10000\n",
      "85/85 [==============================] - 0s 986us/step - loss: 1222.8457 - val_loss: 481.2281\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 261.88565\n",
      "Epoch 62/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1197.9891 - val_loss: 297.1524\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 261.88565\n",
      "Epoch 63/10000\n",
      "85/85 [==============================] - 0s 932us/step - loss: 1230.4846 - val_loss: 225.6894\n",
      "\n",
      "Epoch 00063: val_loss improved from 261.88565 to 225.68939, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 64/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1219.1309 - val_loss: 269.4391\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 225.68939\n",
      "Epoch 65/10000\n",
      "85/85 [==============================] - 0s 934us/step - loss: 1230.7957 - val_loss: 220.5321\n",
      "\n",
      "Epoch 00065: val_loss improved from 225.68939 to 220.53207, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 66/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1236.0962 - val_loss: 411.8703\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 220.53207\n",
      "Epoch 67/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.3920 - val_loss: 282.7940\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 220.53207\n",
      "Epoch 68/10000\n",
      "85/85 [==============================] - 0s 968us/step - loss: 1202.7513 - val_loss: 587.0382\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 220.53207\n",
      "Epoch 69/10000\n",
      "85/85 [==============================] - 0s 994us/step - loss: 1210.6620 - val_loss: 588.4720\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 220.53207\n",
      "Epoch 70/10000\n",
      "85/85 [==============================] - 0s 973us/step - loss: 1233.0248 - val_loss: 354.3352\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 220.53207\n",
      "Epoch 71/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1165.8027 - val_loss: 793.5179\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 220.53207\n",
      "Epoch 72/10000\n",
      "85/85 [==============================] - 0s 917us/step - loss: 1240.0698 - val_loss: 245.6316\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 220.53207\n",
      "Epoch 73/10000\n",
      "85/85 [==============================] - 0s 958us/step - loss: 1203.8914 - val_loss: 446.6737\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 220.53207\n",
      "Epoch 74/10000\n",
      "85/85 [==============================] - 0s 962us/step - loss: 1209.7904 - val_loss: 552.6998\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 220.53207\n",
      "Epoch 75/10000\n",
      "85/85 [==============================] - 0s 982us/step - loss: 1170.2642 - val_loss: 665.0433\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 220.53207\n",
      "Epoch 76/10000\n",
      "85/85 [==============================] - 0s 980us/step - loss: 1171.2631 - val_loss: 551.0806\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 220.53207\n",
      "Epoch 77/10000\n",
      "85/85 [==============================] - 0s 976us/step - loss: 1235.4600 - val_loss: 233.7607\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 220.53207\n",
      "Epoch 78/10000\n",
      "85/85 [==============================] - 0s 961us/step - loss: 1231.7610 - val_loss: 203.9690\n",
      "\n",
      "Epoch 00078: val_loss improved from 220.53207 to 203.96902, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 79/10000\n",
      "85/85 [==============================] - 0s 947us/step - loss: 1233.1116 - val_loss: 234.8743\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 203.96902\n",
      "Epoch 80/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.5803 - val_loss: 208.4250\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 203.96902\n",
      "Epoch 81/10000\n",
      "85/85 [==============================] - 0s 923us/step - loss: 1232.5291 - val_loss: 255.3484\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 203.96902\n",
      "Epoch 82/10000\n",
      "85/85 [==============================] - 0s 950us/step - loss: 1232.2456 - val_loss: 238.3777\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 203.96902\n",
      "Epoch 83/10000\n",
      "85/85 [==============================] - 0s 989us/step - loss: 1233.2882 - val_loss: 248.3453\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 203.96902\n",
      "Epoch 84/10000\n",
      "85/85 [==============================] - 0s 941us/step - loss: 1232.1360 - val_loss: 214.5679\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 203.96902\n",
      "Epoch 85/10000\n",
      "85/85 [==============================] - 0s 961us/step - loss: 1232.2877 - val_loss: 213.2721\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 203.96902\n",
      "Epoch 86/10000\n",
      "85/85 [==============================] - 0s 991us/step - loss: 1231.7861 - val_loss: 202.0392\n",
      "\n",
      "Epoch 00086: val_loss improved from 203.96902 to 202.03922, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 87/10000\n",
      "85/85 [==============================] - 0s 945us/step - loss: 1232.2017 - val_loss: 200.9798\n",
      "\n",
      "Epoch 00087: val_loss improved from 202.03922 to 200.97984, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 88/10000\n",
      "85/85 [==============================] - 0s 976us/step - loss: 1231.7406 - val_loss: 212.0620\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 200.97984\n",
      "Epoch 89/10000\n",
      "85/85 [==============================] - 0s 979us/step - loss: 1232.0377 - val_loss: 238.8384\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 200.97984\n",
      "Epoch 90/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.4353 - val_loss: 258.3032\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 200.97984\n",
      "Epoch 91/10000\n",
      "85/85 [==============================] - 0s 926us/step - loss: 1232.0442 - val_loss: 252.1624\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 200.97984\n",
      "Epoch 92/10000\n",
      "85/85 [==============================] - 0s 955us/step - loss: 1230.9135 - val_loss: 207.1145\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 200.97984\n",
      "Epoch 93/10000\n",
      "85/85 [==============================] - 0s 962us/step - loss: 1231.5225 - val_loss: 198.9397\n",
      "\n",
      "Epoch 00093: val_loss improved from 200.97984 to 198.93965, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 94/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.3730 - val_loss: 253.7126\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 198.93965\n",
      "Epoch 95/10000\n",
      "85/85 [==============================] - 0s 957us/step - loss: 1232.6195 - val_loss: 222.8337\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 198.93965\n",
      "Epoch 96/10000\n",
      "85/85 [==============================] - 0s 973us/step - loss: 1232.6633 - val_loss: 222.9342\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 198.93965\n",
      "Epoch 97/10000\n",
      "85/85 [==============================] - 0s 957us/step - loss: 1232.0068 - val_loss: 210.4102\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 198.93965\n",
      "Epoch 98/10000\n",
      "85/85 [==============================] - 0s 967us/step - loss: 1232.5264 - val_loss: 227.0078\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 198.93965\n",
      "Epoch 99/10000\n",
      "85/85 [==============================] - 0s 974us/step - loss: 1232.8959 - val_loss: 197.5875\n",
      "\n",
      "Epoch 00099: val_loss improved from 198.93965 to 197.58749, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 100/10000\n",
      "85/85 [==============================] - 0s 948us/step - loss: 1231.3656 - val_loss: 201.8530\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 197.58749\n",
      "Epoch 101/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.6991 - val_loss: 272.0342\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 197.58749\n",
      "Epoch 102/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.4935 - val_loss: 269.9793\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 197.58749\n",
      "Epoch 103/10000\n",
      "85/85 [==============================] - 0s 931us/step - loss: 1232.7151 - val_loss: 215.5751\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 197.58749\n",
      "Epoch 104/10000\n",
      "85/85 [==============================] - 0s 965us/step - loss: 1233.3303 - val_loss: 230.7504\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 197.58749\n",
      "Epoch 105/10000\n",
      "85/85 [==============================] - 0s 990us/step - loss: 1231.9843 - val_loss: 203.6793\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 197.58749\n",
      "Epoch 106/10000\n",
      "85/85 [==============================] - 0s 995us/step - loss: 1232.2329 - val_loss: 223.4617\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 197.58749\n",
      "Epoch 107/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.3535 - val_loss: 197.9102\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 197.58749\n",
      "Epoch 108/10000\n",
      "85/85 [==============================] - 0s 963us/step - loss: 1231.7528 - val_loss: 247.6324\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 197.58749\n",
      "Epoch 109/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.2805 - val_loss: 232.7802\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 197.58749\n",
      "Epoch 110/10000\n",
      "85/85 [==============================] - 0s 970us/step - loss: 1232.2771 - val_loss: 204.1882\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 197.58749\n",
      "Epoch 111/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9186 - val_loss: 224.1059\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 197.58749\n",
      "Epoch 112/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.7958 - val_loss: 244.2717\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 197.58749\n",
      "Epoch 113/10000\n",
      "85/85 [==============================] - 0s 941us/step - loss: 1232.4318 - val_loss: 247.9517\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 197.58749\n",
      "Epoch 114/10000\n",
      "85/85 [==============================] - 0s 987us/step - loss: 1230.3956 - val_loss: 200.9658\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 197.58749\n",
      "Epoch 115/10000\n",
      "85/85 [==============================] - 0s 991us/step - loss: 1232.4088 - val_loss: 196.2234\n",
      "\n",
      "Epoch 00115: val_loss improved from 197.58749 to 196.22342, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 116/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.1968 - val_loss: 235.9397\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 196.22342\n",
      "Epoch 117/10000\n",
      "85/85 [==============================] - 0s 996us/step - loss: 1232.8790 - val_loss: 236.2865\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 196.22342\n",
      "Epoch 118/10000\n",
      "85/85 [==============================] - 0s 989us/step - loss: 1230.3962 - val_loss: 206.0576\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 196.22342\n",
      "Epoch 119/10000\n",
      "85/85 [==============================] - 0s 998us/step - loss: 1232.9993 - val_loss: 211.4605\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 196.22342\n",
      "Epoch 120/10000\n",
      "85/85 [==============================] - 0s 978us/step - loss: 1231.8896 - val_loss: 207.1914\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 196.22342\n",
      "Epoch 121/10000\n",
      "85/85 [==============================] - 0s 946us/step - loss: 1232.2787 - val_loss: 205.2349\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 196.22342\n",
      "Epoch 122/10000\n",
      "85/85 [==============================] - 0s 951us/step - loss: 1232.8657 - val_loss: 217.7995\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 196.22342\n",
      "Epoch 123/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9976 - val_loss: 250.3176\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 196.22342\n",
      "Epoch 124/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.1210 - val_loss: 193.0200\n",
      "\n",
      "Epoch 00124: val_loss improved from 196.22342 to 193.02000, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 125/10000\n",
      "85/85 [==============================] - 0s 962us/step - loss: 1233.3414 - val_loss: 233.2338\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 193.02000\n",
      "Epoch 126/10000\n",
      "85/85 [==============================] - 0s 963us/step - loss: 1231.4771 - val_loss: 309.9864\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 193.02000\n",
      "Epoch 127/10000\n",
      "85/85 [==============================] - 0s 979us/step - loss: 1231.8811 - val_loss: 210.9087\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 193.02000\n",
      "Epoch 128/10000\n",
      "85/85 [==============================] - 0s 971us/step - loss: 1232.2084 - val_loss: 227.4869\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 193.02000\n",
      "Epoch 129/10000\n",
      "85/85 [==============================] - 0s 992us/step - loss: 1232.4060 - val_loss: 212.2465\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 193.02000\n",
      "Epoch 130/10000\n",
      "85/85 [==============================] - 0s 995us/step - loss: 1231.3098 - val_loss: 292.5013\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 193.02000\n",
      "Epoch 131/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.9178 - val_loss: 234.0974\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 193.02000\n",
      "Epoch 132/10000\n",
      "85/85 [==============================] - 0s 912us/step - loss: 1231.7841 - val_loss: 235.9133\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 193.02000\n",
      "Epoch 133/10000\n",
      "85/85 [==============================] - 0s 955us/step - loss: 1231.9192 - val_loss: 227.0682\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 193.02000\n",
      "Epoch 134/10000\n",
      "85/85 [==============================] - 0s 967us/step - loss: 1231.2479 - val_loss: 265.9682\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 193.02000\n",
      "Epoch 135/10000\n",
      "85/85 [==============================] - 0s 971us/step - loss: 1233.8474 - val_loss: 247.1177\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 193.02000\n",
      "Epoch 136/10000\n",
      "85/85 [==============================] - 0s 977us/step - loss: 1232.0549 - val_loss: 209.0589\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 193.02000\n",
      "Epoch 137/10000\n",
      "85/85 [==============================] - 0s 961us/step - loss: 1232.7855 - val_loss: 250.9755\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 193.02000\n",
      "Epoch 138/10000\n",
      "85/85 [==============================] - 0s 964us/step - loss: 1231.2747 - val_loss: 196.7941\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 193.02000\n",
      "Epoch 139/10000\n",
      "85/85 [==============================] - 0s 975us/step - loss: 1232.4146 - val_loss: 225.8190\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 193.02000\n",
      "Epoch 140/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.3654 - val_loss: 193.0200\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 193.02000\n",
      "Epoch 141/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.6514 - val_loss: 194.1511\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 193.02000\n",
      "Epoch 142/10000\n",
      "85/85 [==============================] - 0s 952us/step - loss: 1233.0424 - val_loss: 206.0845\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 193.02000\n",
      "Epoch 143/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9070 - val_loss: 257.0412\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 193.02000\n",
      "Epoch 144/10000\n",
      "85/85 [==============================] - 0s 988us/step - loss: 1231.8585 - val_loss: 225.2742\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 193.02000\n",
      "Epoch 145/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.0226 - val_loss: 204.1358\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 193.02000\n",
      "Epoch 146/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.2075 - val_loss: 241.8123\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 193.02000\n",
      "Epoch 147/10000\n",
      "85/85 [==============================] - 0s 943us/step - loss: 1232.0616 - val_loss: 225.2089\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 193.02000\n",
      "Epoch 148/10000\n",
      "85/85 [==============================] - 0s 982us/step - loss: 1232.9591 - val_loss: 266.0037\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 193.02000\n",
      "Epoch 149/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.1582 - val_loss: 286.4088\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 193.02000\n",
      "Epoch 150/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.6240 - val_loss: 235.5014\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 193.02000\n",
      "Epoch 151/10000\n",
      "85/85 [==============================] - 0s 922us/step - loss: 1231.7438 - val_loss: 252.4719\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 193.02000\n",
      "Epoch 152/10000\n",
      "85/85 [==============================] - 0s 964us/step - loss: 1231.4084 - val_loss: 222.1008\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 193.02000\n",
      "Epoch 153/10000\n",
      "85/85 [==============================] - 0s 961us/step - loss: 1233.2163 - val_loss: 237.0973\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 193.02000\n",
      "Epoch 154/10000\n",
      "85/85 [==============================] - 0s 979us/step - loss: 1231.9525 - val_loss: 246.6302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00154: val_loss did not improve from 193.02000\n",
      "Epoch 155/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.8987 - val_loss: 285.4426\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 193.02000\n",
      "Epoch 156/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1230.7330 - val_loss: 251.4997\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 193.02000\n",
      "Epoch 157/10000\n",
      "85/85 [==============================] - 0s 921us/step - loss: 1231.2362 - val_loss: 194.0053\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 193.02000\n",
      "Epoch 158/10000\n",
      "85/85 [==============================] - 0s 968us/step - loss: 1232.7792 - val_loss: 213.0067\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 193.02000\n",
      "Epoch 159/10000\n",
      "85/85 [==============================] - 0s 959us/step - loss: 1228.1074 - val_loss: 364.4563\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 193.02000\n",
      "Epoch 160/10000\n",
      "85/85 [==============================] - 0s 979us/step - loss: 1234.4276 - val_loss: 251.8925\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 193.02000\n",
      "Epoch 161/10000\n",
      "85/85 [==============================] - 0s 967us/step - loss: 1233.5256 - val_loss: 223.8354\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 193.02000\n",
      "Epoch 162/10000\n",
      "85/85 [==============================] - 0s 976us/step - loss: 1232.2411 - val_loss: 231.6385\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 193.02000\n",
      "Epoch 163/10000\n",
      "85/85 [==============================] - 0s 969us/step - loss: 1233.8936 - val_loss: 222.2030\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 193.02000\n",
      "Epoch 164/10000\n",
      "85/85 [==============================] - 0s 967us/step - loss: 1231.3583 - val_loss: 314.6172\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 193.02000\n",
      "Epoch 165/10000\n",
      "85/85 [==============================] - 0s 968us/step - loss: 1233.6869 - val_loss: 281.9915\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 193.02000\n",
      "Epoch 166/10000\n",
      "85/85 [==============================] - 0s 977us/step - loss: 1232.8307 - val_loss: 222.8231\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 193.02000\n",
      "Epoch 167/10000\n",
      "85/85 [==============================] - 0s 982us/step - loss: 1231.9550 - val_loss: 250.8890\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 193.02000\n",
      "Epoch 168/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.6814 - val_loss: 223.0928\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 193.02000\n",
      "Epoch 169/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.2338 - val_loss: 213.1127\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 193.02000\n",
      "Epoch 170/10000\n",
      "85/85 [==============================] - 0s 986us/step - loss: 1232.0122 - val_loss: 238.3327\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 193.02000\n",
      "Epoch 171/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.5834 - val_loss: 300.2438\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 193.02000\n",
      "Epoch 172/10000\n",
      "85/85 [==============================] - 0s 921us/step - loss: 1232.6942 - val_loss: 266.1363\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 193.02000\n",
      "Epoch 173/10000\n",
      "85/85 [==============================] - 0s 958us/step - loss: 1231.9771 - val_loss: 286.1644\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 193.02000\n",
      "Epoch 174/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.1886 - val_loss: 263.0844\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 193.02000\n",
      "Epoch 175/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.6062 - val_loss: 206.8324\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 193.02000\n",
      "Epoch 176/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.8811 - val_loss: 216.6586\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 193.02000\n",
      "Epoch 177/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.8599 - val_loss: 210.8412\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 193.02000\n",
      "Epoch 178/10000\n",
      "85/85 [==============================] - 0s 924us/step - loss: 1232.7955 - val_loss: 211.9582\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 193.02000\n",
      "Epoch 179/10000\n",
      "85/85 [==============================] - 0s 963us/step - loss: 1232.2051 - val_loss: 208.6037\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 193.02000\n",
      "Epoch 180/10000\n",
      "85/85 [==============================] - 0s 959us/step - loss: 1228.1152 - val_loss: 572.2625\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 193.02000\n",
      "Epoch 181/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1228.4949 - val_loss: 223.3859\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 193.02000\n",
      "Epoch 182/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.2611 - val_loss: 223.5833\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 193.02000\n",
      "Epoch 183/10000\n",
      "85/85 [==============================] - 0s 986us/step - loss: 1232.3423 - val_loss: 212.5878\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 193.02000\n",
      "Epoch 184/10000\n",
      "85/85 [==============================] - 0s 995us/step - loss: 1232.2133 - val_loss: 236.6191\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 193.02000\n",
      "Epoch 185/10000\n",
      "85/85 [==============================] - 0s 987us/step - loss: 1232.4634 - val_loss: 261.4842\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 193.02000\n",
      "Epoch 186/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.1895 - val_loss: 205.7581\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 193.02000\n",
      "Epoch 187/10000\n",
      "85/85 [==============================] - 0s 985us/step - loss: 1231.7865 - val_loss: 234.9112\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 193.02000\n",
      "Epoch 188/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.6765 - val_loss: 238.6839\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 193.02000\n",
      "Epoch 189/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.1942 - val_loss: 213.2737\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 193.02000\n",
      "Epoch 190/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.8390 - val_loss: 215.3023\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 193.02000\n",
      "Epoch 191/10000\n",
      "85/85 [==============================] - 0s 971us/step - loss: 1232.0745 - val_loss: 232.9227\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 193.02000\n",
      "Epoch 192/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.6073 - val_loss: 263.7962\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 193.02000\n",
      "Epoch 193/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.4299 - val_loss: 213.7301\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 193.02000\n",
      "Epoch 194/10000\n",
      "85/85 [==============================] - 0s 981us/step - loss: 1231.9293 - val_loss: 241.5005\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 193.02000\n",
      "Epoch 195/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.9539 - val_loss: 227.4634\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 193.02000\n",
      "Epoch 196/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.3632 - val_loss: 249.7482\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 193.02000\n",
      "Epoch 197/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.7551 - val_loss: 234.9028\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 193.02000\n",
      "Epoch 198/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.6456 - val_loss: 219.4198\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 193.02000\n",
      "Epoch 199/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.9652 - val_loss: 197.5970\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 193.02000\n",
      "Epoch 200/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.1600 - val_loss: 201.6623\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 193.02000\n",
      "Epoch 201/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.5513 - val_loss: 228.5199\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 193.02000\n",
      "Epoch 202/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.5841 - val_loss: 236.3321\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 193.02000\n",
      "Epoch 203/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1229.5330 - val_loss: 193.4215\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 193.02000\n",
      "Epoch 204/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.7418 - val_loss: 226.0004\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 193.02000\n",
      "Epoch 205/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.6552 - val_loss: 258.1670\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 193.02000\n",
      "Epoch 206/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1230.2611 - val_loss: 212.8980\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 193.02000\n",
      "Epoch 207/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.1396 - val_loss: 247.6513\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 193.02000\n",
      "Epoch 208/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.3835 - val_loss: 263.4014\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 193.02000\n",
      "Epoch 209/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.4392 - val_loss: 223.4291\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 193.02000\n",
      "Epoch 210/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.7699 - val_loss: 231.8722\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 193.02000\n",
      "Epoch 211/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1230.7830 - val_loss: 189.9975\n",
      "\n",
      "Epoch 00211: val_loss improved from 193.02000 to 189.99750, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 212/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1234.4620 - val_loss: 203.9787\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 189.99750\n",
      "Epoch 213/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9879 - val_loss: 229.6652\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 189.99750\n",
      "Epoch 214/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.3569 - val_loss: 238.2747\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 189.99750\n",
      "Epoch 215/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.7162 - val_loss: 225.5963\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 189.99750\n",
      "Epoch 216/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.7997 - val_loss: 252.9525\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 189.99750\n",
      "Epoch 217/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.5769 - val_loss: 211.1351\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 189.99750\n",
      "Epoch 218/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.5232 - val_loss: 228.5208\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 189.99750\n",
      "Epoch 219/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.2683 - val_loss: 205.0648\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 189.99750\n",
      "Epoch 220/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.0298 - val_loss: 257.3944\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 189.99750\n",
      "Epoch 221/10000\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1232.9407 - val_loss: 275.3335\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 189.99750\n",
      "Epoch 222/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.2103 - val_loss: 252.1255\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 189.99750\n",
      "Epoch 223/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9594 - val_loss: 209.8042\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 189.99750\n",
      "Epoch 224/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.3125 - val_loss: 258.6026\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 189.99750\n",
      "Epoch 225/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1234.0374 - val_loss: 224.8622\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 189.99750\n",
      "Epoch 226/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.2537 - val_loss: 230.7268\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 189.99750\n",
      "Epoch 227/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9506 - val_loss: 240.7432\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 189.99750\n",
      "Epoch 228/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.7319 - val_loss: 222.4666\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 189.99750\n",
      "Epoch 229/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.5359 - val_loss: 235.3698\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 189.99750\n",
      "Epoch 230/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.4537 - val_loss: 202.1124\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 189.99750\n",
      "Epoch 231/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.1846 - val_loss: 212.8159\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 189.99750\n",
      "Epoch 232/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9380 - val_loss: 254.4662\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 189.99750\n",
      "Epoch 233/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.8759 - val_loss: 283.3119\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 189.99750\n",
      "Epoch 234/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.8766 - val_loss: 224.3485\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 189.99750\n",
      "Epoch 235/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.3976 - val_loss: 222.2287\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 189.99750\n",
      "Epoch 236/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.0024 - val_loss: 227.5248\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 189.99750\n",
      "Epoch 237/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.8744 - val_loss: 255.4119\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 189.99750\n",
      "Epoch 238/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.4849 - val_loss: 294.4359\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 189.99750\n",
      "Epoch 239/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.7740 - val_loss: 214.7567\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 189.99750\n",
      "Epoch 240/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.5729 - val_loss: 230.7114\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 189.99750\n",
      "Epoch 241/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.5322 - val_loss: 243.2744\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 189.99750\n",
      "Epoch 242/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.9104 - val_loss: 221.7248\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 189.99750\n",
      "Epoch 243/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.3669 - val_loss: 207.9068\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 189.99750\n",
      "Epoch 244/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9434 - val_loss: 264.4523\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 189.99750\n",
      "Epoch 245/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.2524 - val_loss: 299.6057\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 189.99750\n",
      "Epoch 246/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.4724 - val_loss: 294.4258\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 189.99750\n",
      "Epoch 247/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.8115 - val_loss: 199.7218\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 189.99750\n",
      "Epoch 248/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.9019 - val_loss: 212.9261\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 189.99750\n",
      "Epoch 249/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.2917 - val_loss: 225.2573\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 189.99750\n",
      "Epoch 250/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.9786 - val_loss: 205.5081\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 189.99750\n",
      "Epoch 251/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9487 - val_loss: 244.4875\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 189.99750\n",
      "Epoch 252/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.4592 - val_loss: 232.2071\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 189.99750\n",
      "Epoch 253/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.3425 - val_loss: 202.7370\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 189.99750\n",
      "Epoch 254/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1230.9115 - val_loss: 284.7337\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 189.99750\n",
      "Epoch 255/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.4961 - val_loss: 308.7659\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 189.99750\n",
      "Epoch 256/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.3402 - val_loss: 212.3605\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 189.99750\n",
      "Epoch 257/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.5996 - val_loss: 219.2240\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 189.99750\n",
      "Epoch 258/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.2302 - val_loss: 217.5802\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 189.99750\n",
      "Epoch 259/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.1766 - val_loss: 219.0157\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 189.99750\n",
      "Epoch 260/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1229.6219 - val_loss: 214.2126\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 189.99750\n",
      "Epoch 261/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1229.6334 - val_loss: 258.6084\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 189.99750\n",
      "Epoch 262/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.4850 - val_loss: 209.1052\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 189.99750\n",
      "Epoch 263/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.7417 - val_loss: 234.5213\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 189.99750\n",
      "Epoch 264/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.8970 - val_loss: 198.7847\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 189.99750\n",
      "Epoch 265/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.7866 - val_loss: 197.8936\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 189.99750\n",
      "Epoch 266/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.8242 - val_loss: 241.8802\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 189.99750\n",
      "Epoch 267/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1230.8258 - val_loss: 295.8756\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 189.99750\n",
      "Epoch 268/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.0990 - val_loss: 260.9805\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 189.99750\n",
      "Epoch 269/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.7440 - val_loss: 238.2695\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 189.99750\n",
      "Epoch 270/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.8019 - val_loss: 214.4726\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 189.99750\n",
      "Epoch 271/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.8733 - val_loss: 229.2018\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 189.99750\n",
      "Epoch 272/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.7028 - val_loss: 195.3773\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 189.99750\n",
      "Epoch 273/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.1058 - val_loss: 205.5309\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 189.99750\n",
      "Epoch 274/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.0885 - val_loss: 217.5518\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 189.99750\n",
      "Epoch 275/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.3231 - val_loss: 265.9068\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 189.99750\n",
      "Epoch 276/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.3958 - val_loss: 228.8852\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 189.99750\n",
      "Epoch 277/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9690 - val_loss: 272.3181\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 189.99750\n",
      "Epoch 278/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.7574 - val_loss: 225.3446\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 189.99750\n",
      "Epoch 279/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.5739 - val_loss: 233.6073\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 189.99750\n",
      "Epoch 280/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.7671 - val_loss: 272.2894\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 189.99750\n",
      "Epoch 281/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.3025 - val_loss: 228.1756\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 189.99750\n",
      "Epoch 282/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.3572 - val_loss: 247.0749\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 189.99750\n",
      "Epoch 283/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.5042 - val_loss: 240.1326\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 189.99750\n",
      "Epoch 284/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1230.7283 - val_loss: 255.1029\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 189.99750\n",
      "Epoch 285/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.4542 - val_loss: 220.8603\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 189.99750\n",
      "Epoch 286/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.0187 - val_loss: 271.1980\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 189.99750\n",
      "Epoch 287/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.8330 - val_loss: 274.4201\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 189.99750\n",
      "Epoch 288/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.7787 - val_loss: 232.1447\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 189.99750\n",
      "Epoch 289/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1229.4902 - val_loss: 281.7369\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 189.99750\n",
      "Epoch 290/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.6534 - val_loss: 195.1145\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 189.99750\n",
      "Epoch 291/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.0702 - val_loss: 221.3665\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 189.99750\n",
      "Epoch 292/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.0457 - val_loss: 248.1805\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 189.99750\n",
      "Epoch 293/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9946 - val_loss: 196.0400\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 189.99750\n",
      "Epoch 294/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.8949 - val_loss: 260.8338\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 189.99750\n",
      "Epoch 295/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.2168 - val_loss: 318.9391\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 189.99750\n",
      "Epoch 296/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.0693 - val_loss: 226.7863\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 189.99750\n",
      "Epoch 297/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.0128 - val_loss: 249.8536\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 189.99750\n",
      "Epoch 298/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.5886 - val_loss: 195.5520\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 189.99750\n",
      "Epoch 299/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.2125 - val_loss: 226.6638\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 189.99750\n",
      "Epoch 300/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.0288 - val_loss: 277.6911\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 189.99750\n",
      "Epoch 301/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9990 - val_loss: 222.0116\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 189.99750\n",
      "Epoch 302/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.1958 - val_loss: 193.3754\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 189.99750\n",
      "Epoch 303/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.7434 - val_loss: 224.3560\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 189.99750\n",
      "Epoch 304/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1230.8058 - val_loss: 197.0796\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 189.99750\n",
      "Epoch 305/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1232.7947 - val_loss: 252.2879\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 189.99750\n",
      "Epoch 306/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 1ms/step - loss: 1230.5789 - val_loss: 207.3212\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 189.99750\n",
      "Epoch 307/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.9766 - val_loss: 218.1606\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 189.99750\n",
      "Epoch 308/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.0125 - val_loss: 299.9963\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 189.99750\n",
      "Epoch 309/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1231.5665 - val_loss: 328.8273\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 189.99750\n",
      "Epoch 310/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.4518 - val_loss: 261.6107\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 189.99750\n",
      "Epoch 311/10000\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 1233.0846 - val_loss: 238.4207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▏   | 20/21 [36:12<01:41, 101.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00311: val_loss did not improve from 189.99750\n",
      "Epoch 1/10000\n",
      "55/55 [==============================] - 1s 3ms/step - loss: 12127.2539 - val_loss: 7131.4707\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7131.47070, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10189.0830 - val_loss: 18639.3242\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 7131.47070\n",
      "Epoch 3/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12268.2207 - val_loss: 12806.8662\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 7131.47070\n",
      "Epoch 4/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13048.6250 - val_loss: 12790.0537\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 7131.47070\n",
      "Epoch 5/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12632.2471 - val_loss: 12794.9189\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 7131.47070\n",
      "Epoch 6/10000\n",
      "55/55 [==============================] - 0s 993us/step - loss: 12735.4395 - val_loss: 12820.7266\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 7131.47070\n",
      "Epoch 7/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12856.9590 - val_loss: 12751.8408\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 7131.47070\n",
      "Epoch 8/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12798.0244 - val_loss: 12767.1387\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 7131.47070\n",
      "Epoch 9/10000\n",
      "55/55 [==============================] - 0s 989us/step - loss: 12491.6025 - val_loss: 12813.2334\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 7131.47070\n",
      "Epoch 10/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12850.3604 - val_loss: 12798.0898\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 7131.47070\n",
      "Epoch 11/10000\n",
      "55/55 [==============================] - 0s 998us/step - loss: 12667.3555 - val_loss: 12608.0459\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 7131.47070\n",
      "Epoch 12/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11995.5947 - val_loss: 4951.3027\n",
      "\n",
      "Epoch 00012: val_loss improved from 7131.47070 to 4951.30273, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 13/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11726.7900 - val_loss: 7369.5869\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4951.30273\n",
      "Epoch 14/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12428.8320 - val_loss: 12819.5625\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4951.30273\n",
      "Epoch 15/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12258.2656 - val_loss: 1137.4801\n",
      "\n",
      "Epoch 00015: val_loss improved from 4951.30273 to 1137.48010, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 16/10000\n",
      "55/55 [==============================] - 0s 979us/step - loss: 12249.5166 - val_loss: 12764.0791\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1137.48010\n",
      "Epoch 17/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11801.8145 - val_loss: 12785.4502\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1137.48010\n",
      "Epoch 18/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11984.1396 - val_loss: 12783.6201\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1137.48010\n",
      "Epoch 19/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13015.0156 - val_loss: 12759.0859\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1137.48010\n",
      "Epoch 20/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12371.0420 - val_loss: 10536.1934\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1137.48010\n",
      "Epoch 21/10000\n",
      "55/55 [==============================] - 0s 993us/step - loss: 12313.3125 - val_loss: 6980.6577\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1137.48010\n",
      "Epoch 22/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11452.3262 - val_loss: 11498.6953\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1137.48010\n",
      "Epoch 23/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12365.1689 - val_loss: 12802.0879\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1137.48010\n",
      "Epoch 24/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12162.2158 - val_loss: 12580.1367\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1137.48010\n",
      "Epoch 25/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11947.2354 - val_loss: 12785.5850\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1137.48010\n",
      "Epoch 26/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12545.7666 - val_loss: 12732.1523\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1137.48010\n",
      "Epoch 27/10000\n",
      "55/55 [==============================] - 0s 988us/step - loss: 12076.4375 - val_loss: 18579.2969\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1137.48010\n",
      "Epoch 28/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12051.2695 - val_loss: 12790.1133\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1137.48010\n",
      "Epoch 29/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13076.7432 - val_loss: 12626.9434\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1137.48010\n",
      "Epoch 30/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12208.9746 - val_loss: 12780.0537\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1137.48010\n",
      "Epoch 31/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12115.7217 - val_loss: 12138.2695\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1137.48010\n",
      "Epoch 32/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11924.9824 - val_loss: 12546.4990\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1137.48010\n",
      "Epoch 33/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11418.2100 - val_loss: 2077.6187\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1137.48010\n",
      "Epoch 34/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11423.0205 - val_loss: 7282.6606\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1137.48010\n",
      "Epoch 35/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11883.0518 - val_loss: 12809.5029\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1137.48010\n",
      "Epoch 36/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11467.5176 - val_loss: 12667.7549\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1137.48010\n",
      "Epoch 37/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11500.0283 - val_loss: 12766.9004\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1137.48010\n",
      "Epoch 38/10000\n",
      "55/55 [==============================] - 0s 998us/step - loss: 12582.6650 - val_loss: 12803.6748\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1137.48010\n",
      "Epoch 39/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11373.3086 - val_loss: 12776.4072\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1137.48010\n",
      "Epoch 40/10000\n",
      "55/55 [==============================] - 0s 995us/step - loss: 11857.1553 - val_loss: 3213.8657\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1137.48010\n",
      "Epoch 41/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11532.3535 - val_loss: 12733.2510\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1137.48010\n",
      "Epoch 42/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12404.2246 - val_loss: 12821.6064\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1137.48010\n",
      "Epoch 43/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12764.5967 - val_loss: 15200.7871\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1137.48010\n",
      "Epoch 44/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11805.0010 - val_loss: 12659.0859\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1137.48010\n",
      "Epoch 45/10000\n",
      "55/55 [==============================] - 0s 991us/step - loss: 11472.5596 - val_loss: 12774.1875\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1137.48010\n",
      "Epoch 46/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11521.5088 - val_loss: 39372.6289\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1137.48010\n",
      "Epoch 47/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12071.5684 - val_loss: 19738.1680\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1137.48010\n",
      "Epoch 48/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12799.1416 - val_loss: 12749.0527\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1137.48010\n",
      "Epoch 49/10000\n",
      "55/55 [==============================] - 0s 993us/step - loss: 11848.1357 - val_loss: 11097.5488\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1137.48010\n",
      "Epoch 50/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11606.3516 - val_loss: 8348.8623\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1137.48010\n",
      "Epoch 51/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10770.8428 - val_loss: 12753.0137\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1137.48010\n",
      "Epoch 52/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10968.5771 - val_loss: 8028.0132\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1137.48010\n",
      "Epoch 53/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11789.0273 - val_loss: 12640.8174\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1137.48010\n",
      "Epoch 54/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11177.3164 - val_loss: 12725.7354\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1137.48010\n",
      "Epoch 55/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12294.2793 - val_loss: 10082.3984\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1137.48010\n",
      "Epoch 56/10000\n",
      "55/55 [==============================] - 0s 991us/step - loss: 11968.4258 - val_loss: 12854.8496\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1137.48010\n",
      "Epoch 57/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11085.6846 - val_loss: 12716.3584\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1137.48010\n",
      "Epoch 58/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11488.9404 - val_loss: 12776.5049\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1137.48010\n",
      "Epoch 59/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12019.2041 - val_loss: 12185.3984\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1137.48010\n",
      "Epoch 60/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11138.6641 - val_loss: 12762.9912\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1137.48010\n",
      "Epoch 61/10000\n",
      "55/55 [==============================] - 0s 980us/step - loss: 11566.7949 - val_loss: 3614.8406\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1137.48010\n",
      "Epoch 62/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11629.4551 - val_loss: 12769.5410\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1137.48010\n",
      "Epoch 63/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11428.7188 - val_loss: 12662.5537\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1137.48010\n",
      "Epoch 64/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11723.9111 - val_loss: 12608.3779\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1137.48010\n",
      "Epoch 65/10000\n",
      "55/55 [==============================] - 0s 988us/step - loss: 11859.6602 - val_loss: 12775.7979\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1137.48010\n",
      "Epoch 66/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12846.7051 - val_loss: 11326.7617\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1137.48010\n",
      "Epoch 67/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11953.4639 - val_loss: 12823.7441\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1137.48010\n",
      "Epoch 68/10000\n",
      "55/55 [==============================] - 0s 983us/step - loss: 11768.9365 - val_loss: 9320.7471\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1137.48010\n",
      "Epoch 69/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11129.5176 - val_loss: 12711.1758\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1137.48010\n",
      "Epoch 70/10000\n",
      "55/55 [==============================] - 0s 991us/step - loss: 12237.1973 - val_loss: 12480.6484\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1137.48010\n",
      "Epoch 71/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11483.9824 - val_loss: 12810.7451\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1137.48010\n",
      "Epoch 72/10000\n",
      "55/55 [==============================] - 0s 992us/step - loss: 11984.2051 - val_loss: 12741.8037\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1137.48010\n",
      "Epoch 73/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11360.2871 - val_loss: 12607.5850\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1137.48010\n",
      "Epoch 74/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10579.3877 - val_loss: 11019.0508\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1137.48010\n",
      "Epoch 75/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11006.2041 - val_loss: 20996.9883\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1137.48010\n",
      "Epoch 76/10000\n",
      "55/55 [==============================] - 0s 981us/step - loss: 12609.8633 - val_loss: 12683.5215\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1137.48010\n",
      "Epoch 77/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12303.3838 - val_loss: 2902.9612\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1137.48010\n",
      "Epoch 78/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11182.8730 - val_loss: 11270.0908\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1137.48010\n",
      "Epoch 79/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12356.9131 - val_loss: 12778.2227\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1137.48010\n",
      "Epoch 80/10000\n",
      "55/55 [==============================] - 0s 998us/step - loss: 12822.6162 - val_loss: 12794.7441\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1137.48010\n",
      "Epoch 81/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12221.5254 - val_loss: 12458.1172\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1137.48010\n",
      "Epoch 82/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11125.4385 - val_loss: 12485.0498\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1137.48010\n",
      "Epoch 83/10000\n",
      "55/55 [==============================] - 0s 990us/step - loss: 11014.5146 - val_loss: 10294.8271\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1137.48010\n",
      "Epoch 84/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12147.1738 - val_loss: 3231.2720\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1137.48010\n",
      "Epoch 85/10000\n",
      "55/55 [==============================] - 0s 988us/step - loss: 12843.4121 - val_loss: 12438.5850\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1137.48010\n",
      "Epoch 86/10000\n",
      "55/55 [==============================] - 0s 978us/step - loss: 11553.2783 - val_loss: 8548.0166\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1137.48010\n",
      "Epoch 87/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11660.2783 - val_loss: 12837.1816\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1137.48010\n",
      "Epoch 88/10000\n",
      "55/55 [==============================] - 0s 989us/step - loss: 11896.8818 - val_loss: 12389.3633\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1137.48010\n",
      "Epoch 89/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10744.2422 - val_loss: 12417.9658\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1137.48010\n",
      "Epoch 90/10000\n",
      "55/55 [==============================] - 0s 974us/step - loss: 12041.4365 - val_loss: 7709.5498\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1137.48010\n",
      "Epoch 91/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10608.5078 - val_loss: 12377.6211\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1137.48010\n",
      "Epoch 92/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11161.7119 - val_loss: 12534.9385\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1137.48010\n",
      "Epoch 93/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11707.3594 - val_loss: 11639.4238\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1137.48010\n",
      "Epoch 94/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11395.7080 - val_loss: 12328.2549\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1137.48010\n",
      "Epoch 95/10000\n",
      "55/55 [==============================] - 0s 997us/step - loss: 10668.6426 - val_loss: 11315.5713\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1137.48010\n",
      "Epoch 96/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 9580.4336 - val_loss: 6489.9082\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1137.48010\n",
      "Epoch 97/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 5945.4805 - val_loss: 2554.2966\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1137.48010\n",
      "Epoch 98/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4472.2876 - val_loss: 1683.7532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00098: val_loss did not improve from 1137.48010\n",
      "Epoch 99/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.1675 - val_loss: 1628.8380\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1137.48010\n",
      "Epoch 100/10000\n",
      "55/55 [==============================] - 0s 997us/step - loss: 4420.7979 - val_loss: 1585.4598\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1137.48010\n",
      "Epoch 101/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.2207 - val_loss: 1623.8727\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1137.48010\n",
      "Epoch 102/10000\n",
      "55/55 [==============================] - 0s 981us/step - loss: 4425.8457 - val_loss: 1629.9139\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1137.48010\n",
      "Epoch 103/10000\n",
      "55/55 [==============================] - ETA: 0s - loss: 5196.56 - 0s 1ms/step - loss: 4422.2051 - val_loss: 1570.6395\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1137.48010\n",
      "Epoch 104/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.3774 - val_loss: 1561.0586\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1137.48010\n",
      "Epoch 105/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.8887 - val_loss: 1668.4047\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1137.48010\n",
      "Epoch 106/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.4780 - val_loss: 1572.0969\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1137.48010\n",
      "Epoch 107/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.2559 - val_loss: 1644.1812\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1137.48010\n",
      "Epoch 108/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.5654 - val_loss: 1633.3884\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1137.48010\n",
      "Epoch 109/10000\n",
      "55/55 [==============================] - 0s 998us/step - loss: 4422.8911 - val_loss: 1622.6138\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1137.48010\n",
      "Epoch 110/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.8618 - val_loss: 1660.7975\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1137.48010\n",
      "Epoch 111/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4419.9204 - val_loss: 1732.1608\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1137.48010\n",
      "Epoch 112/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.3833 - val_loss: 1616.9832\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1137.48010\n",
      "Epoch 113/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.6665 - val_loss: 1601.1948\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1137.48010\n",
      "Epoch 114/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.2690 - val_loss: 1562.3175\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1137.48010\n",
      "Epoch 115/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.0752 - val_loss: 1598.5277\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1137.48010\n",
      "Epoch 1/10000\n",
      "55/55 [==============================] - 1s 3ms/step - loss: 12241.0508 - val_loss: 8858.8223\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8858.82227, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12874.3516 - val_loss: 12802.5410\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 8858.82227\n",
      "Epoch 3/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13152.0957 - val_loss: 12801.7314\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 8858.82227\n",
      "Epoch 4/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13151.3555 - val_loss: 12800.9912\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 8858.82227\n",
      "Epoch 5/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13150.4434 - val_loss: 12799.0059\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 8858.82227\n",
      "Epoch 6/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13037.7900 - val_loss: 12800.7334\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 8858.82227\n",
      "Epoch 7/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12025.5947 - val_loss: 12799.8037\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 8858.82227\n",
      "Epoch 8/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13149.2725 - val_loss: 12798.6689\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 8858.82227\n",
      "Epoch 9/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13147.9932 - val_loss: 12796.6152\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 8858.82227\n",
      "Epoch 10/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11833.8477 - val_loss: 8973.0312\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 8858.82227\n",
      "Epoch 11/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11842.6104 - val_loss: 12690.8477\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 8858.82227\n",
      "Epoch 12/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11437.6182 - val_loss: 8040.7754\n",
      "\n",
      "Epoch 00012: val_loss improved from 8858.82227 to 8040.77539, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 13/10000\n",
      "55/55 [==============================] - 0s 907us/step - loss: 11583.8887 - val_loss: 12771.2100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 8040.77539\n",
      "Epoch 14/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12982.3262 - val_loss: 12798.7842\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 8040.77539\n",
      "Epoch 15/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12869.4561 - val_loss: 12786.1709\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 8040.77539\n",
      "Epoch 16/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12948.5889 - val_loss: 12801.5576\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 8040.77539\n",
      "Epoch 17/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11087.0615 - val_loss: 9241.8018\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 8040.77539\n",
      "Epoch 18/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12370.2051 - val_loss: 12586.5566\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 8040.77539\n",
      "Epoch 19/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13084.1836 - val_loss: 12775.4385\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 8040.77539\n",
      "Epoch 20/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12437.4102 - val_loss: 12790.6113\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 8040.77539\n",
      "Epoch 21/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12637.1387 - val_loss: 16243.1016\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 8040.77539\n",
      "Epoch 22/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12414.8447 - val_loss: 12791.9736\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 8040.77539\n",
      "Epoch 23/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12473.7881 - val_loss: 12788.9053\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 8040.77539\n",
      "Epoch 24/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12552.5488 - val_loss: 12706.8760\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 8040.77539\n",
      "Epoch 25/10000\n",
      "55/55 [==============================] - 0s 986us/step - loss: 12363.5635 - val_loss: 12777.9229\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 8040.77539\n",
      "Epoch 26/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12667.9932 - val_loss: 12757.8555\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 8040.77539\n",
      "Epoch 27/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12299.2695 - val_loss: 12685.2471\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 8040.77539\n",
      "Epoch 28/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11328.6562 - val_loss: 12726.5625\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 8040.77539\n",
      "Epoch 29/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12884.5820 - val_loss: 12686.9258\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 8040.77539\n",
      "Epoch 30/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12565.7783 - val_loss: 5962.7559\n",
      "\n",
      "Epoch 00030: val_loss improved from 8040.77539 to 5962.75586, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 31/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12141.9941 - val_loss: 12834.6064\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 5962.75586\n",
      "Epoch 32/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12204.5957 - val_loss: 12797.5596\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 5962.75586\n",
      "Epoch 33/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13027.0146 - val_loss: 12783.5127\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 5962.75586\n",
      "Epoch 34/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11516.8838 - val_loss: 14588.5127\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 5962.75586\n",
      "Epoch 35/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12065.1182 - val_loss: 12382.4678\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 5962.75586\n",
      "Epoch 36/10000\n",
      "55/55 [==============================] - 0s 979us/step - loss: 11599.5840 - val_loss: 12776.2266\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 5962.75586\n",
      "Epoch 37/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11530.4570 - val_loss: 12777.3984\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 5962.75586\n",
      "Epoch 38/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12299.7295 - val_loss: 12771.3789\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 5962.75586\n",
      "Epoch 39/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12179.5928 - val_loss: 12750.2939\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 5962.75586\n",
      "Epoch 40/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11928.9307 - val_loss: 12766.9150\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 5962.75586\n",
      "Epoch 41/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12174.2090 - val_loss: 12580.3613\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 5962.75586\n",
      "Epoch 42/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12043.4209 - val_loss: 12801.5820\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 5962.75586\n",
      "Epoch 43/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12134.5771 - val_loss: 12590.2803\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 5962.75586\n",
      "Epoch 44/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11868.9258 - val_loss: 12691.6562\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 5962.75586\n",
      "Epoch 45/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11605.9678 - val_loss: 2043.8328\n",
      "\n",
      "Epoch 00045: val_loss improved from 5962.75586 to 2043.83276, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 46/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10107.9561 - val_loss: 12737.0898\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2043.83276\n",
      "Epoch 47/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12831.9590 - val_loss: 12818.2529\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2043.83276\n",
      "Epoch 48/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10889.2432 - val_loss: 12665.4775\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2043.83276\n",
      "Epoch 49/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12394.5557 - val_loss: 12688.5586\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2043.83276\n",
      "Epoch 50/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12825.8496 - val_loss: 12123.8320\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2043.83276\n",
      "Epoch 51/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11988.1387 - val_loss: 11248.5527\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2043.83276\n",
      "Epoch 52/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10320.7822 - val_loss: 8039.5923\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2043.83276\n",
      "Epoch 53/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 6047.9863 - val_loss: 2840.8103\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2043.83276\n",
      "Epoch 54/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4485.6689 - val_loss: 1653.6774\n",
      "\n",
      "Epoch 00054: val_loss improved from 2043.83276 to 1653.67737, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 55/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.3730 - val_loss: 1594.7028\n",
      "\n",
      "Epoch 00055: val_loss improved from 1653.67737 to 1594.70276, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 56/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4427.7969 - val_loss: 1629.9507\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1594.70276\n",
      "Epoch 57/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.0796 - val_loss: 1685.7773\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1594.70276\n",
      "Epoch 58/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.8027 - val_loss: 1630.0294\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1594.70276\n",
      "Epoch 59/10000\n",
      "55/55 [==============================] - 0s 990us/step - loss: 4424.4438 - val_loss: 1656.0898\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1594.70276\n",
      "Epoch 60/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.0459 - val_loss: 1548.1935\n",
      "\n",
      "Epoch 00060: val_loss improved from 1594.70276 to 1548.19348, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 61/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.0635 - val_loss: 1611.4750\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1548.19348\n",
      "Epoch 62/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4418.3477 - val_loss: 1574.9727\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1548.19348\n",
      "Epoch 63/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.1377 - val_loss: 1668.1490\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1548.19348\n",
      "Epoch 64/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.3135 - val_loss: 1614.8114\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1548.19348\n",
      "Epoch 65/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.0522 - val_loss: 1582.0900\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1548.19348\n",
      "Epoch 66/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.0171 - val_loss: 1606.7114\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1548.19348\n",
      "Epoch 67/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.9629 - val_loss: 1643.9883\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1548.19348\n",
      "Epoch 68/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.6074 - val_loss: 1601.3612\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1548.19348\n",
      "Epoch 69/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.5454 - val_loss: 1625.5966\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1548.19348\n",
      "Epoch 70/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.2227 - val_loss: 1590.7383\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1548.19348\n",
      "Epoch 71/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.4663 - val_loss: 1563.5793\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1548.19348\n",
      "Epoch 72/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.7485 - val_loss: 1664.1134\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1548.19348\n",
      "Epoch 73/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.2358 - val_loss: 1563.4922\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1548.19348\n",
      "Epoch 74/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4428.3999 - val_loss: 1599.2086\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1548.19348\n",
      "Epoch 75/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.9097 - val_loss: 1604.0309\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1548.19348\n",
      "Epoch 76/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.4561 - val_loss: 1670.4426\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1548.19348\n",
      "Epoch 77/10000\n",
      "55/55 [==============================] - 0s 972us/step - loss: 4419.4507 - val_loss: 1680.3258\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1548.19348\n",
      "Epoch 78/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.8638 - val_loss: 1717.8660\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1548.19348\n",
      "Epoch 79/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.8628 - val_loss: 1597.5353\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1548.19348\n",
      "Epoch 80/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.7227 - val_loss: 1607.8667\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1548.19348\n",
      "Epoch 81/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.9248 - val_loss: 1621.8376\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1548.19348\n",
      "Epoch 82/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.1768 - val_loss: 1634.4376\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1548.19348\n",
      "Epoch 83/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.8931 - val_loss: 1652.7711\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1548.19348\n",
      "Epoch 84/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.8110 - val_loss: 1646.8512\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1548.19348\n",
      "Epoch 85/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.5854 - val_loss: 1602.7852\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1548.19348\n",
      "Epoch 86/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.2603 - val_loss: 1634.8387\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1548.19348\n",
      "Epoch 87/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.2090 - val_loss: 1624.5469\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1548.19348\n",
      "Epoch 88/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.8218 - val_loss: 1637.4882\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1548.19348\n",
      "Epoch 89/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.7656 - val_loss: 1585.9263\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1548.19348\n",
      "Epoch 90/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.0366 - val_loss: 1594.4442\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1548.19348\n",
      "Epoch 91/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.5894 - val_loss: 1608.8489\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1548.19348\n",
      "Epoch 92/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.6548 - val_loss: 1682.6787\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1548.19348\n",
      "Epoch 93/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.4961 - val_loss: 1605.5151\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1548.19348\n",
      "Epoch 94/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.8374 - val_loss: 1629.7382\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1548.19348\n",
      "Epoch 95/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.8198 - val_loss: 1561.8104\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1548.19348\n",
      "Epoch 96/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.6138 - val_loss: 1629.5319\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1548.19348\n",
      "Epoch 97/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.7139 - val_loss: 1645.9022\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1548.19348\n",
      "Epoch 98/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.2974 - val_loss: 1580.6936\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1548.19348\n",
      "Epoch 99/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.1157 - val_loss: 1558.5878\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1548.19348\n",
      "Epoch 100/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.0591 - val_loss: 1613.6633\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1548.19348\n",
      "Epoch 101/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.1758 - val_loss: 1564.7866\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1548.19348\n",
      "Epoch 102/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.9556 - val_loss: 1595.2443\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1548.19348\n",
      "Epoch 103/10000\n",
      "55/55 [==============================] - 0s 996us/step - loss: 4424.0161 - val_loss: 1644.2700\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1548.19348\n",
      "Epoch 104/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.6353 - val_loss: 1628.3794\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1548.19348\n",
      "Epoch 105/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.9009 - val_loss: 1663.0054\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1548.19348\n",
      "Epoch 106/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.4775 - val_loss: 1589.0863\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1548.19348\n",
      "Epoch 107/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.7280 - val_loss: 1583.4083\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1548.19348\n",
      "Epoch 108/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.7827 - val_loss: 1611.4823\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1548.19348\n",
      "Epoch 109/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.9126 - val_loss: 1627.9747\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1548.19348\n",
      "Epoch 110/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.2915 - val_loss: 1686.2822\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1548.19348\n",
      "Epoch 111/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.2217 - val_loss: 1653.2874\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1548.19348\n",
      "Epoch 112/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.9204 - val_loss: 1590.7350\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1548.19348\n",
      "Epoch 113/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.4551 - val_loss: 1606.6290\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1548.19348\n",
      "Epoch 114/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.3921 - val_loss: 1639.2797\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1548.19348\n",
      "Epoch 115/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.7910 - val_loss: 1657.5361\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1548.19348\n",
      "Epoch 116/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.3403 - val_loss: 1584.1586\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1548.19348\n",
      "Epoch 117/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.6372 - val_loss: 1624.1658\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1548.19348\n",
      "Epoch 118/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.9697 - val_loss: 1591.6223\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1548.19348\n",
      "Epoch 119/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.9287 - val_loss: 1603.4146\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1548.19348\n",
      "Epoch 120/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.2524 - val_loss: 1665.1378\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1548.19348\n",
      "Epoch 121/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.2817 - val_loss: 1673.9425\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1548.19348\n",
      "Epoch 122/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.3608 - val_loss: 1676.7205\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1548.19348\n",
      "Epoch 123/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4427.0693 - val_loss: 1651.8434\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1548.19348\n",
      "Epoch 124/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.6221 - val_loss: 1619.5977\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1548.19348\n",
      "Epoch 125/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.9126 - val_loss: 1614.1051\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1548.19348\n",
      "Epoch 126/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4417.7954 - val_loss: 1583.5217\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1548.19348\n",
      "Epoch 127/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.4243 - val_loss: 1527.0647\n",
      "\n",
      "Epoch 00127: val_loss improved from 1548.19348 to 1527.06470, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 128/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.8716 - val_loss: 1630.4680\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1527.06470\n",
      "Epoch 129/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.4097 - val_loss: 1638.7605\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1527.06470\n",
      "Epoch 130/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.7666 - val_loss: 1655.1648\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1527.06470\n",
      "Epoch 131/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.0635 - val_loss: 1655.2710\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1527.06470\n",
      "Epoch 132/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.9951 - val_loss: 1628.8594\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1527.06470\n",
      "Epoch 133/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4419.4185 - val_loss: 1563.4225\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1527.06470\n",
      "Epoch 134/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.4106 - val_loss: 1604.3157\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1527.06470\n",
      "Epoch 135/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.1851 - val_loss: 1621.0665\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1527.06470\n",
      "Epoch 136/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.1274 - val_loss: 1583.8086\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1527.06470\n",
      "Epoch 137/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4427.0693 - val_loss: 1629.4906\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1527.06470\n",
      "Epoch 138/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4417.8501 - val_loss: 1576.7992\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1527.06470\n",
      "Epoch 139/10000\n",
      "55/55 [==============================] - 0s 995us/step - loss: 4424.8887 - val_loss: 1603.5771\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1527.06470\n",
      "Epoch 140/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 4425.8916 - val_loss: 1603.7065\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1527.06470\n",
      "Epoch 141/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 4422.3853 - val_loss: 1638.4517\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1527.06470\n",
      "Epoch 142/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.3423 - val_loss: 1591.6553\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1527.06470\n",
      "Epoch 143/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.0732 - val_loss: 1652.9598\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1527.06470\n",
      "Epoch 144/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.8203 - val_loss: 1619.5778\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1527.06470\n",
      "Epoch 145/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.8438 - val_loss: 1640.5562\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1527.06470\n",
      "Epoch 146/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.9351 - val_loss: 1642.8182\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1527.06470\n",
      "Epoch 147/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 4420.7290 - val_loss: 1699.2025\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1527.06470\n",
      "Epoch 148/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.8457 - val_loss: 1670.1991\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1527.06470\n",
      "Epoch 149/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.1040 - val_loss: 1633.6633\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1527.06470\n",
      "Epoch 150/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.7314 - val_loss: 1630.3087\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1527.06470\n",
      "Epoch 151/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.8818 - val_loss: 1594.1647\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1527.06470\n",
      "Epoch 152/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.7236 - val_loss: 1651.1650\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1527.06470\n",
      "Epoch 153/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.8486 - val_loss: 1607.1708\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1527.06470\n",
      "Epoch 154/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.7441 - val_loss: 1652.0039\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1527.06470\n",
      "Epoch 155/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.8154 - val_loss: 1625.4357\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1527.06470\n",
      "Epoch 156/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.7363 - val_loss: 1653.9990\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1527.06470\n",
      "Epoch 157/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.3535 - val_loss: 1624.1256\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1527.06470\n",
      "Epoch 158/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.7173 - val_loss: 1655.6650\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1527.06470\n",
      "Epoch 159/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.4482 - val_loss: 1612.7515\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1527.06470\n",
      "Epoch 160/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.8950 - val_loss: 1653.2053\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1527.06470\n",
      "Epoch 161/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.5308 - val_loss: 1594.0411\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1527.06470\n",
      "Epoch 162/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.1040 - val_loss: 1599.4508\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1527.06470\n",
      "Epoch 163/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.9878 - val_loss: 1574.6882\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1527.06470\n",
      "Epoch 164/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.7480 - val_loss: 1644.1655\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1527.06470\n",
      "Epoch 165/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.8179 - val_loss: 1627.7920\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1527.06470\n",
      "Epoch 166/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.6455 - val_loss: 1584.5579\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1527.06470\n",
      "Epoch 167/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.5029 - val_loss: 1669.6389\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1527.06470\n",
      "Epoch 168/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.8560 - val_loss: 1631.0765\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1527.06470\n",
      "Epoch 169/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.0107 - val_loss: 1598.4615\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1527.06470\n",
      "Epoch 170/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.8784 - val_loss: 1577.2841\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1527.06470\n",
      "Epoch 171/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.5249 - val_loss: 1597.3237\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1527.06470\n",
      "Epoch 172/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.5493 - val_loss: 1605.3328\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1527.06470\n",
      "Epoch 173/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.3125 - val_loss: 1639.9075\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1527.06470\n",
      "Epoch 174/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.3027 - val_loss: 1576.8845\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1527.06470\n",
      "Epoch 175/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.2852 - val_loss: 1627.9302\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1527.06470\n",
      "Epoch 176/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.0630 - val_loss: 1692.2688\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1527.06470\n",
      "Epoch 177/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4416.5078 - val_loss: 1536.3519\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1527.06470\n",
      "Epoch 178/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4419.4883 - val_loss: 1684.9653\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1527.06470\n",
      "Epoch 179/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.7998 - val_loss: 1627.0609\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1527.06470\n",
      "Epoch 180/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.2124 - val_loss: 1622.6389\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1527.06470\n",
      "Epoch 181/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.1377 - val_loss: 1579.5707\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1527.06470\n",
      "Epoch 182/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4427.9795 - val_loss: 1631.1709\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1527.06470\n",
      "Epoch 183/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.1162 - val_loss: 1590.5178\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1527.06470\n",
      "Epoch 184/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.7832 - val_loss: 1576.7478\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1527.06470\n",
      "Epoch 185/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.6777 - val_loss: 1590.7063\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1527.06470\n",
      "Epoch 186/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.0371 - val_loss: 1596.3361\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1527.06470\n",
      "Epoch 187/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.0356 - val_loss: 1612.4968\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1527.06470\n",
      "Epoch 188/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.8408 - val_loss: 1666.7885\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1527.06470\n",
      "Epoch 189/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.6250 - val_loss: 1571.6655\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1527.06470\n",
      "Epoch 190/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.3340 - val_loss: 1610.2909\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1527.06470\n",
      "Epoch 191/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.8862 - val_loss: 1634.7584\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1527.06470\n",
      "Epoch 192/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.8062 - val_loss: 1594.0173\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1527.06470\n",
      "Epoch 193/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.5405 - val_loss: 1623.9700\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1527.06470\n",
      "Epoch 194/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.5469 - val_loss: 1597.3962\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1527.06470\n",
      "Epoch 195/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.3379 - val_loss: 1668.2942\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1527.06470\n",
      "Epoch 196/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.9053 - val_loss: 1741.5713\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1527.06470\n",
      "Epoch 197/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.3862 - val_loss: 1630.8895\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1527.06470\n",
      "Epoch 198/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.9160 - val_loss: 1587.7688\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 1527.06470\n",
      "Epoch 199/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.1382 - val_loss: 1628.5200\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 1527.06470\n",
      "Epoch 200/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.4380 - val_loss: 1609.7512\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1527.06470\n",
      "Epoch 201/10000\n",
      "55/55 [==============================] - ETA: 0s - loss: 4415.22 - 0s 1ms/step - loss: 4424.7754 - val_loss: 1601.6846\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 1527.06470\n",
      "Epoch 202/10000\n",
      "55/55 [==============================] - 0s 991us/step - loss: 4422.9531 - val_loss: 1579.3622\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 1527.06470\n",
      "Epoch 203/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.3203 - val_loss: 1618.2325\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1527.06470\n",
      "Epoch 204/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.0479 - val_loss: 1644.7744\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1527.06470\n",
      "Epoch 205/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.3940 - val_loss: 1654.5302\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 1527.06470\n",
      "Epoch 206/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.3657 - val_loss: 1583.3788\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1527.06470\n",
      "Epoch 207/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.6055 - val_loss: 1574.9297\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 1527.06470\n",
      "Epoch 208/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.8726 - val_loss: 1654.1127\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1527.06470\n",
      "Epoch 209/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 4423.8135 - val_loss: 1688.7344\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1527.06470\n",
      "Epoch 210/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 4424.2568 - val_loss: 1626.2349\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1527.06470\n",
      "Epoch 211/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.9038 - val_loss: 1645.0668\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1527.06470\n",
      "Epoch 212/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.6484 - val_loss: 1654.4602\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 1527.06470\n",
      "Epoch 213/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 4425.0044 - val_loss: 1668.7546\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 1527.06470\n",
      "Epoch 214/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.9775 - val_loss: 1674.5032\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 1527.06470\n",
      "Epoch 215/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.0190 - val_loss: 1639.5162\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1527.06470\n",
      "Epoch 216/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4416.6392 - val_loss: 1531.2582\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 1527.06470\n",
      "Epoch 217/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.7373 - val_loss: 1596.6667\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 1527.06470\n",
      "Epoch 218/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.2300 - val_loss: 1666.9597\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 1527.06470\n",
      "Epoch 219/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.6938 - val_loss: 1648.7544\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 1527.06470\n",
      "Epoch 220/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.9941 - val_loss: 1647.8254\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 1527.06470\n",
      "Epoch 221/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.8516 - val_loss: 1637.1238\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 1527.06470\n",
      "Epoch 222/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4427.9390 - val_loss: 1592.4565\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 1527.06470\n",
      "Epoch 223/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.7944 - val_loss: 1627.1659\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 1527.06470\n",
      "Epoch 224/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.2363 - val_loss: 1623.6547\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 1527.06470\n",
      "Epoch 225/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.7676 - val_loss: 1558.0685\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 1527.06470\n",
      "Epoch 226/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.0742 - val_loss: 1704.5100\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 1527.06470\n",
      "Epoch 227/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4414.9395 - val_loss: 1527.4946\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 1527.06470\n",
      "Epoch 1/10000\n",
      "55/55 [==============================] - 1s 3ms/step - loss: 13151.4893 - val_loss: 12780.1738\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 12780.17383, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 2/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12887.0918 - val_loss: 12802.9492\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 12780.17383\n",
      "Epoch 3/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12858.4102 - val_loss: 2014.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 12780.17383 to 2014.82458, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 4/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12951.1963 - val_loss: 12801.0977\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2014.82458\n",
      "Epoch 5/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13150.6016 - val_loss: 12800.0342\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2014.82458\n",
      "Epoch 6/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13149.2041 - val_loss: 12798.2383\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2014.82458\n",
      "Epoch 7/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12990.7197 - val_loss: 12703.0859\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2014.82458\n",
      "Epoch 8/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11860.4355 - val_loss: 12792.9609\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2014.82458\n",
      "Epoch 9/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12442.2090 - val_loss: 6921.2061\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2014.82458\n",
      "Epoch 10/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11045.6494 - val_loss: 12800.5273\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2014.82458\n",
      "Epoch 11/10000\n",
      "55/55 [==============================] - 0s 992us/step - loss: 13003.3965 - val_loss: 1943.7834\n",
      "\n",
      "Epoch 00011: val_loss improved from 2014.82458 to 1943.78345, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 12/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12191.6689 - val_loss: 6074.9839\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1943.78345\n",
      "Epoch 13/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12467.1396 - val_loss: 3082.2029\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1943.78345\n",
      "Epoch 14/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12859.0059 - val_loss: 12775.3271\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1943.78345\n",
      "Epoch 15/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11623.4922 - val_loss: 7961.9150\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1943.78345\n",
      "Epoch 16/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11667.8779 - val_loss: 12613.5859\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1943.78345\n",
      "Epoch 17/10000\n",
      "55/55 [==============================] - ETA: 0s - loss: 11436.063 - 0s 1ms/step - loss: 11558.5908 - val_loss: 12794.8535\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1943.78345\n",
      "Epoch 18/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12751.9893 - val_loss: 12784.3086\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1943.78345\n",
      "Epoch 19/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11072.4854 - val_loss: 12796.9326\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1943.78345\n",
      "Epoch 20/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13140.5273 - val_loss: 12777.0127\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1943.78345\n",
      "Epoch 21/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10840.1270 - val_loss: 12808.2471\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1943.78345\n",
      "Epoch 22/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12725.3574 - val_loss: 1613.8838\n",
      "\n",
      "Epoch 00022: val_loss improved from 1943.78345 to 1613.88379, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 23/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12116.8115 - val_loss: 12768.3271\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1613.88379\n",
      "Epoch 24/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12332.9912 - val_loss: 12776.2002\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1613.88379\n",
      "Epoch 25/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12961.4209 - val_loss: 12742.5361\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1613.88379\n",
      "Epoch 26/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10796.5615 - val_loss: 12775.7861\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1613.88379\n",
      "Epoch 27/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12645.0781 - val_loss: 12779.0820\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1613.88379\n",
      "Epoch 28/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12794.7236 - val_loss: 12818.6611\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1613.88379\n",
      "Epoch 29/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11302.1855 - val_loss: 12762.3623\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1613.88379\n",
      "Epoch 30/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12087.1768 - val_loss: 12764.9629\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1613.88379\n",
      "Epoch 31/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12233.7842 - val_loss: 9991.1328\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1613.88379\n",
      "Epoch 32/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12089.6533 - val_loss: 12711.7988\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1613.88379\n",
      "Epoch 33/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11547.0244 - val_loss: 9533.2910\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1613.88379\n",
      "Epoch 34/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12613.0254 - val_loss: 12701.2510\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1613.88379\n",
      "Epoch 35/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 12212.8604 - val_loss: 12708.3467\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1613.88379\n",
      "Epoch 36/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11403.8174 - val_loss: 11071.0000\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1613.88379\n",
      "Epoch 37/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 12557.4629 - val_loss: 12760.6172\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1613.88379\n",
      "Epoch 38/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 11669.8408 - val_loss: 12779.9805\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1613.88379\n",
      "Epoch 39/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 12438.3721 - val_loss: 12896.5322\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1613.88379\n",
      "Epoch 40/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11739.3848 - val_loss: 12765.5615\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1613.88379\n",
      "Epoch 41/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10486.0342 - val_loss: 5186.7759\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1613.88379\n",
      "Epoch 42/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11981.7510 - val_loss: 12604.8213\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1613.88379\n",
      "Epoch 43/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11956.5537 - val_loss: 12501.9688\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1613.88379\n",
      "Epoch 44/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12039.7598 - val_loss: 12861.9121\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1613.88379\n",
      "Epoch 45/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11758.7705 - val_loss: 12599.2148\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1613.88379\n",
      "Epoch 46/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12388.9189 - val_loss: 12600.7666\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1613.88379\n",
      "Epoch 47/10000\n",
      "55/55 [==============================] - 0s 983us/step - loss: 11978.7900 - val_loss: 12186.5049\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1613.88379\n",
      "Epoch 48/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12060.9531 - val_loss: 11407.8379\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1613.88379\n",
      "Epoch 49/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10440.5098 - val_loss: 8137.0674\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1613.88379\n",
      "Epoch 50/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 6075.4048 - val_loss: 2818.7068\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1613.88379\n",
      "Epoch 51/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4492.0830 - val_loss: 1667.1667\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1613.88379\n",
      "Epoch 52/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.3394 - val_loss: 1606.5728\n",
      "\n",
      "Epoch 00052: val_loss improved from 1613.88379 to 1606.57275, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 53/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.5190 - val_loss: 1579.3805\n",
      "\n",
      "Epoch 00053: val_loss improved from 1606.57275 to 1579.38049, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 54/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.0176 - val_loss: 1716.1748\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1579.38049\n",
      "Epoch 55/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.8589 - val_loss: 1654.1556\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1579.38049\n",
      "Epoch 56/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.7832 - val_loss: 1691.5624\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1579.38049\n",
      "Epoch 57/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4426.4316 - val_loss: 1653.0284\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1579.38049\n",
      "Epoch 58/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.9878 - val_loss: 1633.6294\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1579.38049\n",
      "Epoch 59/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.5156 - val_loss: 1605.4125\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1579.38049\n",
      "Epoch 60/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.1426 - val_loss: 1591.3945\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1579.38049\n",
      "Epoch 61/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.1528 - val_loss: 1678.4719\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1579.38049\n",
      "Epoch 62/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.3677 - val_loss: 1655.2378\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1579.38049\n",
      "Epoch 63/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.6050 - val_loss: 1625.3938\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1579.38049\n",
      "Epoch 64/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.1260 - val_loss: 1662.8519\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1579.38049\n",
      "Epoch 65/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4423.7852 - val_loss: 1605.3442\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1579.38049\n",
      "Epoch 66/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.2827 - val_loss: 1717.9114\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1579.38049\n",
      "Epoch 67/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.3027 - val_loss: 1634.4558\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1579.38049\n",
      "Epoch 68/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.7495 - val_loss: 1659.0778\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1579.38049\n",
      "Epoch 69/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.1523 - val_loss: 1642.6903\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1579.38049\n",
      "Epoch 70/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.2866 - val_loss: 1628.6896\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1579.38049\n",
      "Epoch 71/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.1802 - val_loss: 1585.6630\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1579.38049\n",
      "Epoch 72/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4466.6509 - val_loss: 1664.4359\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1579.38049\n",
      "Epoch 73/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4427.8828 - val_loss: 1603.7294\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1579.38049\n",
      "Epoch 74/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4422.5073 - val_loss: 1638.4608\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1579.38049\n",
      "Epoch 75/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4415.9438 - val_loss: 1698.3079\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1579.38049\n",
      "Epoch 76/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4413.5649 - val_loss: 1767.1190\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1579.38049\n",
      "Epoch 77/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4404.9272 - val_loss: 1607.2797\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1579.38049\n",
      "Epoch 78/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4395.2988 - val_loss: 1626.0018\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1579.38049\n",
      "Epoch 79/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4429.7202 - val_loss: 1617.6514\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1579.38049\n",
      "Epoch 80/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4431.6914 - val_loss: 1656.2003\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1579.38049\n",
      "Epoch 81/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4430.3823 - val_loss: 1660.1490\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1579.38049\n",
      "Epoch 82/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4430.5088 - val_loss: 1612.2297\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1579.38049\n",
      "Epoch 83/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4428.7383 - val_loss: 1620.9197\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1579.38049\n",
      "Epoch 84/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.1304 - val_loss: 1625.6715\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1579.38049\n",
      "Epoch 85/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.8145 - val_loss: 1631.8165\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1579.38049\n",
      "Epoch 86/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.4883 - val_loss: 1588.6851\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1579.38049\n",
      "Epoch 87/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4427.6953 - val_loss: 1572.6334\n",
      "\n",
      "Epoch 00087: val_loss improved from 1579.38049 to 1572.63342, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 88/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4425.8242 - val_loss: 1659.4084\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1572.63342\n",
      "Epoch 89/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.3032 - val_loss: 1614.4587\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1572.63342\n",
      "Epoch 90/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4424.9189 - val_loss: 1600.4855\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1572.63342\n",
      "Epoch 91/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4416.7856 - val_loss: 1636.4363\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1572.63342\n",
      "Epoch 92/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4421.4668 - val_loss: 1673.2600\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1572.63342\n",
      "Epoch 93/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4415.6426 - val_loss: 1615.8333\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1572.63342\n",
      "Epoch 94/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4412.0698 - val_loss: 1551.4797\n",
      "\n",
      "Epoch 00094: val_loss improved from 1572.63342 to 1551.47974, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 95/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4414.0498 - val_loss: 1663.8291\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1551.47974\n",
      "Epoch 96/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4399.5205 - val_loss: 1636.2482\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1551.47974\n",
      "Epoch 97/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4396.3628 - val_loss: 1702.4945\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1551.47974\n",
      "Epoch 98/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4406.3921 - val_loss: 1557.8408\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1551.47974\n",
      "Epoch 99/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4405.2070 - val_loss: 1654.4772\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1551.47974\n",
      "Epoch 100/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4404.8896 - val_loss: 1604.7347\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1551.47974\n",
      "Epoch 101/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 4407.6348 - val_loss: 1616.0863\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1551.47974\n",
      "Epoch 102/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4396.2305 - val_loss: 1633.6527\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1551.47974\n",
      "Epoch 103/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4398.2314 - val_loss: 1660.6238\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1551.47974\n",
      "Epoch 104/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4396.7124 - val_loss: 1649.6039\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1551.47974\n",
      "Epoch 105/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4384.6533 - val_loss: 1599.1154\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1551.47974\n",
      "Epoch 106/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4397.4102 - val_loss: 1536.3778\n",
      "\n",
      "Epoch 00106: val_loss improved from 1551.47974 to 1536.37781, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 107/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4405.9976 - val_loss: 1548.2456\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1536.37781\n",
      "Epoch 108/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4379.1006 - val_loss: 1574.6497\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1536.37781\n",
      "Epoch 109/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4388.9995 - val_loss: 1595.1067\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1536.37781\n",
      "Epoch 110/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4384.1040 - val_loss: 1602.9515\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1536.37781\n",
      "Epoch 111/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4384.9043 - val_loss: 1545.7640\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1536.37781\n",
      "Epoch 112/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4389.8003 - val_loss: 1566.3313\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1536.37781\n",
      "Epoch 113/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4388.7603 - val_loss: 1594.3627\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1536.37781\n",
      "Epoch 114/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4375.4072 - val_loss: 1598.7406\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1536.37781\n",
      "Epoch 115/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4391.0347 - val_loss: 1609.9253\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1536.37781\n",
      "Epoch 116/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4378.9463 - val_loss: 1638.5319\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1536.37781\n",
      "Epoch 117/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4374.8018 - val_loss: 1603.6121\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1536.37781\n",
      "Epoch 118/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4376.8379 - val_loss: 1634.7114\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1536.37781\n",
      "Epoch 119/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4378.4438 - val_loss: 1575.7550\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1536.37781\n",
      "Epoch 120/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4376.6953 - val_loss: 1542.2087\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1536.37781\n",
      "Epoch 121/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4428.3589 - val_loss: 1642.6586\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1536.37781\n",
      "Epoch 122/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4420.6357 - val_loss: 1587.5139\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1536.37781\n",
      "Epoch 123/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4405.6274 - val_loss: 1599.2611\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1536.37781\n",
      "Epoch 124/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4371.4858 - val_loss: 1628.4133\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1536.37781\n",
      "Epoch 125/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4371.0869 - val_loss: 1673.0597\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1536.37781\n",
      "Epoch 126/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4378.7329 - val_loss: 1608.5376\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1536.37781\n",
      "Epoch 127/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4382.7295 - val_loss: 1605.8746\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1536.37781\n",
      "Epoch 128/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4374.3096 - val_loss: 1599.1737\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1536.37781\n",
      "Epoch 129/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4384.6572 - val_loss: 1592.0398\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1536.37781\n",
      "Epoch 130/10000\n",
      "55/55 [==============================] - 0s 997us/step - loss: 4366.0820 - val_loss: 1581.1116\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1536.37781\n",
      "Epoch 131/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4368.8291 - val_loss: 1590.9301\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1536.37781\n",
      "Epoch 132/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4365.0054 - val_loss: 1535.8804\n",
      "\n",
      "Epoch 00132: val_loss improved from 1536.37781 to 1535.88037, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 133/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4351.9380 - val_loss: 1591.6552\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1535.88037\n",
      "Epoch 134/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4369.0664 - val_loss: 1590.0657\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1535.88037\n",
      "Epoch 135/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4368.0083 - val_loss: 1579.5900\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1535.88037\n",
      "Epoch 136/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4363.3193 - val_loss: 1671.0406\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1535.88037\n",
      "Epoch 137/10000\n",
      "55/55 [==============================] - 0s 991us/step - loss: 4366.5171 - val_loss: 1618.8363\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1535.88037\n",
      "Epoch 138/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4364.4487 - val_loss: 1623.2284\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1535.88037\n",
      "Epoch 139/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4358.3813 - val_loss: 1540.1019\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1535.88037\n",
      "Epoch 140/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4413.5747 - val_loss: 1524.4553\n",
      "\n",
      "Epoch 00140: val_loss improved from 1535.88037 to 1524.45532, saving model to model\\tmp_checkpoint1.h5\n",
      "Epoch 141/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4367.9683 - val_loss: 1621.9313\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1524.45532\n",
      "Epoch 142/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4357.0005 - val_loss: 1604.1196\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1524.45532\n",
      "Epoch 143/10000\n",
      "55/55 [==============================] - 0s 997us/step - loss: 4365.5386 - val_loss: 1631.8606\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1524.45532\n",
      "Epoch 144/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4361.1348 - val_loss: 1607.1748\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1524.45532\n",
      "Epoch 145/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4380.5186 - val_loss: 1577.8135\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1524.45532\n",
      "Epoch 146/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4359.1680 - val_loss: 1617.3634\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1524.45532\n",
      "Epoch 147/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4358.1606 - val_loss: 1624.6003\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1524.45532\n",
      "Epoch 148/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4363.2412 - val_loss: 1591.1316\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1524.45532\n",
      "Epoch 149/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4348.2544 - val_loss: 1639.9934\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1524.45532\n",
      "Epoch 150/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4360.4824 - val_loss: 1539.9235\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1524.45532\n",
      "Epoch 151/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4359.3291 - val_loss: 1541.9025\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1524.45532\n",
      "Epoch 152/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4360.3521 - val_loss: 1606.1050\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1524.45532\n",
      "Epoch 153/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4370.0791 - val_loss: 1617.0255\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1524.45532\n",
      "Epoch 154/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4358.9922 - val_loss: 1652.9738\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1524.45532\n",
      "Epoch 155/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4362.5601 - val_loss: 1652.0741\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1524.45532\n",
      "Epoch 156/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4347.9243 - val_loss: 1649.6787\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1524.45532\n",
      "Epoch 157/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4339.3901 - val_loss: 1562.9122\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1524.45532\n",
      "Epoch 158/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4346.2095 - val_loss: 1546.2426\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1524.45532\n",
      "Epoch 159/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4351.8555 - val_loss: 1618.3085\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1524.45532\n",
      "Epoch 160/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4342.1597 - val_loss: 1588.4359\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1524.45532\n",
      "Epoch 161/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4390.8687 - val_loss: 1608.1453\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1524.45532\n",
      "Epoch 162/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4356.8896 - val_loss: 1665.9056\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1524.45532\n",
      "Epoch 163/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4355.5752 - val_loss: 1638.1779\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1524.45532\n",
      "Epoch 164/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4338.1411 - val_loss: 1663.6913\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1524.45532\n",
      "Epoch 165/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4347.8994 - val_loss: 1610.8236\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1524.45532\n",
      "Epoch 166/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4350.7266 - val_loss: 1605.4167\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1524.45532\n",
      "Epoch 167/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4351.2144 - val_loss: 1581.4760\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1524.45532\n",
      "Epoch 168/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4347.4761 - val_loss: 1578.3723\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1524.45532\n",
      "Epoch 169/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4340.9287 - val_loss: 1663.1278\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1524.45532\n",
      "Epoch 170/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4337.1484 - val_loss: 1634.5369\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1524.45532\n",
      "Epoch 171/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4355.3940 - val_loss: 1575.7875\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1524.45532\n",
      "Epoch 172/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4351.3672 - val_loss: 1543.3766\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1524.45532\n",
      "Epoch 173/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4349.0728 - val_loss: 1656.1798\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1524.45532\n",
      "Epoch 174/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4343.2104 - val_loss: 1596.7003\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1524.45532\n",
      "Epoch 175/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4335.0054 - val_loss: 1654.7372\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1524.45532\n",
      "Epoch 176/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4343.1992 - val_loss: 1623.9606\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1524.45532\n",
      "Epoch 177/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4342.7168 - val_loss: 1595.2456\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1524.45532\n",
      "Epoch 178/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4332.1255 - val_loss: 1564.0603\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1524.45532\n",
      "Epoch 179/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4345.4229 - val_loss: 1543.2191\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1524.45532\n",
      "Epoch 180/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 4356.2485 - val_loss: 1677.3024\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1524.45532\n",
      "Epoch 181/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 4339.8369 - val_loss: 1607.0045\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1524.45532\n",
      "Epoch 182/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4331.7920 - val_loss: 1565.6769\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1524.45532\n",
      "Epoch 183/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 4341.3130 - val_loss: 1594.5284\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1524.45532\n",
      "Epoch 184/10000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 4332.3540 - val_loss: 1541.8834\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1524.45532\n",
      "Epoch 185/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4347.1704 - val_loss: 1587.6003\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1524.45532\n",
      "Epoch 186/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4329.7476 - val_loss: 1642.4084\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1524.45532\n",
      "Epoch 187/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4337.8369 - val_loss: 1589.4419\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1524.45532\n",
      "Epoch 188/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4327.6753 - val_loss: 1560.0334\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1524.45532\n",
      "Epoch 189/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4337.6538 - val_loss: 1591.9550\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1524.45532\n",
      "Epoch 190/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4333.2734 - val_loss: 1576.3778\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1524.45532\n",
      "Epoch 191/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4336.1548 - val_loss: 1586.5602\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1524.45532\n",
      "Epoch 192/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4338.5850 - val_loss: 1632.9666\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1524.45532\n",
      "Epoch 193/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4341.8682 - val_loss: 1628.9821\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1524.45532\n",
      "Epoch 194/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4339.1108 - val_loss: 1599.2816\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1524.45532\n",
      "Epoch 195/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4325.4717 - val_loss: 1562.7249\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1524.45532\n",
      "Epoch 196/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4336.2266 - val_loss: 1560.8721\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1524.45532\n",
      "Epoch 197/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4340.5234 - val_loss: 1570.9359\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1524.45532\n",
      "Epoch 198/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4334.2671 - val_loss: 1535.7350\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 1524.45532\n",
      "Epoch 199/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4337.4448 - val_loss: 1589.7761\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 1524.45532\n",
      "Epoch 200/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 4337.3452 - val_loss: 1636.4816\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1524.45532\n",
      "Epoch 201/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4338.0747 - val_loss: 1561.0255\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 1524.45532\n",
      "Epoch 202/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4332.1860 - val_loss: 1539.9163\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 1524.45532\n",
      "Epoch 203/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4340.5698 - val_loss: 1623.5806\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1524.45532\n",
      "Epoch 204/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4338.9717 - val_loss: 1549.1360\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1524.45532\n",
      "Epoch 205/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4347.2231 - val_loss: 1585.3158\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 1524.45532\n",
      "Epoch 206/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4336.4204 - val_loss: 1563.6316\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1524.45532\n",
      "Epoch 207/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4332.5645 - val_loss: 1552.3704\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 1524.45532\n",
      "Epoch 208/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4338.9316 - val_loss: 1613.9670\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1524.45532\n",
      "Epoch 209/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4337.2158 - val_loss: 1579.0444\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1524.45532\n",
      "Epoch 210/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4337.5347 - val_loss: 1546.3618\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1524.45532\n",
      "Epoch 211/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4328.5093 - val_loss: 1587.6921\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1524.45532\n",
      "Epoch 212/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4329.3262 - val_loss: 1629.4330\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 1524.45532\n",
      "Epoch 213/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4340.8696 - val_loss: 1609.3506\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 1524.45532\n",
      "Epoch 214/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4332.7588 - val_loss: 1641.1763\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 1524.45532\n",
      "Epoch 215/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4331.7280 - val_loss: 1583.2428\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1524.45532\n",
      "Epoch 216/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4332.8208 - val_loss: 1600.9137\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 1524.45532\n",
      "Epoch 217/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4335.7827 - val_loss: 1590.9084\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 1524.45532\n",
      "Epoch 218/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4333.7104 - val_loss: 1592.5238\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 1524.45532\n",
      "Epoch 219/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4342.2012 - val_loss: 1647.2947\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 1524.45532\n",
      "Epoch 220/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4329.2949 - val_loss: 1624.2505\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 1524.45532\n",
      "Epoch 221/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4336.2832 - val_loss: 1560.4659\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 1524.45532\n",
      "Epoch 222/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4343.1392 - val_loss: 1593.8059\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 1524.45532\n",
      "Epoch 223/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4340.2549 - val_loss: 1617.9325\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 1524.45532\n",
      "Epoch 224/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4336.2510 - val_loss: 1617.8856\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 1524.45532\n",
      "Epoch 225/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4344.1353 - val_loss: 1647.9438\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 1524.45532\n",
      "Epoch 226/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4338.3003 - val_loss: 1600.9404\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 1524.45532\n",
      "Epoch 227/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4343.1343 - val_loss: 1614.6581\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 1524.45532\n",
      "Epoch 228/10000\n",
      "55/55 [==============================] - 0s 996us/step - loss: 4340.7051 - val_loss: 1588.2773\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 1524.45532\n",
      "Epoch 229/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4332.3438 - val_loss: 1575.1001\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 1524.45532\n",
      "Epoch 230/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4337.6187 - val_loss: 1586.3020\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 1524.45532\n",
      "Epoch 231/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4325.8516 - val_loss: 1595.2610\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 1524.45532\n",
      "Epoch 232/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4342.7876 - val_loss: 1539.5244\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 1524.45532\n",
      "Epoch 233/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4333.0859 - val_loss: 1579.8081\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 1524.45532\n",
      "Epoch 234/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4345.6089 - val_loss: 1624.9508\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 1524.45532\n",
      "Epoch 235/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4338.1611 - val_loss: 1540.8231\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 1524.45532\n",
      "Epoch 236/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4329.2197 - val_loss: 1611.1425\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 1524.45532\n",
      "Epoch 237/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4331.0000 - val_loss: 1624.3610\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 1524.45532\n",
      "Epoch 238/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4346.4424 - val_loss: 1576.0736\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 1524.45532\n",
      "Epoch 239/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4331.3247 - val_loss: 1578.2914\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 1524.45532\n",
      "Epoch 240/10000\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4334.3867 - val_loss: 1583.5060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [37:36<00:00, 107.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00240: val_loss did not improve from 1524.45532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "split = 28 #validation\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import LSTM\n",
    "\n",
    "for pum in tqdm(unique_pum + unique_kind):\n",
    "    # 품목 품종별 전처리\n",
    "    temp_df = train[['date',f'{pum}_거래량(kg)', f'{pum}_가격(원/kg)']]\n",
    "    temp_df = preprocessing1(temp_df,train, pum, 28, weather, joosan_dict, code_dict)\n",
    "    temp_df = temp_df[28:]\n",
    "    temp_df = temp_df.fillna(method ='ffill')\n",
    "    temp_df = temp_df.fillna(method ='bfill')\n",
    "    tmep_df = temp_df.dropna()\n",
    "   \n",
    "    train_df = temp_df\n",
    "    quartile_1 = train_df.quantile(0.25)\n",
    "    quartile_3 = train_df.quantile(0.75)\n",
    "    IQR = quartile_3 - quartile_1\n",
    "    condition =(train_df > (quartile_3 + 1.5 * IQR)) | (train_df < (quartile_1 - 1.5 * IQR))\n",
    "    condition = condition.any(axis=1)\n",
    "    search_df = train_df[condition]\n",
    "    a = train_df.drop(search_df.index, axis=0)\n",
    "    if(len(a) > 1000):\n",
    "        temp_df = a  \n",
    "    \n",
    "    # 주차별(1,2,4w) 학습\n",
    "    for week_num in [1,2,4] :\n",
    "        \n",
    "        x = temp_df[temp_df[f'{week_num}_week']>0].iloc[:,:-3]\n",
    "        y = temp_df[temp_df[f'{week_num}_week']>0].iloc[:][f'{week_num}_week']\n",
    "        \n",
    "        if(pum == '배추'):\n",
    "            scaler = scaler1\n",
    "        if(pum == '무'):\n",
    "            scaler = scaler2\n",
    "        if(pum == '양파'):\n",
    "            scaler = scaler3\n",
    "        if(pum == '건고추'):\n",
    "            scaler = scaler4\n",
    "        if(pum == '마늘'):\n",
    "            scaler = scaler5\n",
    "        if(pum == '대파'):\n",
    "            scaler = scaler6\n",
    "        if(pum == '얼갈이배추'):\n",
    "            scaler = scaler7\n",
    "        if(pum == '양배추'):\n",
    "            scaler = scaler8\n",
    "        if(pum == '깻잎'):\n",
    "            scaler = scaler9\n",
    "        if(pum == '시금치'):\n",
    "            scaler = scaler10\n",
    "        if(pum == '미나리'):\n",
    "            scaler = scaler11\n",
    "        if(pum == '당근'):\n",
    "            scaler = scaler12\n",
    "        if(pum == '파프리카'):\n",
    "            scaler = scaler13\n",
    "        if(pum == '새송이'):\n",
    "            scaler = scaler14\n",
    "        if(pum == '팽이버섯'):\n",
    "            scaler = scaler15\n",
    "        if(pum == '토마토'):\n",
    "            print(\"good\")\n",
    "            scaler = scaler16\n",
    "        if(pum == '청상추'):\n",
    "            scaler = scaler17\n",
    "        if(pum == '백다다기'):\n",
    "            scaler = scaler18\n",
    "        if(pum == '애호박'):\n",
    "            scaler = scaler19\n",
    "        if(pum == '캠벨얼리'):\n",
    "            scaler = scaler20\n",
    "        if(pum == '샤인마스캇'):\n",
    "            scaler = scaler21\n",
    "        \n",
    "        \n",
    "        df_scaled_x = scaler.fit_transform(x)\n",
    "        df_scaled_x = pd.DataFrame(df_scaled_x)\n",
    "        df_scaled_x.columns = temp_df.columns[:-3]\n",
    "        x = df_scaled_x\n",
    "    \n",
    "        feature_cols = x.columns\n",
    "        label_cols = [f'{week_num}_week']\n",
    "\n",
    "        # train dataset\n",
    "        train_feature, train_label = make_dataset(x, y, 1)\n",
    "\n",
    "        x_train = train_feature[:-split]\n",
    "        y_train = train_label[:-split]\n",
    "        x_valid = train_feature[-split:]\n",
    "        y_valid = train_label[-split:]\n",
    "        \n",
    "        model_dict[f'{pum}_model_{week_num}'] = Sequential()\n",
    "        model_dict[f'{pum}_model_{week_num}'].add(LSTM(16, \n",
    "               input_shape=(train_feature.shape[1],train_feature.shape[2]), \n",
    "               activation='relu', \n",
    "               return_sequences=False)\n",
    "          )\n",
    "        model_dict[f'{pum}_model_{week_num}'].add(Dense(8))\n",
    "        model_dict[f'{pum}_model_{week_num}'].add(Dense(1))\n",
    "\n",
    "        model_path = 'model'\n",
    "        model_dict[f'{pum}_model_{week_num}'].compile(loss='mean_absolute_error', optimizer='SGD')\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights = True)\n",
    "        filename = os.path.join(model_path, 'tmp_checkpoint1.h5')\n",
    "        checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "        history = model_dict[f'{pum}_model_{week_num}'].fit(x_train, y_train, \n",
    "                    epochs=10000, \n",
    "                    batch_size=16,\n",
    "                    validation_data=(x_valid, y_valid), \n",
    "                    callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbaca68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
